{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import recall_score\n",
    "from tqdm import tqdm\n",
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import learning_curve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' One v.s. All binary classification '"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" One v.s. All binary classification \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../Data_Scrape/Dataset/updated_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sp_song_id</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>...</th>\n",
       "      <th>lda_topic_11</th>\n",
       "      <th>lda_topic_12</th>\n",
       "      <th>lda_topic_13</th>\n",
       "      <th>lda_topic_14</th>\n",
       "      <th>lda_topic_15</th>\n",
       "      <th>lda_topic_16</th>\n",
       "      <th>lda_topic_17</th>\n",
       "      <th>lda_topic_18</th>\n",
       "      <th>lda_topic_19</th>\n",
       "      <th>Playlists</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6edQfeOlqbGteYixpJl3Sm</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.602</td>\n",
       "      <td>10</td>\n",
       "      <td>-8.311</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0290</td>\n",
       "      <td>0.489000</td>\n",
       "      <td>0.02440</td>\n",
       "      <td>0.3170</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.022993</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.122078</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.081108</td>\n",
       "      <td>0.386042</td>\n",
       "      <td>[165]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5Oe7wHPL4hdEXeF4AOayCi</td>\n",
       "      <td>0.322</td>\n",
       "      <td>0.990</td>\n",
       "      <td>8</td>\n",
       "      <td>-1.785</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1710</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.41700</td>\n",
       "      <td>0.0366</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.163142</td>\n",
       "      <td>0.022999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.144614</td>\n",
       "      <td>0.187207</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[79]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>6i1uWZYWabNHq2wQnoca58</td>\n",
       "      <td>0.666</td>\n",
       "      <td>0.884</td>\n",
       "      <td>9</td>\n",
       "      <td>-5.243</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0429</td>\n",
       "      <td>0.506000</td>\n",
       "      <td>0.00612</td>\n",
       "      <td>0.0408</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.582131</td>\n",
       "      <td>[15]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4BzBtS6PBreni5hNPo2hos</td>\n",
       "      <td>0.609</td>\n",
       "      <td>0.578</td>\n",
       "      <td>9</td>\n",
       "      <td>-7.081</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0414</td>\n",
       "      <td>0.296000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.511716</td>\n",
       "      <td>0.084905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.115004</td>\n",
       "      <td>0.108140</td>\n",
       "      <td>[168]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0GvhHQbWSnGltjl0je61dI</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.514</td>\n",
       "      <td>4</td>\n",
       "      <td>-12.610</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0315</td>\n",
       "      <td>0.587000</td>\n",
       "      <td>0.02900</td>\n",
       "      <td>0.2200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.401954</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[30, 133]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               sp_song_id  danceability  energy  key  loudness  mode  \\\n",
       "0  6edQfeOlqbGteYixpJl3Sm         0.857   0.602   10    -8.311     1   \n",
       "1  5Oe7wHPL4hdEXeF4AOayCi         0.322   0.990    8    -1.785     1   \n",
       "2  6i1uWZYWabNHq2wQnoca58         0.666   0.884    9    -5.243     0   \n",
       "3  4BzBtS6PBreni5hNPo2hos         0.609   0.578    9    -7.081     1   \n",
       "4  0GvhHQbWSnGltjl0je61dI         0.699   0.514    4   -12.610     1   \n",
       "\n",
       "   speechiness  acousticness  instrumentalness  liveness  ...  lda_topic_11  \\\n",
       "0       0.0290      0.489000           0.02440    0.3170  ...           0.0   \n",
       "1       0.1710      0.000044           0.41700    0.0366  ...           0.0   \n",
       "2       0.0429      0.506000           0.00612    0.0408  ...           0.0   \n",
       "3       0.0414      0.296000           0.00000    0.1500  ...           0.0   \n",
       "4       0.0315      0.587000           0.02900    0.2200  ...           0.0   \n",
       "\n",
       "   lda_topic_12  lda_topic_13  lda_topic_14  lda_topic_15  lda_topic_16  \\\n",
       "0      0.022993      0.000000      0.122078           0.0      0.000000   \n",
       "1      0.000000      0.163142      0.022999           0.0      0.144614   \n",
       "2      0.000000      0.000000      0.000000           0.0      0.000000   \n",
       "3      0.000000      0.511716      0.084905           0.0      0.000000   \n",
       "4      0.000000      0.000000      0.401954           0.0      0.000000   \n",
       "\n",
       "   lda_topic_17  lda_topic_18  lda_topic_19  Playlists  \n",
       "0      0.000000      0.081108      0.386042      [165]  \n",
       "1      0.187207      0.000000      0.000000       [79]  \n",
       "2      0.000000      0.000000      0.582131       [15]  \n",
       "3      0.000000      0.115004      0.108140      [168]  \n",
       "4      0.000000      0.000000      0.000000  [30, 133]  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To generate non-overlapping playlists from the given list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "(2547, 36)\n",
      "['0EYOdF5FCkgOJJla8DI2Md' 0.556 0.981 1 -2.688 0 0.128 0.00662 0.0 0.218\n",
      " 0.716 101.42299999999999 255467 2005 75 0.1136651337146759\n",
      " 0.13335412740707395 0.0 0.0 0.0 0.0 0.0 0.0 0.030962647870182988 0.0 0.0\n",
      " 0.10412494838237762 0.0 0.0 0.0 0.0 0.28551968932151794\n",
      " 0.11562371999025345 0.09813108295202257 0.11474650353193284\n",
      " '[40, 46, 67, 77, 84]']\n"
     ]
    }
   ],
   "source": [
    "playlists_multi = [132, 123,19,46,60,68,79,125]  #132, 123,19,46,60,68,79,125\n",
    "# playlists_multi = [i for i in range(1,169,1)]  #132, 123,19,46,60,68,79,125\n",
    "\n",
    "dict_playlists_to_songs = {}\n",
    "data = np.array(df)\n",
    "Dataset = []\n",
    "for j in playlists_multi:\n",
    "    l0 = []\n",
    "    for i in df.index:\n",
    "        l = eval(df[\"Playlists\"][i])\n",
    "        if(j in l):\n",
    "            l.remove(j)\n",
    "            flag = 0\n",
    "            for k in playlists_multi:\n",
    "                    if(k!=j and k in l):\n",
    "                        flag = 1\n",
    "            if(flag!=1):\n",
    "                l0.append(df[\"sp_song_id\"][i])\n",
    "                Dataset.append(data[i])\n",
    "                \n",
    "    dict_playlists_to_songs[j] = l0\n",
    "#     print(len(l0))\n",
    "print(len(dict_playlists_to_songs))\n",
    "Dataset = np.array(Dataset)\n",
    "print(Dataset.shape)\n",
    "np.random.shuffle(Dataset)\n",
    "print(Dataset[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2547, 34)\n",
      "(2547,)\n"
     ]
    }
   ],
   "source": [
    "X = Dataset[:,1:-1]\n",
    "Y = Dataset[:,-1]\n",
    "# print(Y)\n",
    "for i in range(len(Y)):\n",
    "    Y[i] = eval(Y[i])\n",
    "    for j in playlists_multi:\n",
    "        if(j in Y[i]):\n",
    "            Y[i] = j\n",
    "            break\n",
    "    \n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2547, 34) (2547, 1)\n"
     ]
    }
   ],
   "source": [
    "X = np.array(X)\n",
    "y = np.array(Y)\n",
    "y = Y.reshape(-1, 1)\n",
    "standardScalar = StandardScaler()\n",
    "X = standardScalar.fit_transform(X)\n",
    "print(X.shape, y.shape)\n",
    "y = np.squeeze(y)\n",
    "# print(X)\n",
    "# print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.astype(\"str\")\n",
    "# print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TSNE PLots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computing 91 nearest neighbors...\n",
      "[t-SNE] Indexed 2037 samples in 0.016s...\n",
      "[t-SNE] Computed neighbors for 2037 samples in 0.368s...\n",
      "[t-SNE] Computed conditional probabilities for sample 1000 / 2037\n",
      "[t-SNE] Computed conditional probabilities for sample 2000 / 2037\n",
      "[t-SNE] Computed conditional probabilities for sample 2037 / 2037\n",
      "[t-SNE] Mean sigma: 1.750670\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 76.951363\n",
      "[t-SNE] KL divergence after 1000 iterations: 1.816343\n",
      "[[ 29.049982    -3.9251611 ]\n",
      " [ 24.07252     -0.63237256]\n",
      " [-44.09343      8.117212  ]\n",
      " ...\n",
      " [ 34.944416    -1.6291178 ]\n",
      " [ 12.277303   -11.581576  ]\n",
      " [ 22.768602    21.652424  ]]\n"
     ]
    }
   ],
   "source": [
    "tsne_em = TSNE(n_components=2, perplexity=30.0, n_iter=1000, verbose=1).fit_transform(X_train)\n",
    "print(tsne_em)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tsne= pd.DataFrame(columns = [\"x\", \"y\", \"label\"] )\n",
    "df_tsne[\"x\"] = tsne_em[:,0]\n",
    "df_tsne[\"y\"] = tsne_em[:,1]\n",
    "df_tsne[\"label\"] = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1440 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.figure(figsize = (20,20))\n",
    "# plt.scatter(tsne_em[:,0], tsne_em[:,1],color = \"green\", hue = y_train);\n",
    "sns.scatterplot(x = df_tsne[\"x\"], y = df_tsne[\"y\"], hue = df_tsne[\"label\"],  palette = sns.color_palette(\"husl\", len(set(y_train))))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6058823529411764 0.5825595116018293 0.5929144700320406 0.6058823529411764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pankil/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "logistic = LogisticRegression(solver = \"saga\", multi_class = \"multinomial\")\n",
    "\n",
    "logistic.fit(X_train, y_train)\n",
    "\n",
    "test_score = logistic.score(X_test, y_test)\n",
    "\n",
    "y_pred = logistic.predict(X_test)\n",
    "pres_score = precision_score(y_test, y_pred, average = \"weighted\")\n",
    "\n",
    "f1= f1_score(y_test, y_pred, average = \"weighted\")\n",
    "recall_Score = recall_score(y_test, y_pred, average = \"weighted\")\n",
    "print(test_score, pres_score, f1, recall_Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' One vs One Binary classification'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" One vs One Binary classification\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../Data_Scrape/Dataset/updated_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sp_song_id</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>...</th>\n",
       "      <th>lda_topic_11</th>\n",
       "      <th>lda_topic_12</th>\n",
       "      <th>lda_topic_13</th>\n",
       "      <th>lda_topic_14</th>\n",
       "      <th>lda_topic_15</th>\n",
       "      <th>lda_topic_16</th>\n",
       "      <th>lda_topic_17</th>\n",
       "      <th>lda_topic_18</th>\n",
       "      <th>lda_topic_19</th>\n",
       "      <th>Playlists</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6edQfeOlqbGteYixpJl3Sm</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.602</td>\n",
       "      <td>10</td>\n",
       "      <td>-8.311</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0290</td>\n",
       "      <td>0.489000</td>\n",
       "      <td>0.02440</td>\n",
       "      <td>0.3170</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.022993</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.122078</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.081108</td>\n",
       "      <td>0.386042</td>\n",
       "      <td>[165]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5Oe7wHPL4hdEXeF4AOayCi</td>\n",
       "      <td>0.322</td>\n",
       "      <td>0.990</td>\n",
       "      <td>8</td>\n",
       "      <td>-1.785</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1710</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.41700</td>\n",
       "      <td>0.0366</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.163142</td>\n",
       "      <td>0.022999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.144614</td>\n",
       "      <td>0.187207</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[79]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6i1uWZYWabNHq2wQnoca58</td>\n",
       "      <td>0.666</td>\n",
       "      <td>0.884</td>\n",
       "      <td>9</td>\n",
       "      <td>-5.243</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0429</td>\n",
       "      <td>0.506000</td>\n",
       "      <td>0.00612</td>\n",
       "      <td>0.0408</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.582131</td>\n",
       "      <td>[15]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4BzBtS6PBreni5hNPo2hos</td>\n",
       "      <td>0.609</td>\n",
       "      <td>0.578</td>\n",
       "      <td>9</td>\n",
       "      <td>-7.081</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0414</td>\n",
       "      <td>0.296000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.511716</td>\n",
       "      <td>0.084905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.115004</td>\n",
       "      <td>0.108140</td>\n",
       "      <td>[168]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0GvhHQbWSnGltjl0je61dI</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.514</td>\n",
       "      <td>4</td>\n",
       "      <td>-12.610</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0315</td>\n",
       "      <td>0.587000</td>\n",
       "      <td>0.02900</td>\n",
       "      <td>0.2200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.401954</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[30, 133]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               sp_song_id  danceability  energy  key  loudness  mode  \\\n",
       "0  6edQfeOlqbGteYixpJl3Sm         0.857   0.602   10    -8.311     1   \n",
       "1  5Oe7wHPL4hdEXeF4AOayCi         0.322   0.990    8    -1.785     1   \n",
       "2  6i1uWZYWabNHq2wQnoca58         0.666   0.884    9    -5.243     0   \n",
       "3  4BzBtS6PBreni5hNPo2hos         0.609   0.578    9    -7.081     1   \n",
       "4  0GvhHQbWSnGltjl0je61dI         0.699   0.514    4   -12.610     1   \n",
       "\n",
       "   speechiness  acousticness  instrumentalness  liveness  ...  lda_topic_11  \\\n",
       "0       0.0290      0.489000           0.02440    0.3170  ...           0.0   \n",
       "1       0.1710      0.000044           0.41700    0.0366  ...           0.0   \n",
       "2       0.0429      0.506000           0.00612    0.0408  ...           0.0   \n",
       "3       0.0414      0.296000           0.00000    0.1500  ...           0.0   \n",
       "4       0.0315      0.587000           0.02900    0.2200  ...           0.0   \n",
       "\n",
       "   lda_topic_12  lda_topic_13  lda_topic_14  lda_topic_15  lda_topic_16  \\\n",
       "0      0.022993      0.000000      0.122078           0.0      0.000000   \n",
       "1      0.000000      0.163142      0.022999           0.0      0.144614   \n",
       "2      0.000000      0.000000      0.000000           0.0      0.000000   \n",
       "3      0.000000      0.511716      0.084905           0.0      0.000000   \n",
       "4      0.000000      0.000000      0.401954           0.0      0.000000   \n",
       "\n",
       "   lda_topic_17  lda_topic_18  lda_topic_19  Playlists  \n",
       "0      0.000000      0.081108      0.386042      [165]  \n",
       "1      0.187207      0.000000      0.000000       [79]  \n",
       "2      0.000000      0.000000      0.582131       [15]  \n",
       "3      0.000000      0.115004      0.108140      [168]  \n",
       "4      0.000000      0.000000      0.000000  [30, 133]  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' SVM - Linear Classification  '"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" SVM - Linear Classification  \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def run_model(model_type = \"LR\", neighbours = 5):\n",
    "    \"\"\"\n",
    "    Runs the model inputed and saves the corresponding pickle file\n",
    "    \n",
    "    Arguments\n",
    "    ----------\n",
    "    model_type : str, of the type [LR, SVM, ANN, DT, KNN, RF, XGB], default = LR\n",
    "    \n",
    "    Returns\n",
    "    --------\n",
    "    result_history \n",
    "    \"\"\"\n",
    "    playlists = []\n",
    "    result_history = {}\n",
    "    saved_models = []\n",
    "\n",
    "    np.random.seed(123)\n",
    "\n",
    "    for playlist in tqdm(range(0,169,1), desc = \"Progress : \", position = 0, leave = True):\n",
    "        X = []\n",
    "        y = []\n",
    "        list_of_is = []\n",
    "        for i in df.index:\n",
    "            a = list(df.iloc[i])[1:-1]\n",
    "            if playlist in eval(df['Playlists'][i]):\n",
    "                X.append(a)\n",
    "                y.append(1)\n",
    "            else:\n",
    "                _ = np.random.randint(0, 26)\n",
    "                if _ == 0:\n",
    "                    X.append(a)\n",
    "                    y.append(0)\n",
    "\n",
    "\n",
    "\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "\n",
    "\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10, stratify = y)\n",
    "\n",
    "        standardScalar = StandardScaler()\n",
    "        X_train = standardScalar.fit_transform(X_train)\n",
    "        X_test = standardScalar.transform(X_test)\n",
    "        \n",
    "        \n",
    "        if(model_type == \"LR\" ):\n",
    "            model = LogisticRegression()\n",
    "            \n",
    "        elif(model_type == \"SVM\"):\n",
    "            model = SVC(kernel = 'linear')\n",
    "        \n",
    "        elif (model_type == \"DT\"):\n",
    "            model = DecisionTreeClassifier(criterion = 'entropy', max_depth =  20)\n",
    "            \n",
    "        elif (model_type == \"RF\"):\n",
    "            model = RandomForestClassifier(criterion = 'entropy')\n",
    "            \n",
    "        \n",
    "        elif(model_type == \"XGB\"):\n",
    "            \n",
    "            param = {\n",
    "                \"learning_rate\" : 0.1,\n",
    "                \"n_estimators\" : 500,\n",
    "                \"max_depth\" : 20,\n",
    "                \"min_child_weight\" : 1,\n",
    "                \"gamma\" : 0.1,\n",
    "                \"subsample\": 0.9,\n",
    "                \"colsample_bytree\" : 0.9,\n",
    "                \"objective\" : 'binary:logistic',\n",
    "                \"nthread\" : 4,\n",
    "                \"scale_pos_weight\" :  1,\n",
    "                \"seed\" : 27\n",
    "            }\n",
    "            \n",
    "            model = XGBClassifier(**param)\n",
    "        \n",
    "        elif(model_type == \"KNN\"):\n",
    "            model = KNeighborsClassifier(n_neighbors=neighbours)\n",
    "            \n",
    "        elif(model_type == \"ANN\"):\n",
    "            model = Sequential([Dense(units = 24, input_shape = (34, ), activation = 'relu'),\n",
    "            Dense(units = 12, activation = 'relu'),\n",
    "            Dense(units = 4, activation = 'relu'),       \n",
    "            Dense(units = 1, activation = 'sigmoid')\n",
    "            ])\n",
    "            model.compile(optimizer = tf.keras.optimizers.Adam(lr = 0.05), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "            model.summary()\n",
    "            \n",
    "        \n",
    "\n",
    "\n",
    "#         xgb = XGBClassifier(**param)    \n",
    "        \n",
    "        if model_type != 'ANN':\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_test)\n",
    "        else:\n",
    "            model.fit(X_train, y_train, validation_data = (X_test, y_test), batch_size = 64, epochs = 20)\n",
    "            y_pred = model.predict_classes(X_test)\n",
    "            \n",
    "\n",
    "        pres_score = precision_score(y_test, y_pred, average = \"macro\")\n",
    "\n",
    "        f1= f1_score(y_test, y_pred, average = \"macro\")\n",
    "        recall_Score = recall_score(y_test, y_pred, average = \"macro\")\n",
    "\n",
    "        result_history[playlist] = {\"Precision Score \" : pres_score, \"Recall Score \" : recall_Score, \"F1 Score \" : f1 }\n",
    "        if(model_type != \"ANN\"):\n",
    "            saved_models.append(model)\n",
    "        else:\n",
    "            model.save(\"saved_models_binary/\" + \"ANN/\" + \"ANN\" + str(playlist) )\n",
    "    \n",
    "    if(model_type !=\"ANN\"):\n",
    "        f = open(\"saved_models_binary/\" + model_type, \"wb\")\n",
    "        pickle.dump(saved_models, f)\n",
    "        f.close()\n",
    "        \n",
    "    print(result_history)\n",
    "    return result_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = open(\"binary_svc_linear_result\", \"wb\")\n",
    "# pickle.dump(result_history, f)\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"binary_svc_linear_result\", \"rb\")\n",
    "l = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = {k: v for k, v in sorted(l.items(), key=lambda item: item[1][\"F1 Score \"], reverse = True)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71  =  {'Precision Score ': 0.9615384615384616, 'Recall Score ': 0.9945652173913043, 'F1 Score ': 0.9772677595628416}\n",
      "89  =  {'Precision Score ': 0.955977229601518, 'Recall Score ': 0.955977229601518, 'F1 Score ': 0.955977229601518}\n",
      "137  =  {'Precision Score ': 0.9624482554701359, 'Recall Score ': 0.9443181818181818, 'F1 Score ': 0.953063885267275}\n",
      "100  =  {'Precision Score ': 0.925, 'Recall Score ': 0.9836956521739131, 'F1 Score ': 0.9511721666417798}\n",
      "99  =  {'Precision Score ': 0.929128277817151, 'Recall Score ': 0.929128277817151, 'F1 Score ': 0.929128277817151}\n",
      "98  =  {'Precision Score ': 0.9108527131782946, 'Recall Score ': 0.9430512016718913, 'F1 Score ': 0.9261120884644383}\n",
      "66  =  {'Precision Score ': 0.9211764705882353, 'Recall Score ': 0.9282296650717703, 'F1 Score ': 0.9245823860828308}\n",
      "97  =  {'Precision Score ': 0.8999208860759493, 'Recall Score ': 0.9457671957671958, 'F1 Score ': 0.9208333333333333}\n",
      "161  =  {'Precision Score ': 0.9332659251769464, 'Recall Score ': 0.9080952380952381, 'F1 Score ': 0.9198529411764705}\n",
      "72  =  {'Precision Score ': 0.9157848324514991, 'Recall Score ': 0.9207317073170731, 'F1 Score ': 0.9181757705669303}\n",
      "102  =  {'Precision Score ': 0.8889228886168911, 'Recall Score ': 0.9462780898876404, 'F1 Score ': 0.9142857142857144}\n",
      "45  =  {'Precision Score ': 0.8938271604938272, 'Recall Score ': 0.9425287356321839, 'F1 Score ': 0.9136904761904763}\n",
      "93  =  {'Precision Score ': 0.8882433356117567, 'Recall Score ': 0.94375, 'F1 Score ': 0.9126478616924476}\n",
      "70  =  {'Precision Score ': 0.8866071428571429, 'Recall Score ': 0.940040650406504, 'F1 Score ': 0.9107312440645774}\n",
      "40  =  {'Precision Score ': 0.9098039215686274, 'Recall Score ': 0.9098039215686274, 'F1 Score ': 0.9098039215686274}\n",
      "79  =  {'Precision Score ': 0.9170358883473637, 'Recall Score ': 0.9041867954911433, 'F1 Score ': 0.9092963114196271}\n",
      "101  =  {'Precision Score ': 0.8789335664335665, 'Recall Score ': 0.9378787878787879, 'F1 Score ': 0.9054307116104868}\n",
      "157  =  {'Precision Score ': 0.9044750430292599, 'Recall Score ': 0.9044750430292599, 'F1 Score ': 0.9044750430292599}\n",
      "92  =  {'Precision Score ': 0.8922369765066395, 'Recall Score ': 0.9063492063492063, 'F1 Score ': 0.8990515785370925}\n",
      "83  =  {'Precision Score ': 0.8947209653092005, 'Recall Score ': 0.8845136644137526, 'F1 Score ': 0.8892857142857143}\n"
     ]
    }
   ],
   "source": [
    "# Top 20 playlists \n",
    "for key in list(l.keys())[:20]:\n",
    "    print(key,\" = \",  l[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Logistic Regression Result'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Logistic Regression Result\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 169/169 [21:04<00:00,  7.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {'Precision Score ': 0.7339366515837105, 'Recall Score ': 0.7339366515837105, 'F1 Score ': 0.7339366515837105}, 1: {'Precision Score ': 0.8248847926267281, 'Recall Score ': 0.7905219780219781, 'F1 Score ': 0.806159420289855}, 2: {'Precision Score ': 0.6427083333333333, 'Recall Score ': 0.6003663003663003, 'F1 Score ': 0.6145454545454545}, 3: {'Precision Score ': 0.844017094017094, 'Recall Score ': 0.836038961038961, 'F1 Score ': 0.839882697947214}, 4: {'Precision Score ': 0.7527472527472527, 'Recall Score ': 0.6931524547803618, 'F1 Score ': 0.7156916347731002}, 5: {'Precision Score ': 0.8527443105756358, 'Recall Score ': 0.7565725413826679, 'F1 Score ': 0.7934904601571269}, 6: {'Precision Score ': 0.8052434456928839, 'Recall Score ': 0.755485893416928, 'F1 Score ': 0.7772727272727272}, 7: {'Precision Score ': 0.875, 'Recall Score ': 0.9772727272727273, 'F1 Score ': 0.9169435215946844}, 8: {'Precision Score ': 0.8111111111111111, 'Recall Score ': 0.8111111111111111, 'F1 Score ': 0.8111111111111111}, 9: {'Precision Score ': 0.8096831771530566, 'Recall Score ': 0.8177655677655677, 'F1 Score ': 0.8135803863970172}, 10: {'Precision Score ': 0.7601744186046512, 'Recall Score ': 0.6598214285714286, 'F1 Score ': 0.6911281489594743}, 11: {'Precision Score ': 0.8540391676866586, 'Recall Score ': 0.8168127053669222, 'F1 Score ': 0.8333092798383605}, 12: {'Precision Score ': 0.8603960396039605, 'Recall Score ': 0.784375, 'F1 Score ': 0.8149383611312546}, 13: {'Precision Score ': 0.7941176470588236, 'Recall Score ': 0.8088662790697674, 'F1 Score ': 0.8011695906432749}, 14: {'Precision Score ': 0.7999365884590995, 'Recall Score ': 0.7884146341463415, 'F1 Score ': 0.793939393939394}, 15: {'Precision Score ': 0.7988904299583912, 'Recall Score ': 0.6363061353573688, 'F1 Score ': 0.6726190476190477}, 16: {'Precision Score ': 0.8045454545454545, 'Recall Score ': 0.7832980972515856, 'F1 Score ': 0.7931034482758621}, 17: {'Precision Score ': 0.7657624633431085, 'Recall Score ': 0.7715355805243446, 'F1 Score ': 0.7685468185607113}, 18: {'Precision Score ': 0.8563988095238095, 'Recall Score ': 0.7892512077294687, 'F1 Score ': 0.817154255319149}, 19: {'Precision Score ': 0.7837795765877957, 'Recall Score ': 0.7925224646983312, 'F1 Score ': 0.7875246742992499}, 20: {'Precision Score ': 0.7056962025316456, 'Recall Score ': 0.7166666666666667, 'F1 Score ': 0.7108947048082777}, 21: {'Precision Score ': 0.8806818181818182, 'Recall Score ': 0.8096638655462185, 'F1 Score ': 0.8397687861271677}, 22: {'Precision Score ': 0.8166585721223896, 'Recall Score ': 0.8574561403508771, 'F1 Score ': 0.8331408034912078}, 23: {'Precision Score ': 0.7125, 'Recall Score ': 0.7260208926875593, 'F1 Score ': 0.7188865884518059}, 24: {'Precision Score ': 0.8875968992248062, 'Recall Score ': 0.8571428571428572, 'F1 Score ': 0.8712074303405573}, 25: {'Precision Score ': 0.8996173093906388, 'Recall Score ': 0.9193697868396664, 'F1 Score ': 0.9081601927130383}, 26: {'Precision Score ': 0.8743589743589744, 'Recall Score ': 0.8201754385964912, 'F1 Score ': 0.8441558441558441}, 27: {'Precision Score ': 0.6473684210526316, 'Recall Score ': 0.6098901098901099, 'F1 Score ': 0.6236559139784946}, 28: {'Precision Score ': 0.8465309200603319, 'Recall Score ': 0.9310506566604128, 'F1 Score ': 0.8812500000000001}, 29: {'Precision Score ': 0.755023923444976, 'Recall Score ': 0.661222020568663, 'F1 Score ': 0.6893772893772894}, 30: {'Precision Score ': 0.7872023809523809, 'Recall Score ': 0.7418546365914787, 'F1 Score ': 0.7562826783606005}, 31: {'Precision Score ': 0.7091503267973855, 'Recall Score ': 0.7, 'F1 Score ': 0.7043478260869566}, 32: {'Precision Score ': 0.8056962025316455, 'Recall Score ': 0.7948717948717949, 'F1 Score ': 0.800062140748796}, 33: {'Precision Score ': 0.6530172413793103, 'Recall Score ': 0.6375968992248062, 'F1 Score ': 0.6446786807208433}, 34: {'Precision Score ': 0.851304945054945, 'Recall Score ': 0.764751552795031, 'F1 Score ': 0.7961904761904761}, 35: {'Precision Score ': 0.8736702127659575, 'Recall Score ': 0.6781864299302472, 'F1 Score ': 0.7225360954174513}, 36: {'Precision Score ': 0.7534883720930232, 'Recall Score ': 0.7289915966386555, 'F1 Score ': 0.7400735294117646}, 37: {'Precision Score ': 0.8869747899159663, 'Recall Score ': 0.9410919540229885, 'F1 Score ': 0.9114490161001789}, 38: {'Precision Score ': 0.8718072289156626, 'Recall Score ': 0.8718072289156626, 'F1 Score ': 0.8718072289156626}, 39: {'Precision Score ': 0.8068181818181819, 'Recall Score ': 0.5935064935064935, 'F1 Score ': 0.6185007974481659}, 40: {'Precision Score ': 0.8914431673052363, 'Recall Score ': 0.8730223123732251, 'F1 Score ': 0.8816445182724253}, 41: {'Precision Score ': 0.7960014809329878, 'Recall Score ': 0.7861147560539186, 'F1 Score ': 0.7885824866956943}, 42: {'Precision Score ': 0.7806451612903226, 'Recall Score ': 0.7548667548667549, 'F1 Score ': 0.7644097907619423}, 43: {'Precision Score ': 0.8184338184338185, 'Recall Score ': 0.8421444527177959, 'F1 Score ': 0.8280060882800608}, 44: {'Precision Score ': 0.7484053216694004, 'Recall Score ': 0.7442652329749104, 'F1 Score ': 0.7460145418416655}, 45: {'Precision Score ': 0.8848637015781922, 'Recall Score ': 0.9252873563218391, 'F1 Score ': 0.9019442096365173}, 46: {'Precision Score ': 0.8278822055137844, 'Recall Score ': 0.8266541822721598, 'F1 Score ': 0.8266208404936728}, 47: {'Precision Score ': 0.8211764705882353, 'Recall Score ': 0.7905491698595146, 'F1 Score ': 0.8036590807675145}, 48: {'Precision Score ': 0.7438409854423292, 'Recall Score ': 0.7334494773519163, 'F1 Score ': 0.7380773178241533}, 49: {'Precision Score ': 0.7675561797752809, 'Recall Score ': 0.7760869565217392, 'F1 Score ': 0.7716629026506597}, 50: {'Precision Score ': 0.790610718737017, 'Recall Score ': 0.790610718737017, 'F1 Score ': 0.790610718737017}, 51: {'Precision Score ': 0.7329268292682927, 'Recall Score ': 0.7267331433998101, 'F1 Score ': 0.7297004691447131}, 52: {'Precision Score ': 0.816557734204793, 'Recall Score ': 0.8340229885057471, 'F1 Score ': 0.8246869409660108}, 53: {'Precision Score ': 0.8008879023307436, 'Recall Score ': 0.8008879023307436, 'F1 Score ': 0.8008879023307436}, 54: {'Precision Score ': 0.7779943302622254, 'Recall Score ': 0.783008658008658, 'F1 Score ': 0.7804093305925464}, 55: {'Precision Score ': 0.8211148648648648, 'Recall Score ': 0.83681785967399, 'F1 Score ': 0.8281344508770414}, 56: {'Precision Score ': 0.7388663967611335, 'Recall Score ': 0.6891025641025641, 'F1 Score ': 0.7066666666666666}, 57: {'Precision Score ': 0.7499245852187029, 'Recall Score ': 0.7573780677228953, 'F1 Score ': 0.7533659730722153}, 58: {'Precision Score ': 0.780570142535634, 'Recall Score ': 0.780570142535634, 'F1 Score ': 0.780570142535634}, 59: {'Precision Score ': 0.8227513227513228, 'Recall Score ': 0.814974182444062, 'F1 Score ': 0.818726183995645}, 60: {'Precision Score ': 0.808666017526777, 'Recall Score ': 0.8117623918174666, 'F1 Score ': 0.8098498557245561}, 61: {'Precision Score ': 0.7794258373205742, 'Recall Score ': 0.7673992673992673, 'F1 Score ': 0.7725572697522207}, 62: {'Precision Score ': 0.8344444444444444, 'Recall Score ': 0.8399849397590362, 'F1 Score ': 0.8369835739173718}, 63: {'Precision Score ': 0.8500384516790567, 'Recall Score ': 0.8500384516790567, 'F1 Score ': 0.8500384516790567}, 64: {'Precision Score ': 0.7619047619047619, 'Recall Score ': 0.7293504410585405, 'F1 Score ': 0.742564758554525}, 65: {'Precision Score ': 0.7765700483091788, 'Recall Score ': 0.7678362573099415, 'F1 Score ': 0.7719037719037718}, 66: {'Precision Score ': 0.9199673336055533, 'Recall Score ': 0.9047619047619048, 'F1 Score ': 0.9118589743589745}, 67: {'Precision Score ': 0.8590243902439024, 'Recall Score ': 0.8538461538461539, 'F1 Score ': 0.8562091503267975}, 68: {'Precision Score ': 0.7978354978354978, 'Recall Score ': 0.7925170068027212, 'F1 Score ': 0.793960162775755}, 69: {'Precision Score ': 0.7479166666666667, 'Recall Score ': 0.7479166666666667, 'F1 Score ': 0.7479166666666667}, 70: {'Precision Score ': 0.872269705603039, 'Recall Score ': 0.8983739837398375, 'F1 Score ': 0.8846625766871166}, 71: {'Precision Score ': 0.9285714285714286, 'Recall Score ': 0.9891304347826086, 'F1 Score ': 0.956043956043956}, 72: {'Precision Score ': 0.9384036144578314, 'Recall Score ': 0.9329268292682926, 'F1 Score ': 0.9355780022446689}, 73: {'Precision Score ': 0.8806620209059233, 'Recall Score ': 0.9050046339202966, 'F1 Score ': 0.8922558922558923}, 74: {'Precision Score ': 0.8274032459425718, 'Recall Score ': 0.8136961722488039, 'F1 Score ': 0.8202779050236677}, 75: {'Precision Score ': 0.7472527472527473, 'Recall Score ': 0.7859237536656891, 'F1 Score ': 0.7644927536231885}, 76: {'Precision Score ': 0.6965277777777777, 'Recall Score ': 0.6965277777777777, 'F1 Score ': 0.6965277777777777}, 77: {'Precision Score ': 0.8208333333333333, 'Recall Score ': 0.7965686274509804, 'F1 Score ': 0.8070494186046512}, 78: {'Precision Score ': 0.7818815331010454, 'Recall Score ': 0.7866761162296244, 'F1 Score ': 0.7841897233201582}, 79: {'Precision Score ': 0.9201833848873178, 'Recall Score ': 0.9033404029692471, 'F1 Score ': 0.9095964367660951}, 80: {'Precision Score ': 0.8451858693142461, 'Recall Score ': 0.8444700460829493, 'F1 Score ': 0.8408999598232222}, 81: {'Precision Score ': 0.858974358974359, 'Recall Score ': 0.8869596031183558, 'F1 Score ': 0.8705862333021357}, 82: {'Precision Score ': 0.9221891288160834, 'Recall Score ': 0.9295454545454545, 'F1 Score ': 0.9257486154134985}, 83: {'Precision Score ': 0.8687270501835985, 'Recall Score ': 0.8540993241257714, 'F1 Score ': 0.8606845929143885}, 84: {'Precision Score ': 0.8223426678711232, 'Recall Score ': 0.8151309979393582, 'F1 Score ': 0.8184523809523809}, 85: {'Precision Score ': 0.9038800705467371, 'Recall Score ': 0.9148550724637681, 'F1 Score ': 0.9087719298245613}, 86: {'Precision Score ': 0.9565548780487805, 'Recall Score ': 0.9350036310820624, 'F1 Score ': 0.9453430005577244}, 87: {'Precision Score ': 0.8073529411764706, 'Recall Score ': 0.8669241573033708, 'F1 Score ': 0.8323754789272031}, 88: {'Precision Score ': 0.8519375361480624, 'Recall Score ': 0.8848829854522454, 'F1 Score ': 0.8671497584541064}, 89: {'Precision Score ': 0.9492248062015505, 'Recall Score ': 0.9398481973434535, 'F1 Score ': 0.9443965104016873}, 90: {'Precision Score ': 0.7405523255813953, 'Recall Score ': 0.7405523255813953, 'F1 Score ': 0.7405523255813953}, 91: {'Precision Score ': 0.7952380952380953, 'Recall Score ': 0.8204134366925064, 'F1 Score ': 0.8068111455108359}, 92: {'Precision Score ': 0.8888888888888888, 'Recall Score ': 0.967032967032967, 'F1 Score ': 0.9204545454545455}, 93: {'Precision Score ': 0.8875, 'Recall Score ': 0.8875, 'F1 Score ': 0.8875000000000001}, 94: {'Precision Score ': 0.7765151515151515, 'Recall Score ': 0.737012987012987, 'F1 Score ': 0.7534883720930232}, 95: {'Precision Score ': 0.7758620689655172, 'Recall Score ': 0.7195121951219512, 'F1 Score ': 0.7413355874894337}, 96: {'Precision Score ': 0.8598629093678598, 'Recall Score ': 0.8181818181818181, 'F1 Score ': 0.8371428571428571}, 97: {'Precision Score ': 0.9054355919583024, 'Recall Score ': 0.9481481481481482, 'F1 Score ': 0.9249999999999999}, 98: {'Precision Score ': 0.7951933124346917, 'Recall Score ': 0.7951933124346917, 'F1 Score ': 0.7951933124346917}, 99: {'Precision Score ': 0.8822368421052631, 'Recall Score ': 0.9167862266857962, 'F1 Score ': 0.8981481481481481}, 100: {'Precision Score ': 0.957997311827957, 'Recall Score ': 0.9357416879795396, 'F1 Score ': 0.9464373464373463}, 101: {'Precision Score ': 0.9945652173913043, 'Recall Score ': 0.9545454545454546, 'F1 Score ': 0.9734582357533177}, 102: {'Precision Score ': 0.8893960674157304, 'Recall Score ': 0.8893960674157304, 'F1 Score ': 0.8893960674157304}, 103: {'Precision Score ': 0.7967479674796748, 'Recall Score ': 0.7607142857142857, 'F1 Score ': 0.7768281101614434}, 104: {'Precision Score ': 0.822415329768271, 'Recall Score ': 0.8132034632034633, 'F1 Score ': 0.8170250109697237}, 105: {'Precision Score ': 0.7278350515463917, 'Recall Score ': 0.6868131868131868, 'F1 Score ': 0.702358926919519}, 106: {'Precision Score ': 0.8223684210526316, 'Recall Score ': 0.7722222222222221, 'F1 Score ': 0.7927927927927927}, 107: {'Precision Score ': 0.7929268292682927, 'Recall Score ': 0.765473032714412, 'F1 Score ': 0.7770833333333333}, 108: {'Precision Score ': 0.7589712918660287, 'Recall Score ': 0.7315508021390373, 'F1 Score ': 0.7435499788523896}, 109: {'Precision Score ': 0.705087440381558, 'Recall Score ': 0.7205128205128205, 'F1 Score ': 0.7113486842105263}, 110: {'Precision Score ': 0.8081560283687943, 'Recall Score ': 0.7270114942528736, 'F1 Score ': 0.7558608332088994}, 111: {'Precision Score ': 0.7647783251231527, 'Recall Score ': 0.7616279069767442, 'F1 Score ': 0.7631417885073104}, 112: {'Precision Score ': 0.7956730769230769, 'Recall Score ': 0.798775748153906, 'F1 Score ': 0.7968697164388193}, 113: {'Precision Score ': 0.6853211009174311, 'Recall Score ': 0.6343085106382979, 'F1 Score ': 0.6445623342175066}, 114: {'Precision Score ': 0.8143363728470112, 'Recall Score ': 0.7253086419753086, 'F1 Score ': 0.749090909090909}, 115: {'Precision Score ': 0.7916666666666667, 'Recall Score ': 0.7731979291119075, 'F1 Score ': 0.7814072932717}, 116: {'Precision Score ': 0.8164362519201229, 'Recall Score ': 0.7566445182724253, 'F1 Score ': 0.7790445787253448}, 117: {'Precision Score ': 0.7491228070175439, 'Recall Score ': 0.642570281124498, 'F1 Score ': 0.6660424469413233}, 118: {'Precision Score ': 0.6437764744216357, 'Recall Score ': 0.6363144887241272, 'F1 Score ': 0.6335164835164835}, 119: {'Precision Score ': 0.5989583333333333, 'Recall Score ': 0.5452380952380952, 'F1 Score ': 0.546031746031746}, 120: {'Precision Score ': 0.8651162790697675, 'Recall Score ': 0.8152610441767068, 'F1 Score ': 0.8370091447014524}, 121: {'Precision Score ': 0.7645502645502645, 'Recall Score ': 0.644927536231884, 'F1 Score ': 0.6672727272727272}, 122: {'Precision Score ': 0.5677655677655677, 'Recall Score ': 0.5415263748597082, 'F1 Score ': 0.5420656634746922}, 123: {'Precision Score ': 0.753125, 'Recall Score ': 0.725, 'F1 Score ': 0.7339181286549707}, 124: {'Precision Score ': 0.8191518467852257, 'Recall Score ': 0.8270255116344267, 'F1 Score ': 0.8228128460686601}, 125: {'Precision Score ': 0.8082225810458328, 'Recall Score ': 0.8110038851986465, 'F1 Score ': 0.8092031425364759}, 126: {'Precision Score ': 0.7936046511627908, 'Recall Score ': 0.7914539400665926, 'F1 Score ': 0.7924812030075188}, 127: {'Precision Score ': 0.7569444444444444, 'Recall Score ': 0.7660130718954248, 'F1 Score ': 0.7611556982343499}, 128: {'Precision Score ': 0.7578187650360866, 'Recall Score ': 0.7469278033794162, 'F1 Score ': 0.7519607843137255}, 129: {'Precision Score ': 0.8079268292682926, 'Recall Score ': 0.8106895667777493, 'F1 Score ': 0.8092503987240829}, 130: {'Precision Score ': 0.764367816091954, 'Recall Score ': 0.7536764705882353, 'F1 Score ': 0.7586271567891973}, 131: {'Precision Score ': 0.8130718954248366, 'Recall Score ': 0.800125313283208, 'F1 Score ': 0.8049169859514687}, 132: {'Precision Score ': 0.7684903748733536, 'Recall Score ': 0.7640398550724637, 'F1 Score ': 0.766089080656576}, 133: {'Precision Score ': 0.818075117370892, 'Recall Score ': 0.8171816479400749, 'F1 Score ': 0.8175958120092197}, 134: {'Precision Score ': 0.807942057942058, 'Recall Score ': 0.8190993788819876, 'F1 Score ': 0.8133180836192655}, 135: {'Precision Score ': 0.7210767468499427, 'Recall Score ': 0.6955420466058764, 'F1 Score ': 0.7066720365149685}, 136: {'Precision Score ': 0.8290529695024077, 'Recall Score ': 0.8106060606060606, 'F1 Score ': 0.8194038573933372}, 137: {'Precision Score ': 0.9545454545454546, 'Recall Score ': 0.9887640449438202, 'F1 Score ': 0.9705086580086579}, 138: {'Precision Score ': 0.6619601328903655, 'Recall Score ': 0.6529411764705882, 'F1 Score ': 0.6571889493849566}, 139: {'Precision Score ': 0.6979166666666667, 'Recall Score ': 0.6682479443390259, 'F1 Score ': 0.6808329066393582}, 140: {'Precision Score ': 0.8181818181818181, 'Recall Score ': 0.7319277108433735, 'F1 Score ': 0.7641325536062378}, 141: {'Precision Score ': 0.6867816091954023, 'Recall Score ': 0.6253858024691358, 'F1 Score ': 0.6446886446886447}, 142: {'Precision Score ': 0.8725527108433735, 'Recall Score ': 0.9061986863711002, 'F1 Score ': 0.8872549019607844}, 143: {'Precision Score ': 0.8843085106382979, 'Recall Score ': 0.82146829810901, 'F1 Score ': 0.845906579608237}, 144: {'Precision Score ': 0.852046783625731, 'Recall Score ': 0.7388888888888889, 'F1 Score ': 0.7800235017626322}, 145: {'Precision Score ': 0.5951219512195122, 'Recall Score ': 0.58125, 'F1 Score ': 0.5869809203142536}, 146: {'Precision Score ': 0.7012195121951219, 'Recall Score ': 0.6606621226874392, 'F1 Score ': 0.6770186335403727}, 147: {'Precision Score ': 0.8849945235487404, 'Recall Score ': 0.8338081671415005, 'F1 Score ': 0.8567073170731707}, 148: {'Precision Score ': 0.862736660929432, 'Recall Score ': 0.8252314814814814, 'F1 Score ': 0.8422764227642277}, 149: {'Precision Score ': 0.64375, 'Recall Score ': 0.6148851148851149, 'F1 Score ': 0.6261423428413182}, 150: {'Precision Score ': 0.7312091503267973, 'Recall Score ': 0.7243183259353203, 'F1 Score ': 0.7274774774774775}, 151: {'Precision Score ': 0.8131578947368421, 'Recall Score ': 0.7335164835164836, 'F1 Score ': 0.7647849462365592}, 152: {'Precision Score ': 0.885, 'Recall Score ': 0.6988636363636364, 'F1 Score ': 0.7440159574468086}, 153: {'Precision Score ': 0.7760453579021971, 'Recall Score ': 0.8443854995579134, 'F1 Score ': 0.803921568627451}, 154: {'Precision Score ': 0.8294975067126966, 'Recall Score ': 0.8841681574239714, 'F1 Score ': 0.8504365690806369}, 155: {'Precision Score ': 0.8250921375921376, 'Recall Score ': 0.8421137685843567, 'F1 Score ': 0.832795656621292}, 156: {'Precision Score ': 0.8924889543446244, 'Recall Score ': 0.7252747252747254, 'F1 Score ': 0.7787234042553192}, 157: {'Precision Score ': 0.8422733077905491, 'Recall Score ': 0.8501742160278746, 'F1 Score ': 0.8460876116672047}, 158: {'Precision Score ': 0.782967032967033, 'Recall Score ': 0.7372430900070872, 'F1 Score ': 0.7534482758620691}, 159: {'Precision Score ': 0.7691558441558441, 'Recall Score ': 0.7691558441558441, 'F1 Score ': 0.7691558441558441}, 160: {'Precision Score ': 0.7775974025974026, 'Recall Score ': 0.7453371592539455, 'F1 Score ': 0.7578747628083491}, 161: {'Precision Score ': 0.9139705882352941, 'Recall Score ': 0.9021428571428571, 'F1 Score ': 0.907861369399831}, 162: {'Precision Score ': 0.8221288515406162, 'Recall Score ': 0.7764423076923077, 'F1 Score ': 0.7949709864603481}, 163: {'Precision Score ': 0.799526270456503, 'Recall Score ': 0.7922268907563026, 'F1 Score ': 0.7957469431153641}, 164: {'Precision Score ': 0.8452797202797202, 'Recall Score ': 0.8379679144385027, 'F1 Score ': 0.8411755172600075}, 165: {'Precision Score ': 0.783851976450799, 'Recall Score ': 0.7777777777777777, 'F1 Score ': 0.7807008422585007}, 166: {'Precision Score ': 0.832051282051282, 'Recall Score ': 0.8503787878787878, 'F1 Score ': 0.8405263157894738}, 167: {'Precision Score ': 0.8029715762273901, 'Recall Score ': 0.8029715762273901, 'F1 Score ': 0.8029715762273901}, 168: {'Precision Score ': 0.8311175737432488, 'Recall Score ': 0.8239837398373984, 'F1 Score ': 0.8274268104776579}}\n"
     ]
    }
   ],
   "source": [
    "result_history = run_model(model_type = \"LR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = open(\"binary_linear_regression_result\", \"wb\")\n",
    "# pickle.dump(result_history, f)\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"binary_linear_regression_result\", \"rb\")\n",
    "l = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = {k: v for k, v in sorted(l.items(), key=lambda item: item[1][\"F1 Score \"], reverse = True)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101  =  {'Precision Score ': 0.9945652173913043, 'Recall Score ': 0.9545454545454546, 'F1 Score ': 0.9734582357533177}\n",
      "137  =  {'Precision Score ': 0.9545454545454546, 'Recall Score ': 0.9887640449438202, 'F1 Score ': 0.9705086580086579}\n",
      "71  =  {'Precision Score ': 0.9285714285714286, 'Recall Score ': 0.9891304347826086, 'F1 Score ': 0.956043956043956}\n",
      "100  =  {'Precision Score ': 0.957997311827957, 'Recall Score ': 0.9357416879795396, 'F1 Score ': 0.9464373464373463}\n",
      "86  =  {'Precision Score ': 0.9565548780487805, 'Recall Score ': 0.9350036310820624, 'F1 Score ': 0.9453430005577244}\n",
      "89  =  {'Precision Score ': 0.9492248062015505, 'Recall Score ': 0.9398481973434535, 'F1 Score ': 0.9443965104016873}\n",
      "72  =  {'Precision Score ': 0.9384036144578314, 'Recall Score ': 0.9329268292682926, 'F1 Score ': 0.9355780022446689}\n",
      "82  =  {'Precision Score ': 0.9221891288160834, 'Recall Score ': 0.9295454545454545, 'F1 Score ': 0.9257486154134985}\n",
      "97  =  {'Precision Score ': 0.9054355919583024, 'Recall Score ': 0.9481481481481482, 'F1 Score ': 0.9249999999999999}\n",
      "92  =  {'Precision Score ': 0.8888888888888888, 'Recall Score ': 0.967032967032967, 'F1 Score ': 0.9204545454545455}\n",
      "7  =  {'Precision Score ': 0.875, 'Recall Score ': 0.9772727272727273, 'F1 Score ': 0.9169435215946844}\n",
      "66  =  {'Precision Score ': 0.9199673336055533, 'Recall Score ': 0.9047619047619048, 'F1 Score ': 0.9118589743589745}\n",
      "37  =  {'Precision Score ': 0.8869747899159663, 'Recall Score ': 0.9410919540229885, 'F1 Score ': 0.9114490161001789}\n",
      "79  =  {'Precision Score ': 0.9201833848873178, 'Recall Score ': 0.9033404029692471, 'F1 Score ': 0.9095964367660951}\n",
      "85  =  {'Precision Score ': 0.9038800705467371, 'Recall Score ': 0.9148550724637681, 'F1 Score ': 0.9087719298245613}\n",
      "25  =  {'Precision Score ': 0.8996173093906388, 'Recall Score ': 0.9193697868396664, 'F1 Score ': 0.9081601927130383}\n",
      "161  =  {'Precision Score ': 0.9139705882352941, 'Recall Score ': 0.9021428571428571, 'F1 Score ': 0.907861369399831}\n",
      "45  =  {'Precision Score ': 0.8848637015781922, 'Recall Score ': 0.9252873563218391, 'F1 Score ': 0.9019442096365173}\n",
      "99  =  {'Precision Score ': 0.8822368421052631, 'Recall Score ': 0.9167862266857962, 'F1 Score ': 0.8981481481481481}\n",
      "73  =  {'Precision Score ': 0.8806620209059233, 'Recall Score ': 0.9050046339202966, 'F1 Score ': 0.8922558922558923}\n"
     ]
    }
   ],
   "source": [
    "# Top 20 playlists \n",
    "for key in list(l.keys())[:20]:\n",
    "    print(key,\" = \",  l[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Decision Tree Result'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Decision Tree Result\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 169/169 [12:08<00:00,  4.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {'Precision Score ': 0.8551810237203495, 'Recall Score ': 0.7574660633484163, 'F1 Score ': 0.7951933124346917}, 1: {'Precision Score ': 0.7569444444444444, 'Recall Score ': 0.6397664835164836, 'F1 Score ': 0.6714912280701754}, 2: {'Precision Score ': 0.648989898989899, 'Recall Score ': 0.672893772893773, 'F1 Score ': 0.659048586422888}, 3: {'Precision Score ': 0.7740461049284579, 'Recall Score ': 0.8198051948051948, 'F1 Score ': 0.7883289124668434}, 4: {'Precision Score ': 0.6931818181818181, 'Recall Score ': 0.6757105943152455, 'F1 Score ': 0.6835699797160244}, 5: {'Precision Score ': 0.7575075075075075, 'Recall Score ': 0.8339824732229796, 'F1 Score ': 0.7866329327429896}, 6: {'Precision Score ': 0.7457013574660634, 'Recall Score ': 0.7836990595611285, 'F1 Score ': 0.7625968992248062}, 7: {'Precision Score ': 0.7633928571428572, 'Recall Score ': 0.8352272727272727, 'F1 Score ': 0.7923588039867109}, 8: {'Precision Score ': 0.9229390681003584, 'Recall Score ': 0.8277777777777777, 'F1 Score ': 0.8672911787665887}, 9: {'Precision Score ': 0.75, 'Recall Score ': 0.7216117216117216, 'F1 Score ': 0.7335271317829457}, 10: {'Precision Score ': 0.6316595223515002, 'Recall Score ': 0.6919642857142857, 'F1 Score ': 0.6466797923751566}, 11: {'Precision Score ': 0.7185978578383642, 'Recall Score ': 0.7458926615553121, 'F1 Score ': 0.7299382716049383}, 12: {'Precision Score ': 0.7178588125292192, 'Recall Score ': 0.7427083333333333, 'F1 Score ': 0.7288052171773102}, 13: {'Precision Score ': 0.727013316423589, 'Recall Score ': 0.7601744186046512, 'F1 Score ': 0.7413355874894336}, 14: {'Precision Score ': 0.7145454545454546, 'Recall Score ': 0.7518292682926829, 'F1 Score ': 0.7291404612159329}, 15: {'Precision Score ': 0.7676767676767677, 'Recall Score ': 0.6843769765970904, 'F1 Score ': 0.7135416666666667}, 16: {'Precision Score ': 0.6751769464105157, 'Recall Score ': 0.6810344827586207, 'F1 Score ': 0.6779704560051381}, 17: {'Precision Score ': 0.7439516129032258, 'Recall Score ': 0.7492509363295881, 'F1 Score ': 0.7465036584236362}, 18: {'Precision Score ': 0.7336309523809523, 'Recall Score ': 0.6896135265700483, 'F1 Score ': 0.7074468085106382}, 19: {'Precision Score ': 0.7472222222222222, 'Recall Score ': 0.7315447154471545, 'F1 Score ': 0.7375785504817765}, 20: {'Precision Score ': 0.675891181988743, 'Recall Score ': 0.65625, 'F1 Score ': 0.6649029982363316}, 21: {'Precision Score ': 0.7504201680672269, 'Recall Score ': 0.7504201680672269, 'F1 Score ': 0.7504201680672269}, 22: {'Precision Score ': 0.7797619047619048, 'Recall Score ': 0.8092105263157895, 'F1 Score ': 0.7920997920997921}, 23: {'Precision Score ': 0.7659883720930232, 'Recall Score ': 0.6737891737891738, 'F1 Score ': 0.7051611063587111}, 24: {'Precision Score ': 0.8210126582278481, 'Recall Score ': 0.8773809523809524, 'F1 Score ': 0.8440354464894342}, 25: {'Precision Score ': 0.9106518282988871, 'Recall Score ': 0.8989805375347544, 'F1 Score ': 0.9044486215538847}, 26: {'Precision Score ': 0.6995495495495496, 'Recall Score ': 0.7397186147186148, 'F1 Score ': 0.7162129016433653}, 27: {'Precision Score ': 0.5054945054945055, 'Recall Score ': 0.5054945054945055, 'F1 Score ': 0.5054945054945055}, 28: {'Precision Score ': 0.743421052631579, 'Recall Score ': 0.8297373358348968, 'F1 Score ': 0.7745253164556962}, 29: {'Precision Score ': 0.596078431372549, 'Recall Score ': 0.603750756200847, 'F1 Score ': 0.5994186046511627}, 30: {'Precision Score ': 0.7202694565708264, 'Recall Score ': 0.7037385129490392, 'F1 Score ': 0.7101279298460872}, 31: {'Precision Score ': 0.5649350649350648, 'Recall Score ': 0.5729166666666666, 'F1 Score ': 0.5678588926996571}, 32: {'Precision Score ': 0.7730263157894737, 'Recall Score ': 0.8001808318264014, 'F1 Score ': 0.7849462365591398}, 33: {'Precision Score ': 0.6702380952380953, 'Recall Score ': 0.6869281045751634, 'F1 Score ': 0.6779819370912489}, 34: {'Precision Score ': 0.6990243902439024, 'Recall Score ': 0.7111801242236024, 'F1 Score ': 0.7045682730923695}, 35: {'Precision Score ': 0.5892857142857143, 'Recall Score ': 0.5856055802155993, 'F1 Score ': 0.5873118627609645}, 36: {'Precision Score ': 0.7577422577422577, 'Recall Score ': 0.6706349206349206, 'F1 Score ': 0.6985221674876847}, 37: {'Precision Score ': 0.8956043956043955, 'Recall Score ': 0.7441860465116279, 'F1 Score ': 0.7960154623847755}, 38: {'Precision Score ': 0.8317384370015949, 'Recall Score ': 0.8466666666666667, 'F1 Score ': 0.8366517675741569}, 39: {'Precision Score ': 0.6720321931589537, 'Recall Score ': 0.7220779220779221, 'F1 Score ': 0.6891891891891893}, 40: {'Precision Score ': 0.8135521885521886, 'Recall Score ': 0.792156862745098, 'F1 Score ': 0.8017442450055775}, 41: {'Precision Score ': 0.6687312312312312, 'Recall Score ': 0.6628229896160347, 'F1 Score ': 0.6636853712325411}, 42: {'Precision Score ': 0.6259124087591241, 'Recall Score ': 0.6304101304101304, 'F1 Score ': 0.6275974025974027}, 43: {'Precision Score ': 0.7686150409530901, 'Recall Score ': 0.7686150409530901, 'F1 Score ': 0.7686150409530901}, 44: {'Precision Score ': 0.8309871703492516, 'Recall Score ': 0.8292272243885147, 'F1 Score ': 0.8300679728108756}, 45: {'Precision Score ': 0.901707779886148, 'Recall Score ': 0.9195402298850575, 'F1 Score ': 0.9100775193798449}, 46: {'Precision Score ': 0.7098873591989987, 'Recall Score ': 0.7093632958801498, 'F1 Score ': 0.7092703648175912}, 47: {'Precision Score ': 0.8161535029004908, 'Recall Score ': 0.8016177096636867, 'F1 Score ': 0.8083623693379791}, 48: {'Precision Score ': 0.6490723804546643, 'Recall Score ': 0.6529080675422139, 'F1 Score ': 0.6507936507936508}, 49: {'Precision Score ': 0.7956495098039216, 'Recall Score ': 0.7330917874396135, 'F1 Score ': 0.7569892473118278}, 50: {'Precision Score ': 0.6845238095238095, 'Recall Score ': 0.6803074366431243, 'F1 Score ': 0.6823195713835488}, 51: {'Precision Score ': 0.652948402948403, 'Recall Score ': 0.6773504273504274, 'F1 Score ': 0.660688901038819}, 52: {'Precision Score ': 0.7502210433244916, 'Recall Score ': 0.7502210433244916, 'F1 Score ': 0.7502210433244916}, 53: {'Precision Score ': 0.7384321653189578, 'Recall Score ': 0.7384321653189578, 'F1 Score ': 0.7384321653189578}, 54: {'Precision Score ': 0.6692567567567567, 'Recall Score ': 0.6807359307359307, 'F1 Score ': 0.6738675958188152}, 55: {'Precision Score ': 0.6599025974025974, 'Recall Score ': 0.6413199426111909, 'F1 Score ': 0.6478178368121442}, 56: {'Precision Score ': 0.6835294117647059, 'Recall Score ': 0.6785714285714286, 'F1 Score ': 0.6809374637428935}, 57: {'Precision Score ': 0.6224747474747474, 'Recall Score ': 0.6205343274308792, 'F1 Score ': 0.6214481409001956}, 58: {'Precision Score ': 0.7278525868178597, 'Recall Score ': 0.741185296324081, 'F1 Score ': 0.7337278106508875}, 59: {'Precision Score ': 0.6959459459459459, 'Recall Score ': 0.7308519793459552, 'F1 Score ': 0.7063204311611955}, 60: {'Precision Score ': 0.7418954996186118, 'Recall Score ': 0.7465021375825884, 'F1 Score ': 0.7424264246963368}, 61: {'Precision Score ': 0.6806277056277057, 'Recall Score ': 0.6910485347985349, 'F1 Score ': 0.6838280166435506}, 62: {'Precision Score ': 0.7862700803212852, 'Recall Score ': 0.7862700803212852, 'F1 Score ': 0.7862700803212851}, 63: {'Precision Score ': 0.8522875816993464, 'Recall Score ': 0.8454242501922584, 'F1 Score ': 0.8486024844720497}, 64: {'Precision Score ': 0.8352534562211982, 'Recall Score ': 0.8500400962309542, 'F1 Score ': 0.842156862745098}, 65: {'Precision Score ': 0.810104052573932, 'Recall Score ': 0.8348610289769367, 'F1 Score ': 0.819909245604084}, 66: {'Precision Score ': 0.794439935064935, 'Recall Score ': 0.789274322169059, 'F1 Score ': 0.79175465057818}, 67: {'Precision Score ': 0.7237547892720306, 'Recall Score ': 0.710576923076923, 'F1 Score ': 0.7147972097043027}, 68: {'Precision Score ': 0.7640692640692641, 'Recall Score ': 0.7593537414965986, 'F1 Score ': 0.7605482972799316}, 69: {'Precision Score ': 0.7003484320557491, 'Recall Score ': 0.6916666666666667, 'F1 Score ': 0.6956151553852703}, 70: {'Precision Score ': 0.7980392156862746, 'Recall Score ': 0.7317073170731707, 'F1 Score ': 0.7587681779298546}, 71: {'Precision Score ': 0.9437927663734116, 'Recall Score ': 0.911231884057971, 'F1 Score ': 0.9266745005875441}, 72: {'Precision Score ': 0.8871517027863778, 'Recall Score ': 0.8719512195121951, 'F1 Score ': 0.878799363298719}, 73: {'Precision Score ': 0.9371035940803383, 'Recall Score ': 0.8786630036630036, 'F1 Score ': 0.9049019607843137}, 74: {'Precision Score ': 0.8192333113020489, 'Recall Score ': 0.8049242424242424, 'F1 Score ': 0.8117836965294593}, 75: {'Precision Score ': 0.718052738336714, 'Recall Score ': 0.81524926686217, 'F1 Score ': 0.7523809523809524}, 76: {'Precision Score ': 0.7401823281907434, 'Recall Score ': 0.7329931972789117, 'F1 Score ': 0.7361518550474547}, 77: {'Precision Score ': 0.8081414748081415, 'Recall Score ': 0.8292335115864528, 'F1 Score ': 0.8172117039586919}, 78: {'Precision Score ': 0.8841652323580035, 'Recall Score ': 0.8907563025210083, 'F1 Score ': 0.8873557233359368}, 79: {'Precision Score ': 0.8868727598566308, 'Recall Score ': 0.8707997852925389, 'F1 Score ': 0.8767194464954741}, 80: {'Precision Score ': 0.8121850664223547, 'Recall Score ': 0.809631985461154, 'F1 Score ': 0.8104873183243091}, 81: {'Precision Score ': 0.7444444444444445, 'Recall Score ': 0.7104890148830616, 'F1 Score ': 0.7228276319529992}, 82: {'Precision Score ': 0.8152631578947369, 'Recall Score ': 0.8403409090909091, 'F1 Score ': 0.8254429804634258}, 83: {'Precision Score ': 0.8080720092915215, 'Recall Score ': 0.811783720246841, 'F1 Score ': 0.809857612267251}, 84: {'Precision Score ': 0.7758928571428572, 'Recall Score ': 0.772887842213718, 'F1 Score ': 0.7743248242693304}, 85: {'Precision Score ': 0.895, 'Recall Score ': 0.9089026915113871, 'F1 Score ': 0.9009146341463414}, 86: {'Precision Score ': 0.7324695121951219, 'Recall Score ': 0.7214960058097313, 'F1 Score ': 0.7267150027886224}, 87: {'Precision Score ': 0.6961444308445532, 'Recall Score ': 0.7250702247191011, 'F1 Score ': 0.7085714285714284}, 88: {'Precision Score ': 0.7364705882352941, 'Recall Score ': 0.8178368121442126, 'F1 Score ': 0.7645799892990904}, 89: {'Precision Score ': 0.9292550977944236, 'Recall Score ': 0.8914611005692599, 'F1 Score ': 0.9080459770114943}, 90: {'Precision Score ': 0.8095238095238095, 'Recall Score ': 0.8401162790697674, 'F1 Score ': 0.8235294117647058}, 91: {'Precision Score ': 0.8188502673796791, 'Recall Score ': 0.8045977011494252, 'F1 Score ': 0.8114285714285714}, 92: {'Precision Score ': 0.8941860465116279, 'Recall Score ': 0.9484126984126984, 'F1 Score ': 0.9177371541501975}, 93: {'Precision Score ': 0.8633655994043187, 'Recall Score ': 0.88125, 'F1 Score ': 0.8719268153230417}, 94: {'Precision Score ': 0.6082317073170731, 'Recall Score ': 0.6152597402597403, 'F1 Score ': 0.611314824515453}, 95: {'Precision Score ': 0.751984126984127, 'Recall Score ': 0.7323170731707318, 'F1 Score ': 0.741280913126189}, 96: {'Precision Score ': 0.8177083333333333, 'Recall Score ': 0.8696969696969697, 'F1 Score ': 0.8405594405594405}, 97: {'Precision Score ': 0.949343339587242, 'Recall Score ': 0.9223985890652557, 'F1 Score ': 0.9352419904567144}, 98: {'Precision Score ': 0.9780219780219781, 'Recall Score ': 0.8181818181818181, 'F1 Score ': 0.877652933832709}, 99: {'Precision Score ': 0.941029900332226, 'Recall Score ': 0.8763288447909283, 'F1 Score ': 0.9045619393013934}, 100: {'Precision Score ': 0.938949938949939, 'Recall Score ': 0.9597186700767264, 'F1 Score ': 0.9489461358313818}, 101: {'Precision Score ': 0.9110486891385767, 'Recall Score ': 0.9434343434343434, 'F1 Score ': 0.9264027204274958}, 102: {'Precision Score ': 0.9065934065934066, 'Recall Score ': 0.8637640449438202, 'F1 Score ': 0.8833333333333333}, 103: {'Precision Score ': 0.9202380952380953, 'Recall Score ': 0.8151785714285715, 'F1 Score ': 0.8567073170731707}, 104: {'Precision Score ': 0.6356181665264928, 'Recall Score ': 0.6379679144385026, 'F1 Score ': 0.6364792538816173}, 105: {'Precision Score ': 0.6635658914728682, 'Recall Score ': 0.6803418803418804, 'F1 Score ': 0.6704545454545454}, 106: {'Precision Score ': 0.9062229904926534, 'Recall Score ': 0.9177777777777778, 'F1 Score ': 0.9118194763939096}, 107: {'Precision Score ': 0.7013052208835342, 'Recall Score ': 0.6772767462422635, 'F1 Score ': 0.6865111918434315}, 108: {'Precision Score ': 0.6697936210131332, 'Recall Score ': 0.6913319238900635, 'F1 Score ': 0.6785714285714286}, 109: {'Precision Score ': 0.6294372294372295, 'Recall Score ': 0.6294372294372295, 'F1 Score ': 0.6294372294372295}, 110: {'Precision Score ': 0.7178921568627451, 'Recall Score ': 0.7322361546499478, 'F1 Score ': 0.724469160768453}, 111: {'Precision Score ': 0.7130030959752323, 'Recall Score ': 0.686046511627907, 'F1 Score ': 0.6945540647198105}, 112: {'Precision Score ': 0.7815524583817266, 'Recall Score ': 0.7826467158958414, 'F1 Score ': 0.782060606060606}, 113: {'Precision Score ': 0.6534090909090908, 'Recall Score ': 0.6651595744680852, 'F1 Score ': 0.6575517505750064}, 114: {'Precision Score ': 0.6829710144927537, 'Recall Score ': 0.6449067431850789, 'F1 Score ': 0.6551724137931035}, 115: {'Precision Score ': 0.6474875335634829, 'Recall Score ': 0.653126244524094, 'F1 Score ': 0.65}, 116: {'Precision Score ': 0.7515212981744421, 'Recall Score ': 0.7574750830564785, 'F1 Score ': 0.7543859649122807}, 117: {'Precision Score ': 0.6683982683982683, 'Recall Score ': 0.695281124497992, 'F1 Score ': 0.6780092592592593}, 118: {'Precision Score ': 0.7454475308641975, 'Recall Score ': 0.7456750077232005, 'F1 Score ': 0.7453023112242929}, 119: {'Precision Score ': 0.5585197934595525, 'Recall Score ': 0.5607142857142857, 'F1 Score ': 0.559515116109245}, 120: {'Precision Score ': 0.6004016064257028, 'Recall Score ': 0.6050420168067226, 'F1 Score ': 0.6025662959794696}, 121: {'Precision Score ': 0.6132218844984803, 'Recall Score ': 0.6056362991846862, 'F1 Score ': 0.60879523591388}, 122: {'Precision Score ': 0.5846385542168675, 'Recall Score ': 0.5788439955106621, 'F1 Score ': 0.5813008130081301}, 123: {'Precision Score ': 0.5944872009369249, 'Recall Score ': 0.5968364197530864, 'F1 Score ': 0.5953323035906984}, 124: {'Precision Score ': 0.7199690002583312, 'Recall Score ': 0.7387160078497337, 'F1 Score ': 0.7258366800535475}, 125: {'Precision Score ': 0.7052424639580603, 'Recall Score ': 0.6987814166031988, 'F1 Score ': 0.7005148005148005}, 126: {'Precision Score ': 0.681159420289855, 'Recall Score ': 0.6914539400665927, 'F1 Score ': 0.6768149882903982}, 127: {'Precision Score ': 0.6678571428571429, 'Recall Score ': 0.6475545274289491, 'F1 Score ': 0.6549789621318374}, 128: {'Precision Score ': 0.6739130434782609, 'Recall Score ': 0.7119815668202765, 'F1 Score ': 0.6778711484593838}, 129: {'Precision Score ': 0.7921842650103519, 'Recall Score ': 0.7894129710330684, 'F1 Score ': 0.7907410984482648}, 130: {'Precision Score ': 0.6931153184165233, 'Recall Score ': 0.7038517441860466, 'F1 Score ': 0.6977832729841915}, 131: {'Precision Score ': 0.7438322368421053, 'Recall Score ': 0.7506869583597549, 'F1 Score ': 0.7453090077446851}, 132: {'Precision Score ': 0.6934065934065934, 'Recall Score ': 0.691304347826087, 'F1 Score ': 0.692286676987524}, 133: {'Precision Score ': 0.7206959706959707, 'Recall Score ': 0.7225642604278898, 'F1 Score ': 0.7209355740152357}, 134: {'Precision Score ': 0.8245341614906833, 'Recall Score ': 0.8245341614906833, 'F1 Score ': 0.8245341614906833}, 135: {'Precision Score ': 0.7689144736842105, 'Recall Score ': 0.7484802431610942, 'F1 Score ': 0.7578947368421052}, 136: {'Precision Score ': 0.8210227272727273, 'Recall Score ': 0.8385767790262172, 'F1 Score ': 0.82941498086386}, 137: {'Precision Score ': 0.8985807214665877, 'Recall Score ': 0.8829545454545455, 'F1 Score ': 0.8904823989569752}, 138: {'Precision Score ': 0.6470588235294118, 'Recall Score ': 0.6470588235294118, 'F1 Score ': 0.6470588235294118}, 139: {'Precision Score ': 0.6409883720930232, 'Recall Score ': 0.6840607210626186, 'F1 Score ': 0.6552663850660854}, 140: {'Precision Score ': 0.9053156146179402, 'Recall Score ': 0.8630952380952381, 'F1 Score ': 0.8823529411764706}, 141: {'Precision Score ': 0.6983805668016194, 'Recall Score ': 0.7390243902439024, 'F1 Score ': 0.7147058823529412}, 142: {'Precision Score ': 0.8249158249158248, 'Recall Score ': 0.8169129720853858, 'F1 Score ': 0.8207792207792208}, 143: {'Precision Score ': 0.8510971786833856, 'Recall Score ': 0.8360840210052514, 'F1 Score ': 0.8431034482758621}, 144: {'Precision Score ': 0.6428571428571429, 'Recall Score ': 0.6341269841269841, 'F1 Score ': 0.6382238592183344}, 145: {'Precision Score ': 0.5909090909090908, 'Recall Score ': 0.6033755274261603, 'F1 Score ': 0.5961538461538461}, 146: {'Precision Score ': 0.7094448449891853, 'Recall Score ': 0.7828627069133398, 'F1 Score ': 0.7351973684210527}, 147: {'Precision Score ': 0.6875593542260209, 'Recall Score ': 0.6875593542260209, 'F1 Score ': 0.6875593542260209}, 148: {'Precision Score ': 0.7922794117647058, 'Recall Score ': 0.806712962962963, 'F1 Score ': 0.7991718426501035}, 149: {'Precision Score ': 0.609704641350211, 'Recall Score ': 0.6025641025641026, 'F1 Score ': 0.6058598726114649}, 150: {'Precision Score ': 0.7412445278298937, 'Recall Score ': 0.7446100190234624, 'F1 Score ': 0.7428571428571429}, 151: {'Precision Score ': 0.8484042553191489, 'Recall Score ': 0.8051242236024845, 'F1 Score ': 0.8246484698097603}, 152: {'Precision Score ': 0.7296015180265655, 'Recall Score ': 0.6875, 'F1 Score ': 0.7039240685649526}, 153: {'Precision Score ': 0.8355464759959141, 'Recall Score ': 0.790450928381963, 'F1 Score ': 0.8106060606060606}, 154: {'Precision Score ': 0.75, 'Recall Score ': 0.7361359570661896, 'F1 Score ': 0.7425287356321839}, 155: {'Precision Score ': 0.8053743398570985, 'Recall Score ': 0.8212418300653594, 'F1 Score ': 0.8125248667144108}, 156: {'Precision Score ': 0.7362637362637363, 'Recall Score ': 0.7362637362637363, 'F1 Score ': 0.7362637362637363}, 157: {'Precision Score ': 0.8328313253012047, 'Recall Score ': 0.8328313253012047, 'F1 Score ': 0.8328313253012047}, 158: {'Precision Score ': 0.7295552367288378, 'Recall Score ': 0.7295552367288378, 'F1 Score ': 0.7295552367288378}, 159: {'Precision Score ': 0.6971571906354515, 'Recall Score ': 0.6935960591133005, 'F1 Score ': 0.6946410097248086}, 160: {'Precision Score ': 0.6722222222222223, 'Recall Score ': 0.6482990786676116, 'F1 Score ': 0.656306263621719}, 161: {'Precision Score ': 0.8403866248693834, 'Recall Score ': 0.8102380952380952, 'F1 Score ': 0.8236904317531418}, 162: {'Precision Score ': 0.7820401046207498, 'Recall Score ': 0.8149951314508277, 'F1 Score ': 0.7953216374269005}, 163: {'Precision Score ': 0.7044334975369457, 'Recall Score ': 0.7092436974789915, 'F1 Score ': 0.7067372573445448}, 164: {'Precision Score ': 0.745608327911516, 'Recall Score ': 0.7422459893048128, 'F1 Score ': 0.743755383290267}, 165: {'Precision Score ': 0.7467774762550883, 'Recall Score ': 0.7993827160493827, 'F1 Score ': 0.7567567567567568}, 166: {'Precision Score ': 0.7802564102564102, 'Recall Score ': 0.7957251082251082, 'F1 Score ': 0.7873684210526315}, 167: {'Precision Score ': 0.7626823081800889, 'Recall Score ': 0.770751633986928, 'F1 Score ': 0.7664092664092664}, 168: {'Precision Score ': 0.815625, 'Recall Score ': 0.8284552845528456, 'F1 Score ': 0.8215850258861012}}\n"
     ]
    }
   ],
   "source": [
    "result_history = run_model(model_type = \"DT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = open(\"binary_decision_tree_result\", \"wb\")\n",
    "# pickle.dump(result_history, f)\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"binary_decision_tree_result\", \"rb\")\n",
    "l = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = {k: v for k, v in sorted(l.items(), key=lambda item: item[1][\"F1 Score \"], reverse = True)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100  =  {'Precision Score ': 0.938949938949939, 'Recall Score ': 0.9597186700767264, 'F1 Score ': 0.9489461358313818}\n",
      "97  =  {'Precision Score ': 0.949343339587242, 'Recall Score ': 0.9223985890652557, 'F1 Score ': 0.9352419904567144}\n",
      "71  =  {'Precision Score ': 0.9437927663734116, 'Recall Score ': 0.911231884057971, 'F1 Score ': 0.9266745005875441}\n",
      "101  =  {'Precision Score ': 0.9110486891385767, 'Recall Score ': 0.9434343434343434, 'F1 Score ': 0.9264027204274958}\n",
      "92  =  {'Precision Score ': 0.8941860465116279, 'Recall Score ': 0.9484126984126984, 'F1 Score ': 0.9177371541501975}\n",
      "106  =  {'Precision Score ': 0.9062229904926534, 'Recall Score ': 0.9177777777777778, 'F1 Score ': 0.9118194763939096}\n",
      "45  =  {'Precision Score ': 0.901707779886148, 'Recall Score ': 0.9195402298850575, 'F1 Score ': 0.9100775193798449}\n",
      "89  =  {'Precision Score ': 0.9292550977944236, 'Recall Score ': 0.8914611005692599, 'F1 Score ': 0.9080459770114943}\n",
      "73  =  {'Precision Score ': 0.9371035940803383, 'Recall Score ': 0.8786630036630036, 'F1 Score ': 0.9049019607843137}\n",
      "99  =  {'Precision Score ': 0.941029900332226, 'Recall Score ': 0.8763288447909283, 'F1 Score ': 0.9045619393013934}\n",
      "25  =  {'Precision Score ': 0.9106518282988871, 'Recall Score ': 0.8989805375347544, 'F1 Score ': 0.9044486215538847}\n",
      "85  =  {'Precision Score ': 0.895, 'Recall Score ': 0.9089026915113871, 'F1 Score ': 0.9009146341463414}\n",
      "137  =  {'Precision Score ': 0.8985807214665877, 'Recall Score ': 0.8829545454545455, 'F1 Score ': 0.8904823989569752}\n",
      "78  =  {'Precision Score ': 0.8841652323580035, 'Recall Score ': 0.8907563025210083, 'F1 Score ': 0.8873557233359368}\n",
      "102  =  {'Precision Score ': 0.9065934065934066, 'Recall Score ': 0.8637640449438202, 'F1 Score ': 0.8833333333333333}\n",
      "140  =  {'Precision Score ': 0.9053156146179402, 'Recall Score ': 0.8630952380952381, 'F1 Score ': 0.8823529411764706}\n",
      "72  =  {'Precision Score ': 0.8871517027863778, 'Recall Score ': 0.8719512195121951, 'F1 Score ': 0.878799363298719}\n",
      "98  =  {'Precision Score ': 0.9780219780219781, 'Recall Score ': 0.8181818181818181, 'F1 Score ': 0.877652933832709}\n",
      "79  =  {'Precision Score ': 0.8868727598566308, 'Recall Score ': 0.8707997852925389, 'F1 Score ': 0.8767194464954741}\n",
      "93  =  {'Precision Score ': 0.8633655994043187, 'Recall Score ': 0.88125, 'F1 Score ': 0.8719268153230417}\n"
     ]
    }
   ],
   "source": [
    "# Top 20 playlists \n",
    "for key in list(l.keys())[:20]:\n",
    "    print(key,\" = \",  l[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Random Forest Result'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Random Forest Result\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                        | 33/169 [02:46<10:55,  4.82s/it]C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Progress :  23%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                     | 39/169 [03:15<10:09,  4.69s/it]C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Progress :  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                    | 119/169 [09:37<03:36,  4.33s/it]C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Progress :  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š        | 149/169 [11:45<01:25,  4.29s/it]C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Progress : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 169/169 [13:07<00:00,  4.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {'Precision Score ': 0.9521276595744681, 'Recall Score ': 0.6538461538461539, 'F1 Score ': 0.7101544528425896}, 1: {'Precision Score ': 0.9423076923076923, 'Recall Score ': 0.625, 'F1 Score ': 0.6693877551020408}, 2: {'Precision Score ': 0.9368932038834952, 'Recall Score ': 0.5666666666666667, 'F1 Score ': 0.5839683023468454}, 3: {'Precision Score ': 0.8964285714285715, 'Recall Score ': 0.8203463203463204, 'F1 Score ': 0.8488172327210255}, 4: {'Precision Score ': 0.8918128654970761, 'Recall Score ': 0.7164082687338501, 'F1 Score ': 0.7659095559648046}, 5: {'Precision Score ': 0.9602272727272727, 'Recall Score ': 0.7307692307692308, 'F1 Score ': 0.7950794145126129}, 6: {'Precision Score ': 0.9728260869565217, 'Recall Score ': 0.7727272727272727, 'F1 Score ': 0.8389746960236608}, 7: {'Precision Score ': 0.9527153558052435, 'Recall Score ': 0.9527153558052435, 'F1 Score ': 0.9527153558052435}, 8: {'Precision Score ': 0.781786941580756, 'Recall Score ': 0.5776515151515151, 'F1 Score ': 0.6036036036036035}, 9: {'Precision Score ': 0.912608225108225, 'Recall Score ': 0.853336422613531, 'F1 Score ': 0.8779395296752519}, 10: {'Precision Score ': 0.7595588235294117, 'Recall Score ': 0.6595840867992767, 'F1 Score ': 0.6906873614190687}, 11: {'Precision Score ': 0.8075268817204301, 'Recall Score ': 0.7267441860465116, 'F1 Score ': 0.7553978559565151}, 12: {'Precision Score ': 0.8591836734693878, 'Recall Score ': 0.7838709677419355, 'F1 Score ': 0.8140613313388183}, 13: {'Precision Score ': 0.8410165484633569, 'Recall Score ': 0.7072557471264368, 'F1 Score ': 0.7496132596685083}, 14: {'Precision Score ': 0.8211805555555556, 'Recall Score ': 0.663235294117647, 'F1 Score ': 0.6999428462564298}, 15: {'Precision Score ': 0.8802083333333334, 'Recall Score ': 0.7831286360698125, 'F1 Score ': 0.8207634150839019}, 16: {'Precision Score ': 0.827922077922078, 'Recall Score ': 0.827922077922078, 'F1 Score ': 0.827922077922078}, 17: {'Precision Score ': 0.7564979480164159, 'Recall Score ': 0.7777777777777777, 'F1 Score ': 0.765625}, 18: {'Precision Score ': 0.8523102310231023, 'Recall Score ': 0.633270911360799, 'F1 Score ': 0.6714912280701755}, 19: {'Precision Score ': 0.8156634746922025, 'Recall Score ': 0.7849644952145725, 'F1 Score ': 0.7963636363636364}, 20: {'Precision Score ': 0.7619047619047619, 'Recall Score ': 0.5603375527426161, 'F1 Score ': 0.5699346405228758}, 21: {'Precision Score ': 0.9393939393939394, 'Recall Score ': 0.5714285714285714, 'F1 Score ': 0.592741935483871}, 22: {'Precision Score ': 0.9367816091954023, 'Recall Score ': 0.7708333333333333, 'F1 Score ': 0.8176090200630078}, 23: {'Precision Score ': 0.7735507246376812, 'Recall Score ': 0.5708255159474671, 'F1 Score ': 0.5905172413793103}, 24: {'Precision Score ': 0.8850931677018633, 'Recall Score ': 0.7883720930232558, 'F1 Score ': 0.8248512888301387}, 25: {'Precision Score ': 0.8533333333333333, 'Recall Score ': 0.8576248313090418, 'F1 Score ': 0.8553944169670551}, 26: {'Precision Score ': 0.9444444444444444, 'Recall Score ': 0.5833333333333334, 'F1 Score ': 0.6134453781512605}, 27: {'Precision Score ': 0.941747572815534, 'Recall Score ': 0.5714285714285714, 'F1 Score ': 0.5940721649484536}, 28: {'Precision Score ': 0.9655172413793103, 'Recall Score ': 0.7692307692307692, 'F1 Score ': 0.8321428571428572}, 29: {'Precision Score ': 0.6705607476635513, 'Recall Score ': 0.5417620137299771, 'F1 Score ': 0.5392178282717937}, 30: {'Precision Score ': 0.8329081632653061, 'Recall Score ': 0.7638076673164392, 'F1 Score ': 0.784482587163627}, 31: {'Precision Score ': 0.7070626003210272, 'Recall Score ': 0.5918803418803419, 'F1 Score ': 0.6091017964071856}, 32: {'Precision Score ': 0.9104020979020979, 'Recall Score ': 0.7794642857142857, 'F1 Score ': 0.8231792717086834}, 33: {'Precision Score ': 0.4536082474226804, 'Recall Score ': 0.5, 'F1 Score ': 0.4756756756756757}, 34: {'Precision Score ': 0.8823232323232323, 'Recall Score ': 0.7109810479375697, 'F1 Score ': 0.7524509803921569}, 35: {'Precision Score ': 0.7552083333333333, 'Recall Score ': 0.5932149651236525, 'F1 Score ': 0.612513966480447}, 36: {'Precision Score ': 0.9253663003663004, 'Recall Score ': 0.8177154582763337, 'F1 Score ': 0.8595363335281512}, 37: {'Precision Score ': 0.8577586206896552, 'Recall Score ': 0.8577586206896552, 'F1 Score ': 0.8577586206896552}, 38: {'Precision Score ': 0.8966068355052864, 'Recall Score ': 0.8934146341463415, 'F1 Score ': 0.8949494949494949}, 39: {'Precision Score ': 0.42105263157894735, 'Recall Score ': 0.5, 'F1 Score ': 0.45714285714285713}, 40: {'Precision Score ': 0.8804347826086956, 'Recall Score ': 0.8156862745098039, 'F1 Score ': 0.8406353267242297}, 41: {'Precision Score ': 0.7609715880263825, 'Recall Score ': 0.7546410891089108, 'F1 Score ': 0.7566063107858774}, 42: {'Precision Score ': 0.7368881118881119, 'Recall Score ': 0.6759740259740259, 'F1 Score ': 0.6885964912280702}, 43: {'Precision Score ': 0.8296255098257324, 'Recall Score ': 0.8112745098039216, 'F1 Score ': 0.8195231668915879}, 44: {'Precision Score ': 0.8737745098039216, 'Recall Score ': 0.8587029569892473, 'F1 Score ': 0.8647491867830851}, 45: {'Precision Score ': 0.92357910906298, 'Recall Score ': 0.942261427425822, 'F1 Score ': 0.9323529411764706}, 46: {'Precision Score ': 0.7871073961499493, 'Recall Score ': 0.7862373737373738, 'F1 Score ': 0.7862740141557129}, 47: {'Precision Score ': 0.7577519379844961, 'Recall Score ': 0.7264793529161345, 'F1 Score ': 0.7390125409558241}, 48: {'Precision Score ': 0.8159090909090909, 'Recall Score ': 0.6904631405864621, 'F1 Score ': 0.7108493286102644}, 49: {'Precision Score ': 0.9207482993197279, 'Recall Score ': 0.798792270531401, 'F1 Score ': 0.8418253079507279}, 50: {'Precision Score ': 0.8202687569988802, 'Recall Score ': 0.7348111658456487, 'F1 Score ': 0.761938202247191}, 51: {'Precision Score ': 0.7212430426716141, 'Recall Score ': 0.6105189990732159, 'F1 Score ': 0.6256532775869792}, 52: {'Precision Score ': 0.8003246753246753, 'Recall Score ': 0.7642857142857142, 'F1 Score ': 0.7795753286147624}, 53: {'Precision Score ': 0.8415770609318997, 'Recall Score ': 0.8173140954495005, 'F1 Score ': 0.8259573492318275}, 54: {'Precision Score ': 0.8971535982814178, 'Recall Score ': 0.7667748917748918, 'F1 Score ': 0.8021978021978022}, 55: {'Precision Score ': 0.8296255098257324, 'Recall Score ': 0.8112745098039216, 'F1 Score ': 0.8195231668915879}, 56: {'Precision Score ': 0.7720364741641337, 'Recall Score ': 0.6679174484052532, 'F1 Score ': 0.6931818181818181}, 57: {'Precision Score ': 0.8333333333333334, 'Recall Score ': 0.7477983601579108, 'F1 Score ': 0.7728950304694877}, 58: {'Precision Score ': 0.8631818181818182, 'Recall Score ': 0.8143194335169157, 'F1 Score ': 0.8338235294117646}, 59: {'Precision Score ': 0.9317460317460318, 'Recall Score ': 0.851118760757315, 'F1 Score ': 0.8821517046124809}, 60: {'Precision Score ': 0.8431122448979592, 'Recall Score ': 0.8301192145862553, 'F1 Score ': 0.8351471900089207}, 61: {'Precision Score ': 0.8237873389969854, 'Recall Score ': 0.8028710587028967, 'F1 Score ': 0.811046511627907}, 62: {'Precision Score ': 0.8660714285714286, 'Recall Score ': 0.8344628514056225, 'F1 Score ': 0.8460031347962382}, 63: {'Precision Score ': 0.833376057421174, 'Recall Score ': 0.833376057421174, 'F1 Score ': 0.833376057421174}, 64: {'Precision Score ': 0.8783333333333333, 'Recall Score ': 0.8403298350824588, 'F1 Score ': 0.8569739952718676}, 65: {'Precision Score ': 0.8589663760896638, 'Recall Score ': 0.8840772818121252, 'F1 Score ': 0.8685815147625161}, 66: {'Precision Score ': 0.854065934065934, 'Recall Score ': 0.7940854326396495, 'F1 Score ': 0.8160919540229885}, 67: {'Precision Score ': 0.8539180072651791, 'Recall Score ': 0.8160333642261353, 'F1 Score ': 0.8277747402952432}, 68: {'Precision Score ': 0.8223270440251573, 'Recall Score ': 0.8137755102040816, 'F1 Score ': 0.8163054695562435}, 69: {'Precision Score ': 0.8006787330316743, 'Recall Score ': 0.7734567901234568, 'F1 Score ': 0.7850688468158347}, 70: {'Precision Score ': 0.8611111111111112, 'Recall Score ': 0.7801724137931034, 'F1 Score ': 0.8135593220338984}, 71: {'Precision Score ': 0.9173951048951049, 'Recall Score ': 0.9470973782771535, 'F1 Score ': 0.9315254237288135}, 72: {'Precision Score ': 0.9403304773561811, 'Recall Score ': 0.9499687304565353, 'F1 Score ': 0.9448051948051949}, 73: {'Precision Score ': 0.7852147852147853, 'Recall Score ': 0.7467588591184097, 'F1 Score ': 0.7638888888888888}, 74: {'Precision Score ': 0.8386970172684458, 'Recall Score ': 0.7468535469107551, 'F1 Score ': 0.7809210526315788}, 75: {'Precision Score ': 0.96875, 'Recall Score ': 0.7272727272727273, 'F1 Score ': 0.7963709677419355}, 76: {'Precision Score ': 0.7308263236021771, 'Recall Score ': 0.7163729128014842, 'F1 Score ': 0.7218107978977546}, 77: {'Precision Score ': 0.8186046511627907, 'Recall Score ': 0.7616501145912911, 'F1 Score ': 0.7807008422585007}, 78: {'Precision Score ': 0.8455517373043147, 'Recall Score ': 0.7957516339869282, 'F1 Score ': 0.8152011922503726}, 79: {'Precision Score ': 0.9231720010408535, 'Recall Score ': 0.9040372670807453, 'F1 Score ': 0.9119634529361378}, 80: {'Precision Score ': 0.8474295190713101, 'Recall Score ': 0.8510682865521575, 'F1 Score ': 0.8481348525050725}, 81: {'Precision Score ': 0.8980614973262032, 'Recall Score ': 0.8980614973262032, 'F1 Score ': 0.8980614973262032}, 82: {'Precision Score ': 0.8098455598455598, 'Recall Score ': 0.825689935064935, 'F1 Score ': 0.8168429376297321}, 83: {'Precision Score ': 0.8921188630490956, 'Recall Score ': 0.865552544414333, 'F1 Score ': 0.8766622598957929}, 84: {'Precision Score ': 0.8797704447632712, 'Recall Score ': 0.8708321658727936, 'F1 Score ': 0.875}, 85: {'Precision Score ': 0.916688028710587, 'Recall Score ': 0.916688028710587, 'F1 Score ': 0.916688028710587}, 86: {'Precision Score ': 0.81524926686217, 'Recall Score ': 0.718052738336714, 'F1 Score ': 0.7523809523809524}, 87: {'Precision Score ': 0.9314516129032258, 'Recall Score ': 0.8381320224719101, 'F1 Score ': 0.8763736263736264}, 88: {'Precision Score ': 0.8448426573426573, 'Recall Score ': 0.7762605042016807, 'F1 Score ': 0.8042635658914729}, 89: {'Precision Score ': 0.9886363636363636, 'Recall Score ': 0.967741935483871, 'F1 Score ': 0.9775862068965517}, 90: {'Precision Score ': 0.9164794007490638, 'Recall Score ': 0.8948863636363636, 'F1 Score ': 0.9052305449243667}, 91: {'Precision Score ': 0.8500000000000001, 'Recall Score ': 0.711352657004831, 'F1 Score ': 0.7544642857142857}, 92: {'Precision Score ': 0.9146825396825397, 'Recall Score ': 0.8686067019400352, 'F1 Score ': 0.8890442890442889}, 93: {'Precision Score ': 0.8995695839311334, 'Recall Score ': 0.9194277108433735, 'F1 Score ': 0.9090909090909092}, 94: {'Precision Score ': 0.7552083333333333, 'Recall Score ': 0.650383631713555, 'F1 Score ': 0.6760852407261246}, 95: {'Precision Score ': 0.820274914089347, 'Recall Score ': 0.7532608695652174, 'F1 Score ': 0.7798941798941799}, 96: {'Precision Score ': 0.8888888888888888, 'Recall Score ': 0.8218390804597702, 'F1 Score ': 0.8505963590709353}, 97: {'Precision Score ': 0.9314024390243902, 'Recall Score ': 0.9546184738955823, 'F1 Score ': 0.9425219941348973}, 98: {'Precision Score ': 0.8343891402714931, 'Recall Score ': 0.8861024033437827, 'F1 Score ': 0.8575581395348837}, 99: {'Precision Score ': 0.9050387596899225, 'Recall Score ': 0.9239350912778905, 'F1 Score ': 0.9141205615194055}, 100: {'Precision Score ': 0.9473684210526316, 'Recall Score ': 0.9893617021276595, 'F1 Score ': 0.9668458781362007}, 101: {'Precision Score ': 0.8271604938271604, 'Recall Score ': 0.9251336898395721, 'F1 Score ': 0.8665430954587581}, 102: {'Precision Score ': 0.9104166666666667, 'Recall Score ': 0.9504573170731707, 'F1 Score ': 0.9288307915758895}, 103: {'Precision Score ': 0.9002976190476191, 'Recall Score ': 0.9468438538205981, 'F1 Score ': 0.9215686274509804}, 104: {'Precision Score ': 0.7898936170212766, 'Recall Score ': 0.7831168831168831, 'F1 Score ': 0.7861076029300329}, 105: {'Precision Score ': 0.757766990291262, 'Recall Score ': 0.6173740053050398, 'F1 Score ': 0.6365497076023392}, 106: {'Precision Score ': 0.9045584045584045, 'Recall Score ': 0.9156097560975609, 'F1 Score ': 0.909900156381571}, 107: {'Precision Score ': 0.8210526315789474, 'Recall Score ': 0.7350912778904666, 'F1 Score ': 0.7625}, 108: {'Precision Score ': 0.8052631578947369, 'Recall Score ': 0.5844988344988346, 'F1 Score ': 0.5932348533504603}, 109: {'Precision Score ': 0.829017517136329, 'Recall Score ': 0.6714285714285714, 'F1 Score ': 0.6990571967316153}, 110: {'Precision Score ': 0.8386850152905199, 'Recall Score ': 0.6082600195503421, 'F1 Score ': 0.634016973125884}, 111: {'Precision Score ': 0.7429356357927785, 'Recall Score ': 0.6777203560149296, 'F1 Score ': 0.68877014006963}, 112: {'Precision Score ': 0.7772998595505618, 'Recall Score ': 0.7785714285714286, 'F1 Score ': 0.7778999692077597}, 113: {'Precision Score ': 0.798989898989899, 'Recall Score ': 0.7202380952380952, 'F1 Score ': 0.739386296763346}, 114: {'Precision Score ': 0.80125, 'Recall Score ': 0.672883787661406, 'F1 Score ': 0.6940659340659341}, 115: {'Precision Score ': 0.8134469696969697, 'Recall Score ': 0.7454579162031887, 'F1 Score ': 0.7688421486751211}, 116: {'Precision Score ': 0.9117826617826618, 'Recall Score ': 0.7973985890652557, 'F1 Score ': 0.8346814964610718}, 117: {'Precision Score ': 0.892156862745098, 'Recall Score ': 0.5416666666666666, 'F1 Score ': 0.5164835164835165}, 118: {'Precision Score ': 0.8047884841363102, 'Recall Score ': 0.8012048192771084, 'F1 Score ': 0.8006187443130117}, 119: {'Precision Score ': 0.40384615384615385, 'Recall Score ': 0.5, 'F1 Score ': 0.44680851063829785}, 120: {'Precision Score ': 0.929245283018868, 'Recall Score ': 0.5588235294117647, 'F1 Score ': 0.5671920919048892}, 121: {'Precision Score ': 0.7142857142857143, 'Recall Score ': 0.6195121951219512, 'F1 Score ': 0.6323232323232324}, 122: {'Precision Score ': 0.7712842712842713, 'Recall Score ': 0.6017316017316017, 'F1 Score ': 0.6205012247974373}, 123: {'Precision Score ': 0.8050913547237077, 'Recall Score ': 0.727980352980353, 'F1 Score ': 0.7417160106815279}, 124: {'Precision Score ': 0.8432233146067416, 'Recall Score ': 0.7980182926829269, 'F1 Score ': 0.8136499959471508}, 125: {'Precision Score ': 0.8362696734789759, 'Recall Score ': 0.8374587458745875, 'F1 Score ': 0.8367647058823529}, 126: {'Precision Score ': 0.7274509803921568, 'Recall Score ': 0.6967352130591478, 'F1 Score ': 0.7042166300737487}, 127: {'Precision Score ': 0.7993548387096774, 'Recall Score ': 0.7436974789915967, 'F1 Score ': 0.7627118644067797}, 128: {'Precision Score ': 0.7789473684210526, 'Recall Score ': 0.6956859696851924, 'F1 Score ': 0.7182022471910112}, 129: {'Precision Score ': 0.824317738791423, 'Recall Score ': 0.8411945654960267, 'F1 Score ': 0.8300018681113395}, 130: {'Precision Score ': 0.7882935352358765, 'Recall Score ': 0.6798691860465116, 'F1 Score ': 0.7038087962457711}, 131: {'Precision Score ': 0.8449314499376817, 'Recall Score ': 0.8468045112781954, 'F1 Score ': 0.8458214006769071}, 132: {'Precision Score ': 0.812751677852349, 'Recall Score ': 0.794489383215369, 'F1 Score ': 0.8012422360248447}, 133: {'Precision Score ': 0.7769886363636364, 'Recall Score ': 0.7708333333333334, 'F1 Score ': 0.7727910238429173}, 134: {'Precision Score ': 0.9567307692307692, 'Recall Score ': 0.7857142857142857, 'F1 Score ': 0.8410232983097305}, 135: {'Precision Score ': 0.89, 'Recall Score ': 0.7086677367576244, 'F1 Score ': 0.7559310462536268}, 136: {'Precision Score ': 0.917741935483871, 'Recall Score ': 0.7943181818181818, 'F1 Score ': 0.8406629834254145}, 137: {'Precision Score ': 0.8590555014605648, 'Recall Score ': 0.9338235294117647, 'F1 Score ': 0.8886532343584306}, 138: {'Precision Score ': 0.884016973125884, 'Recall Score ': 0.6946236559139785, 'F1 Score ': 0.7469540768509841}, 139: {'Precision Score ': 0.7568027210884354, 'Recall Score ': 0.5528711484593838, 'F1 Score ': 0.5560439560439561}, 140: {'Precision Score ': 0.8354838709677419, 'Recall Score ': 0.6189024390243902, 'F1 Score ': 0.6533333333333333}, 141: {'Precision Score ': 0.8137755102040816, 'Recall Score ': 0.5942528735632184, 'F1 Score ': 0.6227596017069701}, 142: {'Precision Score ': 0.897516835016835, 'Recall Score ': 0.8877257799671592, 'F1 Score ': 0.8924675324675325}, 143: {'Precision Score ': 0.8172161172161172, 'Recall Score ': 0.810394265232975, 'F1 Score ': 0.8136944117380672}, 144: {'Precision Score ': 0.5928030303030303, 'Recall Score ': 0.5227272727272727, 'F1 Score ': 0.5133689839572192}, 145: {'Precision Score ': 0.6888888888888889, 'Recall Score ': 0.5354166666666667, 'F1 Score ': 0.5361344537815126}, 146: {'Precision Score ': 0.8111658456486043, 'Recall Score ': 0.6799620132953467, 'F1 Score ': 0.7202380952380952}, 147: {'Precision Score ': 0.8887987012987013, 'Recall Score ': 0.7246716697936211, 'F1 Score ': 0.776470588235294}, 148: {'Precision Score ': 0.8839285714285714, 'Recall Score ': 0.712171052631579, 'F1 Score ': 0.7604166666666667}, 149: {'Precision Score ': 0.43434343434343436, 'Recall Score ': 0.5, 'F1 Score ': 0.4648648648648649}, 150: {'Precision Score ': 0.8787828400399069, 'Recall Score ': 0.8330409356725146, 'F1 Score ': 0.8511973959544292}, 151: {'Precision Score ': 0.9728260869565217, 'Recall Score ': 0.8214285714285714, 'F1 Score ': 0.8773378673791596}, 152: {'Precision Score ': 0.6929824561403508, 'Recall Score ': 0.6420454545454546, 'F1 Score ': 0.6588391670358883}, 153: {'Precision Score ': 0.890937019969278, 'Recall Score ': 0.7250221043324492, 'F1 Score ': 0.7777777777777778}, 154: {'Precision Score ': 0.8700322234156821, 'Recall Score ': 0.7912087912087913, 'F1 Score ': 0.8211640211640212}, 155: {'Precision Score ': 0.8672161172161172, 'Recall Score ': 0.8389114266396214, 'F1 Score ': 0.8512991573033708}, 156: {'Precision Score ': 0.9611111111111111, 'Recall Score ': 0.7307692307692308, 'F1 Score ': 0.7955582598113782}, 157: {'Precision Score ': 0.8829051383399209, 'Recall Score ': 0.8218438538205981, 'F1 Score ': 0.8462921348314607}, 158: {'Precision Score ': 0.8704896907216495, 'Recall Score ': 0.79158215010142, 'F1 Score ': 0.8185907046476761}, 159: {'Precision Score ': 0.8057586022463897, 'Recall Score ': 0.80625, 'F1 Score ': 0.8059681520139168}, 160: {'Precision Score ': 0.8831168831168831, 'Recall Score ': 0.7824897400820794, 'F1 Score ': 0.8136645962732919}, 161: {'Precision Score ': 0.8267355134825014, 'Recall Score ': 0.7883544303797468, 'F1 Score ': 0.8046162104133118}, 162: {'Precision Score ': 0.8737176355642404, 'Recall Score ': 0.842128801431127, 'F1 Score ': 0.856326530612245}, 163: {'Precision Score ': 0.8388480392156863, 'Recall Score ': 0.7323529411764707, 'F1 Score ': 0.7641497851442602}, 164: {'Precision Score ': 0.8745238095238095, 'Recall Score ': 0.8620253164556962, 'F1 Score ': 0.8669003797838154}, 165: {'Precision Score ': 0.8223388305847077, 'Recall Score ': 0.76875, 'F1 Score ': 0.7887244379166196}, 166: {'Precision Score ': 0.9619565217391304, 'Recall Score ': 0.8541666666666667, 'F1 Score ': 0.8948601350420284}, 167: {'Precision Score ': 0.871894697812384, 'Recall Score ': 0.8239664082687339, 'F1 Score ': 0.8427159432746025}, 168: {'Precision Score ': 0.7634887375589314, 'Recall Score ': 0.7206140350877193, 'F1 Score ': 0.7358490566037736}}\n"
     ]
    }
   ],
   "source": [
    "result_history = run_model(model_type = \"RF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = open(\"binary_random_forest_result\", \"wb\")\n",
    "# pickle.dump(result_history, f)\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"binary_random_forest_result\", \"rb\")\n",
    "l = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = {k: v for k, v in sorted(l.items(), key=lambda item: item[1][\"F1 Score \"], reverse = True)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89  =  {'Precision Score ': 0.9886363636363636, 'Recall Score ': 0.967741935483871, 'F1 Score ': 0.9775862068965517}\n",
      "100  =  {'Precision Score ': 0.9473684210526316, 'Recall Score ': 0.9893617021276595, 'F1 Score ': 0.9668458781362007}\n",
      "7  =  {'Precision Score ': 0.9527153558052435, 'Recall Score ': 0.9527153558052435, 'F1 Score ': 0.9527153558052435}\n",
      "72  =  {'Precision Score ': 0.9403304773561811, 'Recall Score ': 0.9499687304565353, 'F1 Score ': 0.9448051948051949}\n",
      "97  =  {'Precision Score ': 0.9314024390243902, 'Recall Score ': 0.9546184738955823, 'F1 Score ': 0.9425219941348973}\n",
      "45  =  {'Precision Score ': 0.92357910906298, 'Recall Score ': 0.942261427425822, 'F1 Score ': 0.9323529411764706}\n",
      "71  =  {'Precision Score ': 0.9173951048951049, 'Recall Score ': 0.9470973782771535, 'F1 Score ': 0.9315254237288135}\n",
      "102  =  {'Precision Score ': 0.9104166666666667, 'Recall Score ': 0.9504573170731707, 'F1 Score ': 0.9288307915758895}\n",
      "103  =  {'Precision Score ': 0.9002976190476191, 'Recall Score ': 0.9468438538205981, 'F1 Score ': 0.9215686274509804}\n",
      "85  =  {'Precision Score ': 0.916688028710587, 'Recall Score ': 0.916688028710587, 'F1 Score ': 0.916688028710587}\n",
      "99  =  {'Precision Score ': 0.9050387596899225, 'Recall Score ': 0.9239350912778905, 'F1 Score ': 0.9141205615194055}\n",
      "79  =  {'Precision Score ': 0.9231720010408535, 'Recall Score ': 0.9040372670807453, 'F1 Score ': 0.9119634529361378}\n",
      "106  =  {'Precision Score ': 0.9045584045584045, 'Recall Score ': 0.9156097560975609, 'F1 Score ': 0.909900156381571}\n",
      "93  =  {'Precision Score ': 0.8995695839311334, 'Recall Score ': 0.9194277108433735, 'F1 Score ': 0.9090909090909092}\n",
      "90  =  {'Precision Score ': 0.9164794007490638, 'Recall Score ': 0.8948863636363636, 'F1 Score ': 0.9052305449243667}\n",
      "81  =  {'Precision Score ': 0.8980614973262032, 'Recall Score ': 0.8980614973262032, 'F1 Score ': 0.8980614973262032}\n",
      "38  =  {'Precision Score ': 0.8966068355052864, 'Recall Score ': 0.8934146341463415, 'F1 Score ': 0.8949494949494949}\n",
      "166  =  {'Precision Score ': 0.9619565217391304, 'Recall Score ': 0.8541666666666667, 'F1 Score ': 0.8948601350420284}\n",
      "142  =  {'Precision Score ': 0.897516835016835, 'Recall Score ': 0.8877257799671592, 'F1 Score ': 0.8924675324675325}\n",
      "92  =  {'Precision Score ': 0.9146825396825397, 'Recall Score ': 0.8686067019400352, 'F1 Score ': 0.8890442890442889}\n"
     ]
    }
   ],
   "source": [
    "# Top 20 playlists \n",
    "for key in list(l.keys())[:20]:\n",
    "    print(key,\" = \",  l[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' XG Boost Result'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" XG Boost Result\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 169/169 [12:42<00:00,  4.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {'Precision Score ': 0.9775280898876404, 'Recall Score ': 0.8461538461538461, 'F1 Score ': 0.8975966562173459}, 1: {'Precision Score ': 0.8587628865979382, 'Recall Score ': 0.739010989010989, 'F1 Score ': 0.7810965630114566}, 2: {'Precision Score ': 0.7301587301587301, 'Recall Score ': 0.6168498168498169, 'F1 Score ': 0.6449760765550239}, 3: {'Precision Score ': 0.8500000000000001, 'Recall Score ': 0.8652597402597402, 'F1 Score ': 0.8570780399274047}, 4: {'Precision Score ': 0.8273408239700375, 'Recall Score ': 0.7822997416020672, 'F1 Score ': 0.8019047619047619}, 5: {'Precision Score ': 0.9017857142857143, 'Recall Score ': 0.7629016553067186, 'F1 Score ': 0.8118609406952966}, 6: {'Precision Score ': 0.8511904761904763, 'Recall Score ': 0.9315569487983281, 'F1 Score ': 0.8853801169590643}, 7: {'Precision Score ': 0.9173297966401415, 'Recall Score ': 0.946969696969697, 'F1 Score ': 0.9314285714285713}, 8: {'Precision Score ': 0.8926073926073926, 'Recall Score ': 0.8638888888888889, 'F1 Score ': 0.8774921931299543}, 9: {'Precision Score ': 0.7486933797909407, 'Recall Score ': 0.7614468864468864, 'F1 Score ': 0.7545738509593931}, 10: {'Precision Score ': 0.8284883720930232, 'Recall Score ': 0.7017857142857142, 'F1 Score ': 0.7426067907995619}, 11: {'Precision Score ': 0.8925561797752809, 'Recall Score ': 0.8061336254107339, 'F1 Score ': 0.8393512851897185}, 12: {'Precision Score ': 0.835, 'Recall Score ': 0.7791666666666667, 'F1 Score ': 0.8027210884353742}, 13: {'Precision Score ': 0.7588235294117647, 'Recall Score ': 0.7718023255813953, 'F1 Score ': 0.7650186071238703}, 14: {'Precision Score ': 0.7999365884590995, 'Recall Score ': 0.7884146341463415, 'F1 Score ': 0.793939393939394}, 15: {'Precision Score ': 0.8181818181818181, 'Recall Score ': 0.7191650853889944, 'F1 Score ': 0.7544642857142856}, 16: {'Precision Score ': 0.8234772324068598, 'Recall Score ': 0.7891120507399577, 'F1 Score ': 0.8043205574912892}, 17: {'Precision Score ': 0.8062448304383788, 'Recall Score ': 0.7773408239700375, 'F1 Score ': 0.7898351648351647}, 18: {'Precision Score ': 0.8636363636363636, 'Recall Score ': 0.7391304347826086, 'F1 Score ': 0.7815490160678822}, 19: {'Precision Score ': 0.8130252100840336, 'Recall Score ': 0.8347240051347882, 'F1 Score ': 0.8194444444444444}, 20: {'Precision Score ': 0.675891181988743, 'Recall Score ': 0.65625, 'F1 Score ': 0.6649029982363316}, 21: {'Precision Score ': 0.8462643678160919, 'Recall Score ': 0.803781512605042, 'F1 Score ': 0.8228980322003578}, 22: {'Precision Score ': 0.8316008316008316, 'Recall Score ': 0.8497807017543859, 'F1 Score ': 0.8400000000000001}, 23: {'Precision Score ': 0.6790799561883899, 'Recall Score ': 0.6552706552706553, 'F1 Score ': 0.665650406504065}, 24: {'Precision Score ': 0.9772727272727273, 'Recall Score ': 0.9, 'F1 Score ': 0.9328165374677003}, 25: {'Precision Score ': 0.9098214285714286, 'Recall Score ': 0.9253938832252085, 'F1 Score ': 0.9168370824812543}, 26: {'Precision Score ': 0.9810126582278481, 'Recall Score ': 0.875, 'F1 Score ': 0.9188940092165898}, 27: {'Precision Score ': 0.6944444444444444, 'Recall Score ': 0.5906593406593407, 'F1 Score ': 0.613157894736842}, 28: {'Precision Score ': 0.8805114638447972, 'Recall Score ': 0.9047842401500938, 'F1 Score ': 0.892069984094524}, 29: {'Precision Score ': 0.7207920792079208, 'Recall Score ': 0.5674531155474895, 'F1 Score ': 0.5771276595744681}, 30: {'Precision Score ': 0.8259685230024213, 'Recall Score ': 0.7624269005847953, 'F1 Score ': 0.7813494407499857}, 31: {'Precision Score ': 0.8226744186046512, 'Recall Score ': 0.73125, 'F1 Score ': 0.763855421686747}, 32: {'Precision Score ': 0.8489010989010989, 'Recall Score ': 0.8489010989010989, 'F1 Score ': 0.8489010989010989}, 33: {'Precision Score ': 0.7666666666666666, 'Recall Score ': 0.6550387596899224, 'F1 Score ': 0.6915584415584415}, 34: {'Precision Score ': 0.8951754385964912, 'Recall Score ': 0.7331780538302277, 'F1 Score ': 0.7779728651237031}, 35: {'Precision Score ': 0.8243727598566308, 'Recall Score ': 0.6721623335447051, 'F1 Score ': 0.7102272727272727}, 36: {'Precision Score ': 0.7124125874125874, 'Recall Score ': 0.6701680672268908, 'F1 Score ': 0.6868217054263566}, 37: {'Precision Score ': 0.8611111111111112, 'Recall Score ': 0.7801724137931034, 'F1 Score ': 0.8135593220338984}, 38: {'Precision Score ': 0.8615384615384616, 'Recall Score ': 0.8737349397590362, 'F1 Score ': 0.8662525879917184}, 39: {'Precision Score ': 0.5663865546218487, 'Recall Score ': 0.5341991341991342, 'F1 Score ': 0.5353535353535354}, 40: {'Precision Score ': 0.8930555555555555, 'Recall Score ': 0.844421906693712, 'F1 Score ': 0.8647978436657682}, 41: {'Precision Score ': 0.7821337540963709, 'Recall Score ': 0.7772873672909459, 'F1 Score ': 0.7788461538461537}, 42: {'Precision Score ': 0.7596072186836518, 'Recall Score ': 0.7310999810999811, 'F1 Score ': 0.7408955223880598}, 43: {'Precision Score ': 0.7689473684210526, 'Recall Score ': 0.7853685778108712, 'F1 Score ': 0.7757936507936509}, 44: {'Precision Score ': 0.9123581336696092, 'Recall Score ': 0.9102150537634408, 'F1 Score ': 0.9112428693347707}, 45: {'Precision Score ': 0.9142857142857144, 'Recall Score ': 0.9655172413793103, 'F1 Score ': 0.9352678571428572}, 46: {'Precision Score ': 0.8555068836045057, 'Recall Score ': 0.8546192259675406, 'F1 Score ': 0.8546351824087955}, 47: {'Precision Score ': 0.8376937984496124, 'Recall Score ': 0.7967220093656875, 'F1 Score ': 0.8135803863970172}, 48: {'Precision Score ': 0.7463985594237695, 'Recall Score ': 0.7200482444384884, 'F1 Score ': 0.7299470899470899}, 49: {'Precision Score ': 0.8521836506159015, 'Recall Score ': 0.8038647342995169, 'F1 Score ': 0.8245341614906833}, 50: {'Precision Score ': 0.789326961369972, 'Recall Score ': 0.8018280016618197, 'F1 Score ': 0.7951219512195122}, 51: {'Precision Score ': 0.7462349397590362, 'Recall Score ': 0.7329059829059829, 'F1 Score ': 0.7390243902439024}, 52: {'Precision Score ': 0.8315018315018314, 'Recall Score ': 0.791264367816092, 'F1 Score ': 0.8085002442598925}, 53: {'Precision Score ': 0.8008879023307436, 'Recall Score ': 0.8008879023307436, 'F1 Score ': 0.8008879023307436}, 54: {'Precision Score ': 0.8258620689655173, 'Recall Score ': 0.8068181818181819, 'F1 Score ': 0.8153717627401837}, 55: {'Precision Score ': 0.8606418918918919, 'Recall Score ': 0.8782778171509568, 'F1 Score ': 0.8685734036118551}, 56: {'Precision Score ': 0.6919642857142857, 'Recall Score ': 0.6181318681318682, 'F1 Score ': 0.6333333333333333}, 57: {'Precision Score ': 0.7688723205964585, 'Recall Score ': 0.7688723205964585, 'F1 Score ': 0.7688723205964585}, 58: {'Precision Score ': 0.8373563218390805, 'Recall Score ': 0.8302700675168793, 'F1 Score ': 0.8336965791717994}, 59: {'Precision Score ': 0.8972701149425287, 'Recall Score ': 0.8569277108433735, 'F1 Score ': 0.8744343891402715}, 60: {'Precision Score ': 0.8304953560371517, 'Recall Score ': 0.8359559402045633, 'F1 Score ': 0.8317429406037}, 61: {'Precision Score ': 0.7849206349206349, 'Recall Score ': 0.7876602564102564, 'F1 Score ': 0.7862391069089253}, 62: {'Precision Score ': 0.9256097560975609, 'Recall Score ': 0.8942018072289157, 'F1 Score ': 0.9064103396765604}, 63: {'Precision Score ': 0.8258281573498965, 'Recall Score ': 0.8227377595488337, 'F1 Score ': 0.8242225226965425}, 64: {'Precision Score ': 0.8013157894736842, 'Recall Score ': 0.729550922213312, 'F1 Score ': 0.753636261134288}, 65: {'Precision Score ': 0.8543091655266758, 'Recall Score ': 0.8786549707602339, 'F1 Score ': 0.8645502645502645}, 66: {'Precision Score ': 0.8613782051282051, 'Recall Score ': 0.854978354978355, 'F1 Score ': 0.8580645161290322}, 67: {'Precision Score ': 0.8714643304130163, 'Recall Score ': 0.8567307692307693, 'F1 Score ': 0.8626262626262626}, 68: {'Precision Score ': 0.85625, 'Recall Score ': 0.8392857142857143, 'F1 Score ': 0.8424242424242424}, 69: {'Precision Score ': 0.8101294065149487, 'Recall Score ': 0.7895833333333333, 'F1 Score ': 0.7987299537186524}, 70: {'Precision Score ': 0.8446428571428571, 'Recall Score ': 0.8922764227642277, 'F1 Score ': 0.866096866096866}, 71: {'Precision Score ': 0.9946236559139785, 'Recall Score ': 0.9583333333333333, 'F1 Score ': 0.9755581668625147}, 72: {'Precision Score ': 0.9409883720930232, 'Recall Score ': 0.9512195121951219, 'F1 Score ': 0.9457671957671958}, 73: {'Precision Score ': 0.8806620209059233, 'Recall Score ': 0.9050046339202966, 'F1 Score ': 0.8922558922558923}, 74: {'Precision Score ': 0.9360047846889952, 'Recall Score ': 0.9360047846889952, 'F1 Score ': 0.9360047846889952}, 75: {'Precision Score ': 0.8070175438596491, 'Recall Score ': 0.7565982404692082, 'F1 Score ': 0.7787234042553192}, 76: {'Precision Score ': 0.7363806406359598, 'Recall Score ': 0.7340277777777777, 'F1 Score ': 0.735155568479209}, 77: {'Precision Score ': 0.8118946144905075, 'Recall Score ': 0.7818627450980392, 'F1 Score ': 0.7942930544086613}, 78: {'Precision Score ': 0.8117283950617284, 'Recall Score ': 0.8221119773210488, 'F1 Score ': 0.8165505226480836}, 79: {'Precision Score ': 0.9301335918982978, 'Recall Score ': 0.9233828207847297, 'F1 Score ': 0.92633547008547}, 80: {'Precision Score ': 0.925, 'Recall Score ': 0.9230414746543778, 'F1 Score ': 0.923805125836989}, 81: {'Precision Score ': 0.8041125541125541, 'Recall Score ': 0.7987243090007088, 'F1 Score ': 0.8013227276789705}, 82: {'Precision Score ': 0.8756302521008403, 'Recall Score ': 0.8386363636363636, 'F1 Score ': 0.8540486835568804}, 83: {'Precision Score ': 0.8906846899794298, 'Recall Score ': 0.8906846899794298, 'F1 Score ': 0.8906846899794298}, 84: {'Precision Score ': 0.8563438327936415, 'Recall Score ': 0.8563438327936415, 'F1 Score ': 0.8563438327936415}, 85: {'Precision Score ': 0.936633912824389, 'Recall Score ': 0.9484989648033126, 'F1 Score ': 0.9419457735247209}, 86: {'Precision Score ': 0.9485943775100402, 'Recall Score ': 0.90559186637618, 'F1 Score ': 0.9253048780487805}, 87: {'Precision Score ': 0.8525280898876404, 'Recall Score ': 0.8525280898876404, 'F1 Score ': 0.8525280898876404}, 88: {'Precision Score ': 0.8393719806763285, 'Recall Score ': 0.8554712207463631, 'F1 Score ': 0.8471042471042471}, 89: {'Precision Score ': 0.9594155844155845, 'Recall Score ': 0.9296015180265655, 'F1 Score ': 0.9431762515920447}, 90: {'Precision Score ': 0.9472402597402598, 'Recall Score ': 0.9004360465116279, 'F1 Score ': 0.92183908045977}, 91: {'Precision Score ': 0.853968253968254, 'Recall Score ': 0.7881136950904393, 'F1 Score ': 0.8153409090909092}, 92: {'Precision Score ': 0.875, 'Recall Score ': 0.9615384615384616, 'F1 Score ': 0.9085714285714286}, 93: {'Precision Score ': 0.9374420759962929, 'Recall Score ': 0.86875, 'F1 Score ': 0.8984556801353925}, 94: {'Precision Score ': 0.7762613730355665, 'Recall Score ': 0.6807359307359307, 'F1 Score ': 0.7091202582728007}, 95: {'Precision Score ': 0.7705882352941177, 'Recall Score ': 0.7384146341463416, 'F1 Score ': 0.7523871176565787}, 96: {'Precision Score ': 0.8663461538461539, 'Recall Score ': 0.7565656565656566, 'F1 Score ': 0.797832512315271}, 97: {'Precision Score ': 0.96875, 'Recall Score ': 0.9938271604938271, 'F1 Score ': 0.9807653776798237}, 98: {'Precision Score ': 0.7684108527131783, 'Recall Score ': 0.78944618599791, 'F1 Score ': 0.778336265393315}, 99: {'Precision Score ': 0.8936708860759495, 'Recall Score ': 0.9461979913916786, 'F1 Score ': 0.9169044821218735}, 100: {'Precision Score ': 0.9893617021276595, 'Recall Score ': 0.9411764705882353, 'F1 Score ': 0.9633736559139785}, 101: {'Precision Score ': 0.9840425531914894, 'Recall Score ': 0.8636363636363636, 'F1 Score ': 0.9129445234708393}, 102: {'Precision Score ': 0.9555555555555555, 'Recall Score ': 0.9318820224719101, 'F1 Score ': 0.94323301495765}, 103: {'Precision Score ': 0.8599240265906933, 'Recall Score ': 0.8383928571428572, 'F1 Score ': 0.8486312399355878}, 104: {'Precision Score ': 0.7546932234432234, 'Recall Score ': 0.7408008658008658, 'F1 Score ': 0.7455201109570042}, 105: {'Precision Score ': 0.7946345975948196, 'Recall Score ': 0.7692307692307693, 'F1 Score ': 0.780584666298952}, 106: {'Precision Score ': 0.8628663003663004, 'Recall Score ': 0.8522222222222222, 'F1 Score ': 0.8573683617093246}, 107: {'Precision Score ': 0.8798670465337132, 'Recall Score ': 0.8536693191865605, 'F1 Score ': 0.8654088050314466}, 108: {'Precision Score ': 0.6924836601307189, 'Recall Score ': 0.6574866310160428, 'F1 Score ': 0.6707692307692308}, 109: {'Precision Score ': 0.6982142857142857, 'Recall Score ': 0.6897435897435897, 'F1 Score ': 0.6935835879528589}, 110: {'Precision Score ': 0.8349624060150376, 'Recall Score ': 0.7327586206896552, 'F1 Score ': 0.7670940170940171}, 111: {'Precision Score ': 0.8153483499214248, 'Recall Score ': 0.8255813953488371, 'F1 Score ': 0.8198922943953194}, 112: {'Precision Score ': 0.7758785332314744, 'Recall Score ': 0.7807034589972794, 'F1 Score ': 0.7769230769230769}, 113: {'Precision Score ': 0.8312262958280657, 'Recall Score ': 0.7090425531914893, 'F1 Score ': 0.7346954937831629}, 114: {'Precision Score ': 0.8858695652173914, 'Recall Score ': 0.796477850399419, 'F1 Score ': 0.8250684514755096}, 115: {'Precision Score ': 0.7455277280858676, 'Recall Score ': 0.7186379928315412, 'F1 Score ': 0.7293833385859859}, 116: {'Precision Score ': 0.7570153061224489, 'Recall Score ': 0.667358803986711, 'F1 Score ': 0.6902173913043479}, 117: {'Precision Score ': 0.6114379084967321, 'Recall Score ': 0.5855923694779116, 'F1 Score ': 0.5926970252361483}, 118: {'Precision Score ': 0.7647689768976897, 'Recall Score ': 0.7478375038616003, 'F1 Score ': 0.7463768115942029}, 119: {'Precision Score ': 0.48639455782312924, 'Recall Score ': 0.49523809523809526, 'F1 Score ': 0.47252747252747257}, 120: {'Precision Score ': 0.8391608391608392, 'Recall Score ': 0.7597054886211513, 'F1 Score ': 0.7904169024712318}, 121: {'Precision Score ': 0.7778816199376947, 'Recall Score ': 0.6615942028985508, 'F1 Score ': 0.6866554997208264}, 122: {'Precision Score ': 0.7483948635634029, 'Recall Score ': 0.6736812570145904, 'F1 Score ': 0.6970588235294117}, 123: {'Precision Score ': 0.7701298701298701, 'Recall Score ': 0.7527777777777778, 'F1 Score ': 0.7594630872483221}, 124: {'Precision Score ': 0.8184738955823293, 'Recall Score ': 0.8334735071488646, 'F1 Score ': 0.8248974008207934}, 125: {'Precision Score ': 0.8249128919860627, 'Recall Score ': 0.827233989221707, 'F1 Score ': 0.8258372608383533}, 126: {'Precision Score ': 0.7715773809523809, 'Recall Score ': 0.7430632630410654, 'F1 Score ': 0.7512067461471359}, 127: {'Precision Score ': 0.7785326086956521, 'Recall Score ': 0.7679738562091503, 'F1 Score ': 0.772893772893773}, 128: {'Precision Score ': 0.7235294117647059, 'Recall Score ': 0.7188940092165899, 'F1 Score ': 0.7211174701716947}, 129: {'Precision Score ': 0.8485764676240867, 'Recall Score ': 0.8546526531658549, 'F1 Score ': 0.8513719512195121}, 130: {'Precision Score ': 0.7897271268057785, 'Recall Score ': 0.7654411764705882, 'F1 Score ': 0.7758620689655172}, 131: {'Precision Score ': 0.8375824175824176, 'Recall Score ': 0.8208020050125313, 'F1 Score ': 0.8268090787716955}, 132: {'Precision Score ': 0.7738139362490735, 'Recall Score ': 0.7676630434782609, 'F1 Score ': 0.7704212454212453}, 133: {'Precision Score ': 0.8120879120879121, 'Recall Score ': 0.8102372034956304, 'F1 Score ': 0.8110328638497653}, 134: {'Precision Score ': 0.842741935483871, 'Recall Score ': 0.8299689440993789, 'F1 Score ': 0.8361239288068555}, 135: {'Precision Score ': 0.843421052631579, 'Recall Score ': 0.8305471124620061, 'F1 Score ': 0.8367531294360562}, 136: {'Precision Score ': 0.8290529695024077, 'Recall Score ': 0.8106060606060606, 'F1 Score ': 0.8194038573933372}, 137: {'Precision Score ': 0.9347826086956521, 'Recall Score ': 0.9831460674157304, 'F1 Score ': 0.9565448504983388}, 138: {'Precision Score ': 0.7827380952380952, 'Recall Score ': 0.7980392156862746, 'F1 Score ': 0.7900362664630655}, 139: {'Precision Score ': 0.8206845238095238, 'Recall Score ': 0.7726122707147376, 'F1 Score ': 0.7934801160607612}, 140: {'Precision Score ': 0.9204545454545454, 'Recall Score ': 0.8064759036144578, 'F1 Score ': 0.8499025341130604}, 141: {'Precision Score ': 0.945054945054945, 'Recall Score ': 0.6875, 'F1 Score ': 0.7436575052854122}, 142: {'Precision Score ': 0.8905372894947875, 'Recall Score ': 0.8998357963875205, 'F1 Score ': 0.8950410708853058}, 143: {'Precision Score ': 0.8916129032258064, 'Recall Score ': 0.8375973303670745, 'F1 Score ': 0.8595238095238095}, 144: {'Precision Score ': 0.7444444444444445, 'Recall Score ': 0.596031746031746, 'F1 Score ': 0.6235032024505708}, 145: {'Precision Score ': 0.661344537815126, 'Recall Score ': 0.6, 'F1 Score ': 0.6185007974481658}, 146: {'Precision Score ': 0.8100840336134454, 'Recall Score ': 0.6796494644595911, 'F1 Score ': 0.7195121951219512}, 147: {'Precision Score ': 0.9821428571428572, 'Recall Score ': 0.8846153846153846, 'F1 Score ': 0.9256916996047431}, 148: {'Precision Score ': 0.9251543209876543, 'Recall Score ': 0.9251543209876543, 'F1 Score ': 0.9251543209876543}, 149: {'Precision Score ': 0.7637195121951219, 'Recall Score ': 0.6728271728271729, 'F1 Score ': 0.7035040431266847}, 150: {'Precision Score ': 0.7876344086021505, 'Recall Score ': 0.7544388078630311, 'F1 Score ': 0.766859344894027}, 151: {'Precision Score ': 0.9131944444444444, 'Recall Score ': 0.7802197802197802, 'F1 Score ': 0.8291095094164148}, 152: {'Precision Score ': 0.8300000000000001, 'Recall Score ': 0.6704545454545454, 'F1 Score ': 0.7074468085106383}, 153: {'Precision Score ': 0.8812292358803986, 'Recall Score ': 0.9058355437665783, 'F1 Score ': 0.8929565403553843}, 154: {'Precision Score ': 0.856060606060606, 'Recall Score ': 0.8363148479427549, 'F1 Score ': 0.8455172413793104}, 155: {'Precision Score ': 0.821236559139785, 'Recall Score ': 0.8089851325145443, 'F1 Score ': 0.8147233201581028}, 156: {'Precision Score ': 0.90625, 'Recall Score ': 0.7637362637362637, 'F1 Score ': 0.8146167557932265}, 157: {'Precision Score ': 0.8979166666666667, 'Recall Score ': 0.9159407665505226, 'F1 Score ': 0.9063431247339293}, 158: {'Precision Score ': 0.856974921630094, 'Recall Score ': 0.8228206945428774, 'F1 Score ': 0.837092731829574}, 159: {'Precision Score ': 0.8467973635288153, 'Recall Score ': 0.8331168831168831, 'F1 Score ': 0.8370125851041882}, 160: {'Precision Score ': 0.874065934065934, 'Recall Score ': 0.8052367288378766, 'F1 Score ': 0.8295287547761341}, 161: {'Precision Score ': 0.8506066734074823, 'Recall Score ': 0.8302380952380952, 'F1 Score ': 0.8397058823529411}, 162: {'Precision Score ': 0.9070121951219512, 'Recall Score ': 0.8850961538461539, 'F1 Score ': 0.8953086419753087}, 163: {'Precision Score ': 0.8386383731211318, 'Recall Score ': 0.8218487394957983, 'F1 Score ': 0.8296726959517657}, 164: {'Precision Score ': 0.9217657342657343, 'Recall Score ': 0.9128342245989305, 'F1 Score ': 0.9168062233266706}, 165: {'Precision Score ': 0.8036130536130537, 'Recall Score ': 0.821604938271605, 'F1 Score ': 0.8116202455825098}, 166: {'Precision Score ': 0.7750320924261874, 'Recall Score ': 0.7318722943722944, 'F1 Score ': 0.7488664618984935}, 167: {'Precision Score ': 0.8792986040177051, 'Recall Score ': 0.8598191214470284, 'F1 Score ': 0.8686542443064182}, 168: {'Precision Score ': 0.8690476190476191, 'Recall Score ': 0.8528455284552845, 'F1 Score ': 0.860407145824678}}\n"
     ]
    }
   ],
   "source": [
    "result_history = run_model(model_type = \"XGB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = open(\"binary_xgb_result\", \"wb\")\n",
    "# pickle.dump(result_history, f)\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"binary_xgb_result\", \"rb\")\n",
    "l = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = {k: v for k, v in sorted(l.items(), key=lambda item: item[1][\"F1 Score \"], reverse = True)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97  =  {'Precision Score ': 0.96875, 'Recall Score ': 0.9938271604938271, 'F1 Score ': 0.9807653776798237}\n",
      "71  =  {'Precision Score ': 0.9946236559139785, 'Recall Score ': 0.9583333333333333, 'F1 Score ': 0.9755581668625147}\n",
      "100  =  {'Precision Score ': 0.9893617021276595, 'Recall Score ': 0.9411764705882353, 'F1 Score ': 0.9633736559139785}\n",
      "137  =  {'Precision Score ': 0.9347826086956521, 'Recall Score ': 0.9831460674157304, 'F1 Score ': 0.9565448504983388}\n",
      "72  =  {'Precision Score ': 0.9409883720930232, 'Recall Score ': 0.9512195121951219, 'F1 Score ': 0.9457671957671958}\n",
      "102  =  {'Precision Score ': 0.9555555555555555, 'Recall Score ': 0.9318820224719101, 'F1 Score ': 0.94323301495765}\n",
      "89  =  {'Precision Score ': 0.9594155844155845, 'Recall Score ': 0.9296015180265655, 'F1 Score ': 0.9431762515920447}\n",
      "85  =  {'Precision Score ': 0.936633912824389, 'Recall Score ': 0.9484989648033126, 'F1 Score ': 0.9419457735247209}\n",
      "74  =  {'Precision Score ': 0.9360047846889952, 'Recall Score ': 0.9360047846889952, 'F1 Score ': 0.9360047846889952}\n",
      "45  =  {'Precision Score ': 0.9142857142857144, 'Recall Score ': 0.9655172413793103, 'F1 Score ': 0.9352678571428572}\n",
      "24  =  {'Precision Score ': 0.9772727272727273, 'Recall Score ': 0.9, 'F1 Score ': 0.9328165374677003}\n",
      "7  =  {'Precision Score ': 0.9173297966401415, 'Recall Score ': 0.946969696969697, 'F1 Score ': 0.9314285714285713}\n",
      "79  =  {'Precision Score ': 0.9301335918982978, 'Recall Score ': 0.9233828207847297, 'F1 Score ': 0.92633547008547}\n",
      "147  =  {'Precision Score ': 0.9821428571428572, 'Recall Score ': 0.8846153846153846, 'F1 Score ': 0.9256916996047431}\n",
      "86  =  {'Precision Score ': 0.9485943775100402, 'Recall Score ': 0.90559186637618, 'F1 Score ': 0.9253048780487805}\n",
      "148  =  {'Precision Score ': 0.9251543209876543, 'Recall Score ': 0.9251543209876543, 'F1 Score ': 0.9251543209876543}\n",
      "80  =  {'Precision Score ': 0.925, 'Recall Score ': 0.9230414746543778, 'F1 Score ': 0.923805125836989}\n",
      "90  =  {'Precision Score ': 0.9472402597402598, 'Recall Score ': 0.9004360465116279, 'F1 Score ': 0.92183908045977}\n",
      "26  =  {'Precision Score ': 0.9810126582278481, 'Recall Score ': 0.875, 'F1 Score ': 0.9188940092165898}\n",
      "99  =  {'Precision Score ': 0.8936708860759495, 'Recall Score ': 0.9461979913916786, 'F1 Score ': 0.9169044821218735}\n"
     ]
    }
   ],
   "source": [
    "# Top 20 playlists \n",
    "for key in list(l.keys())[:20]:\n",
    "    print(key,\" = \",  l[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbours = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :   9%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                               | 15/169 [01:02<10:17,  4.01s/it]C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Progress :  14%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                            | 23/169 [01:35<10:17,  4.23s/it]C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Progress :  20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                        | 33/169 [02:19<10:04,  4.44s/it]C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Progress :  23%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                     | 39/169 [02:44<08:57,  4.13s/it]C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Progress :  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–         | 145/169 [10:40<01:44,  4.35s/it]C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Progress :  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š        | 149/169 [10:56<01:22,  4.11s/it]C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Progress :  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 156/169 [11:26<00:55,  4.24s/it]C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Progress : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 169/169 [12:21<00:00,  4.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {'Precision Score ': 0.9427083333333333, 'Recall Score ': 0.5769230769230769, 'F1 Score ': 0.6029465930018416}, 1: {'Precision Score ': 0.9375, 'Recall Score ': 0.59375, 'F1 Score ': 0.6245614035087719}, 2: {'Precision Score ': 0.42788461538461536, 'Recall Score ': 0.489010989010989, 'F1 Score ': 0.4564102564102564}, 3: {'Precision Score ': 0.7676470588235293, 'Recall Score ': 0.711038961038961, 'F1 Score ': 0.7299382716049383}, 4: {'Precision Score ': 0.7714285714285715, 'Recall Score ': 0.7209302325581395, 'F1 Score ': 0.7414772727272728}, 5: {'Precision Score ': 0.9388888888888889, 'Recall Score ': 0.5769230769230769, 'F1 Score ': 0.6007889546351085}, 6: {'Precision Score ': 0.9484536082474226, 'Recall Score ': 0.5454545454545454, 'F1 Score ': 0.5561594202898551}, 7: {'Precision Score ': 0.7632575757575758, 'Recall Score ': 0.7632575757575758, 'F1 Score ': 0.7632575757575758}, 8: {'Precision Score ': 0.95, 'Recall Score ': 0.5833333333333334, 'F1 Score ': 0.6165413533834587}, 9: {'Precision Score ': 0.7343234323432344, 'Recall Score ': 0.5975274725274725, 'F1 Score ': 0.6092664092664094}, 10: {'Precision Score ': 0.8083333333333333, 'Recall Score ': 0.73125, 'F1 Score ': 0.7611788617886179}, 11: {'Precision Score ': 0.75625, 'Recall Score ': 0.7806681270536692, 'F1 Score ': 0.7670016969064091}, 12: {'Precision Score ': 0.7838283828382838, 'Recall Score ': 0.7239583333333333, 'F1 Score ': 0.747643219724438}, 13: {'Precision Score ': 0.806828003457217, 'Recall Score ': 0.7579941860465116, 'F1 Score ': 0.7789162561576355}, 14: {'Precision Score ': 0.7663731425426528, 'Recall Score ': 0.7951219512195122, 'F1 Score ': 0.7789975444171602}, 15: {'Precision Score ': 0.42272727272727273, 'Recall Score ': 0.5, 'F1 Score ': 0.458128078817734}, 16: {'Precision Score ': 0.7708333333333333, 'Recall Score ': 0.7885835095137421, 'F1 Score ': 0.7790281329923274}, 17: {'Precision Score ': 0.7395960832313342, 'Recall Score ': 0.7932584269662921, 'F1 Score ': 0.7530095475300955}, 18: {'Precision Score ': 0.9423076923076923, 'Recall Score ': 0.6666666666666666, 'F1 Score ': 0.7193877551020408}, 19: {'Precision Score ': 0.6780487804878048, 'Recall Score ': 0.6639922978177151, 'F1 Score ': 0.6687208527648234}, 20: {'Precision Score ': 0.9347826086956521, 'Recall Score ': 0.6, 'F1 Score ': 0.6317829457364341}, 21: {'Precision Score ': 0.9381443298969072, 'Recall Score ': 0.5714285714285714, 'F1 Score ': 0.592032967032967}, 22: {'Precision Score ': 0.7875, 'Recall Score ': 0.7521929824561404, 'F1 Score ': 0.766899766899767}, 23: {'Precision Score ': 0.4308510638297872, 'Recall Score ': 0.5, 'F1 Score ': 0.46285714285714286}, 24: {'Precision Score ': 0.8296703296703296, 'Recall Score ': 0.7321428571428572, 'F1 Score ': 0.7658874458874458}, 25: {'Precision Score ': 0.8411654135338347, 'Recall Score ': 0.8364226135310473, 'F1 Score ': 0.8387121860175752}, 26: {'Precision Score ': 0.9367816091954023, 'Recall Score ': 0.5416666666666666, 'F1 Score ': 0.5431807456347334}, 27: {'Precision Score ': 0.6868932038834952, 'Recall Score ': 0.5302197802197802, 'F1 Score ': 0.5264175257731958}, 28: {'Precision Score ': 0.8717228464419475, 'Recall Score ': 0.6862101313320825, 'F1 Score ': 0.7368421052631579}, 29: {'Precision Score ': 0.6666666666666667, 'Recall Score ': 0.5411373260738053, 'F1 Score ': 0.5366919714745803}, 30: {'Precision Score ': 0.7286910197869102, 'Recall Score ': 0.6255221386800334, 'F1 Score ': 0.6294871794871796}, 31: {'Precision Score ': 0.8083333333333333, 'Recall Score ': 0.6541666666666667, 'F1 Score ': 0.6895927601809955}, 32: {'Precision Score ': 0.8306451612903226, 'Recall Score ': 0.6126373626373627, 'F1 Score ': 0.635477582846004}, 33: {'Precision Score ': 0.45263157894736844, 'Recall Score ': 0.5, 'F1 Score ': 0.47513812154696133}, 34: {'Precision Score ': 0.8290229885057472, 'Recall Score ': 0.7963250517598344, 'F1 Score ': 0.8108255133958928}, 35: {'Precision Score ': 0.822680412371134, 'Recall Score ': 0.5992390615091947, 'F1 Score ': 0.6222222222222222}, 36: {'Precision Score ': 0.6882022471910112, 'Recall Score ': 0.6407563025210085, 'F1 Score ': 0.6577636037472593}, 37: {'Precision Score ': 0.8577586206896552, 'Recall Score ': 0.8577586206896552, 'F1 Score ': 0.8577586206896552}, 38: {'Precision Score ': 0.849271402550091, 'Recall Score ': 0.8696385542168674, 'F1 Score ': 0.8531240918337692}, 39: {'Precision Score ': 0.41847826086956524, 'Recall Score ': 0.5, 'F1 Score ': 0.455621301775148}, 40: {'Precision Score ': 0.7982022471910113, 'Recall Score ': 0.7691683569979716, 'F1 Score ': 0.7816091954022988}, 41: {'Precision Score ': 0.7405133928571428, 'Recall Score ': 0.705654300369796, 'F1 Score ': 0.7051930507995351}, 42: {'Precision Score ': 0.8320570570570571, 'Recall Score ': 0.708986958986959, 'F1 Score ': 0.7276378545728391}, 43: {'Precision Score ': 0.7568558673469388, 'Recall Score ': 0.7998883097542815, 'F1 Score ': 0.7619850029488584}, 44: {'Precision Score ': 0.7251782298730656, 'Recall Score ': 0.7320788530465949, 'F1 Score ': 0.7259816207184628}, 45: {'Precision Score ': 0.8938271604938272, 'Recall Score ': 0.9425287356321839, 'F1 Score ': 0.9136904761904763}, 46: {'Precision Score ': 0.7539601430761369, 'Recall Score ': 0.7481897627965044, 'F1 Score ': 0.7470560527555347}, 47: {'Precision Score ': 0.795, 'Recall Score ': 0.6255853554704129, 'F1 Score ': 0.6415922935259952}, 48: {'Precision Score ': 0.7525233644859812, 'Recall Score ': 0.6810506566604128, 'F1 Score ': 0.696969696969697}, 49: {'Precision Score ': 0.7378787878787878, 'Recall Score ': 0.5379227053140097, 'F1 Score ': 0.5219230769230769}, 50: {'Precision Score ': 0.6778176025487853, 'Recall Score ': 0.6855006231823847, 'F1 Score ': 0.6813008130081302}, 51: {'Precision Score ': 0.6546341463414633, 'Recall Score ': 0.6505223171889838, 'F1 Score ': 0.6524720317574881}, 52: {'Precision Score ': 0.7831825037707391, 'Recall Score ': 0.845287356321839, 'F1 Score ': 0.8044170518746789}, 53: {'Precision Score ': 0.7331928345626976, 'Recall Score ': 0.7456159822419535, 'F1 Score ': 0.7335335764857327}, 54: {'Precision Score ': 0.731392557022809, 'Recall Score ': 0.7781385281385282, 'F1 Score ': 0.7371630295250321}, 55: {'Precision Score ': 0.8207637997432606, 'Recall Score ': 0.8541814316087881, 'F1 Score ': 0.8332075471698114}, 56: {'Precision Score ': 0.7609621115368241, 'Recall Score ': 0.7806776556776557, 'F1 Score ': 0.7696969696969698}, 57: {'Precision Score ': 0.6893280632411067, 'Recall Score ': 0.723205964585275, 'F1 Score ': 0.6889632107023411}, 58: {'Precision Score ': 0.6833333333333333, 'Recall Score ': 0.7166166541635408, 'F1 Score ': 0.6913979409512465}, 59: {'Precision Score ': 0.8378378378378379, 'Recall Score ': 0.8980206540447504, 'F1 Score ': 0.8585987261146497}, 60: {'Precision Score ': 0.7254312851327778, 'Recall Score ': 0.728756884343037, 'F1 Score ': 0.7261956998683633}, 61: {'Precision Score ': 0.7702973127501429, 'Recall Score ': 0.7164606227106227, 'F1 Score ': 0.7299617722629568}, 62: {'Precision Score ': 0.8207161125319693, 'Recall Score ': 0.8147590361445782, 'F1 Score ': 0.817502532928065}, 63: {'Precision Score ': 0.6993464052287581, 'Recall Score ': 0.6954627018713151, 'F1 Score ': 0.6972049689440993}, 64: {'Precision Score ': 0.6180241327300151, 'Recall Score ': 0.5627506014434643, 'F1 Score ': 0.5630699088145897}, 65: {'Precision Score ': 0.7287081339712919, 'Recall Score ': 0.7096491228070176, 'F1 Score ': 0.7173962695089455}, 66: {'Precision Score ': 0.782051282051282, 'Recall Score ': 0.7424242424242424, 'F1 Score ': 0.7568165070007369}, 67: {'Precision Score ': 0.8012987012987013, 'Recall Score ': 0.8067307692307693, 'F1 Score ': 0.8035597356985535}, 68: {'Precision Score ': 0.7666355721393034, 'Recall Score ': 0.7083333333333334, 'F1 Score ': 0.7028474399164055}, 69: {'Precision Score ': 0.7117647058823529, 'Recall Score ': 0.6875, 'F1 Score ': 0.696969696969697}, 70: {'Precision Score ': 0.8529411764705883, 'Recall Score ': 0.9695121951219512, 'F1 Score ': 0.8980698330080243}, 71: {'Precision Score ': 0.8296703296703296, 'Recall Score ': 0.8532608695652174, 'F1 Score ': 0.8408743169398907}, 72: {'Precision Score ': 0.9451219512195121, 'Recall Score ': 0.9451219512195121, 'F1 Score ': 0.9451219512195121}, 73: {'Precision Score ': 0.83125, 'Recall Score ': 0.8929564411492122, 'F1 Score ': 0.8578379521895494}, 74: {'Precision Score ': 0.8080143540669856, 'Recall Score ': 0.8080143540669856, 'F1 Score ': 0.8080143540669856}, 75: {'Precision Score ': 0.7383720930232558, 'Recall Score ': 0.8607038123167156, 'F1 Score ': 0.7796185706029666}, 76: {'Precision Score ': 0.6731271777003485, 'Recall Score ': 0.6840277777777778, 'F1 Score ': 0.6759838998211092}, 77: {'Precision Score ': 0.7419507575757576, 'Recall Score ': 0.678921568627451, 'F1 Score ': 0.6956349206349206}, 78: {'Precision Score ': 0.7304597701149425, 'Recall Score ': 0.7131467044649185, 'F1 Score ': 0.7204044117647059}, 79: {'Precision Score ': 0.890286161412922, 'Recall Score ': 0.8702545068928951, 'F1 Score ': 0.8771187589835381}, 80: {'Precision Score ': 0.776124907794443, 'Recall Score ': 0.7587557603686637, 'F1 Score ': 0.7475514343668501}, 81: {'Precision Score ': 0.8304761904761905, 'Recall Score ': 0.8688873139617292, 'F1 Score ': 0.8441039307128579}, 82: {'Precision Score ': 0.8747368421052631, 'Recall Score ': 0.9045454545454545, 'F1 Score ': 0.8870513402998637}, 83: {'Precision Score ': 0.8648809523809524, 'Recall Score ': 0.8602703496914488, 'F1 Score ': 0.8624972277666889}, 84: {'Precision Score ': 0.8108974358974359, 'Recall Score ': 0.8141006770680013, 'F1 Score ': 0.8124313639358665}, 85: {'Precision Score ': 0.8787499999999999, 'Recall Score ': 0.8920807453416149, 'F1 Score ': 0.8844004065040652}, 86: {'Precision Score ': 0.8434389140271493, 'Recall Score ': 0.775599128540305, 'F1 Score ': 0.8032128514056225}, 87: {'Precision Score ': 0.795120320855615, 'Recall Score ': 0.8100421348314606, 'F1 Score ': 0.8022598870056498}, 88: {'Precision Score ': 0.8393719806763285, 'Recall Score ': 0.8554712207463631, 'F1 Score ': 0.8471042471042471}, 89: {'Precision Score ': 0.9223985890652557, 'Recall Score ': 0.9544592030360531, 'F1 Score ': 0.936473165388828}, 90: {'Precision Score ': 0.9390665514261021, 'Recall Score ': 0.8691860465116279, 'F1 Score ': 0.8995073891625616}, 91: {'Precision Score ': 0.8667157584683358, 'Recall Score ': 0.6608527131782945, 'F1 Score ': 0.7044808743169398}, 92: {'Precision Score ': 0.828125, 'Recall Score ': 0.9395604395604396, 'F1 Score ': 0.8640626724042811}, 93: {'Precision Score ': 0.8760683760683761, 'Recall Score ': 0.9125, 'F1 Score ': 0.892777364110201}, 94: {'Precision Score ': 0.8545069570477919, 'Recall Score ': 0.8170995670995671, 'F1 Score ': 0.8336899158465269}, 95: {'Precision Score ': 0.8058823529411765, 'Recall Score ': 0.7695121951219512, 'F1 Score ': 0.7854021686357016}, 96: {'Precision Score ': 0.7847222222222223, 'Recall Score ': 0.8313131313131312, 'F1 Score ': 0.8051282051282052}, 97: {'Precision Score ': 0.9166666666666667, 'Recall Score ': 0.9814814814814814, 'F1 Score ': 0.9451114922813035}, 98: {'Precision Score ': 0.8272727272727273, 'Recall Score ': 0.8009404388714734, 'F1 Score ': 0.8133333333333332}, 99: {'Precision Score ': 0.8936708860759495, 'Recall Score ': 0.9461979913916786, 'F1 Score ': 0.9169044821218735}, 100: {'Precision Score ': 0.925, 'Recall Score ': 0.9836956521739131, 'F1 Score ': 0.9511721666417798}, 101: {'Precision Score ': 0.9583333333333333, 'Recall Score ': 0.9945054945054945, 'F1 Score ': 0.9754984386259908}, 102: {'Precision Score ': 0.8889228886168911, 'Recall Score ': 0.9462780898876404, 'F1 Score ': 0.9142857142857144}, 103: {'Precision Score ': 0.8873417721518988, 'Recall Score ': 0.9098214285714286, 'F1 Score ': 0.8980698330080243}, 104: {'Precision Score ': 0.7566619915848527, 'Recall Score ': 0.7376623376623377, 'F1 Score ': 0.7434133243832858}, 105: {'Precision Score ': 0.6490825688073394, 'Recall Score ': 0.554945054945055, 'F1 Score ': 0.5526470588235294}, 106: {'Precision Score ': 0.8738095238095238, 'Recall Score ': 0.6744444444444444, 'F1 Score ': 0.7135531135531135}, 107: {'Precision Score ': 0.723529411764706, 'Recall Score ': 0.6511936339522546, 'F1 Score ': 0.6677018633540373}, 108: {'Precision Score ': 0.7068627450980391, 'Recall Score ': 0.5564171122994652, 'F1 Score ': 0.5549613784907903}, 109: {'Precision Score ': 0.7232142857142857, 'Recall Score ': 0.6923076923076923, 'F1 Score ': 0.7037037037037037}, 110: {'Precision Score ': 0.9065420560747663, 'Recall Score ': 0.5454545454545454, 'F1 Score ': 0.531786941580756}, 111: {'Precision Score ': 0.8046558704453441, 'Recall Score ': 0.7848837209302326, 'F1 Score ': 0.7930529399455954}, 112: {'Precision Score ': 0.7745949074074074, 'Recall Score ': 0.7766226195102992, 'F1 Score ': 0.7754548974061168}, 113: {'Precision Score ': 0.6523809523809523, 'Recall Score ': 0.5680851063829787, 'F1 Score ': 0.5593631014191762}, 114: {'Precision Score ': 0.7803571428571429, 'Recall Score ': 0.785039941902687, 'F1 Score ': 0.782608695652174}, 115: {'Precision Score ': 0.6865979381443299, 'Recall Score ': 0.6081242532855436, 'F1 Score ': 0.6170004885197851}, 116: {'Precision Score ': 0.7666666666666666, 'Recall Score ': 0.739202657807309, 'F1 Score ': 0.7508741258741258}, 117: {'Precision Score ': 0.38571428571428573, 'Recall Score ': 0.4879518072289157, 'F1 Score ': 0.4308510638297873}, 118: {'Precision Score ': 0.6687196715192236, 'Recall Score ': 0.6396354649366698, 'F1 Score ': 0.6273299492385787}, 119: {'Precision Score ': 0.5040404040404041, 'Recall Score ': 0.5011904761904762, 'F1 Score ': 0.47715846994535516}, 120: {'Precision Score ': 0.9191919191919191, 'Recall Score ': 0.5555555555555556, 'F1 Score ': 0.5560439560439561}, 121: {'Precision Score ': 0.7181603773584906, 'Recall Score ': 0.6340579710144928, 'F1 Score ': 0.6517347386912604}, 122: {'Precision Score ': 0.7651515151515151, 'Recall Score ': 0.6964085297418631, 'F1 Score ': 0.7199744122821046}, 123: {'Precision Score ': 0.696969696969697, 'Recall Score ': 0.6444444444444444, 'F1 Score ': 0.6499999999999999}, 124: {'Precision Score ': 0.7387669801462905, 'Recall Score ': 0.6921783010933558, 'F1 Score ': 0.7050691244239631}, 125: {'Precision Score ': 0.76, 'Recall Score ': 0.7240255671136734, 'F1 Score ': 0.7265882974507991}, 126: {'Precision Score ': 0.7243063263041065, 'Recall Score ': 0.7243063263041065, 'F1 Score ': 0.7243063263041065}, 127: {'Precision Score ': 0.7960858585858586, 'Recall Score ': 0.8065359477124183, 'F1 Score ': 0.8009630818619583}, 128: {'Precision Score ': 0.6515837104072397, 'Recall Score ': 0.5771889400921659, 'F1 Score ': 0.5784457478005866}, 129: {'Precision Score ': 0.8128063725490196, 'Recall Score ': 0.7617277621122789, 'F1 Score ': 0.7758466101110421}, 130: {'Precision Score ': 0.7686011904761905, 'Recall Score ': 0.6990808823529412, 'F1 Score ': 0.7194829563223183}, 131: {'Precision Score ': 0.8081852004960728, 'Recall Score ': 0.8114035087719298, 'F1 Score ': 0.8096177814707104}, 132: {'Precision Score ': 0.7448298008991651, 'Recall Score ': 0.6726449275362318, 'F1 Score ': 0.6803601286173633}, 133: {'Precision Score ': 0.7501594896331738, 'Recall Score ': 0.7447721598002497, 'F1 Score ': 0.7463768115942029}, 134: {'Precision Score ': 0.7672265288544358, 'Recall Score ': 0.8211697722567288, 'F1 Score ': 0.7883895131086143}, 135: {'Precision Score ': 0.7285714285714285, 'Recall Score ': 0.621580547112462, 'F1 Score ': 0.6458096936294374}, 136: {'Precision Score ': 0.8290529695024077, 'Recall Score ': 0.8106060606060606, 'F1 Score ': 0.8194038573933372}, 137: {'Precision Score ': 0.9166666666666667, 'Recall Score ': 0.9775280898876404, 'F1 Score ': 0.9430512016718913}, 138: {'Precision Score ': 0.6497695852534562, 'Recall Score ': 0.5764705882352941, 'F1 Score ': 0.5914198161389173}, 139: {'Precision Score ': 0.679245283018868, 'Recall Score ': 0.5480708412397217, 'F1 Score ': 0.5525245273988992}, 140: {'Precision Score ': 0.9322916666666667, 'Recall Score ': 0.59375, 'F1 Score ': 0.621581887680094}, 141: {'Precision Score ': 0.7673992673992673, 'Recall Score ': 0.6126543209876543, 'F1 Score ': 0.6411205073995772}, 142: {'Precision Score ': 0.7447349310094409, 'Recall Score ': 0.7766830870279147, 'F1 Score ': 0.7571044546850998}, 143: {'Precision Score ': 0.8325969563082964, 'Recall Score ': 0.7512050426399703, 'F1 Score ': 0.778010033444816}, 144: {'Precision Score ': 0.8200000000000001, 'Recall Score ': 0.6015873015873016, 'F1 Score ': 0.6350877192982456}, 145: {'Precision Score ': 0.43478260869565216, 'Recall Score ': 0.5, 'F1 Score ': 0.46511627906976744}, 146: {'Precision Score ': 0.7573170731707317, 'Recall Score ': 0.7054527750730282, 'F1 Score ': 0.7267080745341614}, 147: {'Precision Score ': 0.945054945054945, 'Recall Score ': 0.6153846153846154, 'F1 Score ': 0.6584302325581395}, 148: {'Precision Score ': 0.8636029411764705, 'Recall Score ': 0.8815586419753086, 'F1 Score ': 0.8722002635046113}, 149: {'Precision Score ': 0.42777777777777776, 'Recall Score ': 0.5, 'F1 Score ': 0.4610778443113772}, 150: {'Precision Score ': 0.752028397565923, 'Recall Score ': 0.7363665187064046, 'F1 Score ': 0.7429738562091504}, 151: {'Precision Score ': 0.882495164410058, 'Recall Score ': 0.8104395604395604, 'F1 Score ': 0.8410810810810811}, 152: {'Precision Score ': 0.7946428571428572, 'Recall Score ': 0.7045454545454546, 'F1 Score ': 0.7342995169082125}, 153: {'Precision Score ': 0.7191078963230861, 'Recall Score ': 0.821396993810787, 'F1 Score ': 0.7519489723600283}, 154: {'Precision Score ': 0.7110344827586207, 'Recall Score ': 0.7052772808586762, 'F1 Score ': 0.7080358154822624}, 155: {'Precision Score ': 0.6651844532279314, 'Recall Score ': 0.6620879120879121, 'F1 Score ': 0.6635674088573525}, 156: {'Precision Score ': 0.4375, 'Recall Score ': 0.5, 'F1 Score ': 0.4666666666666667}, 157: {'Precision Score ': 0.8118131868131868, 'Recall Score ': 0.7966027874564461, 'F1 Score ': 0.8036590807675146}, 158: {'Precision Score ': 0.7528735632183907, 'Recall Score ': 0.7338766832034018, 'F1 Score ': 0.7419117647058824}, 159: {'Precision Score ': 0.7602564102564102, 'Recall Score ': 0.7636363636363637, 'F1 Score ': 0.7588755020080321}, 160: {'Precision Score ': 0.7606701940035273, 'Recall Score ': 0.76506456241033, 'F1 Score ': 0.7627811860940695}, 161: {'Precision Score ': 0.8983686067019401, 'Recall Score ': 0.9302380952380953, 'F1 Score ': 0.9127501429388221}, 162: {'Precision Score ': 0.8572433192686357, 'Recall Score ': 0.8663461538461539, 'F1 Score ': 0.8616352201257862}, 163: {'Precision Score ': 0.7645197319434103, 'Recall Score ': 0.7985294117647059, 'F1 Score ': 0.7777340676632573}, 164: {'Precision Score ': 0.8245757513800859, 'Recall Score ': 0.839572192513369, 'F1 Score ': 0.8256899771736874}, 165: {'Precision Score ': 0.8207831325301205, 'Recall Score ': 0.80679012345679, 'F1 Score ': 0.8132884777123632}, 166: {'Precision Score ': 0.8051643192488263, 'Recall Score ': 0.8517316017316017, 'F1 Score ': 0.8230730730730731}, 167: {'Precision Score ': 0.7553447756699789, 'Recall Score ': 0.7739018087855297, 'F1 Score ': 0.7628120382611401}, 168: {'Precision Score ': 0.7380556709597008, 'Recall Score ': 0.7329268292682927, 'F1 Score ': 0.7353877760657421}}\n"
     ]
    }
   ],
   "source": [
    "result_history = run_model(model_type = \"KNN\", neighbours = n_neighbours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"binary_KNN_\"+str(n_neighbours)+\"_result\", \"wb\")\n",
    "pickle.dump(result_history, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"binary_KNN_\"+str(n_neighbours)+\"_result\", \"rb\")\n",
    "l = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = {k: v for k, v in sorted(l.items(), key=lambda item: item[1][\"F1 Score \"], reverse = True)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101  =  {'Precision Score ': 0.9583333333333333, 'Recall Score ': 0.9945054945054945, 'F1 Score ': 0.9754984386259908}\n",
      "100  =  {'Precision Score ': 0.925, 'Recall Score ': 0.9836956521739131, 'F1 Score ': 0.9511721666417798}\n",
      "72  =  {'Precision Score ': 0.9451219512195121, 'Recall Score ': 0.9451219512195121, 'F1 Score ': 0.9451219512195121}\n",
      "97  =  {'Precision Score ': 0.9166666666666667, 'Recall Score ': 0.9814814814814814, 'F1 Score ': 0.9451114922813035}\n",
      "137  =  {'Precision Score ': 0.9166666666666667, 'Recall Score ': 0.9775280898876404, 'F1 Score ': 0.9430512016718913}\n",
      "89  =  {'Precision Score ': 0.9223985890652557, 'Recall Score ': 0.9544592030360531, 'F1 Score ': 0.936473165388828}\n",
      "99  =  {'Precision Score ': 0.8936708860759495, 'Recall Score ': 0.9461979913916786, 'F1 Score ': 0.9169044821218735}\n",
      "102  =  {'Precision Score ': 0.8889228886168911, 'Recall Score ': 0.9462780898876404, 'F1 Score ': 0.9142857142857144}\n",
      "45  =  {'Precision Score ': 0.8938271604938272, 'Recall Score ': 0.9425287356321839, 'F1 Score ': 0.9136904761904763}\n",
      "161  =  {'Precision Score ': 0.8983686067019401, 'Recall Score ': 0.9302380952380953, 'F1 Score ': 0.9127501429388221}\n",
      "90  =  {'Precision Score ': 0.9390665514261021, 'Recall Score ': 0.8691860465116279, 'F1 Score ': 0.8995073891625616}\n",
      "70  =  {'Precision Score ': 0.8529411764705883, 'Recall Score ': 0.9695121951219512, 'F1 Score ': 0.8980698330080243}\n",
      "103  =  {'Precision Score ': 0.8873417721518988, 'Recall Score ': 0.9098214285714286, 'F1 Score ': 0.8980698330080243}\n",
      "93  =  {'Precision Score ': 0.8760683760683761, 'Recall Score ': 0.9125, 'F1 Score ': 0.892777364110201}\n",
      "82  =  {'Precision Score ': 0.8747368421052631, 'Recall Score ': 0.9045454545454545, 'F1 Score ': 0.8870513402998637}\n",
      "85  =  {'Precision Score ': 0.8787499999999999, 'Recall Score ': 0.8920807453416149, 'F1 Score ': 0.8844004065040652}\n",
      "79  =  {'Precision Score ': 0.890286161412922, 'Recall Score ': 0.8702545068928951, 'F1 Score ': 0.8771187589835381}\n",
      "148  =  {'Precision Score ': 0.8636029411764705, 'Recall Score ': 0.8815586419753086, 'F1 Score ': 0.8722002635046113}\n",
      "92  =  {'Precision Score ': 0.828125, 'Recall Score ': 0.9395604395604396, 'F1 Score ': 0.8640626724042811}\n",
      "83  =  {'Precision Score ': 0.8648809523809524, 'Recall Score ': 0.8602703496914488, 'F1 Score ': 0.8624972277666889}\n"
     ]
    }
   ],
   "source": [
    "# Top 20 playlists \n",
    "for key in list(l.keys())[:20]:\n",
    "    print(key,\" = \",  l[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_list = []\n",
    "for key in list(l.keys()):\n",
    "    f1_list.append(l[key]['F1 Score '])\n",
    "print(f1_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum(f1_list)/len(f1_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANN Classification (Deep Learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :   0%|                                                                               | 0/169 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.7974 - accuracy: 0.21 - 0s 47ms/step - loss: 0.6584 - accuracy: 0.7340 - val_loss: 0.4655 - val_accuracy: 0.8673\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.4970 - accuracy: 0.85 - 0s 18ms/step - loss: 0.3709 - accuracy: 0.8670 - val_loss: 0.3170 - val_accuracy: 0.8673\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1717 - accuracy: 0.90 - 0s 17ms/step - loss: 0.2510 - accuracy: 0.8670 - val_loss: 0.2849 - val_accuracy: 0.8673\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2466 - accuracy: 0.85 - 0s 16ms/step - loss: 0.2068 - accuracy: 0.8670 - val_loss: 0.3488 - val_accuracy: 0.8673\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2535 - accuracy: 0.79 - 0s 18ms/step - loss: 0.1972 - accuracy: 0.8670 - val_loss: 0.4785 - val_accuracy: 0.8673\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1438 - accuracy: 0.89 - 0s 14ms/step - loss: 0.1802 - accuracy: 0.8670 - val_loss: 0.3722 - val_accuracy: 0.8673\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1484 - accuracy: 0.89 - 0s 17ms/step - loss: 0.1604 - accuracy: 0.8670 - val_loss: 0.5818 - val_accuracy: 0.8673\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2081 - accuracy: 0.87 - 0s 15ms/step - loss: 0.1679 - accuracy: 0.8670 - val_loss: 0.4539 - val_accuracy: 0.8673\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1107 - accuracy: 0.92 - 0s 14ms/step - loss: 0.1477 - accuracy: 0.8670 - val_loss: 0.4984 - val_accuracy: 0.8673\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1920 - accuracy: 0.81 - 0s 15ms/step - loss: 0.1344 - accuracy: 0.8670 - val_loss: 0.5804 - val_accuracy: 0.9082\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1198 - accuracy: 0.95 - 0s 17ms/step - loss: 0.1243 - accuracy: 0.9565 - val_loss: 0.6577 - val_accuracy: 0.9082\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1296 - accuracy: 0.92 - 0s 18ms/step - loss: 0.1234 - accuracy: 0.9565 - val_loss: 0.6035 - val_accuracy: 0.8980\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1110 - accuracy: 0.98 - 0s 17ms/step - loss: 0.1111 - accuracy: 0.9591 - val_loss: 0.6065 - val_accuracy: 0.8776\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1212 - accuracy: 0.98 - 0s 18ms/step - loss: 0.1127 - accuracy: 0.9540 - val_loss: 0.5313 - val_accuracy: 0.8980\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0637 - accuracy: 0.98 - 0s 17ms/step - loss: 0.1073 - accuracy: 0.9616 - val_loss: 0.5414 - val_accuracy: 0.8980\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0881 - accuracy: 0.96 - 0s 8ms/step - loss: 0.1291 - accuracy: 0.9540 - val_loss: 0.6592 - val_accuracy: 0.8878\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1074 - accuracy: 0.93 - 0s 5ms/step - loss: 0.1169 - accuracy: 0.9591 - val_loss: 0.5929 - val_accuracy: 0.8878\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1176 - accuracy: 0.95 - 0s 5ms/step - loss: 0.1130 - accuracy: 0.9540 - val_loss: 0.5893 - val_accuracy: 0.8776\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1264 - accuracy: 0.93 - 0s 6ms/step - loss: 0.0923 - accuracy: 0.9719 - val_loss: 0.4584 - val_accuracy: 0.8878\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1086 - accuracy: 0.96 - 0s 6ms/step - loss: 0.0918 - accuracy: 0.9719 - val_loss: 0.6353 - val_accuracy: 0.8980\n",
      "WARNING:tensorflow:From <ipython-input-5-0b824b3bdf17>:90: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "WARNING:tensorflow:From C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN0\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :   1%|â–                                                                      | 1/169 [00:13<38:53, 13.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1.0163 - accuracy: 0.2188WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 0.6374 - accuracy: 0.6729 - val_loss: 0.3437 - val_accuracy: 0.8505\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.3938 - accuracy: 0.81 - 0s 7ms/step - loss: 0.3119 - accuracy: 0.8551 - val_loss: 0.4017 - val_accuracy: 0.8505\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2199 - accuracy: 0.85 - 0s 7ms/step - loss: 0.2330 - accuracy: 0.8551 - val_loss: 0.3542 - val_accuracy: 0.8505\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1980 - accuracy: 0.87 - 0s 6ms/step - loss: 0.1987 - accuracy: 0.8551 - val_loss: 0.4161 - val_accuracy: 0.8505\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1960 - accuracy: 0.84 - 0s 6ms/step - loss: 0.1943 - accuracy: 0.8551 - val_loss: 0.4734 - val_accuracy: 0.8505\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1352 - accuracy: 0.89 - 0s 7ms/step - loss: 0.1820 - accuracy: 0.8551 - val_loss: 0.5141 - val_accuracy: 0.8505\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1697 - accuracy: 0.84 - 0s 6ms/step - loss: 0.1814 - accuracy: 0.8551 - val_loss: 0.5144 - val_accuracy: 0.8505\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1454 - accuracy: 0.84 - 0s 6ms/step - loss: 0.1656 - accuracy: 0.8551 - val_loss: 0.5215 - val_accuracy: 0.8505\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1593 - accuracy: 0.82 - 0s 6ms/step - loss: 0.1475 - accuracy: 0.9206 - val_loss: 0.8129 - val_accuracy: 0.8692\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1134 - accuracy: 0.96 - 0s 6ms/step - loss: 0.1450 - accuracy: 0.9369 - val_loss: 0.8387 - val_accuracy: 0.8411\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1062 - accuracy: 0.95 - 0s 7ms/step - loss: 0.1525 - accuracy: 0.9322 - val_loss: 0.8167 - val_accuracy: 0.8785\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1712 - accuracy: 0.95 - 0s 6ms/step - loss: 0.1371 - accuracy: 0.9439 - val_loss: 0.7324 - val_accuracy: 0.8598\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1262 - accuracy: 0.92 - 0s 6ms/step - loss: 0.1308 - accuracy: 0.9579 - val_loss: 0.7289 - val_accuracy: 0.8785\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1199 - accuracy: 0.96 - 0s 5ms/step - loss: 0.1133 - accuracy: 0.9556 - val_loss: 0.6501 - val_accuracy: 0.8785\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0744 - accuracy: 0.96 - 0s 5ms/step - loss: 0.1056 - accuracy: 0.9626 - val_loss: 0.6523 - val_accuracy: 0.8879\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1551 - accuracy: 0.90 - 0s 5ms/step - loss: 0.1058 - accuracy: 0.9579 - val_loss: 0.7287 - val_accuracy: 0.8692\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0319 - accuracy: 1.00 - 0s 7ms/step - loss: 0.1189 - accuracy: 0.9626 - val_loss: 0.6581 - val_accuracy: 0.8692\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1022 - accuracy: 0.95 - 0s 6ms/step - loss: 0.0973 - accuracy: 0.9650 - val_loss: 0.7117 - val_accuracy: 0.8692\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1347 - accuracy: 0.95 - 0s 6ms/step - loss: 0.1022 - accuracy: 0.9650 - val_loss: 0.8844 - val_accuracy: 0.8598\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0983 - accuracy: 0.95 - 0s 7ms/step - loss: 0.0890 - accuracy: 0.9696 - val_loss: 0.8573 - val_accuracy: 0.8411\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :   1%|â–Š                                                                      | 2/169 [00:21<33:31, 12.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.7863 - accuracy: 0.51 - 0s 28ms/step - loss: 0.5642 - accuracy: 0.7991 - val_loss: 0.3849 - val_accuracy: 0.8585\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.3642 - accuracy: 0.84 - 0s 6ms/step - loss: 0.3085 - accuracy: 0.8605 - val_loss: 0.3848 - val_accuracy: 0.8585\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2610 - accuracy: 0.89 - 0s 5ms/step - loss: 0.2595 - accuracy: 0.8605 - val_loss: 0.2949 - val_accuracy: 0.8585\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2526 - accuracy: 0.85 - 0s 5ms/step - loss: 0.2074 - accuracy: 0.8605 - val_loss: 0.3217 - val_accuracy: 0.8585\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1588 - accuracy: 0.85 - 0s 5ms/step - loss: 0.1863 - accuracy: 0.8605 - val_loss: 0.3526 - val_accuracy: 0.8585\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1646 - accuracy: 0.87 - 0s 6ms/step - loss: 0.1615 - accuracy: 0.9102 - val_loss: 0.3476 - val_accuracy: 0.8679\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1606 - accuracy: 0.92 - 0s 5ms/step - loss: 0.1651 - accuracy: 0.9291 - val_loss: 0.4380 - val_accuracy: 0.8679\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1410 - accuracy: 0.92 - 0s 5ms/step - loss: 0.1295 - accuracy: 0.9551 - val_loss: 0.4440 - val_accuracy: 0.8208\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0930 - accuracy: 0.98 - 0s 5ms/step - loss: 0.1274 - accuracy: 0.9551 - val_loss: 0.5759 - val_accuracy: 0.8396\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1789 - accuracy: 0.90 - 0s 5ms/step - loss: 0.1327 - accuracy: 0.9456 - val_loss: 0.3955 - val_accuracy: 0.8396\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1311 - accuracy: 0.92 - 0s 5ms/step - loss: 0.1252 - accuracy: 0.9527 - val_loss: 0.5871 - val_accuracy: 0.8491\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0683 - accuracy: 0.96 - 0s 5ms/step - loss: 0.1074 - accuracy: 0.9527 - val_loss: 0.6870 - val_accuracy: 0.8302\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0986 - accuracy: 0.96 - 0s 5ms/step - loss: 0.0983 - accuracy: 0.9622 - val_loss: 0.7734 - val_accuracy: 0.8302\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0976 - accuracy: 0.96 - 0s 5ms/step - loss: 0.0963 - accuracy: 0.9574 - val_loss: 0.7010 - val_accuracy: 0.8396\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0543 - accuracy: 0.98 - 0s 5ms/step - loss: 0.1015 - accuracy: 0.9598 - val_loss: 0.5931 - val_accuracy: 0.8491\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1292 - accuracy: 0.95 - 0s 6ms/step - loss: 0.1010 - accuracy: 0.9598 - val_loss: 0.6142 - val_accuracy: 0.8396\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1050 - accuracy: 0.95 - 0s 7ms/step - loss: 0.0939 - accuracy: 0.9622 - val_loss: 0.7390 - val_accuracy: 0.8679\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0427 - accuracy: 1.00 - 0s 7ms/step - loss: 0.1014 - accuracy: 0.9622 - val_loss: 0.7975 - val_accuracy: 0.8302\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1098 - accuracy: 0.95 - 0s 6ms/step - loss: 0.1143 - accuracy: 0.9551 - val_loss: 0.9822 - val_accuracy: 0.8396\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1180 - accuracy: 0.95 - 0s 7ms/step - loss: 0.1141 - accuracy: 0.9574 - val_loss: 0.6086 - val_accuracy: 0.8585\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :   2%|â–ˆâ–Ž                                                                     | 3/169 [00:29<29:35, 10.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.6820 - accuracy: 0.62 - 0s 34ms/step - loss: 0.5452 - accuracy: 0.7194 - val_loss: 0.4861 - val_accuracy: 0.7333\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.4096 - accuracy: 0.71 - 0s 8ms/step - loss: 0.3707 - accuracy: 0.7674 - val_loss: 0.4939 - val_accuracy: 0.8381\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2286 - accuracy: 0.85 - 0s 8ms/step - loss: 0.2734 - accuracy: 0.8729 - val_loss: 0.4684 - val_accuracy: 0.8571\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1885 - accuracy: 0.89 - 0s 6ms/step - loss: 0.2101 - accuracy: 0.9017 - val_loss: 0.5311 - val_accuracy: 0.8667\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1531 - accuracy: 0.95 - 0s 8ms/step - loss: 0.1665 - accuracy: 0.9353 - val_loss: 0.5042 - val_accuracy: 0.8571\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1003 - accuracy: 0.98 - 0s 8ms/step - loss: 0.1100 - accuracy: 0.9616 - val_loss: 0.5725 - val_accuracy: 0.8476\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1201 - accuracy: 0.93 - 0s 7ms/step - loss: 0.0833 - accuracy: 0.9640 - val_loss: 0.7659 - val_accuracy: 0.8381\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1106 - accuracy: 0.93 - 0s 7ms/step - loss: 0.0753 - accuracy: 0.9616 - val_loss: 1.0854 - val_accuracy: 0.8381\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0445 - accuracy: 0.98 - 0s 8ms/step - loss: 0.0744 - accuracy: 0.9712 - val_loss: 1.6880 - val_accuracy: 0.8095\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0514 - accuracy: 0.96 - 0s 8ms/step - loss: 0.1176 - accuracy: 0.9784 - val_loss: 1.1174 - val_accuracy: 0.8095\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0586 - accuracy: 0.98 - 0s 7ms/step - loss: 0.1418 - accuracy: 0.9736 - val_loss: 0.7316 - val_accuracy: 0.8381\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0310 - accuracy: 0.98 - 0s 6ms/step - loss: 0.1265 - accuracy: 0.9568 - val_loss: 0.5541 - val_accuracy: 0.8476\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1273 - accuracy: 0.95 - 0s 5ms/step - loss: 0.0909 - accuracy: 0.9760 - val_loss: 0.6397 - val_accuracy: 0.8476\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0577 - accuracy: 0.98 - 0s 5ms/step - loss: 0.0455 - accuracy: 0.9856 - val_loss: 0.8885 - val_accuracy: 0.8667\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0044 - accuracy: 1.00 - 0s 6ms/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 0.9692 - val_accuracy: 0.8667\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0042 - accuracy: 1.00 - 0s 6ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 1.0469 - val_accuracy: 0.8762\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 1.00 - 0s 5ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.1691 - val_accuracy: 0.8857\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 4.8529e-04 - accuracy: 1.00 - 0s 5ms/step - loss: 7.8873e-04 - accuracy: 1.0000 - val_loss: 1.2690 - val_accuracy: 0.8762\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 2.8622e-04 - accuracy: 1.00 - 0s 6ms/step - loss: 4.3447e-04 - accuracy: 1.0000 - val_loss: 1.3411 - val_accuracy: 0.8762\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 6.5540e-05 - accuracy: 1.00 - 0s 6ms/step - loss: 2.4575e-04 - accuracy: 1.0000 - val_loss: 1.3876 - val_accuracy: 0.8762\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN3\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :   2%|â–ˆâ–‹                                                                     | 4/169 [00:37<27:26,  9.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_16 (Dense)             (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.6414 - accuracy: 0.59 - 0s 27ms/step - loss: 0.3924 - accuracy: 0.7928 - val_loss: 0.3094 - val_accuracy: 0.8269\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2900 - accuracy: 0.78 - 0s 5ms/step - loss: 0.3054 - accuracy: 0.8241 - val_loss: 0.3298 - val_accuracy: 0.8269\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2663 - accuracy: 0.81 - 0s 5ms/step - loss: 0.2648 - accuracy: 0.8241 - val_loss: 0.3071 - val_accuracy: 0.8269\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2404 - accuracy: 0.81 - 0s 6ms/step - loss: 0.2340 - accuracy: 0.8241 - val_loss: 0.3247 - val_accuracy: 0.8654\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1858 - accuracy: 0.92 - 0s 5ms/step - loss: 0.2075 - accuracy: 0.9084 - val_loss: 0.3468 - val_accuracy: 0.8365\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1654 - accuracy: 0.92 - 0s 6ms/step - loss: 0.1872 - accuracy: 0.9253 - val_loss: 0.4334 - val_accuracy: 0.8365\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2202 - accuracy: 0.87 - 0s 5ms/step - loss: 0.1650 - accuracy: 0.9301 - val_loss: 0.3884 - val_accuracy: 0.8269\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1241 - accuracy: 0.96 - 0s 5ms/step - loss: 0.1418 - accuracy: 0.9470 - val_loss: 0.5782 - val_accuracy: 0.8269\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1719 - accuracy: 0.92 - 0s 5ms/step - loss: 0.1505 - accuracy: 0.9325 - val_loss: 0.3658 - val_accuracy: 0.8365\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1127 - accuracy: 0.93 - 0s 6ms/step - loss: 0.1290 - accuracy: 0.9494 - val_loss: 0.5704 - val_accuracy: 0.8462\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0380 - accuracy: 1.00 - 0s 6ms/step - loss: 0.1104 - accuracy: 0.9590 - val_loss: 0.4873 - val_accuracy: 0.8269\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0892 - accuracy: 0.96 - 0s 6ms/step - loss: 0.1001 - accuracy: 0.9639 - val_loss: 0.5411 - val_accuracy: 0.8365\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1007 - accuracy: 0.96 - 0s 6ms/step - loss: 0.0811 - accuracy: 0.9759 - val_loss: 0.7260 - val_accuracy: 0.8269\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0539 - accuracy: 0.98 - 0s 6ms/step - loss: 0.1067 - accuracy: 0.9663 - val_loss: 0.5545 - val_accuracy: 0.8462\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0366 - accuracy: 1.00 - 0s 6ms/step - loss: 0.1049 - accuracy: 0.9566 - val_loss: 0.4330 - val_accuracy: 0.8558\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0413 - accuracy: 1.00 - 0s 7ms/step - loss: 0.1414 - accuracy: 0.9639 - val_loss: 0.3792 - val_accuracy: 0.8558\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0688 - accuracy: 0.98 - 0s 6ms/step - loss: 0.0984 - accuracy: 0.9614 - val_loss: 0.3478 - val_accuracy: 0.8365\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1101 - accuracy: 0.96 - 0s 5ms/step - loss: 0.0787 - accuracy: 0.9759 - val_loss: 0.5702 - val_accuracy: 0.8558\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0897 - accuracy: 0.95 - 0s 6ms/step - loss: 0.0660 - accuracy: 0.9783 - val_loss: 0.4882 - val_accuracy: 0.8173\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0309 - accuracy: 1.00 - 0s 6ms/step - loss: 0.0734 - accuracy: 0.9759 - val_loss: 0.4601 - val_accuracy: 0.8558\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :   3%|â–ˆâ–ˆ                                                                     | 5/169 [00:44<24:40,  9.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_20 (Dense)             (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.6773 - accuracy: 0.68 - 0s 25ms/step - loss: 0.4463 - accuracy: 0.8342 - val_loss: 0.3000 - val_accuracy: 0.8587\n",
      "Epoch 2/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.3087 - accuracy: 0.82 - 0s 5ms/step - loss: 0.2689 - accuracy: 0.8641 - val_loss: 0.2664 - val_accuracy: 0.8587\n",
      "Epoch 3/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1781 - accuracy: 0.87 - 0s 6ms/step - loss: 0.2296 - accuracy: 0.8641 - val_loss: 0.2831 - val_accuracy: 0.8587\n",
      "Epoch 4/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1511 - accuracy: 0.89 - 0s 6ms/step - loss: 0.1788 - accuracy: 0.8641 - val_loss: 0.2618 - val_accuracy: 0.8587\n",
      "Epoch 5/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1958 - accuracy: 0.89 - 0s 7ms/step - loss: 0.1608 - accuracy: 0.8641 - val_loss: 0.3441 - val_accuracy: 0.8587\n",
      "Epoch 6/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1673 - accuracy: 0.84 - 0s 7ms/step - loss: 0.1240 - accuracy: 0.9348 - val_loss: 0.3432 - val_accuracy: 0.8587\n",
      "Epoch 7/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0848 - accuracy: 0.98 - 0s 7ms/step - loss: 0.1020 - accuracy: 0.9837 - val_loss: 0.4209 - val_accuracy: 0.8478\n",
      "Epoch 8/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0833 - accuracy: 1.00 - 0s 6ms/step - loss: 0.0864 - accuracy: 0.9864 - val_loss: 0.4374 - val_accuracy: 0.8696\n",
      "Epoch 9/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0859 - accuracy: 0.98 - 0s 7ms/step - loss: 0.0732 - accuracy: 0.9918 - val_loss: 0.5298 - val_accuracy: 0.8587\n",
      "Epoch 10/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0617 - accuracy: 1.00 - 0s 6ms/step - loss: 0.0668 - accuracy: 0.9918 - val_loss: 0.6586 - val_accuracy: 0.8478\n",
      "Epoch 11/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0293 - accuracy: 1.00 - 0s 5ms/step - loss: 0.0580 - accuracy: 0.9918 - val_loss: 0.7099 - val_accuracy: 0.8587\n",
      "Epoch 12/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0610 - accuracy: 0.98 - 0s 5ms/step - loss: 0.0536 - accuracy: 0.9946 - val_loss: 0.7231 - val_accuracy: 0.8478\n",
      "Epoch 13/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0541 - accuracy: 1.00 - 0s 5ms/step - loss: 0.0537 - accuracy: 0.9891 - val_loss: 0.7774 - val_accuracy: 0.9022\n",
      "Epoch 14/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0707 - accuracy: 0.98 - 0s 6ms/step - loss: 0.0523 - accuracy: 0.9891 - val_loss: 0.5302 - val_accuracy: 0.8478\n",
      "Epoch 15/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0577 - accuracy: 0.98 - 0s 6ms/step - loss: 0.0712 - accuracy: 0.9783 - val_loss: 0.5192 - val_accuracy: 0.8587\n",
      "Epoch 16/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0375 - accuracy: 1.00 - 0s 5ms/step - loss: 0.0514 - accuracy: 0.9864 - val_loss: 0.3610 - val_accuracy: 0.8913\n",
      "Epoch 17/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0237 - accuracy: 1.00 - 0s 6ms/step - loss: 0.0725 - accuracy: 0.9864 - val_loss: 0.3272 - val_accuracy: 0.9130\n",
      "Epoch 18/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0251 - accuracy: 1.00 - 0s 6ms/step - loss: 0.0557 - accuracy: 0.9837 - val_loss: 0.3893 - val_accuracy: 0.9130\n",
      "Epoch 19/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0327 - accuracy: 1.00 - 0s 6ms/step - loss: 0.0983 - accuracy: 0.9728 - val_loss: 0.5131 - val_accuracy: 0.8913\n",
      "Epoch 20/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0241 - accuracy: 1.00 - 0s 6ms/step - loss: 0.0651 - accuracy: 0.9755 - val_loss: 0.5688 - val_accuracy: 0.9130\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :   4%|â–ˆâ–ˆâ–Œ                                                                    | 6/169 [00:50<22:27,  8.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_24 (Dense)             (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.7418 - accuracy: 0.54 - 0s 22ms/step - loss: 0.4225 - accuracy: 0.8303 - val_loss: 0.2293 - val_accuracy: 0.8878\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1149 - accuracy: 0.93 - 0s 4ms/step - loss: 0.1833 - accuracy: 0.8843 - val_loss: 0.2305 - val_accuracy: 0.8878\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0873 - accuracy: 0.92 - 0s 5ms/step - loss: 0.1467 - accuracy: 0.8843 - val_loss: 0.2196 - val_accuracy: 0.8878\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1965 - accuracy: 0.81 - 0s 6ms/step - loss: 0.1366 - accuracy: 0.8843 - val_loss: 0.2276 - val_accuracy: 0.8878\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0795 - accuracy: 0.93 - 0s 5ms/step - loss: 0.1158 - accuracy: 0.8843 - val_loss: 0.2130 - val_accuracy: 0.8878\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1081 - accuracy: 0.89 - 0s 5ms/step - loss: 0.1040 - accuracy: 0.8920 - val_loss: 0.2533 - val_accuracy: 0.9082\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1036 - accuracy: 1.00 - 0s 5ms/step - loss: 0.0935 - accuracy: 0.9692 - val_loss: 0.2878 - val_accuracy: 0.9082\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0947 - accuracy: 0.95 - 0s 5ms/step - loss: 0.0842 - accuracy: 0.9743 - val_loss: 0.2864 - val_accuracy: 0.8980\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0851 - accuracy: 0.96 - 0s 5ms/step - loss: 0.0789 - accuracy: 0.9769 - val_loss: 0.3159 - val_accuracy: 0.8980\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0789 - accuracy: 0.98 - 0s 5ms/step - loss: 0.0742 - accuracy: 0.9769 - val_loss: 0.3503 - val_accuracy: 0.8878\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0676 - accuracy: 0.98 - 0s 5ms/step - loss: 0.0704 - accuracy: 0.9769 - val_loss: 0.4021 - val_accuracy: 0.8878\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0577 - accuracy: 0.98 - 0s 5ms/step - loss: 0.0680 - accuracy: 0.9769 - val_loss: 0.2855 - val_accuracy: 0.8980\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0707 - accuracy: 0.96 - 0s 5ms/step - loss: 0.0669 - accuracy: 0.9769 - val_loss: 0.4100 - val_accuracy: 0.8367\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0470 - accuracy: 1.00 - 0s 5ms/step - loss: 0.0741 - accuracy: 0.9769 - val_loss: 0.2180 - val_accuracy: 0.8776\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0839 - accuracy: 0.96 - 0s 5ms/step - loss: 0.0858 - accuracy: 0.9692 - val_loss: 0.2357 - val_accuracy: 0.8878\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0471 - accuracy: 0.98 - 0s 5ms/step - loss: 0.0635 - accuracy: 0.9769 - val_loss: 0.2188 - val_accuracy: 0.8980\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0640 - accuracy: 0.98 - 0s 5ms/step - loss: 0.0703 - accuracy: 0.9769 - val_loss: 0.2187 - val_accuracy: 0.8878\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0891 - accuracy: 0.96 - 0s 6ms/step - loss: 0.0597 - accuracy: 0.9846 - val_loss: 0.2605 - val_accuracy: 0.8980\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0828 - accuracy: 0.96 - 0s 5ms/step - loss: 0.0521 - accuracy: 0.9820 - val_loss: 0.2530 - val_accuracy: 0.9184\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0349 - accuracy: 1.00 - 0s 5ms/step - loss: 0.0457 - accuracy: 0.9897 - val_loss: 0.3301 - val_accuracy: 0.9082\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN6\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :   4%|â–ˆâ–ˆâ–‰                                                                    | 7/169 [00:57<20:58,  7.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_28 (Dense)             (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.8919 - accuracy: 0.31 - 0s 21ms/step - loss: 0.4480 - accuracy: 0.7820 - val_loss: 0.1958 - val_accuracy: 0.8800\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2451 - accuracy: 0.87 - 0s 5ms/step - loss: 0.2198 - accuracy: 0.8772 - val_loss: 0.1970 - val_accuracy: 0.8800\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1877 - accuracy: 0.85 - 0s 5ms/step - loss: 0.1705 - accuracy: 0.8772 - val_loss: 0.1602 - val_accuracy: 0.8800\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0878 - accuracy: 0.92 - 0s 5ms/step - loss: 0.1478 - accuracy: 0.8772 - val_loss: 0.1666 - val_accuracy: 0.8800\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1461 - accuracy: 0.90 - 0s 5ms/step - loss: 0.1268 - accuracy: 0.8772 - val_loss: 0.1568 - val_accuracy: 0.9200\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0999 - accuracy: 0.98 - 0s 5ms/step - loss: 0.1175 - accuracy: 0.9599 - val_loss: 0.1582 - val_accuracy: 0.9200\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0703 - accuracy: 0.96 - 0s 5ms/step - loss: 0.1229 - accuracy: 0.9499 - val_loss: 0.1655 - val_accuracy: 0.8900\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0794 - accuracy: 0.96 - 0s 5ms/step - loss: 0.1143 - accuracy: 0.9549 - val_loss: 0.1675 - val_accuracy: 0.9000\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0852 - accuracy: 0.96 - 0s 5ms/step - loss: 0.1153 - accuracy: 0.9524 - val_loss: 0.1991 - val_accuracy: 0.8600\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1056 - accuracy: 0.96 - 0s 5ms/step - loss: 0.1193 - accuracy: 0.9449 - val_loss: 0.1642 - val_accuracy: 0.9000\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0940 - accuracy: 0.95 - 0s 5ms/step - loss: 0.0979 - accuracy: 0.9624 - val_loss: 0.1731 - val_accuracy: 0.9000\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0969 - accuracy: 0.98 - 0s 5ms/step - loss: 0.1027 - accuracy: 0.9674 - val_loss: 0.1743 - val_accuracy: 0.8900\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0549 - accuracy: 1.00 - 0s 5ms/step - loss: 0.0809 - accuracy: 0.9724 - val_loss: 0.1343 - val_accuracy: 0.9200\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0871 - accuracy: 0.95 - 0s 5ms/step - loss: 0.0842 - accuracy: 0.9699 - val_loss: 0.1375 - val_accuracy: 0.9300\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0958 - accuracy: 0.95 - 0s 5ms/step - loss: 0.0968 - accuracy: 0.9649 - val_loss: 0.1424 - val_accuracy: 0.9200\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0640 - accuracy: 0.98 - 0s 5ms/step - loss: 0.0799 - accuracy: 0.9674 - val_loss: 0.1579 - val_accuracy: 0.9100\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0796 - accuracy: 0.96 - 0s 5ms/step - loss: 0.0740 - accuracy: 0.9699 - val_loss: 0.1436 - val_accuracy: 0.9200\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0335 - accuracy: 1.00 - 0s 5ms/step - loss: 0.0703 - accuracy: 0.9749 - val_loss: 0.1509 - val_accuracy: 0.9200\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0456 - accuracy: 0.98 - 0s 5ms/step - loss: 0.0633 - accuracy: 0.9799 - val_loss: 0.1605 - val_accuracy: 0.9100\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0589 - accuracy: 0.98 - 0s 5ms/step - loss: 0.0616 - accuracy: 0.9799 - val_loss: 0.1685 - val_accuracy: 0.9100\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN7\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :   5%|â–ˆâ–ˆâ–ˆâ–Ž                                                                   | 8/169 [01:04<19:55,  7.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_32 (Dense)             (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.4070 - accuracy: 0.89 - 0s 22ms/step - loss: 0.3121 - accuracy: 0.8837 - val_loss: 0.3119 - val_accuracy: 0.8824\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1858 - accuracy: 0.85 - 0s 5ms/step - loss: 0.1971 - accuracy: 0.8886 - val_loss: 0.2368 - val_accuracy: 0.9118\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1227 - accuracy: 0.95 - 0s 5ms/step - loss: 0.1378 - accuracy: 0.9332 - val_loss: 0.3362 - val_accuracy: 0.9118\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1310 - accuracy: 0.93 - 0s 5ms/step - loss: 0.1077 - accuracy: 0.9530 - val_loss: 0.3258 - val_accuracy: 0.9020\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0815 - accuracy: 0.96 - 0s 5ms/step - loss: 0.0852 - accuracy: 0.9752 - val_loss: 0.4486 - val_accuracy: 0.9118\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0572 - accuracy: 0.98 - 0s 6ms/step - loss: 0.0670 - accuracy: 0.9851 - val_loss: 0.3291 - val_accuracy: 0.9118\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0789 - accuracy: 0.96 - 0s 5ms/step - loss: 0.0573 - accuracy: 0.9876 - val_loss: 0.3997 - val_accuracy: 0.9118\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0441 - accuracy: 1.00 - 0s 5ms/step - loss: 0.0488 - accuracy: 0.9901 - val_loss: 0.4382 - val_accuracy: 0.9216\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0244 - accuracy: 1.00 - 0s 5ms/step - loss: 0.0453 - accuracy: 0.9901 - val_loss: 0.4603 - val_accuracy: 0.9216\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0502 - accuracy: 0.98 - 0s 5ms/step - loss: 0.0414 - accuracy: 0.9901 - val_loss: 0.4374 - val_accuracy: 0.9216\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0458 - accuracy: 0.98 - 0s 5ms/step - loss: 0.0400 - accuracy: 0.9901 - val_loss: 0.4954 - val_accuracy: 0.8922\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0267 - accuracy: 1.00 - 0s 5ms/step - loss: 0.0375 - accuracy: 0.9901 - val_loss: 0.7545 - val_accuracy: 0.8824\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0231 - accuracy: 1.00 - 0s 5ms/step - loss: 0.0355 - accuracy: 0.9901 - val_loss: 0.6067 - val_accuracy: 0.8824\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0328 - accuracy: 1.00 - 0s 5ms/step - loss: 0.0336 - accuracy: 0.9926 - val_loss: 0.7603 - val_accuracy: 0.9216\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0506 - accuracy: 0.98 - 0s 5ms/step - loss: 0.0440 - accuracy: 0.9876 - val_loss: 0.8111 - val_accuracy: 0.9020\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0374 - accuracy: 0.98 - 0s 5ms/step - loss: 0.0577 - accuracy: 0.9827 - val_loss: 0.6420 - val_accuracy: 0.9216\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0443 - accuracy: 0.98 - 0s 5ms/step - loss: 0.0504 - accuracy: 0.9802 - val_loss: 0.5272 - val_accuracy: 0.9020\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0236 - accuracy: 1.00 - 0s 5ms/step - loss: 0.0575 - accuracy: 0.9802 - val_loss: 0.7831 - val_accuracy: 0.8627\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0831 - accuracy: 0.96 - 0s 5ms/step - loss: 0.0448 - accuracy: 0.9851 - val_loss: 0.7732 - val_accuracy: 0.8529\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0876 - accuracy: 0.96 - 0s 5ms/step - loss: 0.0351 - accuracy: 0.9901 - val_loss: 0.7690 - val_accuracy: 0.8922\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN8\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :   5%|â–ˆâ–ˆâ–ˆâ–Š                                                                   | 9/169 [01:10<19:12,  7.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_36 (Dense)             (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.8505 - accuracy: 0.23 - 0s 23ms/step - loss: 0.6811 - accuracy: 0.6979 - val_loss: 0.6181 - val_accuracy: 0.7636\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.6175 - accuracy: 0.76 - 0s 4ms/step - loss: 0.5907 - accuracy: 0.7757 - val_loss: 0.5576 - val_accuracy: 0.7727\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.5183 - accuracy: 0.85 - 0s 5ms/step - loss: 0.5204 - accuracy: 0.8124 - val_loss: 0.5780 - val_accuracy: 0.8000\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.5544 - accuracy: 0.75 - 0s 5ms/step - loss: 0.4651 - accuracy: 0.8238 - val_loss: 0.5149 - val_accuracy: 0.8000\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.4533 - accuracy: 0.84 - 0s 5ms/step - loss: 0.4350 - accuracy: 0.8444 - val_loss: 0.7012 - val_accuracy: 0.8273\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.3414 - accuracy: 0.92 - 0s 5ms/step - loss: 0.4226 - accuracy: 0.8444 - val_loss: 0.5600 - val_accuracy: 0.7909\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.4097 - accuracy: 0.84 - 0s 5ms/step - loss: 0.4023 - accuracy: 0.8490 - val_loss: 0.7555 - val_accuracy: 0.7455\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.4748 - accuracy: 0.81 - 0s 5ms/step - loss: 0.3570 - accuracy: 0.8764 - val_loss: 0.6256 - val_accuracy: 0.7909\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.3877 - accuracy: 0.85 - 0s 5ms/step - loss: 0.3377 - accuracy: 0.8924 - val_loss: 0.4897 - val_accuracy: 0.8364\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.3406 - accuracy: 0.89 - 0s 5ms/step - loss: 0.3002 - accuracy: 0.9062 - val_loss: 0.6880 - val_accuracy: 0.7818\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.3510 - accuracy: 0.89 - 0s 5ms/step - loss: 0.2850 - accuracy: 0.9153 - val_loss: 0.6223 - val_accuracy: 0.7636\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2067 - accuracy: 0.95 - 0s 5ms/step - loss: 0.2627 - accuracy: 0.9268 - val_loss: 0.7076 - val_accuracy: 0.7727\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2787 - accuracy: 0.90 - 0s 5ms/step - loss: 0.2522 - accuracy: 0.9199 - val_loss: 0.6713 - val_accuracy: 0.7909\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2590 - accuracy: 0.92 - 0s 5ms/step - loss: 0.2435 - accuracy: 0.9291 - val_loss: 0.7773 - val_accuracy: 0.7909\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1190 - accuracy: 0.98 - 0s 5ms/step - loss: 0.2407 - accuracy: 0.9291 - val_loss: 1.0086 - val_accuracy: 0.7818\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2222 - accuracy: 0.93 - 0s 5ms/step - loss: 0.2341 - accuracy: 0.9336 - val_loss: 0.8121 - val_accuracy: 0.8000\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1133 - accuracy: 0.98 - 0s 5ms/step - loss: 0.2286 - accuracy: 0.9359 - val_loss: 0.7174 - val_accuracy: 0.8000\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1885 - accuracy: 0.95 - 0s 5ms/step - loss: 0.2361 - accuracy: 0.9314 - val_loss: 0.8887 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.3019 - accuracy: 0.90 - 0s 5ms/step - loss: 0.2335 - accuracy: 0.9314 - val_loss: 1.5482 - val_accuracy: 0.7636\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2353 - accuracy: 0.92 - 0s 6ms/step - loss: 0.2417 - accuracy: 0.9291 - val_loss: 1.1008 - val_accuracy: 0.7727\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN9\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :   6%|â–ˆâ–ˆâ–ˆâ–ˆâ–                                                                 | 10/169 [01:17<18:28,  6.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_40 (Dense)             (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.9017 - accuracy: 0.35 - 0s 24ms/step - loss: 0.5012 - accuracy: 0.7587 - val_loss: 0.2901 - val_accuracy: 0.8511\n",
      "Epoch 2/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.3399 - accuracy: 0.79 - 0s 5ms/step - loss: 0.2804 - accuracy: 0.8472 - val_loss: 0.2673 - val_accuracy: 0.8511\n",
      "Epoch 3/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.3464 - accuracy: 0.81 - 0s 5ms/step - loss: 0.2372 - accuracy: 0.8472 - val_loss: 0.2864 - val_accuracy: 0.8511\n",
      "Epoch 4/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.2548 - accuracy: 0.79 - 0s 5ms/step - loss: 0.2062 - accuracy: 0.8472 - val_loss: 0.3145 - val_accuracy: 0.8511\n",
      "Epoch 5/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.2102 - accuracy: 0.84 - 0s 5ms/step - loss: 0.1815 - accuracy: 0.8472 - val_loss: 0.3403 - val_accuracy: 0.8511\n",
      "Epoch 6/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.2286 - accuracy: 0.73 - 0s 5ms/step - loss: 0.1672 - accuracy: 0.8606 - val_loss: 0.3680 - val_accuracy: 0.9255\n",
      "Epoch 7/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1930 - accuracy: 0.87 - 0s 5ms/step - loss: 0.1540 - accuracy: 0.9357 - val_loss: 0.4227 - val_accuracy: 0.9043\n",
      "Epoch 8/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1552 - accuracy: 0.93 - 0s 5ms/step - loss: 0.1359 - accuracy: 0.9544 - val_loss: 0.5386 - val_accuracy: 0.9043\n",
      "Epoch 9/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1434 - accuracy: 0.92 - 0s 5ms/step - loss: 0.1396 - accuracy: 0.9383 - val_loss: 0.4840 - val_accuracy: 0.9149\n",
      "Epoch 10/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1629 - accuracy: 0.92 - 0s 6ms/step - loss: 0.1518 - accuracy: 0.9383 - val_loss: 0.5004 - val_accuracy: 0.9149\n",
      "Epoch 11/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1242 - accuracy: 0.92 - 0s 7ms/step - loss: 0.1466 - accuracy: 0.9303 - val_loss: 0.5669 - val_accuracy: 0.9043\n",
      "Epoch 12/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1407 - accuracy: 0.93 - 0s 6ms/step - loss: 0.1243 - accuracy: 0.9517 - val_loss: 0.4794 - val_accuracy: 0.8936\n",
      "Epoch 13/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1247 - accuracy: 0.95 - 0s 6ms/step - loss: 0.1167 - accuracy: 0.9544 - val_loss: 0.5131 - val_accuracy: 0.8723\n",
      "Epoch 14/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0958 - accuracy: 0.95 - 0s 6ms/step - loss: 0.1157 - accuracy: 0.9464 - val_loss: 0.4963 - val_accuracy: 0.8830\n",
      "Epoch 15/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0932 - accuracy: 0.96 - 0s 6ms/step - loss: 0.1061 - accuracy: 0.9598 - val_loss: 0.5373 - val_accuracy: 0.8830\n",
      "Epoch 16/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0834 - accuracy: 0.96 - 0s 6ms/step - loss: 0.1050 - accuracy: 0.9571 - val_loss: 0.5730 - val_accuracy: 0.8936\n",
      "Epoch 17/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1038 - accuracy: 0.96 - 0s 5ms/step - loss: 0.1064 - accuracy: 0.9571 - val_loss: 0.5981 - val_accuracy: 0.8936\n",
      "Epoch 18/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1296 - accuracy: 0.93 - 0s 5ms/step - loss: 0.1112 - accuracy: 0.9544 - val_loss: 0.5597 - val_accuracy: 0.8830\n",
      "Epoch 19/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1751 - accuracy: 0.90 - 0s 5ms/step - loss: 0.1137 - accuracy: 0.9517 - val_loss: 0.6836 - val_accuracy: 0.8936\n",
      "Epoch 20/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0560 - accuracy: 1.00 - 0s 5ms/step - loss: 0.1044 - accuracy: 0.9544 - val_loss: 0.8371 - val_accuracy: 0.9043\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN10\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :   7%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                                 | 11/169 [01:23<17:51,  6.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_44 (Dense)             (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.6947 - accuracy: 0.51 - 0s 33ms/step - loss: 0.4526 - accuracy: 0.7452 - val_loss: 0.2633 - val_accuracy: 0.8476\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2894 - accuracy: 0.79 - 0s 8ms/step - loss: 0.2381 - accuracy: 0.8762 - val_loss: 0.2730 - val_accuracy: 0.8762\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2032 - accuracy: 0.89 - 0s 7ms/step - loss: 0.2009 - accuracy: 0.9024 - val_loss: 0.2870 - val_accuracy: 0.8762\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1876 - accuracy: 0.92 - 0s 6ms/step - loss: 0.1936 - accuracy: 0.9190 - val_loss: 0.2967 - val_accuracy: 0.8762\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1596 - accuracy: 0.92 - 0s 7ms/step - loss: 0.1679 - accuracy: 0.9286 - val_loss: 0.3676 - val_accuracy: 0.8952\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1614 - accuracy: 0.96 - 0s 6ms/step - loss: 0.1489 - accuracy: 0.9429 - val_loss: 0.3806 - val_accuracy: 0.8952\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1813 - accuracy: 0.93 - 0s 6ms/step - loss: 0.1326 - accuracy: 0.9476 - val_loss: 0.5892 - val_accuracy: 0.9143\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0664 - accuracy: 0.98 - 0s 5ms/step - loss: 0.1261 - accuracy: 0.9548 - val_loss: 0.5397 - val_accuracy: 0.8857\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1796 - accuracy: 0.95 - 0s 6ms/step - loss: 0.1197 - accuracy: 0.9571 - val_loss: 0.3992 - val_accuracy: 0.8857\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1584 - accuracy: 0.93 - 0s 6ms/step - loss: 0.0948 - accuracy: 0.9714 - val_loss: 0.4243 - val_accuracy: 0.8952\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0397 - accuracy: 0.98 - 0s 6ms/step - loss: 0.0847 - accuracy: 0.9738 - val_loss: 0.6433 - val_accuracy: 0.8857\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0666 - accuracy: 0.96 - 0s 5ms/step - loss: 0.0645 - accuracy: 0.9786 - val_loss: 0.5656 - val_accuracy: 0.8762\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0192 - accuracy: 1.00 - 0s 5ms/step - loss: 0.0592 - accuracy: 0.9762 - val_loss: 0.8007 - val_accuracy: 0.8762\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0420 - accuracy: 0.98 - 0s 5ms/step - loss: 0.0789 - accuracy: 0.9762 - val_loss: 0.3913 - val_accuracy: 0.9143\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0934 - accuracy: 0.96 - 0s 5ms/step - loss: 0.0630 - accuracy: 0.9738 - val_loss: 1.0337 - val_accuracy: 0.8762\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2030 - accuracy: 0.93 - 0s 5ms/step - loss: 0.1281 - accuracy: 0.9667 - val_loss: 0.5585 - val_accuracy: 0.8952\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1995 - accuracy: 0.92 - 0s 5ms/step - loss: 0.0932 - accuracy: 0.9667 - val_loss: 0.4729 - val_accuracy: 0.9048\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0824 - accuracy: 0.96 - 0s 6ms/step - loss: 0.0435 - accuracy: 0.9881 - val_loss: 0.6056 - val_accuracy: 0.8857\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0590 - accuracy: 0.98 - 0s 6ms/step - loss: 0.0324 - accuracy: 0.9905 - val_loss: 0.6413 - val_accuracy: 0.8952\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0391 - accuracy: 0.98 - 0s 5ms/step - loss: 0.0167 - accuracy: 0.9952 - val_loss: 0.8017 - val_accuracy: 0.8952\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN11\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :   7%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                                 | 12/169 [01:31<18:46,  7.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_48 (Dense)             (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.5504 - accuracy: 0.81 - 0s 19ms/step - loss: 0.3860 - accuracy: 0.8243 - val_loss: 0.2839 - val_accuracy: 0.8362\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2211 - accuracy: 0.84 - 0s 4ms/step - loss: 0.2496 - accuracy: 0.8742 - val_loss: 0.3107 - val_accuracy: 0.8362\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1640 - accuracy: 0.90 - 0s 4ms/step - loss: 0.1886 - accuracy: 0.9046 - val_loss: 0.2852 - val_accuracy: 0.8879\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0851 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1583 - accuracy: 0.9262 - val_loss: 0.3127 - val_accuracy: 0.8793\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1533 - accuracy: 0.92 - 0s 4ms/step - loss: 0.1474 - accuracy: 0.9328 - val_loss: 0.3649 - val_accuracy: 0.9052\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0753 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1119 - accuracy: 0.9501 - val_loss: 0.4657 - val_accuracy: 0.8966\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1510 - accuracy: 0.92 - 0s 4ms/step - loss: 0.1030 - accuracy: 0.9588 - val_loss: 0.5345 - val_accuracy: 0.8879\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0872 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1357 - accuracy: 0.9371 - val_loss: 0.5270 - val_accuracy: 0.8966\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0882 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1081 - accuracy: 0.9544 - val_loss: 0.3687 - val_accuracy: 0.9052\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1235 - accuracy: 0.93 - 0s 4ms/step - loss: 0.0926 - accuracy: 0.9566 - val_loss: 0.4867 - val_accuracy: 0.8966\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0964 - accuracy: 0.96 - 0s 4ms/step - loss: 0.0715 - accuracy: 0.9783 - val_loss: 0.5973 - val_accuracy: 0.8966\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0514 - accuracy: 0.98 - 0s 5ms/step - loss: 0.0499 - accuracy: 0.9761 - val_loss: 0.7345 - val_accuracy: 0.9052\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0254 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0339 - accuracy: 0.9892 - val_loss: 0.8460 - val_accuracy: 0.8966\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0156 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0291 - accuracy: 0.9870 - val_loss: 0.8802 - val_accuracy: 0.9138\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0208 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0246 - accuracy: 0.9913 - val_loss: 0.9269 - val_accuracy: 0.9052\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0304 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0255 - accuracy: 0.9913 - val_loss: 1.0096 - val_accuracy: 0.8966\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0156 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0253 - accuracy: 0.9892 - val_loss: 1.0665 - val_accuracy: 0.8966\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0274 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0182 - accuracy: 0.9935 - val_loss: 1.2018 - val_accuracy: 0.8966\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0108 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0197 - accuracy: 0.9913 - val_loss: 1.1293 - val_accuracy: 0.8966\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0184 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0601 - accuracy: 0.9826 - val_loss: 1.4353 - val_accuracy: 0.8966\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN12\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :   8%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                | 13/169 [01:38<18:47,  7.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_52 (Dense)             (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.6444 - accuracy: 0.5938WARNING:tensorflow:Callbacks method `on_test_batch_begin` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_begin` time: 0.0010s). Check your callbacks.\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.4367 - accuracy: 0.8113 - val_loss: 0.3074 - val_accuracy: 0.8431\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2465 - accuracy: 0.82 - 0s 4ms/step - loss: 0.2660 - accuracy: 0.8431 - val_loss: 0.2782 - val_accuracy: 0.8431\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2371 - accuracy: 0.79 - 0s 4ms/step - loss: 0.2109 - accuracy: 0.8431 - val_loss: 0.3164 - val_accuracy: 0.8431\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2057 - accuracy: 0.81 - 0s 4ms/step - loss: 0.1669 - accuracy: 0.8873 - val_loss: 0.3167 - val_accuracy: 0.8922\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1041 - accuracy: 0.95 - 0s 5ms/step - loss: 0.1561 - accuracy: 0.9461 - val_loss: 0.3136 - val_accuracy: 0.8725\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1421 - accuracy: 0.93 - 0s 4ms/step - loss: 0.1286 - accuracy: 0.9583 - val_loss: 0.2544 - val_accuracy: 0.8922\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1332 - accuracy: 0.95 - 0s 5ms/step - loss: 0.1175 - accuracy: 0.9657 - val_loss: 0.3224 - val_accuracy: 0.8922\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0795 - accuracy: 0.98 - 0s 5ms/step - loss: 0.1020 - accuracy: 0.9632 - val_loss: 0.5060 - val_accuracy: 0.8922\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1215 - accuracy: 0.96 - 0s 5ms/step - loss: 0.0918 - accuracy: 0.9730 - val_loss: 0.5065 - val_accuracy: 0.8824\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1007 - accuracy: 0.95 - 0s 5ms/step - loss: 0.0823 - accuracy: 0.9730 - val_loss: 0.6131 - val_accuracy: 0.8922\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2028 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1002 - accuracy: 0.9730 - val_loss: 0.2330 - val_accuracy: 0.8922\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0637 - accuracy: 0.96 - 0s 4ms/step - loss: 0.0838 - accuracy: 0.9706 - val_loss: 0.2799 - val_accuracy: 0.8922\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0641 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0842 - accuracy: 0.9681 - val_loss: 0.2340 - val_accuracy: 0.8824\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0658 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0839 - accuracy: 0.9706 - val_loss: 0.2319 - val_accuracy: 0.8922\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0543 - accuracy: 0.98 - 0s 5ms/step - loss: 0.0899 - accuracy: 0.9681 - val_loss: 0.2478 - val_accuracy: 0.8725\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0410 - accuracy: 1.00 - 0s 5ms/step - loss: 0.0783 - accuracy: 0.9730 - val_loss: 0.3625 - val_accuracy: 0.8725\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0588 - accuracy: 1.00 - 0s 5ms/step - loss: 0.0852 - accuracy: 0.9706 - val_loss: 0.3492 - val_accuracy: 0.8627\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0359 - accuracy: 1.00 - 0s 5ms/step - loss: 0.0757 - accuracy: 0.9755 - val_loss: 0.3965 - val_accuracy: 0.8627\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1165 - accuracy: 0.95 - 0s 5ms/step - loss: 0.0763 - accuracy: 0.9755 - val_loss: 0.3856 - val_accuracy: 0.8824\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0882 - accuracy: 0.96 - 0s 5ms/step - loss: 0.0711 - accuracy: 0.9755 - val_loss: 0.4171 - val_accuracy: 0.8824\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN13\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :   8%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                                | 14/169 [01:45<18:02,  6.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_56 (Dense)             (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.8286 - accuracy: 0.31 - 0s 24ms/step - loss: 0.5584 - accuracy: 0.7224 - val_loss: 0.3256 - val_accuracy: 0.8039\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.3586 - accuracy: 0.76 - 0s 4ms/step - loss: 0.3044 - accuracy: 0.8084 - val_loss: 0.3324 - val_accuracy: 0.8039\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2957 - accuracy: 0.79 - 0s 5ms/step - loss: 0.2524 - accuracy: 0.8084 - val_loss: 0.3748 - val_accuracy: 0.8039\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2579 - accuracy: 0.76 - 0s 4ms/step - loss: 0.2261 - accuracy: 0.8084 - val_loss: 0.3286 - val_accuracy: 0.8039\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2298 - accuracy: 0.76 - 0s 5ms/step - loss: 0.2043 - accuracy: 0.8526 - val_loss: 0.3011 - val_accuracy: 0.9020\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2151 - accuracy: 0.89 - 0s 5ms/step - loss: 0.1843 - accuracy: 0.9165 - val_loss: 0.3623 - val_accuracy: 0.8922\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2067 - accuracy: 0.89 - 0s 5ms/step - loss: 0.1652 - accuracy: 0.9337 - val_loss: 0.4095 - val_accuracy: 0.9216\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1234 - accuracy: 0.95 - 0s 5ms/step - loss: 0.1458 - accuracy: 0.9386 - val_loss: 0.4175 - val_accuracy: 0.8922\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1334 - accuracy: 0.95 - 0s 5ms/step - loss: 0.1330 - accuracy: 0.9509 - val_loss: 0.4119 - val_accuracy: 0.8922\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1088 - accuracy: 0.95 - 0s 5ms/step - loss: 0.1214 - accuracy: 0.9582 - val_loss: 0.4345 - val_accuracy: 0.8922\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0991 - accuracy: 0.98 - 0s 5ms/step - loss: 0.1175 - accuracy: 0.9582 - val_loss: 0.4983 - val_accuracy: 0.8922\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1548 - accuracy: 0.93 - 0s 4ms/step - loss: 0.1134 - accuracy: 0.9582 - val_loss: 0.5465 - val_accuracy: 0.8922\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0475 - accuracy: 1.00 - 0s 4ms/step - loss: 0.1126 - accuracy: 0.9582 - val_loss: 0.5043 - val_accuracy: 0.8824\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1098 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1141 - accuracy: 0.9558 - val_loss: 0.4827 - val_accuracy: 0.8725\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1137 - accuracy: 0.95 - 0s 5ms/step - loss: 0.1138 - accuracy: 0.9558 - val_loss: 0.7517 - val_accuracy: 0.8922\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1760 - accuracy: 0.90 - 0s 4ms/step - loss: 0.1301 - accuracy: 0.9459 - val_loss: 0.5826 - val_accuracy: 0.8824\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1563 - accuracy: 0.93 - 0s 5ms/step - loss: 0.2071 - accuracy: 0.9287 - val_loss: 0.3638 - val_accuracy: 0.8824\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1314 - accuracy: 0.95 - 0s 5ms/step - loss: 0.2024 - accuracy: 0.9115 - val_loss: 0.2765 - val_accuracy: 0.8922\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1759 - accuracy: 0.92 - 0s 6ms/step - loss: 0.1625 - accuracy: 0.9263 - val_loss: 0.2376 - val_accuracy: 0.9020\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1923 - accuracy: 0.90 - 0s 6ms/step - loss: 0.1415 - accuracy: 0.9410 - val_loss: 0.3078 - val_accuracy: 0.8725\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN14\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :   9%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                               | 15/169 [01:52<18:01,  7.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_60 (Dense)             (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.8013 - accuracy: 0.45 - 0s 28ms/step - loss: 0.5032 - accuracy: 0.7818 - val_loss: 0.3572 - val_accuracy: 0.8455\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.4097 - accuracy: 0.79 - 0s 5ms/step - loss: 0.3067 - accuracy: 0.8477 - val_loss: 0.3082 - val_accuracy: 0.8455\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.3353 - accuracy: 0.78 - 0s 5ms/step - loss: 0.2524 - accuracy: 0.8477 - val_loss: 0.3081 - val_accuracy: 0.8455\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2407 - accuracy: 0.78 - 0s 5ms/step - loss: 0.1983 - accuracy: 0.8477 - val_loss: 0.3383 - val_accuracy: 0.8455\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1991 - accuracy: 0.81 - 0s 5ms/step - loss: 0.1719 - accuracy: 0.8886 - val_loss: 0.4365 - val_accuracy: 0.8818\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1941 - accuracy: 0.90 - 0s 5ms/step - loss: 0.1358 - accuracy: 0.9636 - val_loss: 0.5092 - val_accuracy: 0.8636\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1249 - accuracy: 0.98 - 0s 5ms/step - loss: 0.1151 - accuracy: 0.9614 - val_loss: 0.6316 - val_accuracy: 0.8727\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0910 - accuracy: 0.98 - 0s 6ms/step - loss: 0.0980 - accuracy: 0.9795 - val_loss: 0.6432 - val_accuracy: 0.8909\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1058 - accuracy: 0.98 - 0s 5ms/step - loss: 0.0839 - accuracy: 0.9841 - val_loss: 0.8411 - val_accuracy: 0.8909\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0591 - accuracy: 0.98 - 0s 5ms/step - loss: 0.0748 - accuracy: 0.9864 - val_loss: 0.8760 - val_accuracy: 0.8909\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0808 - accuracy: 0.98 - 0s 5ms/step - loss: 0.0675 - accuracy: 0.9841 - val_loss: 1.0379 - val_accuracy: 0.9000\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0517 - accuracy: 1.00 - 0s 5ms/step - loss: 0.0575 - accuracy: 0.9909 - val_loss: 1.2509 - val_accuracy: 0.8909\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0265 - accuracy: 1.00 - 0s 5ms/step - loss: 0.0578 - accuracy: 0.9841 - val_loss: 1.2662 - val_accuracy: 0.8727\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0541 - accuracy: 1.00 - 0s 5ms/step - loss: 0.0497 - accuracy: 0.9909 - val_loss: 1.3767 - val_accuracy: 0.9091\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0589 - accuracy: 0.98 - 0s 5ms/step - loss: 0.0470 - accuracy: 0.9886 - val_loss: 1.3892 - val_accuracy: 0.9000\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0395 - accuracy: 1.00 - 0s 5ms/step - loss: 0.0458 - accuracy: 0.9886 - val_loss: 1.4210 - val_accuracy: 0.8909\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0321 - accuracy: 1.00 - 0s 5ms/step - loss: 0.0424 - accuracy: 0.9909 - val_loss: 1.4358 - val_accuracy: 0.9182\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0340 - accuracy: 1.00 - 0s 6ms/step - loss: 0.0437 - accuracy: 0.9909 - val_loss: 1.3111 - val_accuracy: 0.8909\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0111 - accuracy: 1.00 - 0s 5ms/step - loss: 0.0422 - accuracy: 0.9886 - val_loss: 1.6764 - val_accuracy: 0.9091\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0284 - accuracy: 1.00 - 0s 5ms/step - loss: 0.0602 - accuracy: 0.9864 - val_loss: 1.5183 - val_accuracy: 0.9091\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN15\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :   9%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                               | 16/169 [01:59<17:51,  7.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_64 (Dense)             (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.7164 - accuracy: 0.29 - 0s 25ms/step - loss: 0.4611 - accuracy: 0.7199 - val_loss: 0.3888 - val_accuracy: 0.7963\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2988 - accuracy: 0.81 - 0s 5ms/step - loss: 0.2817 - accuracy: 0.7986 - val_loss: 0.3558 - val_accuracy: 0.7963\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2704 - accuracy: 0.70 - 0s 5ms/step - loss: 0.2424 - accuracy: 0.7986 - val_loss: 0.4537 - val_accuracy: 0.7963\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.3030 - accuracy: 0.70 - 0s 4ms/step - loss: 0.2378 - accuracy: 0.8565 - val_loss: 0.4740 - val_accuracy: 0.7778\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1475 - accuracy: 0.90 - 0s 4ms/step - loss: 0.1966 - accuracy: 0.9028 - val_loss: 0.5655 - val_accuracy: 0.8333\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1730 - accuracy: 0.96 - 0s 5ms/step - loss: 0.1899 - accuracy: 0.9120 - val_loss: 0.5582 - val_accuracy: 0.8426\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1959 - accuracy: 0.93 - 0s 5ms/step - loss: 0.1875 - accuracy: 0.9097 - val_loss: 0.5523 - val_accuracy: 0.8333\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1159 - accuracy: 0.93 - 0s 5ms/step - loss: 0.1781 - accuracy: 0.9144 - val_loss: 0.6842 - val_accuracy: 0.8611\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1398 - accuracy: 0.95 - 0s 5ms/step - loss: 0.1720 - accuracy: 0.9190 - val_loss: 0.8650 - val_accuracy: 0.8611\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1470 - accuracy: 0.93 - 0s 4ms/step - loss: 0.1713 - accuracy: 0.9236 - val_loss: 0.9547 - val_accuracy: 0.8611\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1650 - accuracy: 0.92 - 0s 4ms/step - loss: 0.1686 - accuracy: 0.9236 - val_loss: 0.8310 - val_accuracy: 0.8519\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1575 - accuracy: 0.93 - 0s 4ms/step - loss: 0.1598 - accuracy: 0.9306 - val_loss: 0.9361 - val_accuracy: 0.8519\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2067 - accuracy: 0.89 - 0s 4ms/step - loss: 0.1558 - accuracy: 0.9306 - val_loss: 0.8552 - val_accuracy: 0.8426\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1126 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1455 - accuracy: 0.9375 - val_loss: 0.9277 - val_accuracy: 0.8519\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1857 - accuracy: 0.90 - 0s 4ms/step - loss: 0.1416 - accuracy: 0.9398 - val_loss: 0.9443 - val_accuracy: 0.8611\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1409 - accuracy: 0.93 - 0s 4ms/step - loss: 0.1403 - accuracy: 0.9421 - val_loss: 0.9260 - val_accuracy: 0.8611\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1048 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1458 - accuracy: 0.9375 - val_loss: 0.9997 - val_accuracy: 0.8611\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0993 - accuracy: 0.96 - 0s 5ms/step - loss: 0.1467 - accuracy: 0.9352 - val_loss: 0.8783 - val_accuracy: 0.8519\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1376 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1456 - accuracy: 0.9375 - val_loss: 1.0391 - val_accuracy: 0.8611\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1955 - accuracy: 0.89 - 0s 5ms/step - loss: 0.1408 - accuracy: 0.9421 - val_loss: 1.1199 - val_accuracy: 0.8704\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN16\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  10%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                               | 17/169 [02:06<17:28,  6.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_68 (Dense)             (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_70 (Dense)             (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.7868 - accuracy: 0.34 - 0s 18ms/step - loss: 0.5428 - accuracy: 0.6814 - val_loss: 0.4069 - val_accuracy: 0.7479\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.3435 - accuracy: 0.78 - 0s 3ms/step - loss: 0.3491 - accuracy: 0.7869 - val_loss: 0.3496 - val_accuracy: 0.8151\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.3019 - accuracy: 0.87 - 0s 4ms/step - loss: 0.2704 - accuracy: 0.8713 - val_loss: 0.3657 - val_accuracy: 0.7815\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2547 - accuracy: 0.90 - 0s 4ms/step - loss: 0.2450 - accuracy: 0.8840 - val_loss: 0.3550 - val_accuracy: 0.8235\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2821 - accuracy: 0.85 - 0s 4ms/step - loss: 0.2032 - accuracy: 0.9198 - val_loss: 0.3726 - val_accuracy: 0.8319\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2111 - accuracy: 0.92 - 0s 4ms/step - loss: 0.1766 - accuracy: 0.9262 - val_loss: 0.4127 - val_accuracy: 0.8151\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1180 - accuracy: 0.93 - 0s 4ms/step - loss: 0.1651 - accuracy: 0.9325 - val_loss: 0.5212 - val_accuracy: 0.8319\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1108 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1309 - accuracy: 0.9451 - val_loss: 0.5966 - val_accuracy: 0.8319\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0865 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1132 - accuracy: 0.9451 - val_loss: 0.7492 - val_accuracy: 0.8487\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0584 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1101 - accuracy: 0.9494 - val_loss: 0.8801 - val_accuracy: 0.8235\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0977 - accuracy: 0.95 - 0s 4ms/step - loss: 0.0980 - accuracy: 0.9494 - val_loss: 0.9418 - val_accuracy: 0.8403\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0845 - accuracy: 0.96 - 0s 4ms/step - loss: 0.0984 - accuracy: 0.9515 - val_loss: 0.9933 - val_accuracy: 0.8403\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0527 - accuracy: 0.96 - 0s 4ms/step - loss: 0.0916 - accuracy: 0.9578 - val_loss: 0.8908 - val_accuracy: 0.8235\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0496 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1172 - accuracy: 0.9430 - val_loss: 1.1501 - val_accuracy: 0.8067\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0621 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1347 - accuracy: 0.9325 - val_loss: 1.0332 - val_accuracy: 0.7899\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0234 - accuracy: 1.00 - 0s 4ms/step - loss: 0.1276 - accuracy: 0.9536 - val_loss: 0.9980 - val_accuracy: 0.8235\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0992 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1247 - accuracy: 0.9388 - val_loss: 0.7593 - val_accuracy: 0.8151\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0323 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0799 - accuracy: 0.9599 - val_loss: 0.8901 - val_accuracy: 0.8151\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0656 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0661 - accuracy: 0.9662 - val_loss: 0.9494 - val_accuracy: 0.8235\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0150 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0588 - accuracy: 0.9662 - val_loss: 1.1316 - val_accuracy: 0.8235\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN17\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  11%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                              | 18/169 [02:12<16:58,  6.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_72 (Dense)             (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_73 (Dense)             (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_74 (Dense)             (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_75 (Dense)             (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 1.1877 - accuracy: 0.28 - 0s 21ms/step - loss: 0.5767 - accuracy: 0.7437 - val_loss: 0.3665 - val_accuracy: 0.8364\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.3371 - accuracy: 0.85 - 0s 5ms/step - loss: 0.3485 - accuracy: 0.8375 - val_loss: 0.2764 - val_accuracy: 0.8364\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2188 - accuracy: 0.87 - 0s 4ms/step - loss: 0.2660 - accuracy: 0.8375 - val_loss: 0.2693 - val_accuracy: 0.8364\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.3219 - accuracy: 0.73 - 0s 4ms/step - loss: 0.2270 - accuracy: 0.8375 - val_loss: 0.2778 - val_accuracy: 0.8364\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2379 - accuracy: 0.81 - 0s 4ms/step - loss: 0.2059 - accuracy: 0.8375 - val_loss: 0.3100 - val_accuracy: 0.8364\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1742 - accuracy: 0.85 - 0s 4ms/step - loss: 0.1866 - accuracy: 0.8375 - val_loss: 0.3215 - val_accuracy: 0.8364\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2606 - accuracy: 0.71 - 0s 4ms/step - loss: 0.1814 - accuracy: 0.8421 - val_loss: 0.3452 - val_accuracy: 0.9182\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1735 - accuracy: 0.92 - 0s 4ms/step - loss: 0.1644 - accuracy: 0.9291 - val_loss: 0.3974 - val_accuracy: 0.9182\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1489 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1668 - accuracy: 0.9153 - val_loss: 0.3752 - val_accuracy: 0.9182\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1630 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1546 - accuracy: 0.9314 - val_loss: 0.3887 - val_accuracy: 0.9273\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1463 - accuracy: 0.93 - 0s 4ms/step - loss: 0.1611 - accuracy: 0.9359 - val_loss: 0.3602 - val_accuracy: 0.9091\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1383 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1561 - accuracy: 0.9245 - val_loss: 0.3507 - val_accuracy: 0.9182\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1809 - accuracy: 0.90 - 0s 4ms/step - loss: 0.1479 - accuracy: 0.9314 - val_loss: 0.3942 - val_accuracy: 0.9091\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1541 - accuracy: 0.92 - 0s 4ms/step - loss: 0.1516 - accuracy: 0.9314 - val_loss: 0.3408 - val_accuracy: 0.9182\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1085 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1338 - accuracy: 0.9382 - val_loss: 0.3337 - val_accuracy: 0.9091\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1240 - accuracy: 0.93 - 0s 4ms/step - loss: 0.1292 - accuracy: 0.9428 - val_loss: 0.3572 - val_accuracy: 0.9091\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1185 - accuracy: 0.92 - 0s 4ms/step - loss: 0.1174 - accuracy: 0.9474 - val_loss: 0.2935 - val_accuracy: 0.9000\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1105 - accuracy: 0.98 - 0s 4ms/step - loss: 0.1073 - accuracy: 0.9611 - val_loss: 0.3853 - val_accuracy: 0.9091\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1274 - accuracy: 0.93 - 0s 4ms/step - loss: 0.1052 - accuracy: 0.9588 - val_loss: 0.4015 - val_accuracy: 0.8909\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0882 - accuracy: 0.96 - 0s 4ms/step - loss: 0.0973 - accuracy: 0.9634 - val_loss: 0.4329 - val_accuracy: 0.9000\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN18\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  11%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                              | 19/169 [02:18<16:39,  6.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_76 (Dense)             (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_77 (Dense)             (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_78 (Dense)             (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_79 (Dense)             (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.7319 - accuracy: 0.45 - 0s 18ms/step - loss: 0.5938 - accuracy: 0.6789 - val_loss: 0.4712 - val_accuracy: 0.7521\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.5214 - accuracy: 0.73 - 0s 4ms/step - loss: 0.4459 - accuracy: 0.7737 - val_loss: 0.4612 - val_accuracy: 0.7949\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.4814 - accuracy: 0.81 - 0s 4ms/step - loss: 0.4000 - accuracy: 0.8233 - val_loss: 0.5433 - val_accuracy: 0.7009\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.4680 - accuracy: 0.73 - 0s 3ms/step - loss: 0.3726 - accuracy: 0.8147 - val_loss: 0.3751 - val_accuracy: 0.8205\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.3135 - accuracy: 0.87 - 0s 4ms/step - loss: 0.3245 - accuracy: 0.8448 - val_loss: 0.4065 - val_accuracy: 0.8120\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1971 - accuracy: 0.87 - 0s 3ms/step - loss: 0.2903 - accuracy: 0.8642 - val_loss: 0.4602 - val_accuracy: 0.7778\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1629 - accuracy: 0.98 - 0s 4ms/step - loss: 0.2568 - accuracy: 0.8901 - val_loss: 0.3861 - val_accuracy: 0.8120\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2031 - accuracy: 0.90 - 0s 4ms/step - loss: 0.1948 - accuracy: 0.9116 - val_loss: 0.5435 - val_accuracy: 0.8205\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2261 - accuracy: 0.92 - 0s 4ms/step - loss: 0.1815 - accuracy: 0.9310 - val_loss: 0.4388 - val_accuracy: 0.8547\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1564 - accuracy: 0.92 - 0s 4ms/step - loss: 0.1860 - accuracy: 0.9203 - val_loss: 0.6662 - val_accuracy: 0.7778\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1238 - accuracy: 0.93 - 0s 4ms/step - loss: 0.1968 - accuracy: 0.9246 - val_loss: 0.5492 - val_accuracy: 0.8034\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2191 - accuracy: 0.89 - 0s 4ms/step - loss: 0.1616 - accuracy: 0.9418 - val_loss: 0.5836 - val_accuracy: 0.7949\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0513 - accuracy: 1.00 - 0s 4ms/step - loss: 0.1130 - accuracy: 0.9612 - val_loss: 0.9764 - val_accuracy: 0.7607\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0442 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0789 - accuracy: 0.9784 - val_loss: 1.1613 - val_accuracy: 0.7949\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0207 - accuracy: 1.00 - 0s 3ms/step - loss: 0.0591 - accuracy: 0.9784 - val_loss: 1.2624 - val_accuracy: 0.7949\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0140 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0643 - accuracy: 0.9828 - val_loss: 1.1290 - val_accuracy: 0.7863\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0095 - accuracy: 1.00 - 0s 4ms/step - loss: 0.1079 - accuracy: 0.9763 - val_loss: 1.4222 - val_accuracy: 0.7863\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0263 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0906 - accuracy: 0.9677 - val_loss: 1.0050 - val_accuracy: 0.8034\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0175 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0860 - accuracy: 0.9698 - val_loss: 1.8977 - val_accuracy: 0.7607\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1981 - accuracy: 0.92 - 0s 4ms/step - loss: 0.1899 - accuracy: 0.9418 - val_loss: 1.1666 - val_accuracy: 0.7521\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN19\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  12%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                             | 20/169 [02:25<16:11,  6.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_80 (Dense)             (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_81 (Dense)             (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_82 (Dense)             (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_83 (Dense)             (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.5237 - accuracy: 0.85 - 0s 22ms/step - loss: 0.4437 - accuracy: 0.8307 - val_loss: 0.3111 - val_accuracy: 0.8421\n",
      "Epoch 2/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.2440 - accuracy: 0.89 - 0s 4ms/step - loss: 0.2431 - accuracy: 0.9048 - val_loss: 0.3356 - val_accuracy: 0.8526\n",
      "Epoch 3/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1430 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1622 - accuracy: 0.9392 - val_loss: 0.3361 - val_accuracy: 0.8316\n",
      "Epoch 4/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1310 - accuracy: 0.93 - 0s 6ms/step - loss: 0.1264 - accuracy: 0.9471 - val_loss: 0.3580 - val_accuracy: 0.8737\n",
      "Epoch 5/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0721 - accuracy: 0.96 - 0s 5ms/step - loss: 0.0931 - accuracy: 0.9550 - val_loss: 0.3901 - val_accuracy: 0.8842\n",
      "Epoch 6/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1330 - accuracy: 0.93 - 0s 5ms/step - loss: 0.0799 - accuracy: 0.9709 - val_loss: 0.4634 - val_accuracy: 0.8632\n",
      "Epoch 7/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0200 - accuracy: 1.00 - 0s 5ms/step - loss: 0.0597 - accuracy: 0.9735 - val_loss: 0.5585 - val_accuracy: 0.8526\n",
      "Epoch 8/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0377 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0447 - accuracy: 0.9868 - val_loss: 0.6260 - val_accuracy: 0.8737\n",
      "Epoch 9/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0209 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0324 - accuracy: 0.9894 - val_loss: 0.7251 - val_accuracy: 0.8632\n",
      "Epoch 10/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0458 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0239 - accuracy: 0.9894 - val_loss: 0.7276 - val_accuracy: 0.8632\n",
      "Epoch 11/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0142 - accuracy: 0.9921 - val_loss: 0.7775 - val_accuracy: 0.8632\n",
      "Epoch 12/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 1.00 - 0s 5ms/step - loss: 0.0076 - accuracy: 0.9974 - val_loss: 0.8838 - val_accuracy: 0.8737\n",
      "Epoch 13/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0041 - accuracy: 1.00 - 0s 5ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 1.0240 - val_accuracy: 0.8421\n",
      "Epoch 14/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0089 - accuracy: 1.00 - 0s 5ms/step - loss: 0.0354 - accuracy: 0.9947 - val_loss: 1.2060 - val_accuracy: 0.8526\n",
      "Epoch 15/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0084 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0436 - accuracy: 0.9894 - val_loss: 1.0599 - val_accuracy: 0.8526\n",
      "Epoch 16/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0114 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0499 - accuracy: 0.9841 - val_loss: 1.1088 - val_accuracy: 0.8421\n",
      "Epoch 17/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1684 - accuracy: 0.98 - 0s 5ms/step - loss: 0.1548 - accuracy: 0.9762 - val_loss: 0.7841 - val_accuracy: 0.8421\n",
      "Epoch 18/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1640 - accuracy: 0.93 - 0s 5ms/step - loss: 0.0955 - accuracy: 0.9683 - val_loss: 0.5749 - val_accuracy: 0.8632\n",
      "Epoch 19/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0990 - accuracy: 0.95 - 0s 5ms/step - loss: 0.0885 - accuracy: 0.9630 - val_loss: 0.5195 - val_accuracy: 0.8632\n",
      "Epoch 20/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0256 - accuracy: 1.00 - 0s 5ms/step - loss: 0.0509 - accuracy: 0.9841 - val_loss: 0.5969 - val_accuracy: 0.8737\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN20\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  12%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                             | 21/169 [02:31<15:40,  6.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_84 (Dense)             (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_85 (Dense)             (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_86 (Dense)             (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_87 (Dense)             (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.7221 - accuracy: 0.53 - 0s 21ms/step - loss: 0.6560 - accuracy: 0.8015 - val_loss: 0.5840 - val_accuracy: 0.8586\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.5946 - accuracy: 0.82 - 0s 4ms/step - loss: 0.5534 - accuracy: 0.8550 - val_loss: 0.5078 - val_accuracy: 0.8586\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.4863 - accuracy: 0.89 - 0s 4ms/step - loss: 0.4906 - accuracy: 0.8550 - val_loss: 0.4581 - val_accuracy: 0.8586\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.4574 - accuracy: 0.85 - 0s 4ms/step - loss: 0.4489 - accuracy: 0.8550 - val_loss: 0.4307 - val_accuracy: 0.8586\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.4489 - accuracy: 0.84 - 0s 4ms/step - loss: 0.4294 - accuracy: 0.8550 - val_loss: 0.4172 - val_accuracy: 0.8586\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.3939 - accuracy: 0.87 - 0s 4ms/step - loss: 0.4205 - accuracy: 0.8550 - val_loss: 0.4111 - val_accuracy: 0.8586\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.4099 - accuracy: 0.85 - 0s 4ms/step - loss: 0.4159 - accuracy: 0.8550 - val_loss: 0.4087 - val_accuracy: 0.8586\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.4595 - accuracy: 0.82 - 0s 4ms/step - loss: 0.4144 - accuracy: 0.8550 - val_loss: 0.4079 - val_accuracy: 0.8586\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.4335 - accuracy: 0.84 - 0s 4ms/step - loss: 0.4141 - accuracy: 0.8550 - val_loss: 0.4076 - val_accuracy: 0.8586\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.3786 - accuracy: 0.87 - 0s 4ms/step - loss: 0.4142 - accuracy: 0.8550 - val_loss: 0.4075 - val_accuracy: 0.8586\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.4342 - accuracy: 0.84 - 0s 4ms/step - loss: 0.4141 - accuracy: 0.8550 - val_loss: 0.4076 - val_accuracy: 0.8586\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.4061 - accuracy: 0.85 - 0s 4ms/step - loss: 0.4142 - accuracy: 0.8550 - val_loss: 0.4075 - val_accuracy: 0.8586\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.3777 - accuracy: 0.87 - 0s 4ms/step - loss: 0.4142 - accuracy: 0.8550 - val_loss: 0.4075 - val_accuracy: 0.8586\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.4061 - accuracy: 0.85 - 0s 4ms/step - loss: 0.4141 - accuracy: 0.8550 - val_loss: 0.4075 - val_accuracy: 0.8586\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.4908 - accuracy: 0.81 - 0s 4ms/step - loss: 0.4140 - accuracy: 0.8550 - val_loss: 0.4076 - val_accuracy: 0.8586\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.4062 - accuracy: 0.85 - 0s 4ms/step - loss: 0.4140 - accuracy: 0.8550 - val_loss: 0.4076 - val_accuracy: 0.8586\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.4613 - accuracy: 0.82 - 0s 4ms/step - loss: 0.4141 - accuracy: 0.8550 - val_loss: 0.4076 - val_accuracy: 0.8586\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.3786 - accuracy: 0.87 - 0s 4ms/step - loss: 0.4142 - accuracy: 0.8550 - val_loss: 0.4075 - val_accuracy: 0.8586\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.5733 - accuracy: 0.76 - 0s 4ms/step - loss: 0.4142 - accuracy: 0.8550 - val_loss: 0.4076 - val_accuracy: 0.8586\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.3783 - accuracy: 0.87 - 0s 4ms/step - loss: 0.4141 - accuracy: 0.8550 - val_loss: 0.4075 - val_accuracy: 0.8586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN21\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  13%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                             | 22/169 [02:36<15:15,  6.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_88 (Dense)             (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_89 (Dense)             (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_90 (Dense)             (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_91 (Dense)             (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.6637 - accuracy: 0.64 - 0s 20ms/step - loss: 0.4755 - accuracy: 0.7431 - val_loss: 0.4604 - val_accuracy: 0.7600\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.3101 - accuracy: 0.81 - 0s 4ms/step - loss: 0.3415 - accuracy: 0.7859 - val_loss: 0.4116 - val_accuracy: 0.7800\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.3713 - accuracy: 0.85 - 0s 4ms/step - loss: 0.2853 - accuracy: 0.8892 - val_loss: 0.3694 - val_accuracy: 0.8000\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2615 - accuracy: 0.84 - 0s 4ms/step - loss: 0.2214 - accuracy: 0.9118 - val_loss: 0.3535 - val_accuracy: 0.7900\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1645 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1834 - accuracy: 0.9345 - val_loss: 0.3693 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1808 - accuracy: 0.92 - 0s 4ms/step - loss: 0.1640 - accuracy: 0.9395 - val_loss: 0.3728 - val_accuracy: 0.8000\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2074 - accuracy: 0.92 - 0s 5ms/step - loss: 0.1457 - accuracy: 0.9471 - val_loss: 0.4072 - val_accuracy: 0.8300\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1482 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1399 - accuracy: 0.9521 - val_loss: 0.4231 - val_accuracy: 0.8000\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1230 - accuracy: 0.95 - 0s 5ms/step - loss: 0.1317 - accuracy: 0.9521 - val_loss: 0.5358 - val_accuracy: 0.8200\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0778 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1424 - accuracy: 0.9471 - val_loss: 0.4090 - val_accuracy: 0.8200\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1044 - accuracy: 0.96 - 0s 5ms/step - loss: 0.1417 - accuracy: 0.9446 - val_loss: 0.5754 - val_accuracy: 0.8400\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2494 - accuracy: 0.92 - 0s 4ms/step - loss: 0.1578 - accuracy: 0.9446 - val_loss: 0.3065 - val_accuracy: 0.8600\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1791 - accuracy: 0.92 - 0s 4ms/step - loss: 0.1494 - accuracy: 0.9395 - val_loss: 0.3468 - val_accuracy: 0.8400\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0914 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1459 - accuracy: 0.9496 - val_loss: 0.3723 - val_accuracy: 0.8400\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1302 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1297 - accuracy: 0.9521 - val_loss: 0.3880 - val_accuracy: 0.8000\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1457 - accuracy: 0.93 - 0s 5ms/step - loss: 0.1200 - accuracy: 0.9572 - val_loss: 0.3817 - val_accuracy: 0.8200\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0469 - accuracy: 1.00 - 0s 5ms/step - loss: 0.1306 - accuracy: 0.9572 - val_loss: 0.3619 - val_accuracy: 0.8300\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1425 - accuracy: 0.93 - 0s 5ms/step - loss: 0.1271 - accuracy: 0.9547 - val_loss: 0.3664 - val_accuracy: 0.8200\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0754 - accuracy: 0.98 - 0s 4ms/step - loss: 0.1124 - accuracy: 0.9622 - val_loss: 0.3885 - val_accuracy: 0.8400\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1021 - accuracy: 0.96 - 0s 5ms/step - loss: 0.1059 - accuracy: 0.9647 - val_loss: 0.3705 - val_accuracy: 0.8600\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN22\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  14%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                            | 23/169 [02:43<15:08,  6.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_92 (Dense)             (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_93 (Dense)             (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_94 (Dense)             (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_95 (Dense)             (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.9272 - accuracy: 0.31 - 0s 23ms/step - loss: 0.5138 - accuracy: 0.7660 - val_loss: 0.3739 - val_accuracy: 0.8617\n",
      "Epoch 2/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.3381 - accuracy: 0.87 - 0s 5ms/step - loss: 0.2800 - accuracy: 0.8777 - val_loss: 0.3565 - val_accuracy: 0.8404\n",
      "Epoch 3/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.2676 - accuracy: 0.89 - 0s 4ms/step - loss: 0.2127 - accuracy: 0.9202 - val_loss: 0.3867 - val_accuracy: 0.8511\n",
      "Epoch 4/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1504 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1448 - accuracy: 0.9415 - val_loss: 0.6095 - val_accuracy: 0.8617\n",
      "Epoch 5/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1691 - accuracy: 0.92 - 0s 5ms/step - loss: 0.1003 - accuracy: 0.9601 - val_loss: 0.5877 - val_accuracy: 0.8404\n",
      "Epoch 6/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0471 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0676 - accuracy: 0.9734 - val_loss: 0.6687 - val_accuracy: 0.8404\n",
      "Epoch 7/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0140 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0496 - accuracy: 0.9787 - val_loss: 0.8064 - val_accuracy: 0.8404\n",
      "Epoch 8/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0574 - accuracy: 0.96 - 0s 4ms/step - loss: 0.0348 - accuracy: 0.9840 - val_loss: 1.0441 - val_accuracy: 0.8191\n",
      "Epoch 9/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0224 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0189 - accuracy: 0.9894 - val_loss: 1.2399 - val_accuracy: 0.8191\n",
      "Epoch 10/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0245 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0383 - accuracy: 0.9787 - val_loss: 1.5527 - val_accuracy: 0.8298\n",
      "Epoch 11/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0857 - accuracy: 0.95 - 0s 5ms/step - loss: 0.0667 - accuracy: 0.9761 - val_loss: 1.0818 - val_accuracy: 0.8617\n",
      "Epoch 12/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.2071 - accuracy: 0.95 - 0s 4ms/step - loss: 0.0745 - accuracy: 0.9787 - val_loss: 0.8310 - val_accuracy: 0.8511\n",
      "Epoch 13/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0472 - accuracy: 0.96 - 0s 4ms/step - loss: 0.0396 - accuracy: 0.9814 - val_loss: 0.8406 - val_accuracy: 0.8404\n",
      "Epoch 14/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0453 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0302 - accuracy: 0.9894 - val_loss: 0.9484 - val_accuracy: 0.8617\n",
      "Epoch 15/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0123 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0200 - accuracy: 0.9894 - val_loss: 1.1524 - val_accuracy: 0.8617\n",
      "Epoch 16/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0388 - accuracy: 0.96 - 0s 4ms/step - loss: 0.0138 - accuracy: 0.9920 - val_loss: 1.3277 - val_accuracy: 0.8511\n",
      "Epoch 17/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0025 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0155 - accuracy: 0.9920 - val_loss: 1.5561 - val_accuracy: 0.8511\n",
      "Epoch 18/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 7.6478e-04 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0112 - accuracy: 0.9920 - val_loss: 1.7555 - val_accuracy: 0.8404\n",
      "Epoch 19/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0119 - accuracy: 0.9894 - val_loss: 1.7993 - val_accuracy: 0.8511\n",
      "Epoch 20/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 2.7677e-04 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0100 - accuracy: 0.9920 - val_loss: 1.8274 - val_accuracy: 0.8404\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN23\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  14%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                            | 24/169 [02:48<14:37,  6.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_96 (Dense)             (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_97 (Dense)             (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_98 (Dense)             (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_99 (Dense)             (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.6980 - accuracy: 0.53 - 0s 20ms/step - loss: 0.4954 - accuracy: 0.7566 - val_loss: 0.3218 - val_accuracy: 0.8077\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2794 - accuracy: 0.81 - 0s 4ms/step - loss: 0.3348 - accuracy: 0.8096 - val_loss: 0.3368 - val_accuracy: 0.8365\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1864 - accuracy: 0.85 - 0s 4ms/step - loss: 0.2330 - accuracy: 0.8843 - val_loss: 0.3567 - val_accuracy: 0.8558\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2162 - accuracy: 0.92 - 0s 5ms/step - loss: 0.2000 - accuracy: 0.9277 - val_loss: 0.3391 - val_accuracy: 0.8942\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1055 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1683 - accuracy: 0.9301 - val_loss: 0.3812 - val_accuracy: 0.8942\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1676 - accuracy: 0.92 - 0s 4ms/step - loss: 0.1558 - accuracy: 0.9277 - val_loss: 0.3793 - val_accuracy: 0.8750\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1173 - accuracy: 0.93 - 0s 4ms/step - loss: 0.1277 - accuracy: 0.9494 - val_loss: 0.4257 - val_accuracy: 0.8846\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0821 - accuracy: 0.95 - 0s 4ms/step - loss: 0.0966 - accuracy: 0.9494 - val_loss: 0.5768 - val_accuracy: 0.8750\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1031 - accuracy: 0.95 - 0s 4ms/step - loss: 0.0839 - accuracy: 0.9711 - val_loss: 0.6856 - val_accuracy: 0.8750\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0888 - accuracy: 0.96 - 0s 4ms/step - loss: 0.0827 - accuracy: 0.9663 - val_loss: 0.7033 - val_accuracy: 0.8846\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0909 - accuracy: 0.95 - 0s 4ms/step - loss: 0.0593 - accuracy: 0.9831 - val_loss: 0.7629 - val_accuracy: 0.9038\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0563 - accuracy: 0.96 - 0s 4ms/step - loss: 0.0730 - accuracy: 0.9831 - val_loss: 0.7634 - val_accuracy: 0.9038\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0467 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0420 - accuracy: 0.9855 - val_loss: 0.6447 - val_accuracy: 0.9135\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0940 - accuracy: 0.93 - 0s 4ms/step - loss: 0.0497 - accuracy: 0.9807 - val_loss: 0.5354 - val_accuracy: 0.9038\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0664 - accuracy: 0.96 - 0s 4ms/step - loss: 0.0307 - accuracy: 0.9855 - val_loss: 0.6866 - val_accuracy: 0.8846\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0394 - accuracy: 0.96 - 0s 4ms/step - loss: 0.0605 - accuracy: 0.9807 - val_loss: 0.7234 - val_accuracy: 0.8942\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0045 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0661 - accuracy: 0.9783 - val_loss: 1.4646 - val_accuracy: 0.8462\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0604 - accuracy: 0.96 - 0s 4ms/step - loss: 0.0612 - accuracy: 0.9783 - val_loss: 2.0506 - val_accuracy: 0.8462\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0515 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0439 - accuracy: 0.9807 - val_loss: 2.6251 - val_accuracy: 0.8365\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0145 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0285 - accuracy: 0.9855 - val_loss: 3.3214 - val_accuracy: 0.8269\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN24\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  15%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                           | 25/169 [02:54<14:18,  5.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_100 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_101 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_102 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_103 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.7439 - accuracy: 0.50 - 0s 17ms/step - loss: 0.5723 - accuracy: 0.6536 - val_loss: 0.3597 - val_accuracy: 0.8033\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.3703 - accuracy: 0.79 - 0s 3ms/step - loss: 0.3197 - accuracy: 0.8412 - val_loss: 0.2441 - val_accuracy: 0.8934\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2768 - accuracy: 0.84 - 0s 3ms/step - loss: 0.2408 - accuracy: 0.8742 - val_loss: 0.2037 - val_accuracy: 0.9098\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1720 - accuracy: 0.92 - 0s 4ms/step - loss: 0.1956 - accuracy: 0.9155 - val_loss: 0.3129 - val_accuracy: 0.8852\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1990 - accuracy: 0.90 - 0s 4ms/step - loss: 0.1826 - accuracy: 0.9216 - val_loss: 0.2491 - val_accuracy: 0.9016\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1248 - accuracy: 0.93 - 0s 4ms/step - loss: 0.1453 - accuracy: 0.9423 - val_loss: 0.3054 - val_accuracy: 0.8361\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1268 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1463 - accuracy: 0.9381 - val_loss: 0.2562 - val_accuracy: 0.9016\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0878 - accuracy: 0.95 - 0s 3ms/step - loss: 0.1152 - accuracy: 0.9546 - val_loss: 0.2381 - val_accuracy: 0.9180\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1028 - accuracy: 0.96 - 0s 3ms/step - loss: 0.0858 - accuracy: 0.9711 - val_loss: 0.3242 - val_accuracy: 0.8934\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1059 - accuracy: 0.96 - 0s 3ms/step - loss: 0.0634 - accuracy: 0.9814 - val_loss: 0.4073 - val_accuracy: 0.8934\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0412 - accuracy: 1.00 - 0s 3ms/step - loss: 0.0626 - accuracy: 0.9814 - val_loss: 0.4693 - val_accuracy: 0.8934\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0297 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0670 - accuracy: 0.9732 - val_loss: 0.4964 - val_accuracy: 0.8361\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0337 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0794 - accuracy: 0.9670 - val_loss: 0.5785 - val_accuracy: 0.8689\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1416 - accuracy: 0.93 - 0s 4ms/step - loss: 0.1001 - accuracy: 0.9588 - val_loss: 0.3587 - val_accuracy: 0.8607\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0727 - accuracy: 0.96 - 0s 4ms/step - loss: 0.0697 - accuracy: 0.9773 - val_loss: 0.4017 - val_accuracy: 0.9016\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0534 - accuracy: 0.98 - 0s 3ms/step - loss: 0.0484 - accuracy: 0.9814 - val_loss: 0.5390 - val_accuracy: 0.8770\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0490 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0499 - accuracy: 0.9773 - val_loss: 0.5734 - val_accuracy: 0.8607\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0451 - accuracy: 0.98 - 0s 3ms/step - loss: 0.0421 - accuracy: 0.9897 - val_loss: 0.6500 - val_accuracy: 0.8770\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0778 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0498 - accuracy: 0.9814 - val_loss: 0.6837 - val_accuracy: 0.8607\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0462 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0354 - accuracy: 0.9876 - val_loss: 0.6271 - val_accuracy: 0.8525\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN25\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  15%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                           | 26/169 [03:00<14:00,  5.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_104 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_105 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_106 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_107 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.6840 - accuracy: 0.57 - 0s 22ms/step - loss: 0.4545 - accuracy: 0.8153 - val_loss: 0.3309 - val_accuracy: 0.8636\n",
      "Epoch 2/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.2929 - accuracy: 0.87 - 0s 4ms/step - loss: 0.2682 - accuracy: 0.8693 - val_loss: 0.2571 - val_accuracy: 0.8636\n",
      "Epoch 3/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1703 - accuracy: 0.92 - 0s 4ms/step - loss: 0.2113 - accuracy: 0.8693 - val_loss: 0.2841 - val_accuracy: 0.8636\n",
      "Epoch 4/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1362 - accuracy: 0.90 - 0s 4ms/step - loss: 0.1768 - accuracy: 0.8693 - val_loss: 0.3319 - val_accuracy: 0.8636\n",
      "Epoch 5/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1345 - accuracy: 0.85 - 0s 4ms/step - loss: 0.1496 - accuracy: 0.8693 - val_loss: 0.3973 - val_accuracy: 0.8636\n",
      "Epoch 6/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1547 - accuracy: 0.84 - 0s 4ms/step - loss: 0.1378 - accuracy: 0.8807 - val_loss: 0.4779 - val_accuracy: 0.8750\n",
      "Epoch 7/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1329 - accuracy: 0.93 - 0s 4ms/step - loss: 0.1229 - accuracy: 0.9460 - val_loss: 0.4636 - val_accuracy: 0.8864\n",
      "Epoch 8/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0741 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1183 - accuracy: 0.9545 - val_loss: 0.3653 - val_accuracy: 0.8864\n",
      "Epoch 9/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1388 - accuracy: 0.93 - 0s 4ms/step - loss: 0.1182 - accuracy: 0.9489 - val_loss: 0.4142 - val_accuracy: 0.7955\n",
      "Epoch 10/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1374 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1317 - accuracy: 0.9290 - val_loss: 0.4056 - val_accuracy: 0.8182\n",
      "Epoch 11/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1011 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1532 - accuracy: 0.9176 - val_loss: 0.4408 - val_accuracy: 0.7500\n",
      "Epoch 12/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1418 - accuracy: 0.92 - 0s 5ms/step - loss: 0.1566 - accuracy: 0.9148 - val_loss: 0.3967 - val_accuracy: 0.8864\n",
      "Epoch 13/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1460 - accuracy: 0.93 - 0s 4ms/step - loss: 0.1505 - accuracy: 0.9403 - val_loss: 0.4193 - val_accuracy: 0.8523\n",
      "Epoch 14/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1079 - accuracy: 0.93 - 0s 4ms/step - loss: 0.1322 - accuracy: 0.9347 - val_loss: 0.4132 - val_accuracy: 0.8750\n",
      "Epoch 15/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1142 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1372 - accuracy: 0.9432 - val_loss: 0.4912 - val_accuracy: 0.8977\n",
      "Epoch 16/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1540 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1647 - accuracy: 0.9489 - val_loss: 0.3693 - val_accuracy: 0.8523\n",
      "Epoch 17/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1559 - accuracy: 0.93 - 0s 4ms/step - loss: 0.1488 - accuracy: 0.9290 - val_loss: 0.4253 - val_accuracy: 0.8409\n",
      "Epoch 18/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1517 - accuracy: 0.93 - 0s 4ms/step - loss: 0.1470 - accuracy: 0.9261 - val_loss: 0.4461 - val_accuracy: 0.8977\n",
      "Epoch 19/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1575 - accuracy: 0.92 - 0s 4ms/step - loss: 0.1303 - accuracy: 0.9403 - val_loss: 0.3773 - val_accuracy: 0.8750\n",
      "Epoch 20/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0938 - accuracy: 0.98 - 0s 4ms/step - loss: 0.1039 - accuracy: 0.9574 - val_loss: 0.3500 - val_accuracy: 0.8523\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN26\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  16%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                          | 27/169 [03:05<13:45,  5.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_108 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_109 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_110 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_111 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.8396 - accuracy: 0.34 - 0s 20ms/step - loss: 0.5161 - accuracy: 0.7823 - val_loss: 0.3694 - val_accuracy: 0.8667\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.3288 - accuracy: 0.87 - 0s 4ms/step - loss: 0.2880 - accuracy: 0.8708 - val_loss: 0.3374 - val_accuracy: 0.8667\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2776 - accuracy: 0.82 - 0s 4ms/step - loss: 0.2260 - accuracy: 0.8708 - val_loss: 0.3966 - val_accuracy: 0.8667\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1542 - accuracy: 0.90 - 0s 4ms/step - loss: 0.1883 - accuracy: 0.8708 - val_loss: 0.4542 - val_accuracy: 0.8667\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1472 - accuracy: 0.87 - 0s 4ms/step - loss: 0.1609 - accuracy: 0.8708 - val_loss: 0.5898 - val_accuracy: 0.8667\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1234 - accuracy: 0.90 - 0s 4ms/step - loss: 0.1449 - accuracy: 0.8708 - val_loss: 0.7554 - val_accuracy: 0.8667\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1437 - accuracy: 0.85 - 0s 4ms/step - loss: 0.1243 - accuracy: 0.8828 - val_loss: 0.9063 - val_accuracy: 0.8000\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1351 - accuracy: 0.95 - 0s 3ms/step - loss: 0.1197 - accuracy: 0.9522 - val_loss: 0.9762 - val_accuracy: 0.8095\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1151 - accuracy: 0.93 - 0s 4ms/step - loss: 0.1228 - accuracy: 0.9545 - val_loss: 0.8854 - val_accuracy: 0.7714\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1188 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1108 - accuracy: 0.9522 - val_loss: 0.7606 - val_accuracy: 0.7905\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1726 - accuracy: 0.90 - 0s 4ms/step - loss: 0.1208 - accuracy: 0.9498 - val_loss: 0.8484 - val_accuracy: 0.7619\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1068 - accuracy: 0.96 - 0s 4ms/step - loss: 0.0971 - accuracy: 0.9617 - val_loss: 0.9612 - val_accuracy: 0.7810\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0881 - accuracy: 0.96 - 0s 4ms/step - loss: 0.0915 - accuracy: 0.9593 - val_loss: 0.8352 - val_accuracy: 0.7524\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1029 - accuracy: 0.95 - 0s 4ms/step - loss: 0.0914 - accuracy: 0.9617 - val_loss: 1.2322 - val_accuracy: 0.7905\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2029 - accuracy: 0.95 - 0s 4ms/step - loss: 0.0937 - accuracy: 0.9617 - val_loss: 1.0564 - val_accuracy: 0.7714\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0151 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0777 - accuracy: 0.9617 - val_loss: 1.1303 - val_accuracy: 0.7810\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0127 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0642 - accuracy: 0.9737 - val_loss: 1.2693 - val_accuracy: 0.7810\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0457 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0548 - accuracy: 0.9737 - val_loss: 1.4906 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0643 - accuracy: 0.95 - 0s 4ms/step - loss: 0.0576 - accuracy: 0.9737 - val_loss: 1.7000 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0118 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0411 - accuracy: 0.9833 - val_loss: 1.7013 - val_accuracy: 0.8000\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN27\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  17%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                          | 28/169 [03:11<13:42,  5.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_112 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_113 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_114 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_115 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.5967 - accuracy: 0.84 - 0s 23ms/step - loss: 0.3864 - accuracy: 0.8579 - val_loss: 0.2813 - val_accuracy: 0.8632\n",
      "Epoch 2/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1748 - accuracy: 0.93 - 0s 5ms/step - loss: 0.2271 - accuracy: 0.8579 - val_loss: 0.2398 - val_accuracy: 0.8632\n",
      "Epoch 3/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1392 - accuracy: 0.89 - 0s 4ms/step - loss: 0.1919 - accuracy: 0.8579 - val_loss: 0.2199 - val_accuracy: 0.8632\n",
      "Epoch 4/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0801 - accuracy: 0.93 - 0s 5ms/step - loss: 0.1598 - accuracy: 0.8579 - val_loss: 0.1904 - val_accuracy: 0.8632\n",
      "Epoch 5/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1478 - accuracy: 0.85 - 0s 5ms/step - loss: 0.1491 - accuracy: 0.9026 - val_loss: 0.1958 - val_accuracy: 0.8842\n",
      "Epoch 6/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1347 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1305 - accuracy: 0.9500 - val_loss: 0.2061 - val_accuracy: 0.8842\n",
      "Epoch 7/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0944 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1193 - accuracy: 0.9632 - val_loss: 0.2558 - val_accuracy: 0.9158\n",
      "Epoch 8/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1142 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1581 - accuracy: 0.9553 - val_loss: 0.1969 - val_accuracy: 0.8632\n",
      "Epoch 9/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1446 - accuracy: 0.93 - 0s 4ms/step - loss: 0.1484 - accuracy: 0.9316 - val_loss: 0.3069 - val_accuracy: 0.8526\n",
      "Epoch 10/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1539 - accuracy: 0.90 - 0s 4ms/step - loss: 0.1321 - accuracy: 0.9421 - val_loss: 0.3650 - val_accuracy: 0.9053\n",
      "Epoch 11/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0911 - accuracy: 0.95 - 0s 5ms/step - loss: 0.1096 - accuracy: 0.9579 - val_loss: 0.2043 - val_accuracy: 0.8947\n",
      "Epoch 12/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1329 - accuracy: 0.95 - 0s 4ms/step - loss: 0.0979 - accuracy: 0.9658 - val_loss: 0.1759 - val_accuracy: 0.9263\n",
      "Epoch 13/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0684 - accuracy: 0.96 - 0s 4ms/step - loss: 0.0820 - accuracy: 0.9737 - val_loss: 0.1968 - val_accuracy: 0.9158\n",
      "Epoch 14/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0424 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0707 - accuracy: 0.9789 - val_loss: 0.2259 - val_accuracy: 0.9158\n",
      "Epoch 15/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0383 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0545 - accuracy: 0.9868 - val_loss: 0.2028 - val_accuracy: 0.9263\n",
      "Epoch 16/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1001 - accuracy: 0.96 - 0s 4ms/step - loss: 0.0453 - accuracy: 0.9921 - val_loss: 0.1954 - val_accuracy: 0.9158\n",
      "Epoch 17/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0262 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0420 - accuracy: 0.9921 - val_loss: 0.2208 - val_accuracy: 0.9263\n",
      "Epoch 18/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0312 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0398 - accuracy: 0.9921 - val_loss: 0.2344 - val_accuracy: 0.9158\n",
      "Epoch 19/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0202 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0378 - accuracy: 0.9921 - val_loss: 0.2335 - val_accuracy: 0.9263\n",
      "Epoch 20/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0472 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0359 - accuracy: 0.9921 - val_loss: 0.2392 - val_accuracy: 0.9263\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN28\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  17%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                          | 29/169 [03:17<13:35,  5.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_29\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_116 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_117 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_118 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_119 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.5694 - accuracy: 0.81 - 0s 19ms/step - loss: 0.4779 - accuracy: 0.8266 - val_loss: 0.3490 - val_accuracy: 0.8208\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.3755 - accuracy: 0.79 - 0s 4ms/step - loss: 0.3308 - accuracy: 0.8266 - val_loss: 0.3939 - val_accuracy: 0.8208\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2331 - accuracy: 0.82 - 0s 4ms/step - loss: 0.2924 - accuracy: 0.8266 - val_loss: 0.3325 - val_accuracy: 0.8208\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1875 - accuracy: 0.90 - 0s 4ms/step - loss: 0.2498 - accuracy: 0.8266 - val_loss: 0.4270 - val_accuracy: 0.8208\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2670 - accuracy: 0.79 - 0s 4ms/step - loss: 0.2246 - accuracy: 0.8717 - val_loss: 0.4055 - val_accuracy: 0.8396\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2275 - accuracy: 0.90 - 0s 4ms/step - loss: 0.1977 - accuracy: 0.9287 - val_loss: 0.5053 - val_accuracy: 0.8113\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1947 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1736 - accuracy: 0.9335 - val_loss: 0.5127 - val_accuracy: 0.8396\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1302 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1437 - accuracy: 0.9620 - val_loss: 0.7974 - val_accuracy: 0.8585\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2092 - accuracy: 0.90 - 0s 4ms/step - loss: 0.1716 - accuracy: 0.9335 - val_loss: 0.4749 - val_accuracy: 0.8396\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1711 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1890 - accuracy: 0.9145 - val_loss: 0.6111 - val_accuracy: 0.8491\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1751 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1725 - accuracy: 0.9335 - val_loss: 0.3891 - val_accuracy: 0.8774\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0928 - accuracy: 0.96 - 0s 5ms/step - loss: 0.1335 - accuracy: 0.9525 - val_loss: 0.5417 - val_accuracy: 0.8585\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0737 - accuracy: 0.98 - 0s 4ms/step - loss: 0.1253 - accuracy: 0.9596 - val_loss: 0.6580 - val_accuracy: 0.8396\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0784 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0846 - accuracy: 0.9786 - val_loss: 0.7076 - val_accuracy: 0.8396\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0743 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0886 - accuracy: 0.9739 - val_loss: 0.7431 - val_accuracy: 0.8302\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1109 - accuracy: 0.95 - 0s 4ms/step - loss: 0.0995 - accuracy: 0.9620 - val_loss: 0.8290 - val_accuracy: 0.8302\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0763 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0976 - accuracy: 0.9620 - val_loss: 0.9493 - val_accuracy: 0.8113\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0733 - accuracy: 0.98 - 0s 4ms/step - loss: 0.1006 - accuracy: 0.9620 - val_loss: 1.0426 - val_accuracy: 0.8019\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0646 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0951 - accuracy: 0.9739 - val_loss: 1.0865 - val_accuracy: 0.8208\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0578 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0932 - accuracy: 0.9644 - val_loss: 1.3486 - val_accuracy: 0.8208\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN29\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  18%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                         | 30/169 [03:23<13:25,  5.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_30\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_120 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_121 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_122 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_123 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 0.6700 - accuracy: 0.5625WARNING:tensorflow:Callbacks method `on_test_batch_begin` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_begin` time: 0.0010s). Check your callbacks.\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.5713 - accuracy: 0.6611 - val_loss: 0.5450 - val_accuracy: 0.6706\n",
      "Epoch 2/20\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4860 - accuracy: 0.62 - 0s 2ms/step - loss: 0.4689 - accuracy: 0.7760 - val_loss: 0.5514 - val_accuracy: 0.7647\n",
      "Epoch 3/20\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.3890 - accuracy: 0.81 - 0s 2ms/step - loss: 0.4115 - accuracy: 0.8124 - val_loss: 0.5435 - val_accuracy: 0.7922\n",
      "Epoch 4/20\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4791 - accuracy: 0.76 - 0s 2ms/step - loss: 0.4141 - accuracy: 0.8114 - val_loss: 0.5275 - val_accuracy: 0.7294\n",
      "Epoch 5/20\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4548 - accuracy: 0.78 - 0s 2ms/step - loss: 0.4296 - accuracy: 0.8114 - val_loss: 0.5422 - val_accuracy: 0.7412\n",
      "Epoch 6/20\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4505 - accuracy: 0.79 - 0s 2ms/step - loss: 0.3816 - accuracy: 0.8222 - val_loss: 0.5448 - val_accuracy: 0.7765\n",
      "Epoch 7/20\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.3648 - accuracy: 0.82 - 0s 2ms/step - loss: 0.3431 - accuracy: 0.8409 - val_loss: 0.6129 - val_accuracy: 0.7647\n",
      "Epoch 8/20\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.1822 - accuracy: 0.95 - 0s 2ms/step - loss: 0.3208 - accuracy: 0.8595 - val_loss: 0.6250 - val_accuracy: 0.7647\n",
      "Epoch 9/20\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.3382 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3013 - accuracy: 0.8723 - val_loss: 0.6447 - val_accuracy: 0.7882\n",
      "Epoch 10/20\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.2366 - accuracy: 0.92 - 0s 2ms/step - loss: 0.3137 - accuracy: 0.8556 - val_loss: 0.7574 - val_accuracy: 0.7961\n",
      "Epoch 11/20\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.3304 - accuracy: 0.82 - 0s 2ms/step - loss: 0.3362 - accuracy: 0.8468 - val_loss: 0.6641 - val_accuracy: 0.7529\n",
      "Epoch 12/20\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.3698 - accuracy: 0.82 - 0s 2ms/step - loss: 0.3050 - accuracy: 0.8684 - val_loss: 0.7221 - val_accuracy: 0.7686\n",
      "Epoch 13/20\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.3259 - accuracy: 0.87 - 0s 2ms/step - loss: 0.2686 - accuracy: 0.8811 - val_loss: 0.8772 - val_accuracy: 0.7686\n",
      "Epoch 14/20\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.1473 - accuracy: 0.93 - 0s 2ms/step - loss: 0.2468 - accuracy: 0.8802 - val_loss: 1.0255 - val_accuracy: 0.8039\n",
      "Epoch 15/20\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.1887 - accuracy: 0.92 - 0s 2ms/step - loss: 0.2693 - accuracy: 0.8723 - val_loss: 0.8220 - val_accuracy: 0.7686\n",
      "Epoch 16/20\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4245 - accuracy: 0.78 - 0s 2ms/step - loss: 0.3020 - accuracy: 0.8733 - val_loss: 0.7114 - val_accuracy: 0.8078\n",
      "Epoch 17/20\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.2060 - accuracy: 0.95 - 0s 3ms/step - loss: 0.2991 - accuracy: 0.8792 - val_loss: 0.8065 - val_accuracy: 0.8235\n",
      "Epoch 18/20\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.1623 - accuracy: 0.95 - 0s 2ms/step - loss: 0.2370 - accuracy: 0.8969 - val_loss: 0.7982 - val_accuracy: 0.7922\n",
      "Epoch 19/20\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.1802 - accuracy: 0.93 - 0s 2ms/step - loss: 0.2066 - accuracy: 0.9106 - val_loss: 0.9750 - val_accuracy: 0.7725\n",
      "Epoch 20/20\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.1560 - accuracy: 0.93 - 0s 2ms/step - loss: 0.1975 - accuracy: 0.9145 - val_loss: 1.1220 - val_accuracy: 0.7686\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN30\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  18%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                         | 31/169 [03:29<13:32,  5.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_31\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_124 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_125 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_126 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_127 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.6829 - accuracy: 0.6406WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.5050 - accuracy: 0.7887 - val_loss: 0.3832 - val_accuracy: 0.8061\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.3301 - accuracy: 0.79 - 0s 4ms/step - loss: 0.3679 - accuracy: 0.8299 - val_loss: 0.3699 - val_accuracy: 0.8163\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.3344 - accuracy: 0.79 - 0s 4ms/step - loss: 0.2616 - accuracy: 0.8376 - val_loss: 0.5342 - val_accuracy: 0.8469\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2142 - accuracy: 0.90 - 0s 4ms/step - loss: 0.2155 - accuracy: 0.8789 - val_loss: 0.6914 - val_accuracy: 0.8673\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1744 - accuracy: 0.90 - 0s 4ms/step - loss: 0.1811 - accuracy: 0.9021 - val_loss: 0.6707 - val_accuracy: 0.8878\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1386 - accuracy: 0.92 - 0s 4ms/step - loss: 0.1355 - accuracy: 0.9304 - val_loss: 0.8204 - val_accuracy: 0.8571\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1094 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1113 - accuracy: 0.9407 - val_loss: 0.9046 - val_accuracy: 0.8469\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0755 - accuracy: 0.96 - 0s 4ms/step - loss: 0.0816 - accuracy: 0.9562 - val_loss: 1.0577 - val_accuracy: 0.8571\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1044 - accuracy: 0.95 - 0s 4ms/step - loss: 0.0622 - accuracy: 0.9639 - val_loss: 1.2969 - val_accuracy: 0.8571\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0319 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0403 - accuracy: 0.9742 - val_loss: 1.8056 - val_accuracy: 0.8571\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0557 - accuracy: 0.95 - 0s 4ms/step - loss: 0.0374 - accuracy: 0.9794 - val_loss: 2.1452 - val_accuracy: 0.8469\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.3320 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1979 - accuracy: 0.9716 - val_loss: 2.0635 - val_accuracy: 0.8367\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1855 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1534 - accuracy: 0.9613 - val_loss: 1.4570 - val_accuracy: 0.8265\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0630 - accuracy: 0.95 - 0s 4ms/step - loss: 0.0866 - accuracy: 0.9536 - val_loss: 1.2660 - val_accuracy: 0.8061\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0927 - accuracy: 0.92 - 0s 4ms/step - loss: 0.0737 - accuracy: 0.9665 - val_loss: 1.3491 - val_accuracy: 0.8367\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0551 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0507 - accuracy: 0.9845 - val_loss: 1.5604 - val_accuracy: 0.8367\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0257 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0295 - accuracy: 0.9948 - val_loss: 2.0967 - val_accuracy: 0.8265\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0118 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0153 - accuracy: 0.9948 - val_loss: 2.4756 - val_accuracy: 0.8367\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0025 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0154 - accuracy: 0.9948 - val_loss: 3.1635 - val_accuracy: 0.8265\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0397 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1507 - accuracy: 0.9716 - val_loss: 2.2167 - val_accuracy: 0.8163\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN31\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  19%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                        | 32/169 [03:35<13:27,  5.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_32\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_128 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_129 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_130 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_131 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.7914 - accuracy: 0.34 - 0s 20ms/step - loss: 0.5464 - accuracy: 0.7247 - val_loss: 0.3803 - val_accuracy: 0.7879\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.4279 - accuracy: 0.76 - 0s 4ms/step - loss: 0.3721 - accuracy: 0.7854 - val_loss: 0.3165 - val_accuracy: 0.7879\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2746 - accuracy: 0.81 - 0s 4ms/step - loss: 0.3084 - accuracy: 0.7854 - val_loss: 0.3388 - val_accuracy: 0.8081\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.3187 - accuracy: 0.87 - 0s 4ms/step - loss: 0.2741 - accuracy: 0.8813 - val_loss: 0.3869 - val_accuracy: 0.8182\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1803 - accuracy: 0.95 - 0s 4ms/step - loss: 0.2488 - accuracy: 0.8737 - val_loss: 0.3960 - val_accuracy: 0.8283\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2166 - accuracy: 0.93 - 0s 4ms/step - loss: 0.2136 - accuracy: 0.9141 - val_loss: 0.4155 - val_accuracy: 0.8283\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1559 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1938 - accuracy: 0.9318 - val_loss: 0.7193 - val_accuracy: 0.8081\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1394 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1679 - accuracy: 0.9444 - val_loss: 0.6639 - val_accuracy: 0.8182\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1319 - accuracy: 0.93 - 0s 5ms/step - loss: 0.1642 - accuracy: 0.9419 - val_loss: 0.7645 - val_accuracy: 0.8081\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1226 - accuracy: 0.93 - 0s 4ms/step - loss: 0.1527 - accuracy: 0.9343 - val_loss: 1.0018 - val_accuracy: 0.7980\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1557 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1711 - accuracy: 0.9394 - val_loss: 1.0607 - val_accuracy: 0.8081\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1740 - accuracy: 0.92 - 0s 4ms/step - loss: 0.1421 - accuracy: 0.9470 - val_loss: 0.9284 - val_accuracy: 0.8182\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1242 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1278 - accuracy: 0.9520 - val_loss: 1.0304 - val_accuracy: 0.7980\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1442 - accuracy: 0.93 - 0s 4ms/step - loss: 0.1405 - accuracy: 0.9470 - val_loss: 1.2540 - val_accuracy: 0.8182\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1234 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1475 - accuracy: 0.9470 - val_loss: 1.1431 - val_accuracy: 0.8384\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1275 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1325 - accuracy: 0.9470 - val_loss: 0.9949 - val_accuracy: 0.8182\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0932 - accuracy: 0.98 - 0s 4ms/step - loss: 0.1158 - accuracy: 0.9621 - val_loss: 1.0183 - val_accuracy: 0.8384\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0964 - accuracy: 0.96 - 0s 4ms/step - loss: 0.0967 - accuracy: 0.9722 - val_loss: 1.2073 - val_accuracy: 0.8384\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0627 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0947 - accuracy: 0.9672 - val_loss: 1.5033 - val_accuracy: 0.8485\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0773 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0906 - accuracy: 0.9722 - val_loss: 1.6541 - val_accuracy: 0.8586\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN32\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                        | 33/169 [03:41<13:41,  6.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_33\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_132 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_133 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_134 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_135 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.7010 - accuracy: 0.51 - 0s 26ms/step - loss: 0.3838 - accuracy: 0.8382 - val_loss: 0.2375 - val_accuracy: 0.9053\n",
      "Epoch 2/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.2475 - accuracy: 0.85 - 0s 5ms/step - loss: 0.1861 - accuracy: 0.9125 - val_loss: 0.2004 - val_accuracy: 0.9158\n",
      "Epoch 3/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1764 - accuracy: 0.89 - 0s 5ms/step - loss: 0.1125 - accuracy: 0.9416 - val_loss: 0.1408 - val_accuracy: 0.9368\n",
      "Epoch 4/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0816 - accuracy: 0.96 - 0s 5ms/step - loss: 0.0664 - accuracy: 0.9735 - val_loss: 0.1752 - val_accuracy: 0.9474\n",
      "Epoch 5/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1081 - accuracy: 0.95 - 0s 5ms/step - loss: 0.0471 - accuracy: 0.9788 - val_loss: 0.1797 - val_accuracy: 0.9368\n",
      "Epoch 6/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0219 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0145 - accuracy: 0.9947 - val_loss: 0.3602 - val_accuracy: 0.9368\n",
      "Epoch 7/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0107 - accuracy: 1.00 - 0s 6ms/step - loss: 0.0111 - accuracy: 0.9947 - val_loss: 0.4531 - val_accuracy: 0.9263\n",
      "Epoch 8/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 1.00 - 0s 5ms/step - loss: 0.0077 - accuracy: 0.9973 - val_loss: 0.6653 - val_accuracy: 0.9263\n",
      "Epoch 9/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 1.00 - 0s 5ms/step - loss: 0.0467 - accuracy: 0.9947 - val_loss: 0.5426 - val_accuracy: 0.9158\n",
      "Epoch 10/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0288 - accuracy: 0.98 - 0s 5ms/step - loss: 0.0465 - accuracy: 0.9788 - val_loss: 0.7381 - val_accuracy: 0.9368\n",
      "Epoch 11/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1503 - accuracy: 0.96 - 0s 5ms/step - loss: 0.0684 - accuracy: 0.9867 - val_loss: 0.3973 - val_accuracy: 0.9053\n",
      "Epoch 12/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0457 - accuracy: 0.98 - 0s 5ms/step - loss: 0.0409 - accuracy: 0.9788 - val_loss: 0.2349 - val_accuracy: 0.9263\n",
      "Epoch 13/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0035 - accuracy: 1.00 - 0s 5ms/step - loss: 0.0199 - accuracy: 0.9947 - val_loss: 0.1583 - val_accuracy: 0.9579\n",
      "Epoch 14/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0081 - accuracy: 1.00 - 0s 6ms/step - loss: 0.0240 - accuracy: 0.9920 - val_loss: 0.2378 - val_accuracy: 0.9158\n",
      "Epoch 15/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0044 - accuracy: 1.00 - 0s 5ms/step - loss: 0.0122 - accuracy: 0.9973 - val_loss: 0.2931 - val_accuracy: 0.9158\n",
      "Epoch 16/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0047 - accuracy: 1.00 - 0s 7ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.3902 - val_accuracy: 0.9158\n",
      "Epoch 17/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 1.00 - 0s 5ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.4743 - val_accuracy: 0.9263\n",
      "Epoch 18/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0010 - accuracy: 1.00 - 0s 5ms/step - loss: 9.0861e-04 - accuracy: 1.0000 - val_loss: 0.5319 - val_accuracy: 0.9368\n",
      "Epoch 19/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 3.1042e-04 - accuracy: 1.00 - 0s 5ms/step - loss: 5.1443e-04 - accuracy: 1.0000 - val_loss: 0.5761 - val_accuracy: 0.9368\n",
      "Epoch 20/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 5.6572e-04 - accuracy: 1.00 - 0s 5ms/step - loss: 3.2968e-04 - accuracy: 1.0000 - val_loss: 0.6085 - val_accuracy: 0.9368\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN33\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                        | 34/169 [03:48<13:52,  6.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_34\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_136 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_137 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_138 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_139 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.8395 - accuracy: 0.34 - 0s 19ms/step - loss: 0.4851 - accuracy: 0.7254 - val_loss: 0.3061 - val_accuracy: 0.7850\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2847 - accuracy: 0.82 - 0s 4ms/step - loss: 0.3095 - accuracy: 0.7793 - val_loss: 0.2615 - val_accuracy: 0.7850\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2159 - accuracy: 0.87 - 0s 4ms/step - loss: 0.2712 - accuracy: 0.8122 - val_loss: 0.2527 - val_accuracy: 0.9159\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2940 - accuracy: 0.89 - 0s 4ms/step - loss: 0.2422 - accuracy: 0.8897 - val_loss: 0.2687 - val_accuracy: 0.8972\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2471 - accuracy: 0.95 - 0s 4ms/step - loss: 0.2160 - accuracy: 0.9085 - val_loss: 0.2845 - val_accuracy: 0.8972\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1620 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1905 - accuracy: 0.9155 - val_loss: 0.3248 - val_accuracy: 0.8972\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2112 - accuracy: 0.92 - 0s 4ms/step - loss: 0.1806 - accuracy: 0.9225 - val_loss: 0.3435 - val_accuracy: 0.8972\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1819 - accuracy: 0.90 - 0s 4ms/step - loss: 0.1762 - accuracy: 0.9225 - val_loss: 0.3912 - val_accuracy: 0.8972\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1467 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1701 - accuracy: 0.9249 - val_loss: 0.4483 - val_accuracy: 0.8972\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1514 - accuracy: 0.93 - 0s 4ms/step - loss: 0.1711 - accuracy: 0.9225 - val_loss: 0.3701 - val_accuracy: 0.8972\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1952 - accuracy: 0.92 - 0s 4ms/step - loss: 0.1750 - accuracy: 0.9225 - val_loss: 0.3363 - val_accuracy: 0.8692\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2165 - accuracy: 0.89 - 0s 4ms/step - loss: 0.1887 - accuracy: 0.9061 - val_loss: 0.5455 - val_accuracy: 0.8972\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2047 - accuracy: 0.93 - 0s 4ms/step - loss: 0.2258 - accuracy: 0.9155 - val_loss: 0.3641 - val_accuracy: 0.8879\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1906 - accuracy: 0.90 - 0s 4ms/step - loss: 0.2001 - accuracy: 0.9038 - val_loss: 0.3126 - val_accuracy: 0.9065\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2273 - accuracy: 0.89 - 0s 4ms/step - loss: 0.2058 - accuracy: 0.8991 - val_loss: 0.2691 - val_accuracy: 0.8972\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2474 - accuracy: 0.87 - 0s 4ms/step - loss: 0.1901 - accuracy: 0.9108 - val_loss: 0.2439 - val_accuracy: 0.8972\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1376 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1933 - accuracy: 0.9061 - val_loss: 0.2612 - val_accuracy: 0.9065\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2337 - accuracy: 0.89 - 0s 4ms/step - loss: 0.1822 - accuracy: 0.9155 - val_loss: 0.3552 - val_accuracy: 0.8879\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1650 - accuracy: 0.93 - 0s 4ms/step - loss: 0.1718 - accuracy: 0.9225 - val_loss: 0.3059 - val_accuracy: 0.8879\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1331 - accuracy: 0.93 - 0s 4ms/step - loss: 0.1745 - accuracy: 0.9225 - val_loss: 0.3280 - val_accuracy: 0.8879\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN34\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                       | 35/169 [03:54<13:34,  6.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_35\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_140 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_141 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_142 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_143 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.6523 - accuracy: 0.78 - 0s 19ms/step - loss: 0.4403 - accuracy: 0.8153 - val_loss: 0.3994 - val_accuracy: 0.8235\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2777 - accuracy: 0.82 - 0s 4ms/step - loss: 0.3108 - accuracy: 0.8325 - val_loss: 0.3870 - val_accuracy: 0.8333\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2543 - accuracy: 0.87 - 0s 4ms/step - loss: 0.2510 - accuracy: 0.8744 - val_loss: 0.3988 - val_accuracy: 0.8137\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2137 - accuracy: 0.87 - 0s 4ms/step - loss: 0.2010 - accuracy: 0.8990 - val_loss: 0.4109 - val_accuracy: 0.8333\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1747 - accuracy: 0.92 - 0s 4ms/step - loss: 0.1617 - accuracy: 0.9310 - val_loss: 0.5183 - val_accuracy: 0.8039\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1089 - accuracy: 0.93 - 0s 4ms/step - loss: 0.1456 - accuracy: 0.9286 - val_loss: 0.6801 - val_accuracy: 0.8235\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1469 - accuracy: 0.93 - 0s 4ms/step - loss: 0.1279 - accuracy: 0.9360 - val_loss: 0.7503 - val_accuracy: 0.8235\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0550 - accuracy: 0.98 - 0s 4ms/step - loss: 0.1004 - accuracy: 0.9532 - val_loss: 0.9097 - val_accuracy: 0.8431\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0540 - accuracy: 0.98 - 0s 4ms/step - loss: 0.1066 - accuracy: 0.9507 - val_loss: 0.8229 - val_accuracy: 0.7941\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0632 - accuracy: 0.96 - 0s 4ms/step - loss: 0.0648 - accuracy: 0.9729 - val_loss: 1.0174 - val_accuracy: 0.8431\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0444 - accuracy: 0.96 - 0s 4ms/step - loss: 0.0688 - accuracy: 0.9680 - val_loss: 1.0709 - val_accuracy: 0.8235\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0186 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0425 - accuracy: 0.9778 - val_loss: 1.2042 - val_accuracy: 0.8431\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0805 - accuracy: 0.95 - 0s 4ms/step - loss: 0.0381 - accuracy: 0.9803 - val_loss: 1.7324 - val_accuracy: 0.8333\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0340 - accuracy: 0.96 - 0s 4ms/step - loss: 0.0990 - accuracy: 0.9680 - val_loss: 2.6708 - val_accuracy: 0.7941\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0870 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1124 - accuracy: 0.9581 - val_loss: 1.6096 - val_accuracy: 0.7843\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0843 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1182 - accuracy: 0.9507 - val_loss: 1.1827 - val_accuracy: 0.8333\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0592 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0966 - accuracy: 0.9606 - val_loss: 1.9502 - val_accuracy: 0.8235\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0876 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1146 - accuracy: 0.9680 - val_loss: 0.9763 - val_accuracy: 0.8137\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0514 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0909 - accuracy: 0.9704 - val_loss: 1.1453 - val_accuracy: 0.8137\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1518 - accuracy: 0.96 - 0s 4ms/step - loss: 0.0939 - accuracy: 0.9680 - val_loss: 1.0775 - val_accuracy: 0.8333\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN35\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                       | 36/169 [03:59<13:11,  5.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_36\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_144 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_145 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_146 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_147 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.5067 - accuracy: 0.81 - 0s 21ms/step - loss: 0.3822 - accuracy: 0.8267 - val_loss: 0.2704 - val_accuracy: 0.8515\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2368 - accuracy: 0.92 - 0s 4ms/step - loss: 0.2538 - accuracy: 0.8787 - val_loss: 0.2207 - val_accuracy: 0.9010\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1611 - accuracy: 0.93 - 0s 4ms/step - loss: 0.1833 - accuracy: 0.9307 - val_loss: 0.2674 - val_accuracy: 0.9010\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0740 - accuracy: 1.00 - 0s 4ms/step - loss: 0.1598 - accuracy: 0.9431 - val_loss: 0.3083 - val_accuracy: 0.9109\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1423 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1288 - accuracy: 0.9604 - val_loss: 0.3072 - val_accuracy: 0.9307\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1099 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0995 - accuracy: 0.9728 - val_loss: 0.3603 - val_accuracy: 0.9109\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0959 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0791 - accuracy: 0.9851 - val_loss: 0.4659 - val_accuracy: 0.9010\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0924 - accuracy: 0.96 - 0s 5ms/step - loss: 0.0731 - accuracy: 0.9802 - val_loss: 0.4061 - val_accuracy: 0.9010\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0587 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0672 - accuracy: 0.9802 - val_loss: 0.4258 - val_accuracy: 0.9010\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0482 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0467 - accuracy: 0.9901 - val_loss: 0.6319 - val_accuracy: 0.9307\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1269 - accuracy: 0.96 - 0s 4ms/step - loss: 0.0673 - accuracy: 0.9777 - val_loss: 0.4968 - val_accuracy: 0.9406\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0975 - accuracy: 0.95 - 0s 4ms/step - loss: 0.0962 - accuracy: 0.9703 - val_loss: 0.6445 - val_accuracy: 0.9109\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0708 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0616 - accuracy: 0.9777 - val_loss: 0.5998 - val_accuracy: 0.9010\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0294 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0438 - accuracy: 0.9901 - val_loss: 0.5260 - val_accuracy: 0.9109\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0242 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0342 - accuracy: 0.9926 - val_loss: 0.6297 - val_accuracy: 0.9109\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0544 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0301 - accuracy: 0.9926 - val_loss: 0.6656 - val_accuracy: 0.9208\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0084 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0173 - accuracy: 0.9975 - val_loss: 0.7182 - val_accuracy: 0.9208\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0044 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0176 - accuracy: 0.9950 - val_loss: 0.7534 - val_accuracy: 0.9406\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0137 - accuracy: 0.9975 - val_loss: 0.7670 - val_accuracy: 0.9109\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0563 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0119 - accuracy: 0.9975 - val_loss: 0.7377 - val_accuracy: 0.9307\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN36\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                      | 37/169 [04:05<12:52,  5.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_37\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_148 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_149 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_150 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_151 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.3750 - accuracy: 0.92 - 0s 19ms/step - loss: 0.2768 - accuracy: 0.8804 - val_loss: 0.1752 - val_accuracy: 0.8788\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2546 - accuracy: 0.81 - 0s 4ms/step - loss: 0.1692 - accuracy: 0.8906 - val_loss: 0.1288 - val_accuracy: 0.9596\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1647 - accuracy: 0.90 - 0s 4ms/step - loss: 0.1318 - accuracy: 0.9389 - val_loss: 0.1281 - val_accuracy: 0.9596\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1158 - accuracy: 0.98 - 0s 4ms/step - loss: 0.1060 - accuracy: 0.9593 - val_loss: 0.1281 - val_accuracy: 0.9596\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0455 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0967 - accuracy: 0.9644 - val_loss: 0.1444 - val_accuracy: 0.9394\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1232 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0998 - accuracy: 0.9695 - val_loss: 0.1661 - val_accuracy: 0.9495\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0759 - accuracy: 0.96 - 0s 4ms/step - loss: 0.0805 - accuracy: 0.9746 - val_loss: 0.1569 - val_accuracy: 0.9394\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0598 - accuracy: 1.00 - 0s 5ms/step - loss: 0.0692 - accuracy: 0.9796 - val_loss: 0.1518 - val_accuracy: 0.9697\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0732 - accuracy: 0.98 - 0s 5ms/step - loss: 0.0659 - accuracy: 0.9796 - val_loss: 0.1286 - val_accuracy: 0.9495\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1327 - accuracy: 0.93 - 0s 4ms/step - loss: 0.0588 - accuracy: 0.9822 - val_loss: 0.1572 - val_accuracy: 0.9596\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0850 - accuracy: 0.96 - 0s 4ms/step - loss: 0.0638 - accuracy: 0.9796 - val_loss: 0.1700 - val_accuracy: 0.9192\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0997 - accuracy: 0.95 - 0s 4ms/step - loss: 0.0737 - accuracy: 0.9695 - val_loss: 0.1777 - val_accuracy: 0.9394\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0547 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0636 - accuracy: 0.9771 - val_loss: 0.2405 - val_accuracy: 0.9596\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0486 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0622 - accuracy: 0.9771 - val_loss: 0.1120 - val_accuracy: 0.9394\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0488 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0694 - accuracy: 0.9746 - val_loss: 0.1089 - val_accuracy: 0.9495\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0741 - accuracy: 0.96 - 0s 4ms/step - loss: 0.0683 - accuracy: 0.9746 - val_loss: 0.1051 - val_accuracy: 0.9495\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0645 - accuracy: 0.96 - 0s 4ms/step - loss: 0.0665 - accuracy: 0.9746 - val_loss: 0.1549 - val_accuracy: 0.9394\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0479 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0760 - accuracy: 0.9720 - val_loss: 0.2151 - val_accuracy: 0.9091\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1347 - accuracy: 0.93 - 0s 5ms/step - loss: 0.0782 - accuracy: 0.9669 - val_loss: 0.2912 - val_accuracy: 0.8889\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0283 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0837 - accuracy: 0.9720 - val_loss: 0.4013 - val_accuracy: 0.8889\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN37\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                      | 38/169 [04:11<12:42,  5.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_38\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_152 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_153 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_154 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_155 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.7730 - accuracy: 0.37 - 0s 15ms/step - loss: 0.5808 - accuracy: 0.6410 - val_loss: 0.3623 - val_accuracy: 0.8571\n",
      "Epoch 2/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.4309 - accuracy: 0.79 - 0s 3ms/step - loss: 0.3380 - accuracy: 0.8628 - val_loss: 0.3320 - val_accuracy: 0.8647\n",
      "Epoch 3/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2218 - accuracy: 0.92 - 0s 3ms/step - loss: 0.2317 - accuracy: 0.8947 - val_loss: 0.3052 - val_accuracy: 0.8797\n",
      "Epoch 4/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1788 - accuracy: 0.90 - 0s 3ms/step - loss: 0.1926 - accuracy: 0.9211 - val_loss: 0.3479 - val_accuracy: 0.8722\n",
      "Epoch 5/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1457 - accuracy: 0.93 - 0s 3ms/step - loss: 0.1683 - accuracy: 0.9211 - val_loss: 0.3638 - val_accuracy: 0.8722\n",
      "Epoch 6/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1517 - accuracy: 0.92 - 0s 3ms/step - loss: 0.1738 - accuracy: 0.9192 - val_loss: 0.3585 - val_accuracy: 0.8722\n",
      "Epoch 7/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0955 - accuracy: 0.98 - 0s 3ms/step - loss: 0.1310 - accuracy: 0.9398 - val_loss: 0.4475 - val_accuracy: 0.8722\n",
      "Epoch 8/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0599 - accuracy: 1.00 - 0s 3ms/step - loss: 0.1143 - accuracy: 0.9474 - val_loss: 0.5343 - val_accuracy: 0.8571\n",
      "Epoch 9/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0580 - accuracy: 0.98 - 0s 3ms/step - loss: 0.0885 - accuracy: 0.9568 - val_loss: 0.6560 - val_accuracy: 0.8797\n",
      "Epoch 10/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1332 - accuracy: 0.92 - 0s 3ms/step - loss: 0.1274 - accuracy: 0.9474 - val_loss: 0.5598 - val_accuracy: 0.8797\n",
      "Epoch 11/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0629 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0744 - accuracy: 0.9662 - val_loss: 0.6961 - val_accuracy: 0.8722\n",
      "Epoch 12/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0132 - accuracy: 1.00 - 0s 3ms/step - loss: 0.0942 - accuracy: 0.9605 - val_loss: 0.7514 - val_accuracy: 0.8797\n",
      "Epoch 13/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1107 - accuracy: 0.95 - 0s 4ms/step - loss: 0.0642 - accuracy: 0.9680 - val_loss: 0.7856 - val_accuracy: 0.8947\n",
      "Epoch 14/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0128 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0575 - accuracy: 0.9774 - val_loss: 1.1856 - val_accuracy: 0.8722\n",
      "Epoch 15/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0774 - accuracy: 0.96 - 0s 3ms/step - loss: 0.0546 - accuracy: 0.9737 - val_loss: 1.0570 - val_accuracy: 0.8872\n",
      "Epoch 16/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0480 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0602 - accuracy: 0.9774 - val_loss: 1.1149 - val_accuracy: 0.8797\n",
      "Epoch 17/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0160 - accuracy: 1.00 - 0s 3ms/step - loss: 0.0247 - accuracy: 0.9906 - val_loss: 1.2652 - val_accuracy: 0.8722\n",
      "Epoch 18/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0199 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0204 - accuracy: 0.9925 - val_loss: 1.4406 - val_accuracy: 0.8722\n",
      "Epoch 19/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0256 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0209 - accuracy: 0.9906 - val_loss: 1.4228 - val_accuracy: 0.8647\n",
      "Epoch 20/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0265 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0312 - accuracy: 0.9906 - val_loss: 1.3565 - val_accuracy: 0.8722\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN38\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  23%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                     | 39/169 [04:17<12:43,  5.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_39\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_156 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_157 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_158 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_159 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.9781 - accuracy: 0.25 - 0s 23ms/step - loss: 0.6130 - accuracy: 0.7166 - val_loss: 0.3810 - val_accuracy: 0.8370\n",
      "Epoch 2/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.4522 - accuracy: 0.79 - 0s 5ms/step - loss: 0.3825 - accuracy: 0.8311 - val_loss: 0.3612 - val_accuracy: 0.8370\n",
      "Epoch 3/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.3328 - accuracy: 0.82 - 0s 4ms/step - loss: 0.3177 - accuracy: 0.8311 - val_loss: 0.3787 - val_accuracy: 0.8370\n",
      "Epoch 4/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.2751 - accuracy: 0.81 - 0s 4ms/step - loss: 0.2693 - accuracy: 0.8311 - val_loss: 0.3854 - val_accuracy: 0.8370\n",
      "Epoch 5/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.2582 - accuracy: 0.81 - 0s 4ms/step - loss: 0.2380 - accuracy: 0.8311 - val_loss: 0.4290 - val_accuracy: 0.8370\n",
      "Epoch 6/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.2017 - accuracy: 0.82 - 0s 4ms/step - loss: 0.2079 - accuracy: 0.8311 - val_loss: 0.4936 - val_accuracy: 0.8370\n",
      "Epoch 7/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1610 - accuracy: 0.79 - 0s 4ms/step - loss: 0.1759 - accuracy: 0.9155 - val_loss: 0.5856 - val_accuracy: 0.8261\n",
      "Epoch 8/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1780 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1747 - accuracy: 0.9264 - val_loss: 0.6228 - val_accuracy: 0.8478\n",
      "Epoch 9/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1571 - accuracy: 0.92 - 0s 4ms/step - loss: 0.1497 - accuracy: 0.9510 - val_loss: 0.7201 - val_accuracy: 0.8478\n",
      "Epoch 10/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1285 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1271 - accuracy: 0.9537 - val_loss: 0.7865 - val_accuracy: 0.8478\n",
      "Epoch 11/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1169 - accuracy: 0.98 - 0s 4ms/step - loss: 0.1096 - accuracy: 0.9700 - val_loss: 0.9782 - val_accuracy: 0.8804\n",
      "Epoch 12/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0739 - accuracy: 0.98 - 0s 5ms/step - loss: 0.1021 - accuracy: 0.9646 - val_loss: 0.8886 - val_accuracy: 0.8478\n",
      "Epoch 13/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1023 - accuracy: 0.95 - 0s 5ms/step - loss: 0.0944 - accuracy: 0.9782 - val_loss: 1.2550 - val_accuracy: 0.8587\n",
      "Epoch 14/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0796 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0851 - accuracy: 0.9755 - val_loss: 1.4038 - val_accuracy: 0.8478\n",
      "Epoch 15/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1206 - accuracy: 0.95 - 0s 4ms/step - loss: 0.0976 - accuracy: 0.9755 - val_loss: 1.0443 - val_accuracy: 0.8261\n",
      "Epoch 16/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1006 - accuracy: 0.96 - 0s 5ms/step - loss: 0.0846 - accuracy: 0.9755 - val_loss: 1.1392 - val_accuracy: 0.8152\n",
      "Epoch 17/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0709 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0814 - accuracy: 0.9755 - val_loss: 1.2588 - val_accuracy: 0.8478\n",
      "Epoch 18/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0941 - accuracy: 0.96 - 0s 4ms/step - loss: 0.0844 - accuracy: 0.9728 - val_loss: 1.6133 - val_accuracy: 0.8152\n",
      "Epoch 19/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0427 - accuracy: 1.00 - 0s 4ms/step - loss: 0.1003 - accuracy: 0.9673 - val_loss: 1.3911 - val_accuracy: 0.7717\n",
      "Epoch 20/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1059 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1445 - accuracy: 0.9455 - val_loss: 1.9192 - val_accuracy: 0.8478\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN39\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  24%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                     | 40/169 [04:22<12:31,  5.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_40\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_160 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_161 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_162 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_163 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.6609 - accuracy: 0.73 - 0s 16ms/step - loss: 0.4777 - accuracy: 0.7544 - val_loss: 0.4682 - val_accuracy: 0.7807\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2538 - accuracy: 0.89 - 0s 3ms/step - loss: 0.3001 - accuracy: 0.8575 - val_loss: 0.5321 - val_accuracy: 0.8158\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2787 - accuracy: 0.85 - 0s 3ms/step - loss: 0.2400 - accuracy: 0.8925 - val_loss: 0.6051 - val_accuracy: 0.8860\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2127 - accuracy: 0.93 - 0s 3ms/step - loss: 0.1898 - accuracy: 0.9320 - val_loss: 0.6553 - val_accuracy: 0.8860\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1455 - accuracy: 0.93 - 0s 3ms/step - loss: 0.1498 - accuracy: 0.9496 - val_loss: 0.7720 - val_accuracy: 0.8947\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1590 - accuracy: 0.93 - 0s 3ms/step - loss: 0.1186 - accuracy: 0.9583 - val_loss: 1.0359 - val_accuracy: 0.8684\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1909 - accuracy: 0.93 - 0s 3ms/step - loss: 0.1202 - accuracy: 0.9671 - val_loss: 0.6477 - val_accuracy: 0.8684\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1182 - accuracy: 0.96 - 0s 3ms/step - loss: 0.0888 - accuracy: 0.9737 - val_loss: 0.5028 - val_accuracy: 0.8860\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0661 - accuracy: 0.98 - 0s 3ms/step - loss: 0.0717 - accuracy: 0.9781 - val_loss: 0.6846 - val_accuracy: 0.8596\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0951 - accuracy: 0.95 - 0s 4ms/step - loss: 0.0697 - accuracy: 0.9759 - val_loss: 0.4881 - val_accuracy: 0.8860\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1097 - accuracy: 0.95 - 0s 4ms/step - loss: 0.0880 - accuracy: 0.9715 - val_loss: 0.6217 - val_accuracy: 0.8684\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0545 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0711 - accuracy: 0.9825 - val_loss: 0.4937 - val_accuracy: 0.8860\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0306 - accuracy: 1.00 - 0s 3ms/step - loss: 0.0730 - accuracy: 0.9803 - val_loss: 0.7454 - val_accuracy: 0.8860\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0618 - accuracy: 0.98 - 0s 3ms/step - loss: 0.0667 - accuracy: 0.9825 - val_loss: 0.9512 - val_accuracy: 0.8860\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0229 - accuracy: 1.00 - 0s 3ms/step - loss: 0.0647 - accuracy: 0.9825 - val_loss: 1.0142 - val_accuracy: 0.8772\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0153 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0809 - accuracy: 0.9671 - val_loss: 1.3470 - val_accuracy: 0.8684\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0224 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0769 - accuracy: 0.9825 - val_loss: 1.0465 - val_accuracy: 0.8684\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1095 - accuracy: 0.96 - 0s 4ms/step - loss: 0.0609 - accuracy: 0.9868 - val_loss: 1.1511 - val_accuracy: 0.8596\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0194 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0660 - accuracy: 0.9868 - val_loss: 1.0025 - val_accuracy: 0.8772\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0735 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0496 - accuracy: 0.9825 - val_loss: 0.8535 - val_accuracy: 0.8860\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN40\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  24%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                     | 41/169 [04:29<12:46,  5.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_41\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_164 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_165 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_166 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_167 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.7132 - accuracy: 0.43 - 0s 12ms/step - loss: 0.6035 - accuracy: 0.6749 - val_loss: 0.5021 - val_accuracy: 0.7826\n",
      "Epoch 2/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.4034 - accuracy: 0.85 - 0s 3ms/step - loss: 0.3883 - accuracy: 0.8333 - val_loss: 0.5048 - val_accuracy: 0.8098\n",
      "Epoch 3/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.1712 - accuracy: 0.93 - 0s 3ms/step - loss: 0.3673 - accuracy: 0.8470 - val_loss: 0.4560 - val_accuracy: 0.8043\n",
      "Epoch 4/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2547 - accuracy: 0.87 - 0s 3ms/step - loss: 0.3113 - accuracy: 0.8675 - val_loss: 0.5323 - val_accuracy: 0.7989\n",
      "Epoch 5/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.1655 - accuracy: 0.93 - 0s 3ms/step - loss: 0.2955 - accuracy: 0.8866 - val_loss: 0.5456 - val_accuracy: 0.7989\n",
      "Epoch 6/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2222 - accuracy: 0.92 - 0s 3ms/step - loss: 0.2573 - accuracy: 0.8907 - val_loss: 0.5417 - val_accuracy: 0.7880\n",
      "Epoch 7/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2028 - accuracy: 0.93 - 0s 3ms/step - loss: 0.2249 - accuracy: 0.9085 - val_loss: 0.6096 - val_accuracy: 0.7989\n",
      "Epoch 8/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2613 - accuracy: 0.87 - 0s 3ms/step - loss: 0.2135 - accuracy: 0.9098 - val_loss: 0.7298 - val_accuracy: 0.7935\n",
      "Epoch 9/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.1772 - accuracy: 0.90 - 0s 3ms/step - loss: 0.1884 - accuracy: 0.9235 - val_loss: 0.8551 - val_accuracy: 0.7826\n",
      "Epoch 10/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.3850 - accuracy: 0.84 - 0s 3ms/step - loss: 0.1971 - accuracy: 0.9139 - val_loss: 0.7117 - val_accuracy: 0.7772\n",
      "Epoch 11/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.1299 - accuracy: 0.95 - 0s 3ms/step - loss: 0.1631 - accuracy: 0.9358 - val_loss: 1.1263 - val_accuracy: 0.7609\n",
      "Epoch 12/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.1653 - accuracy: 0.95 - 0s 3ms/step - loss: 0.1543 - accuracy: 0.9358 - val_loss: 1.3012 - val_accuracy: 0.7446\n",
      "Epoch 13/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.1212 - accuracy: 0.93 - 0s 3ms/step - loss: 0.1412 - accuracy: 0.9440 - val_loss: 1.3527 - val_accuracy: 0.7880\n",
      "Epoch 14/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.0693 - accuracy: 0.98 - 0s 3ms/step - loss: 0.1977 - accuracy: 0.9167 - val_loss: 0.9389 - val_accuracy: 0.7391\n",
      "Epoch 15/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.1082 - accuracy: 0.95 - 0s 3ms/step - loss: 0.1603 - accuracy: 0.9317 - val_loss: 0.9907 - val_accuracy: 0.7446\n",
      "Epoch 16/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2631 - accuracy: 0.89 - 0s 3ms/step - loss: 0.1335 - accuracy: 0.9467 - val_loss: 1.2499 - val_accuracy: 0.7228\n",
      "Epoch 17/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.1054 - accuracy: 0.95 - 0s 3ms/step - loss: 0.1042 - accuracy: 0.9577 - val_loss: 1.4784 - val_accuracy: 0.7609\n",
      "Epoch 18/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.1303 - accuracy: 0.93 - 0s 3ms/step - loss: 0.0843 - accuracy: 0.9631 - val_loss: 1.7087 - val_accuracy: 0.7554\n",
      "Epoch 19/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.1010 - accuracy: 0.98 - 0s 3ms/step - loss: 0.0829 - accuracy: 0.9713 - val_loss: 1.7676 - val_accuracy: 0.7446\n",
      "Epoch 20/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.0305 - accuracy: 1.00 - 0s 3ms/step - loss: 0.1025 - accuracy: 0.9590 - val_loss: 1.3784 - val_accuracy: 0.7717\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN41\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                    | 42/169 [04:34<12:29,  5.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_42\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_168 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_169 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_170 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_171 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.7350 - accuracy: 0.32 - 0s 14ms/step - loss: 0.6067 - accuracy: 0.6319 - val_loss: 0.5778 - val_accuracy: 0.6590\n",
      "Epoch 2/20\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.4858 - accuracy: 0.67 - 0s 3ms/step - loss: 0.5461 - accuracy: 0.6597 - val_loss: 0.5576 - val_accuracy: 0.6912\n",
      "Epoch 3/20\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.5488 - accuracy: 0.75 - 0s 3ms/step - loss: 0.5107 - accuracy: 0.7870 - val_loss: 0.5294 - val_accuracy: 0.7327\n",
      "Epoch 4/20\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.5512 - accuracy: 0.71 - 0s 3ms/step - loss: 0.4697 - accuracy: 0.8021 - val_loss: 0.5123 - val_accuracy: 0.7650\n",
      "Epoch 5/20\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.4186 - accuracy: 0.81 - 0s 3ms/step - loss: 0.4395 - accuracy: 0.8044 - val_loss: 0.5147 - val_accuracy: 0.7604\n",
      "Epoch 6/20\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.4286 - accuracy: 0.84 - 0s 3ms/step - loss: 0.4187 - accuracy: 0.8218 - val_loss: 0.5413 - val_accuracy: 0.7558\n",
      "Epoch 7/20\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.4220 - accuracy: 0.84 - 0s 3ms/step - loss: 0.3955 - accuracy: 0.8218 - val_loss: 0.6153 - val_accuracy: 0.7281\n",
      "Epoch 8/20\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.4265 - accuracy: 0.79 - 0s 3ms/step - loss: 0.3849 - accuracy: 0.8287 - val_loss: 0.5648 - val_accuracy: 0.7465\n",
      "Epoch 9/20\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.3169 - accuracy: 0.82 - 0s 3ms/step - loss: 0.3526 - accuracy: 0.8461 - val_loss: 0.5802 - val_accuracy: 0.7235\n",
      "Epoch 10/20\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.2962 - accuracy: 0.93 - 0s 3ms/step - loss: 0.3460 - accuracy: 0.8542 - val_loss: 0.5492 - val_accuracy: 0.7419\n",
      "Epoch 11/20\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.4168 - accuracy: 0.78 - 0s 3ms/step - loss: 0.3498 - accuracy: 0.8380 - val_loss: 0.6612 - val_accuracy: 0.7051\n",
      "Epoch 12/20\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.3348 - accuracy: 0.90 - 0s 3ms/step - loss: 0.3431 - accuracy: 0.8519 - val_loss: 0.6366 - val_accuracy: 0.7512\n",
      "Epoch 13/20\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.3283 - accuracy: 0.82 - 0s 3ms/step - loss: 0.3084 - accuracy: 0.8634 - val_loss: 0.6806 - val_accuracy: 0.7281\n",
      "Epoch 14/20\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.1610 - accuracy: 0.95 - 0s 3ms/step - loss: 0.2991 - accuracy: 0.8681 - val_loss: 0.7657 - val_accuracy: 0.7097\n",
      "Epoch 15/20\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.2560 - accuracy: 0.85 - 0s 3ms/step - loss: 0.2796 - accuracy: 0.8831 - val_loss: 0.9217 - val_accuracy: 0.7327\n",
      "Epoch 16/20\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.2097 - accuracy: 0.92 - 0s 3ms/step - loss: 0.2772 - accuracy: 0.8819 - val_loss: 0.8483 - val_accuracy: 0.7097\n",
      "Epoch 17/20\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.3506 - accuracy: 0.82 - 0s 3ms/step - loss: 0.2493 - accuracy: 0.8958 - val_loss: 0.9031 - val_accuracy: 0.7373\n",
      "Epoch 18/20\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.1755 - accuracy: 0.96 - 0s 4ms/step - loss: 0.2674 - accuracy: 0.8947 - val_loss: 0.7394 - val_accuracy: 0.6866\n",
      "Epoch 19/20\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.2040 - accuracy: 0.92 - 0s 3ms/step - loss: 0.2604 - accuracy: 0.8947 - val_loss: 0.8426 - val_accuracy: 0.7327\n",
      "Epoch 20/20\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.2186 - accuracy: 0.89 - 0s 4ms/step - loss: 0.2282 - accuracy: 0.9051 - val_loss: 0.9427 - val_accuracy: 0.6912\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN42\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                    | 43/169 [04:41<12:49,  6.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_43\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_172 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_173 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_174 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_175 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.7028 - accuracy: 0.51 - 0s 42ms/step - loss: 0.5783 - accuracy: 0.6718 - val_loss: 0.4692 - val_accuracy: 0.6991\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.4556 - accuracy: 0.67 - 0s 3ms/step - loss: 0.4491 - accuracy: 0.6984 - val_loss: 0.4308 - val_accuracy: 0.7699\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.4185 - accuracy: 0.78 - 0s 4ms/step - loss: 0.4127 - accuracy: 0.7960 - val_loss: 0.4132 - val_accuracy: 0.8142\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.3570 - accuracy: 0.81 - 0s 4ms/step - loss: 0.3896 - accuracy: 0.8204 - val_loss: 0.4183 - val_accuracy: 0.8142\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.4859 - accuracy: 0.76 - 0s 4ms/step - loss: 0.3717 - accuracy: 0.8248 - val_loss: 0.4115 - val_accuracy: 0.8053\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2853 - accuracy: 0.92 - 0s 4ms/step - loss: 0.3313 - accuracy: 0.8537 - val_loss: 0.4095 - val_accuracy: 0.8142\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.3474 - accuracy: 0.84 - 0s 4ms/step - loss: 0.3118 - accuracy: 0.8559 - val_loss: 0.4223 - val_accuracy: 0.8230\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2441 - accuracy: 0.89 - 0s 4ms/step - loss: 0.2938 - accuracy: 0.8670 - val_loss: 0.4154 - val_accuracy: 0.8319\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2516 - accuracy: 0.95 - 0s 4ms/step - loss: 0.2720 - accuracy: 0.8847 - val_loss: 0.4225 - val_accuracy: 0.8496\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2574 - accuracy: 0.89 - 0s 4ms/step - loss: 0.2825 - accuracy: 0.8736 - val_loss: 0.4610 - val_accuracy: 0.8319\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2927 - accuracy: 0.85 - 0s 4ms/step - loss: 0.2876 - accuracy: 0.8736 - val_loss: 0.4775 - val_accuracy: 0.7876\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2131 - accuracy: 0.93 - 0s 4ms/step - loss: 0.3114 - accuracy: 0.8514 - val_loss: 0.4177 - val_accuracy: 0.7876\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2991 - accuracy: 0.85 - 0s 4ms/step - loss: 0.3232 - accuracy: 0.8315 - val_loss: 0.4231 - val_accuracy: 0.7965\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2818 - accuracy: 0.84 - 0s 4ms/step - loss: 0.2803 - accuracy: 0.8780 - val_loss: 0.3582 - val_accuracy: 0.8496\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2397 - accuracy: 0.89 - 0s 4ms/step - loss: 0.2397 - accuracy: 0.8891 - val_loss: 0.3857 - val_accuracy: 0.8584\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2310 - accuracy: 0.90 - 0s 3ms/step - loss: 0.2346 - accuracy: 0.9180 - val_loss: 0.4160 - val_accuracy: 0.8230\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1760 - accuracy: 0.93 - 0s 4ms/step - loss: 0.1997 - accuracy: 0.9246 - val_loss: 0.4970 - val_accuracy: 0.8053\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1028 - accuracy: 1.00 - 0s 4ms/step - loss: 0.1865 - accuracy: 0.9379 - val_loss: 0.5037 - val_accuracy: 0.8496\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1853 - accuracy: 0.95 - 0s 3ms/step - loss: 0.1641 - accuracy: 0.9468 - val_loss: 0.6252 - val_accuracy: 0.8319\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1362 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1488 - accuracy: 0.9534 - val_loss: 0.6013 - val_accuracy: 0.8319\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN43\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  26%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                   | 44/169 [04:47<12:47,  6.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_44\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_176 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_177 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_178 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_179 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.8171 - accuracy: 0.43 - 0s 13ms/step - loss: 0.6479 - accuracy: 0.5898 - val_loss: 0.5617 - val_accuracy: 0.7237\n",
      "Epoch 2/20\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.5597 - accuracy: 0.70 - 0s 3ms/step - loss: 0.4947 - accuracy: 0.7479 - val_loss: 0.5556 - val_accuracy: 0.7566\n",
      "Epoch 3/20\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3387 - accuracy: 0.92 - 0s 3ms/step - loss: 0.3859 - accuracy: 0.8254 - val_loss: 0.5018 - val_accuracy: 0.7763\n",
      "Epoch 4/20\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3019 - accuracy: 0.85 - 0s 3ms/step - loss: 0.3150 - accuracy: 0.8731 - val_loss: 0.4534 - val_accuracy: 0.8092\n",
      "Epoch 5/20\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2050 - accuracy: 0.95 - 0s 3ms/step - loss: 0.2291 - accuracy: 0.9193 - val_loss: 0.4384 - val_accuracy: 0.8224\n",
      "Epoch 6/20\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1330 - accuracy: 0.96 - 0s 3ms/step - loss: 0.1950 - accuracy: 0.9209 - val_loss: 0.5090 - val_accuracy: 0.8355\n",
      "Epoch 7/20\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1097 - accuracy: 0.96 - 0s 3ms/step - loss: 0.1884 - accuracy: 0.9341 - val_loss: 0.4732 - val_accuracy: 0.8355\n",
      "Epoch 8/20\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1037 - accuracy: 0.95 - 0s 3ms/step - loss: 0.1401 - accuracy: 0.9506 - val_loss: 0.5143 - val_accuracy: 0.8224\n",
      "Epoch 9/20\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0984 - accuracy: 0.96 - 0s 3ms/step - loss: 0.1240 - accuracy: 0.9572 - val_loss: 0.7261 - val_accuracy: 0.8158\n",
      "Epoch 10/20\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0459 - accuracy: 1.00 - 0s 3ms/step - loss: 0.1132 - accuracy: 0.9621 - val_loss: 0.6877 - val_accuracy: 0.8224\n",
      "Epoch 11/20\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1189 - accuracy: 0.96 - 0s 3ms/step - loss: 0.1137 - accuracy: 0.9539 - val_loss: 0.5385 - val_accuracy: 0.8684\n",
      "Epoch 12/20\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1285 - accuracy: 0.95 - 0s 3ms/step - loss: 0.1005 - accuracy: 0.9654 - val_loss: 0.6898 - val_accuracy: 0.8355\n",
      "Epoch 13/20\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0259 - accuracy: 1.00 - 0s 3ms/step - loss: 0.0998 - accuracy: 0.9621 - val_loss: 0.6792 - val_accuracy: 0.8224\n",
      "Epoch 14/20\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0530 - accuracy: 0.95 - 0s 3ms/step - loss: 0.1161 - accuracy: 0.9654 - val_loss: 0.8895 - val_accuracy: 0.7895\n",
      "Epoch 15/20\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1605 - accuracy: 0.93 - 0s 3ms/step - loss: 0.0933 - accuracy: 0.9638 - val_loss: 0.9741 - val_accuracy: 0.8092\n",
      "Epoch 16/20\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1036 - accuracy: 0.96 - 0s 3ms/step - loss: 0.0525 - accuracy: 0.9786 - val_loss: 0.8750 - val_accuracy: 0.7697\n",
      "Epoch 17/20\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0194 - accuracy: 1.00 - 0s 3ms/step - loss: 0.0373 - accuracy: 0.9885 - val_loss: 1.1079 - val_accuracy: 0.7895\n",
      "Epoch 18/20\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0292 - accuracy: 0.98 - 0s 3ms/step - loss: 0.0407 - accuracy: 0.9835 - val_loss: 1.0709 - val_accuracy: 0.8158\n",
      "Epoch 19/20\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0215 - accuracy: 0.98 - 0s 3ms/step - loss: 0.0801 - accuracy: 0.9753 - val_loss: 0.9808 - val_accuracy: 0.8355\n",
      "Epoch 20/20\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0295 - accuracy: 0.98 - 0s 3ms/step - loss: 0.0698 - accuracy: 0.9687 - val_loss: 0.8658 - val_accuracy: 0.7829\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN44\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                   | 45/169 [04:53<12:41,  6.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_45\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_180 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_181 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_182 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_183 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.7536 - accuracy: 0.21 - 0s 17ms/step - loss: 0.6562 - accuracy: 0.7134 - val_loss: 0.5137 - val_accuracy: 0.9569\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.4959 - accuracy: 0.93 - 0s 3ms/step - loss: 0.4329 - accuracy: 0.9591 - val_loss: 0.4658 - val_accuracy: 0.9397\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.3279 - accuracy: 0.96 - 0s 3ms/step - loss: 0.3188 - accuracy: 0.9763 - val_loss: 0.4827 - val_accuracy: 0.9310\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2877 - accuracy: 0.95 - 0s 4ms/step - loss: 0.2376 - accuracy: 0.9741 - val_loss: 0.4747 - val_accuracy: 0.9397\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1782 - accuracy: 0.98 - 0s 4ms/step - loss: 0.1885 - accuracy: 0.9741 - val_loss: 0.4580 - val_accuracy: 0.9397\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1567 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1525 - accuracy: 0.9763 - val_loss: 0.4501 - val_accuracy: 0.9310\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1599 - accuracy: 0.98 - 0s 4ms/step - loss: 0.1335 - accuracy: 0.9806 - val_loss: 0.2791 - val_accuracy: 0.9397\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0876 - accuracy: 1.00 - 0s 3ms/step - loss: 0.1138 - accuracy: 0.9784 - val_loss: 0.3294 - val_accuracy: 0.9397\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1191 - accuracy: 0.98 - 0s 3ms/step - loss: 0.1048 - accuracy: 0.9784 - val_loss: 0.3221 - val_accuracy: 0.9310\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0967 - accuracy: 0.98 - 0s 3ms/step - loss: 0.0859 - accuracy: 0.9849 - val_loss: 0.3510 - val_accuracy: 0.9397\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0930 - accuracy: 0.95 - 0s 4ms/step - loss: 0.0712 - accuracy: 0.9871 - val_loss: 0.5218 - val_accuracy: 0.9310\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0702 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0601 - accuracy: 0.9914 - val_loss: 0.4865 - val_accuracy: 0.9224\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0486 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0636 - accuracy: 0.9914 - val_loss: 0.5753 - val_accuracy: 0.9224\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0317 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0467 - accuracy: 0.9957 - val_loss: 0.6109 - val_accuracy: 0.9397\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0443 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0698 - accuracy: 0.9892 - val_loss: 1.9017 - val_accuracy: 0.9052\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0375 - accuracy: 1.00 - 0s 4ms/step - loss: 0.1060 - accuracy: 0.9871 - val_loss: 1.1334 - val_accuracy: 0.9138\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0239 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0524 - accuracy: 0.9871 - val_loss: 0.4854 - val_accuracy: 0.9397\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0454 - accuracy: 0.98 - 0s 3ms/step - loss: 0.0522 - accuracy: 0.9871 - val_loss: 0.4136 - val_accuracy: 0.9138\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0439 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0420 - accuracy: 0.9935 - val_loss: 0.3643 - val_accuracy: 0.9310\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0352 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0507 - accuracy: 0.9892 - val_loss: 0.4452 - val_accuracy: 0.9224\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN45\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                   | 46/169 [04:59<12:22,  6.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_46\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_184 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_185 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_186 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_187 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.7152 - accuracy: 0.39 - 0s 12ms/step - loss: 0.5547 - accuracy: 0.7025 - val_loss: 0.4793 - val_accuracy: 0.7933\n",
      "Epoch 2/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2763 - accuracy: 0.87 - 0s 3ms/step - loss: 0.4270 - accuracy: 0.8240 - val_loss: 0.4857 - val_accuracy: 0.8324\n",
      "Epoch 3/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.3353 - accuracy: 0.82 - 0s 3ms/step - loss: 0.3252 - accuracy: 0.8603 - val_loss: 0.6160 - val_accuracy: 0.7933\n",
      "Epoch 4/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2488 - accuracy: 0.90 - 0s 3ms/step - loss: 0.2812 - accuracy: 0.8799 - val_loss: 0.7981 - val_accuracy: 0.7933\n",
      "Epoch 5/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2993 - accuracy: 0.87 - 0s 3ms/step - loss: 0.2757 - accuracy: 0.8771 - val_loss: 0.9682 - val_accuracy: 0.8101\n",
      "Epoch 6/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2400 - accuracy: 0.90 - 0s 3ms/step - loss: 0.2501 - accuracy: 0.9008 - val_loss: 0.9101 - val_accuracy: 0.8045\n",
      "Epoch 7/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.0816 - accuracy: 0.98 - 0s 3ms/step - loss: 0.2508 - accuracy: 0.9050 - val_loss: 0.8837 - val_accuracy: 0.8156\n",
      "Epoch 8/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2307 - accuracy: 0.87 - 0s 3ms/step - loss: 0.2612 - accuracy: 0.8869 - val_loss: 0.8615 - val_accuracy: 0.8212\n",
      "Epoch 9/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2077 - accuracy: 0.92 - 0s 3ms/step - loss: 0.2220 - accuracy: 0.9050 - val_loss: 1.1126 - val_accuracy: 0.8268\n",
      "Epoch 10/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.1640 - accuracy: 0.92 - 0s 3ms/step - loss: 0.1980 - accuracy: 0.9162 - val_loss: 1.0620 - val_accuracy: 0.8436\n",
      "Epoch 11/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.1485 - accuracy: 0.95 - 0s 3ms/step - loss: 0.1555 - accuracy: 0.9413 - val_loss: 1.5227 - val_accuracy: 0.8324\n",
      "Epoch 12/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.1105 - accuracy: 0.95 - 0s 3ms/step - loss: 0.1379 - accuracy: 0.9385 - val_loss: 1.5955 - val_accuracy: 0.7933\n",
      "Epoch 13/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.1103 - accuracy: 0.96 - 0s 3ms/step - loss: 0.1454 - accuracy: 0.9553 - val_loss: 1.9247 - val_accuracy: 0.8324\n",
      "Epoch 14/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.0752 - accuracy: 0.96 - 0s 3ms/step - loss: 0.1532 - accuracy: 0.9399 - val_loss: 1.3386 - val_accuracy: 0.7765\n",
      "Epoch 15/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.1441 - accuracy: 0.95 - 0s 3ms/step - loss: 0.1593 - accuracy: 0.9413 - val_loss: 1.5913 - val_accuracy: 0.7821\n",
      "Epoch 16/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.1967 - accuracy: 0.96 - 0s 3ms/step - loss: 0.1343 - accuracy: 0.9553 - val_loss: 2.4086 - val_accuracy: 0.7654\n",
      "Epoch 17/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.0635 - accuracy: 0.98 - 0s 3ms/step - loss: 0.1577 - accuracy: 0.9497 - val_loss: 1.7495 - val_accuracy: 0.7989\n",
      "Epoch 18/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.1300 - accuracy: 0.95 - 0s 3ms/step - loss: 0.1533 - accuracy: 0.9511 - val_loss: 1.4142 - val_accuracy: 0.8045\n",
      "Epoch 19/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.0551 - accuracy: 0.98 - 0s 3ms/step - loss: 0.1252 - accuracy: 0.9469 - val_loss: 1.7818 - val_accuracy: 0.8045\n",
      "Epoch 20/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.0952 - accuracy: 0.95 - 0s 3ms/step - loss: 0.1264 - accuracy: 0.9581 - val_loss: 1.5487 - val_accuracy: 0.7933\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN46\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  28%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                  | 47/169 [05:05<12:12,  6.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_47\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_188 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_189 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_190 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_191 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.7352 - accuracy: 0.46 - 0s 20ms/step - loss: 0.5325 - accuracy: 0.7009 - val_loss: 0.4500 - val_accuracy: 0.7364\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.4904 - accuracy: 0.68 - 0s 4ms/step - loss: 0.3830 - accuracy: 0.7352 - val_loss: 0.3752 - val_accuracy: 0.7364\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.3355 - accuracy: 0.71 - 0s 4ms/step - loss: 0.3221 - accuracy: 0.8676 - val_loss: 0.3599 - val_accuracy: 0.8273\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.3032 - accuracy: 0.90 - 0s 4ms/step - loss: 0.2525 - accuracy: 0.8881 - val_loss: 0.3674 - val_accuracy: 0.8273\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2176 - accuracy: 0.92 - 0s 4ms/step - loss: 0.1968 - accuracy: 0.9292 - val_loss: 0.4075 - val_accuracy: 0.8091\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1654 - accuracy: 0.92 - 0s 5ms/step - loss: 0.1697 - accuracy: 0.9406 - val_loss: 0.4595 - val_accuracy: 0.8091\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0673 - accuracy: 0.98 - 0s 5ms/step - loss: 0.1344 - accuracy: 0.9498 - val_loss: 0.5277 - val_accuracy: 0.7727\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1089 - accuracy: 0.96 - 0s 5ms/step - loss: 0.1230 - accuracy: 0.9543 - val_loss: 0.6275 - val_accuracy: 0.8000\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1002 - accuracy: 0.95 - 0s 4ms/step - loss: 0.0968 - accuracy: 0.9589 - val_loss: 0.6343 - val_accuracy: 0.8000\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0538 - accuracy: 0.98 - 0s 5ms/step - loss: 0.0830 - accuracy: 0.9726 - val_loss: 0.7170 - val_accuracy: 0.8182\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0783 - accuracy: 0.96 - 0s 4ms/step - loss: 0.0859 - accuracy: 0.9635 - val_loss: 0.7852 - val_accuracy: 0.7909\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0872 - accuracy: 0.96 - 0s 5ms/step - loss: 0.1195 - accuracy: 0.9566 - val_loss: 1.0357 - val_accuracy: 0.7545\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0757 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1407 - accuracy: 0.9498 - val_loss: 0.6809 - val_accuracy: 0.7818\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1754 - accuracy: 0.95 - 0s 5ms/step - loss: 0.1332 - accuracy: 0.9429 - val_loss: 0.6027 - val_accuracy: 0.7909\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0715 - accuracy: 0.96 - 0s 4ms/step - loss: 0.0815 - accuracy: 0.9703 - val_loss: 0.6875 - val_accuracy: 0.8182\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0300 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0559 - accuracy: 0.9726 - val_loss: 0.6916 - val_accuracy: 0.8182\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0369 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0533 - accuracy: 0.9726 - val_loss: 0.8028 - val_accuracy: 0.8000\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0233 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0424 - accuracy: 0.9817 - val_loss: 0.9251 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0117 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0280 - accuracy: 0.9886 - val_loss: 0.9579 - val_accuracy: 0.8182\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0346 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0229 - accuracy: 0.9932 - val_loss: 1.1100 - val_accuracy: 0.8091\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN47\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  28%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                  | 48/169 [05:11<12:06,  6.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_48\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_192 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_193 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_194 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_195 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.7463 - accuracy: 0.35 - 0s 15ms/step - loss: 0.5829 - accuracy: 0.6483 - val_loss: 0.4940 - val_accuracy: 0.6894\n",
      "Epoch 2/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.4850 - accuracy: 0.71 - 0s 3ms/step - loss: 0.4569 - accuracy: 0.6920 - val_loss: 0.5308 - val_accuracy: 0.6970\n",
      "Epoch 3/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.4971 - accuracy: 0.73 - 0s 3ms/step - loss: 0.4299 - accuracy: 0.7605 - val_loss: 0.4380 - val_accuracy: 0.7424\n",
      "Epoch 4/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.4538 - accuracy: 0.79 - 0s 3ms/step - loss: 0.3715 - accuracy: 0.8346 - val_loss: 0.5017 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.3481 - accuracy: 0.82 - 0s 3ms/step - loss: 0.3645 - accuracy: 0.8308 - val_loss: 0.4623 - val_accuracy: 0.7576\n",
      "Epoch 6/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.4104 - accuracy: 0.78 - 0s 3ms/step - loss: 0.3214 - accuracy: 0.8593 - val_loss: 0.5444 - val_accuracy: 0.7652\n",
      "Epoch 7/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2819 - accuracy: 0.85 - 0s 3ms/step - loss: 0.2865 - accuracy: 0.8783 - val_loss: 0.5881 - val_accuracy: 0.7652\n",
      "Epoch 8/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1838 - accuracy: 0.90 - 0s 3ms/step - loss: 0.2571 - accuracy: 0.8802 - val_loss: 0.7173 - val_accuracy: 0.7273\n",
      "Epoch 9/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1697 - accuracy: 0.95 - 0s 3ms/step - loss: 0.2457 - accuracy: 0.8935 - val_loss: 0.8936 - val_accuracy: 0.7197\n",
      "Epoch 10/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1922 - accuracy: 0.90 - 0s 3ms/step - loss: 0.2175 - accuracy: 0.8916 - val_loss: 0.8986 - val_accuracy: 0.7576\n",
      "Epoch 11/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1645 - accuracy: 0.92 - 0s 3ms/step - loss: 0.2609 - accuracy: 0.8821 - val_loss: 0.7098 - val_accuracy: 0.7273\n",
      "Epoch 12/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2642 - accuracy: 0.89 - 0s 3ms/step - loss: 0.2436 - accuracy: 0.8878 - val_loss: 0.7284 - val_accuracy: 0.7424\n",
      "Epoch 13/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.3960 - accuracy: 0.76 - 0s 3ms/step - loss: 0.2422 - accuracy: 0.8840 - val_loss: 0.6486 - val_accuracy: 0.7652\n",
      "Epoch 14/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2199 - accuracy: 0.87 - 0s 3ms/step - loss: 0.2055 - accuracy: 0.9106 - val_loss: 0.7171 - val_accuracy: 0.7273\n",
      "Epoch 15/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.3993 - accuracy: 0.89 - 0s 3ms/step - loss: 0.2120 - accuracy: 0.9221 - val_loss: 0.6586 - val_accuracy: 0.7576\n",
      "Epoch 16/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1710 - accuracy: 0.93 - 0s 4ms/step - loss: 0.1990 - accuracy: 0.9202 - val_loss: 0.7588 - val_accuracy: 0.7879\n",
      "Epoch 17/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2054 - accuracy: 0.89 - 0s 4ms/step - loss: 0.1860 - accuracy: 0.9144 - val_loss: 0.8655 - val_accuracy: 0.7348\n",
      "Epoch 18/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1511 - accuracy: 0.92 - 0s 4ms/step - loss: 0.1668 - accuracy: 0.9163 - val_loss: 0.8340 - val_accuracy: 0.7424\n",
      "Epoch 19/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1023 - accuracy: 0.95 - 0s 3ms/step - loss: 0.1593 - accuracy: 0.9144 - val_loss: 0.9549 - val_accuracy: 0.7727\n",
      "Epoch 20/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1154 - accuracy: 0.95 - 0s 3ms/step - loss: 0.1165 - accuracy: 0.9468 - val_loss: 1.1137 - val_accuracy: 0.7879\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN48\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  29%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                 | 49/169 [05:17<11:59,  6.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_49\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_196 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_197 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_198 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_199 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.3981 - accuracy: 0.85 - 0s 16ms/step - loss: 0.5052 - accuracy: 0.7894 - val_loss: 0.4130 - val_accuracy: 0.8319\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.3749 - accuracy: 0.90 - 0s 3ms/step - loss: 0.3241 - accuracy: 0.8226 - val_loss: 0.5222 - val_accuracy: 0.8230\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2441 - accuracy: 0.87 - 0s 3ms/step - loss: 0.2418 - accuracy: 0.9002 - val_loss: 0.4776 - val_accuracy: 0.8673\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2109 - accuracy: 0.92 - 0s 3ms/step - loss: 0.2179 - accuracy: 0.9335 - val_loss: 0.4758 - val_accuracy: 0.8761\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2380 - accuracy: 0.92 - 0s 3ms/step - loss: 0.1866 - accuracy: 0.9379 - val_loss: 0.7743 - val_accuracy: 0.8584\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1594 - accuracy: 0.93 - 0s 4ms/step - loss: 0.1928 - accuracy: 0.9268 - val_loss: 0.7847 - val_accuracy: 0.8761\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1675 - accuracy: 0.95 - 0s 3ms/step - loss: 0.1411 - accuracy: 0.9579 - val_loss: 0.7467 - val_accuracy: 0.9027\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1634 - accuracy: 0.92 - 0s 3ms/step - loss: 0.1373 - accuracy: 0.9468 - val_loss: 0.8629 - val_accuracy: 0.8850\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0921 - accuracy: 0.98 - 0s 3ms/step - loss: 0.1092 - accuracy: 0.9712 - val_loss: 1.0244 - val_accuracy: 0.8761\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1438 - accuracy: 0.95 - 0s 3ms/step - loss: 0.0934 - accuracy: 0.9756 - val_loss: 1.1661 - val_accuracy: 0.8673\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0752 - accuracy: 0.98 - 0s 3ms/step - loss: 0.0797 - accuracy: 0.9823 - val_loss: 1.2507 - val_accuracy: 0.8673\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0437 - accuracy: 1.00 - 0s 3ms/step - loss: 0.0715 - accuracy: 0.9845 - val_loss: 1.3530 - val_accuracy: 0.8761\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1038 - accuracy: 0.96 - 0s 4ms/step - loss: 0.0663 - accuracy: 0.9845 - val_loss: 1.4235 - val_accuracy: 0.8761\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0335 - accuracy: 1.00 - 0s 3ms/step - loss: 0.0641 - accuracy: 0.9845 - val_loss: 1.5067 - val_accuracy: 0.8761\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0898 - accuracy: 0.96 - 0s 4ms/step - loss: 0.0614 - accuracy: 0.9845 - val_loss: 1.5887 - val_accuracy: 0.8584\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0236 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0606 - accuracy: 0.9845 - val_loss: 1.6039 - val_accuracy: 0.8761\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1287 - accuracy: 0.95 - 0s 4ms/step - loss: 0.0848 - accuracy: 0.9690 - val_loss: 1.9593 - val_accuracy: 0.8673\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0549 - accuracy: 0.98 - 0s 4ms/step - loss: 0.1240 - accuracy: 0.9690 - val_loss: 1.6971 - val_accuracy: 0.8850\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0258 - accuracy: 1.00 - 0s 4ms/step - loss: 0.1229 - accuracy: 0.9579 - val_loss: 1.8410 - val_accuracy: 0.8761\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0847 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1944 - accuracy: 0.9401 - val_loss: 1.4502 - val_accuracy: 0.8850\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN49\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                 | 50/169 [05:23<11:43,  5.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_50\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_200 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_201 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_202 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_203 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.7164 - accuracy: 0.46 - 0s 22ms/step - loss: 0.6659 - accuracy: 0.6980 - val_loss: 0.6277 - val_accuracy: 0.7411\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.5946 - accuracy: 0.84 - 0s 4ms/step - loss: 0.6128 - accuracy: 0.7427 - val_loss: 0.5896 - val_accuracy: 0.7411\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.5549 - accuracy: 0.79 - 0s 4ms/step - loss: 0.5778 - accuracy: 0.7405 - val_loss: 0.5331 - val_accuracy: 0.7679\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.5416 - accuracy: 0.76 - 0s 4ms/step - loss: 0.4840 - accuracy: 0.8143 - val_loss: 0.4846 - val_accuracy: 0.8125\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.4136 - accuracy: 0.84 - 0s 4ms/step - loss: 0.3807 - accuracy: 0.8881 - val_loss: 0.4920 - val_accuracy: 0.8304\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2913 - accuracy: 0.93 - 0s 4ms/step - loss: 0.3032 - accuracy: 0.9172 - val_loss: 0.5006 - val_accuracy: 0.8125\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2483 - accuracy: 0.93 - 0s 4ms/step - loss: 0.2433 - accuracy: 0.9396 - val_loss: 0.5973 - val_accuracy: 0.7946\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1756 - accuracy: 0.98 - 0s 4ms/step - loss: 0.2030 - accuracy: 0.9508 - val_loss: 0.6323 - val_accuracy: 0.7857\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1113 - accuracy: 0.98 - 0s 5ms/step - loss: 0.1941 - accuracy: 0.9485 - val_loss: 0.7036 - val_accuracy: 0.8304\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1937 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1735 - accuracy: 0.9575 - val_loss: 0.7226 - val_accuracy: 0.8036\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1071 - accuracy: 0.98 - 0s 4ms/step - loss: 0.1774 - accuracy: 0.9530 - val_loss: 0.8749 - val_accuracy: 0.8036\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1103 - accuracy: 0.98 - 0s 4ms/step - loss: 0.1443 - accuracy: 0.9642 - val_loss: 0.8025 - val_accuracy: 0.8036\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1271 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1390 - accuracy: 0.9687 - val_loss: 0.8277 - val_accuracy: 0.8036\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1335 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1314 - accuracy: 0.9709 - val_loss: 0.8358 - val_accuracy: 0.8036\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1326 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1241 - accuracy: 0.9709 - val_loss: 1.0559 - val_accuracy: 0.7946\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1317 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1222 - accuracy: 0.9709 - val_loss: 1.0487 - val_accuracy: 0.8036\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1317 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1194 - accuracy: 0.9732 - val_loss: 0.9884 - val_accuracy: 0.7946\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0826 - accuracy: 0.98 - 0s 4ms/step - loss: 0.1189 - accuracy: 0.9732 - val_loss: 0.9994 - val_accuracy: 0.7857\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1299 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1179 - accuracy: 0.9732 - val_loss: 1.0500 - val_accuracy: 0.7857\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2254 - accuracy: 0.93 - 0s 5ms/step - loss: 0.1173 - accuracy: 0.9732 - val_loss: 1.1178 - val_accuracy: 0.8036\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN50\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                 | 51/169 [05:29<11:42,  5.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_51\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_204 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_205 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_206 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_207 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.5570 - accuracy: 0.79 - 0s 19ms/step - loss: 0.4696 - accuracy: 0.7618 - val_loss: 0.4321 - val_accuracy: 0.8037\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.3078 - accuracy: 0.89 - 0s 4ms/step - loss: 0.3628 - accuracy: 0.8514 - val_loss: 0.4608 - val_accuracy: 0.8318\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2285 - accuracy: 0.89 - 0s 4ms/step - loss: 0.2972 - accuracy: 0.8797 - val_loss: 0.4852 - val_accuracy: 0.8598\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2328 - accuracy: 0.92 - 0s 4ms/step - loss: 0.2561 - accuracy: 0.8797 - val_loss: 0.5888 - val_accuracy: 0.8505\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1721 - accuracy: 0.95 - 0s 4ms/step - loss: 0.2229 - accuracy: 0.9292 - val_loss: 0.7463 - val_accuracy: 0.8411\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2278 - accuracy: 0.89 - 0s 4ms/step - loss: 0.1875 - accuracy: 0.9316 - val_loss: 0.7611 - val_accuracy: 0.8411\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1383 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1511 - accuracy: 0.9528 - val_loss: 0.9625 - val_accuracy: 0.8318\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1269 - accuracy: 0.98 - 0s 4ms/step - loss: 0.1520 - accuracy: 0.9528 - val_loss: 0.7701 - val_accuracy: 0.8224\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0742 - accuracy: 1.00 - 0s 4ms/step - loss: 0.1454 - accuracy: 0.9528 - val_loss: 1.0459 - val_accuracy: 0.8505\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0680 - accuracy: 0.98 - 0s 4ms/step - loss: 0.1279 - accuracy: 0.9599 - val_loss: 1.1628 - val_accuracy: 0.8037\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0843 - accuracy: 0.98 - 0s 4ms/step - loss: 0.1114 - accuracy: 0.9623 - val_loss: 1.3079 - val_accuracy: 0.8037\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0917 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1069 - accuracy: 0.9599 - val_loss: 1.0882 - val_accuracy: 0.8318\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0506 - accuracy: 1.00 - 0s 4ms/step - loss: 0.1120 - accuracy: 0.9623 - val_loss: 1.3734 - val_accuracy: 0.8411\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0960 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1050 - accuracy: 0.9623 - val_loss: 1.3661 - val_accuracy: 0.7850\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1217 - accuracy: 0.95 - 0s 4ms/step - loss: 0.0955 - accuracy: 0.9670 - val_loss: 1.0995 - val_accuracy: 0.8037\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0348 - accuracy: 1.00 - 0s 4ms/step - loss: 0.1146 - accuracy: 0.9552 - val_loss: 1.0029 - val_accuracy: 0.8037\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0648 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0740 - accuracy: 0.9764 - val_loss: 1.4567 - val_accuracy: 0.7944\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1137 - accuracy: 0.95 - 0s 4ms/step - loss: 0.0778 - accuracy: 0.9788 - val_loss: 1.3162 - val_accuracy: 0.8224\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1393 - accuracy: 0.95 - 0s 4ms/step - loss: 0.0723 - accuracy: 0.9811 - val_loss: 1.3633 - val_accuracy: 0.8318\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1303 - accuracy: 0.95 - 0s 4ms/step - loss: 0.0715 - accuracy: 0.9788 - val_loss: 1.3701 - val_accuracy: 0.8131\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN51\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                | 52/169 [05:35<11:27,  5.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_52\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_208 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_209 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_210 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_211 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.6289 - accuracy: 0.73 - 0s 20ms/step - loss: 0.4861 - accuracy: 0.7679 - val_loss: 0.3908 - val_accuracy: 0.7768\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.4352 - accuracy: 0.75 - 0s 4ms/step - loss: 0.3415 - accuracy: 0.7723 - val_loss: 0.2742 - val_accuracy: 0.7768\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2279 - accuracy: 0.82 - 0s 3ms/step - loss: 0.2835 - accuracy: 0.8750 - val_loss: 0.2712 - val_accuracy: 0.8661\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2102 - accuracy: 0.90 - 0s 4ms/step - loss: 0.2268 - accuracy: 0.9241 - val_loss: 0.2861 - val_accuracy: 0.8750\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1917 - accuracy: 0.93 - 0s 4ms/step - loss: 0.2073 - accuracy: 0.9286 - val_loss: 0.2824 - val_accuracy: 0.8482\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1327 - accuracy: 0.93 - 0s 5ms/step - loss: 0.1688 - accuracy: 0.9420 - val_loss: 0.2780 - val_accuracy: 0.8482\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1225 - accuracy: 0.96 - 0s 5ms/step - loss: 0.1538 - accuracy: 0.9442 - val_loss: 0.2773 - val_accuracy: 0.8661\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1183 - accuracy: 0.98 - 0s 4ms/step - loss: 0.1413 - accuracy: 0.9509 - val_loss: 0.2904 - val_accuracy: 0.8571\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1191 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1215 - accuracy: 0.9598 - val_loss: 0.3313 - val_accuracy: 0.8571\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0951 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1107 - accuracy: 0.9665 - val_loss: 0.3146 - val_accuracy: 0.8482\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0950 - accuracy: 0.98 - 0s 4ms/step - loss: 0.1069 - accuracy: 0.9665 - val_loss: 0.3445 - val_accuracy: 0.8571\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0343 - accuracy: 1.00 - 0s 4ms/step - loss: 0.1037 - accuracy: 0.9665 - val_loss: 0.3785 - val_accuracy: 0.8750\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0875 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1086 - accuracy: 0.9621 - val_loss: 0.2714 - val_accuracy: 0.8750\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1544 - accuracy: 0.93 - 0s 4ms/step - loss: 0.1100 - accuracy: 0.9621 - val_loss: 0.4564 - val_accuracy: 0.8839\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0681 - accuracy: 0.98 - 0s 4ms/step - loss: 0.1158 - accuracy: 0.9621 - val_loss: 0.4479 - val_accuracy: 0.8661\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1508 - accuracy: 0.93 - 0s 4ms/step - loss: 0.1429 - accuracy: 0.9509 - val_loss: 0.4587 - val_accuracy: 0.8750\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0780 - accuracy: 0.98 - 0s 4ms/step - loss: 0.1276 - accuracy: 0.9576 - val_loss: 0.4145 - val_accuracy: 0.8661\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0826 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1122 - accuracy: 0.9554 - val_loss: 0.3421 - val_accuracy: 0.8661\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1085 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1028 - accuracy: 0.9554 - val_loss: 0.3796 - val_accuracy: 0.8750\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0323 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0975 - accuracy: 0.9688 - val_loss: 0.4290 - val_accuracy: 0.8750\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN52\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                | 53/169 [05:40<11:22,  5.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_53\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_212 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_213 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_214 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_215 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.6937 - accuracy: 0.51 - 0s 15ms/step - loss: 0.5717 - accuracy: 0.6131 - val_loss: 0.4712 - val_accuracy: 0.7971\n",
      "Epoch 2/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.5612 - accuracy: 0.59 - 0s 3ms/step - loss: 0.4935 - accuracy: 0.7482 - val_loss: 0.4206 - val_accuracy: 0.8043\n",
      "Epoch 3/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.4234 - accuracy: 0.78 - 0s 3ms/step - loss: 0.4236 - accuracy: 0.7993 - val_loss: 0.3949 - val_accuracy: 0.8116\n",
      "Epoch 4/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.3444 - accuracy: 0.89 - 0s 4ms/step - loss: 0.3697 - accuracy: 0.8376 - val_loss: 0.3952 - val_accuracy: 0.8188\n",
      "Epoch 5/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.3495 - accuracy: 0.82 - 0s 4ms/step - loss: 0.3270 - accuracy: 0.8577 - val_loss: 0.3932 - val_accuracy: 0.8043\n",
      "Epoch 6/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2654 - accuracy: 0.87 - 0s 4ms/step - loss: 0.3009 - accuracy: 0.8668 - val_loss: 0.4311 - val_accuracy: 0.7754\n",
      "Epoch 7/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.3444 - accuracy: 0.87 - 0s 4ms/step - loss: 0.2716 - accuracy: 0.8887 - val_loss: 0.5373 - val_accuracy: 0.7899\n",
      "Epoch 8/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.3509 - accuracy: 0.82 - 0s 4ms/step - loss: 0.2727 - accuracy: 0.8814 - val_loss: 0.4369 - val_accuracy: 0.7826\n",
      "Epoch 9/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.3348 - accuracy: 0.84 - 0s 4ms/step - loss: 0.2740 - accuracy: 0.8869 - val_loss: 0.5508 - val_accuracy: 0.7754\n",
      "Epoch 10/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1921 - accuracy: 0.93 - 0s 3ms/step - loss: 0.2511 - accuracy: 0.9051 - val_loss: 0.6700 - val_accuracy: 0.7899\n",
      "Epoch 11/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2466 - accuracy: 0.92 - 0s 4ms/step - loss: 0.2661 - accuracy: 0.8978 - val_loss: 0.5943 - val_accuracy: 0.7609\n",
      "Epoch 12/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2861 - accuracy: 0.87 - 0s 4ms/step - loss: 0.3093 - accuracy: 0.8759 - val_loss: 0.4778 - val_accuracy: 0.7609\n",
      "Epoch 13/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.3295 - accuracy: 0.87 - 0s 4ms/step - loss: 0.3400 - accuracy: 0.8449 - val_loss: 0.5641 - val_accuracy: 0.7681\n",
      "Epoch 14/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.3023 - accuracy: 0.89 - 0s 4ms/step - loss: 0.2911 - accuracy: 0.8832 - val_loss: 0.4295 - val_accuracy: 0.7971\n",
      "Epoch 15/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1999 - accuracy: 0.95 - 0s 5ms/step - loss: 0.2626 - accuracy: 0.8996 - val_loss: 0.5862 - val_accuracy: 0.7681\n",
      "Epoch 16/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2479 - accuracy: 0.89 - 0s 4ms/step - loss: 0.2520 - accuracy: 0.9069 - val_loss: 0.4592 - val_accuracy: 0.7754\n",
      "Epoch 17/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2712 - accuracy: 0.89 - 0s 4ms/step - loss: 0.2287 - accuracy: 0.9161 - val_loss: 0.5083 - val_accuracy: 0.8043\n",
      "Epoch 18/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2386 - accuracy: 0.92 - 0s 4ms/step - loss: 0.1941 - accuracy: 0.9343 - val_loss: 0.6528 - val_accuracy: 0.7971\n",
      "Epoch 19/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.3093 - accuracy: 0.85 - 0s 4ms/step - loss: 0.1990 - accuracy: 0.9307 - val_loss: 0.6052 - val_accuracy: 0.7899\n",
      "Epoch 20/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1983 - accuracy: 0.93 - 0s 4ms/step - loss: 0.2040 - accuracy: 0.9252 - val_loss: 0.6497 - val_accuracy: 0.7899\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN53\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  32%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                               | 54/169 [05:46<11:19,  5.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_54\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_216 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_217 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_218 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_219 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.9348 - accuracy: 0.3594WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.5915 - accuracy: 0.6667 - val_loss: 0.4706 - val_accuracy: 0.7179\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.4401 - accuracy: 0.67 - 0s 4ms/step - loss: 0.4101 - accuracy: 0.7161 - val_loss: 0.4124 - val_accuracy: 0.8547\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2319 - accuracy: 0.92 - 0s 4ms/step - loss: 0.3403 - accuracy: 0.8796 - val_loss: 0.4078 - val_accuracy: 0.8718\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2651 - accuracy: 0.85 - 0s 4ms/step - loss: 0.2894 - accuracy: 0.8860 - val_loss: 0.4255 - val_accuracy: 0.8291\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2772 - accuracy: 0.87 - 0s 5ms/step - loss: 0.2453 - accuracy: 0.8989 - val_loss: 0.4886 - val_accuracy: 0.8376\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1304 - accuracy: 0.98 - 0s 5ms/step - loss: 0.2002 - accuracy: 0.9247 - val_loss: 0.6135 - val_accuracy: 0.8376\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2261 - accuracy: 0.92 - 0s 5ms/step - loss: 0.1716 - accuracy: 0.9419 - val_loss: 0.5889 - val_accuracy: 0.8462\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1989 - accuracy: 0.92 - 0s 5ms/step - loss: 0.1722 - accuracy: 0.9441 - val_loss: 0.8598 - val_accuracy: 0.8462\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1329 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1357 - accuracy: 0.9656 - val_loss: 0.8638 - val_accuracy: 0.8120\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0727 - accuracy: 1.00 - 0s 5ms/step - loss: 0.1390 - accuracy: 0.9591 - val_loss: 0.9609 - val_accuracy: 0.8462\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1192 - accuracy: 0.96 - 0s 6ms/step - loss: 0.1300 - accuracy: 0.9613 - val_loss: 0.9644 - val_accuracy: 0.8376\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0855 - accuracy: 0.98 - 0s 4ms/step - loss: 0.1154 - accuracy: 0.9677 - val_loss: 0.8769 - val_accuracy: 0.8376\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1392 - accuracy: 0.95 - 0s 4ms/step - loss: 0.0976 - accuracy: 0.9699 - val_loss: 1.0191 - val_accuracy: 0.8376\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0876 - accuracy: 0.96 - 0s 5ms/step - loss: 0.0832 - accuracy: 0.9763 - val_loss: 1.1013 - val_accuracy: 0.8376\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0329 - accuracy: 1.00 - 0s 6ms/step - loss: 0.0860 - accuracy: 0.9785 - val_loss: 1.1229 - val_accuracy: 0.8291\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0793 - accuracy: 0.96 - 0s 5ms/step - loss: 0.0932 - accuracy: 0.9720 - val_loss: 1.1164 - val_accuracy: 0.8034\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1127 - accuracy: 0.96 - 0s 5ms/step - loss: 0.0795 - accuracy: 0.9785 - val_loss: 1.4050 - val_accuracy: 0.8120\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0269 - accuracy: 1.00 - 0s 5ms/step - loss: 0.0997 - accuracy: 0.9656 - val_loss: 1.3202 - val_accuracy: 0.7949\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0270 - accuracy: 1.00 - 0s 4ms/step - loss: 0.1022 - accuracy: 0.9677 - val_loss: 1.0212 - val_accuracy: 0.8547\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0440 - accuracy: 0.98 - 0s 4ms/step - loss: 0.1151 - accuracy: 0.9677 - val_loss: 1.3935 - val_accuracy: 0.7692\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN54\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                               | 55/169 [05:53<11:45,  6.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_55\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_220 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_221 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_222 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_223 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.5045 - accuracy: 0.76 - 0s 20ms/step - loss: 0.4358 - accuracy: 0.8004 - val_loss: 0.3547 - val_accuracy: 0.8291\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.3718 - accuracy: 0.81 - 0s 4ms/step - loss: 0.3232 - accuracy: 0.8326 - val_loss: 0.3330 - val_accuracy: 0.8462\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2526 - accuracy: 0.89 - 0s 4ms/step - loss: 0.2509 - accuracy: 0.8820 - val_loss: 0.3927 - val_accuracy: 0.8632\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1798 - accuracy: 0.89 - 0s 5ms/step - loss: 0.2048 - accuracy: 0.9077 - val_loss: 0.4245 - val_accuracy: 0.8803\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2076 - accuracy: 0.90 - 0s 4ms/step - loss: 0.1902 - accuracy: 0.9206 - val_loss: 0.4810 - val_accuracy: 0.8376\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1696 - accuracy: 0.92 - 0s 5ms/step - loss: 0.1563 - accuracy: 0.9421 - val_loss: 0.6130 - val_accuracy: 0.8376\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1192 - accuracy: 0.95 - 0s 5ms/step - loss: 0.1320 - accuracy: 0.9485 - val_loss: 0.7142 - val_accuracy: 0.8376\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0726 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1291 - accuracy: 0.9506 - val_loss: 0.9436 - val_accuracy: 0.8718\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0658 - accuracy: 0.98 - 0s 5ms/step - loss: 0.1252 - accuracy: 0.9399 - val_loss: 0.9894 - val_accuracy: 0.8120\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1517 - accuracy: 0.95 - 0s 5ms/step - loss: 0.1116 - accuracy: 0.9528 - val_loss: 1.0739 - val_accuracy: 0.8547\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1145 - accuracy: 0.93 - 0s 5ms/step - loss: 0.2150 - accuracy: 0.9421 - val_loss: 0.8924 - val_accuracy: 0.8034\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1422 - accuracy: 0.96 - 0s 5ms/step - loss: 0.2002 - accuracy: 0.9227 - val_loss: 0.6545 - val_accuracy: 0.8120\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1419 - accuracy: 0.93 - 0s 6ms/step - loss: 0.1532 - accuracy: 0.9292 - val_loss: 0.6501 - val_accuracy: 0.8291\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1288 - accuracy: 0.89 - 0s 4ms/step - loss: 0.1128 - accuracy: 0.9464 - val_loss: 0.7536 - val_accuracy: 0.8376\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0639 - accuracy: 0.98 - 0s 5ms/step - loss: 0.0980 - accuracy: 0.9592 - val_loss: 0.8747 - val_accuracy: 0.8462\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1263 - accuracy: 0.92 - 0s 5ms/step - loss: 0.0792 - accuracy: 0.9635 - val_loss: 0.8236 - val_accuracy: 0.8376\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1079 - accuracy: 0.95 - 0s 5ms/step - loss: 0.0692 - accuracy: 0.9657 - val_loss: 0.8514 - val_accuracy: 0.8291\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0346 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0559 - accuracy: 0.9700 - val_loss: 0.9536 - val_accuracy: 0.8376\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0219 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0584 - accuracy: 0.9700 - val_loss: 0.9919 - val_accuracy: 0.8205\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0410 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0464 - accuracy: 0.9785 - val_loss: 0.9743 - val_accuracy: 0.8291\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN55\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                              | 56/169 [06:01<12:28,  6.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_56\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_224 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_225 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_226 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_227 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.7719 - accuracy: 0.53 - 0s 21ms/step - loss: 0.5373 - accuracy: 0.7346 - val_loss: 0.4125 - val_accuracy: 0.7636\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.4383 - accuracy: 0.73 - 0s 4ms/step - loss: 0.4004 - accuracy: 0.7643 - val_loss: 0.3641 - val_accuracy: 0.7636\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.3544 - accuracy: 0.81 - 0s 5ms/step - loss: 0.3456 - accuracy: 0.7643 - val_loss: 0.3511 - val_accuracy: 0.7636\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2665 - accuracy: 0.76 - 0s 5ms/step - loss: 0.3083 - accuracy: 0.8055 - val_loss: 0.3632 - val_accuracy: 0.8000\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.3209 - accuracy: 0.82 - 0s 4ms/step - loss: 0.2719 - accuracy: 0.8764 - val_loss: 0.4081 - val_accuracy: 0.7909\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2129 - accuracy: 0.90 - 0s 4ms/step - loss: 0.2545 - accuracy: 0.8879 - val_loss: 0.4257 - val_accuracy: 0.7727\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1710 - accuracy: 0.95 - 0s 4ms/step - loss: 0.2145 - accuracy: 0.9245 - val_loss: 0.5140 - val_accuracy: 0.7818\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2401 - accuracy: 0.93 - 0s 5ms/step - loss: 0.1924 - accuracy: 0.9245 - val_loss: 0.5101 - val_accuracy: 0.8182\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1722 - accuracy: 0.93 - 0s 5ms/step - loss: 0.1804 - accuracy: 0.9314 - val_loss: 0.6955 - val_accuracy: 0.7818\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1599 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1651 - accuracy: 0.9382 - val_loss: 0.9483 - val_accuracy: 0.7636\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1861 - accuracy: 0.92 - 0s 4ms/step - loss: 0.1502 - accuracy: 0.9497 - val_loss: 0.7255 - val_accuracy: 0.7909\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1724 - accuracy: 0.93 - 0s 4ms/step - loss: 0.1724 - accuracy: 0.9314 - val_loss: 1.1825 - val_accuracy: 0.8000\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1388 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1637 - accuracy: 0.9336 - val_loss: 1.0752 - val_accuracy: 0.7727\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1021 - accuracy: 0.96 - 0s 5ms/step - loss: 0.1479 - accuracy: 0.9451 - val_loss: 0.9571 - val_accuracy: 0.7818\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1132 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1535 - accuracy: 0.9474 - val_loss: 0.8973 - val_accuracy: 0.8091\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1290 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1405 - accuracy: 0.9565 - val_loss: 1.0289 - val_accuracy: 0.8091\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0540 - accuracy: 1.00 - 0s 4ms/step - loss: 0.1140 - accuracy: 0.9634 - val_loss: 1.2307 - val_accuracy: 0.8182\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0706 - accuracy: 0.98 - 0s 4ms/step - loss: 0.1271 - accuracy: 0.9542 - val_loss: 0.8531 - val_accuracy: 0.8545\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1300 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1270 - accuracy: 0.9519 - val_loss: 1.1021 - val_accuracy: 0.8364\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2124 - accuracy: 0.90 - 0s 4ms/step - loss: 0.1110 - accuracy: 0.9611 - val_loss: 1.2874 - val_accuracy: 0.8545\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN56\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                              | 57/169 [06:07<12:03,  6.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_57\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_228 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_229 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_230 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_231 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.7472 - accuracy: 0.37 - 0s 18ms/step - loss: 0.6151 - accuracy: 0.6633 - val_loss: 0.5456 - val_accuracy: 0.7016\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.4696 - accuracy: 0.68 - 0s 3ms/step - loss: 0.4798 - accuracy: 0.7039 - val_loss: 0.4779 - val_accuracy: 0.7016\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.4708 - accuracy: 0.68 - 0s 3ms/step - loss: 0.4284 - accuracy: 0.7039 - val_loss: 0.4783 - val_accuracy: 0.7016\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.3445 - accuracy: 0.75 - 0s 3ms/step - loss: 0.3834 - accuracy: 0.7059 - val_loss: 0.4902 - val_accuracy: 0.7823\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.3977 - accuracy: 0.82 - 0s 3ms/step - loss: 0.3315 - accuracy: 0.8479 - val_loss: 0.5323 - val_accuracy: 0.7581\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.4013 - accuracy: 0.78 - 0s 4ms/step - loss: 0.2880 - accuracy: 0.8803 - val_loss: 0.6111 - val_accuracy: 0.8306\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2689 - accuracy: 0.93 - 0s 4ms/step - loss: 0.2633 - accuracy: 0.8884 - val_loss: 0.6472 - val_accuracy: 0.7742\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2739 - accuracy: 0.87 - 0s 4ms/step - loss: 0.2284 - accuracy: 0.9067 - val_loss: 0.7508 - val_accuracy: 0.7661\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2556 - accuracy: 0.89 - 0s 4ms/step - loss: 0.2094 - accuracy: 0.9209 - val_loss: 0.8188 - val_accuracy: 0.7419\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1546 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1882 - accuracy: 0.9290 - val_loss: 1.0029 - val_accuracy: 0.7500\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1939 - accuracy: 0.92 - 0s 4ms/step - loss: 0.1867 - accuracy: 0.9331 - val_loss: 1.0351 - val_accuracy: 0.7742\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1261 - accuracy: 0.96 - 0s 6ms/step - loss: 0.1692 - accuracy: 0.9432 - val_loss: 1.1563 - val_accuracy: 0.7500\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1524 - accuracy: 0.93 - 0s 4ms/step - loss: 0.1602 - accuracy: 0.9391 - val_loss: 1.1534 - val_accuracy: 0.7500\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1064 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1516 - accuracy: 0.9412 - val_loss: 1.1855 - val_accuracy: 0.7339\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0855 - accuracy: 1.00 - 0s 4ms/step - loss: 0.1408 - accuracy: 0.9574 - val_loss: 1.3370 - val_accuracy: 0.7419\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1010 - accuracy: 0.96 - 0s 3ms/step - loss: 0.1638 - accuracy: 0.9412 - val_loss: 1.2534 - val_accuracy: 0.7419\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2000 - accuracy: 0.92 - 0s 4ms/step - loss: 0.1969 - accuracy: 0.9290 - val_loss: 1.0006 - val_accuracy: 0.7581\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2851 - accuracy: 0.87 - 0s 4ms/step - loss: 0.2083 - accuracy: 0.9209 - val_loss: 1.0732 - val_accuracy: 0.7823\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1445 - accuracy: 0.95 - 0s 3ms/step - loss: 0.1747 - accuracy: 0.9412 - val_loss: 0.9808 - val_accuracy: 0.7419\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2649 - accuracy: 0.90 - 0s 3ms/step - loss: 0.1894 - accuracy: 0.9391 - val_loss: 0.9001 - val_accuracy: 0.7661\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN57\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                              | 58/169 [06:13<11:49,  6.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_58\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_232 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_233 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_234 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_235 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.7475 - accuracy: 0.46 - 0s 21ms/step - loss: 0.5633 - accuracy: 0.6875 - val_loss: 0.4428 - val_accuracy: 0.7350\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.3968 - accuracy: 0.75 - 0s 4ms/step - loss: 0.4081 - accuracy: 0.7371 - val_loss: 0.4736 - val_accuracy: 0.7350\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.3940 - accuracy: 0.67 - 0s 4ms/step - loss: 0.3315 - accuracy: 0.7522 - val_loss: 0.5274 - val_accuracy: 0.8120\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2659 - accuracy: 0.85 - 0s 4ms/step - loss: 0.2766 - accuracy: 0.8772 - val_loss: 0.5994 - val_accuracy: 0.8291\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2089 - accuracy: 0.96 - 0s 4ms/step - loss: 0.2424 - accuracy: 0.9224 - val_loss: 0.7249 - val_accuracy: 0.8120\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1393 - accuracy: 0.96 - 0s 4ms/step - loss: 0.2467 - accuracy: 0.9052 - val_loss: 0.8096 - val_accuracy: 0.8205\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1910 - accuracy: 0.93 - 0s 5ms/step - loss: 0.1836 - accuracy: 0.9267 - val_loss: 0.5558 - val_accuracy: 0.8205\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1469 - accuracy: 0.96 - 0s 5ms/step - loss: 0.1517 - accuracy: 0.9591 - val_loss: 0.7377 - val_accuracy: 0.8291\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1024 - accuracy: 0.98 - 0s 4ms/step - loss: 0.1090 - accuracy: 0.9655 - val_loss: 0.9718 - val_accuracy: 0.8120\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1634 - accuracy: 0.93 - 0s 4ms/step - loss: 0.0902 - accuracy: 0.9698 - val_loss: 1.2635 - val_accuracy: 0.8120\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0386 - accuracy: 0.98 - 0s 3ms/step - loss: 0.0774 - accuracy: 0.9741 - val_loss: 1.1466 - val_accuracy: 0.8120\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0931 - accuracy: 0.98 - 0s 3ms/step - loss: 0.0715 - accuracy: 0.9763 - val_loss: 1.4763 - val_accuracy: 0.8205\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0651 - accuracy: 0.98 - 0s 3ms/step - loss: 0.0986 - accuracy: 0.9677 - val_loss: 1.1624 - val_accuracy: 0.8120\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0180 - accuracy: 1.00 - 0s 3ms/step - loss: 0.0908 - accuracy: 0.9698 - val_loss: 1.3486 - val_accuracy: 0.8120\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1670 - accuracy: 0.95 - 0s 4ms/step - loss: 0.0856 - accuracy: 0.9698 - val_loss: 1.5145 - val_accuracy: 0.8205\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0652 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0948 - accuracy: 0.9698 - val_loss: 1.4893 - val_accuracy: 0.7863\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0930 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1089 - accuracy: 0.9698 - val_loss: 1.1576 - val_accuracy: 0.8120\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0635 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0543 - accuracy: 0.9849 - val_loss: 1.3367 - val_accuracy: 0.8205\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0469 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0501 - accuracy: 0.9849 - val_loss: 1.4020 - val_accuracy: 0.8291\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0197 - accuracy: 1.00 - 0s 3ms/step - loss: 0.0333 - accuracy: 0.9914 - val_loss: 1.5816 - val_accuracy: 0.8291\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN58\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                             | 59/169 [06:19<11:30,  6.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_59\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_236 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_237 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_238 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_239 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.8496 - accuracy: 0.37 - 0s 27ms/step - loss: 0.5357 - accuracy: 0.6900 - val_loss: 0.3931 - val_accuracy: 0.7477\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.3062 - accuracy: 0.76 - 0s 4ms/step - loss: 0.3226 - accuracy: 0.7511 - val_loss: 0.3264 - val_accuracy: 0.7477\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2468 - accuracy: 0.75 - 0s 4ms/step - loss: 0.2570 - accuracy: 0.8416 - val_loss: 0.3112 - val_accuracy: 0.8559\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1832 - accuracy: 0.90 - 0s 5ms/step - loss: 0.2360 - accuracy: 0.9095 - val_loss: 0.3368 - val_accuracy: 0.8739\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1770 - accuracy: 0.98 - 0s 4ms/step - loss: 0.2060 - accuracy: 0.9276 - val_loss: 0.3353 - val_accuracy: 0.8739\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1635 - accuracy: 0.93 - 0s 4ms/step - loss: 0.1873 - accuracy: 0.9276 - val_loss: 0.3791 - val_accuracy: 0.8739\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1135 - accuracy: 1.00 - 0s 4ms/step - loss: 0.1530 - accuracy: 0.9525 - val_loss: 0.3456 - val_accuracy: 0.8739\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0683 - accuracy: 0.98 - 0s 5ms/step - loss: 0.1374 - accuracy: 0.9615 - val_loss: 0.4715 - val_accuracy: 0.8649\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1463 - accuracy: 0.93 - 0s 5ms/step - loss: 0.1234 - accuracy: 0.9615 - val_loss: 0.5255 - val_accuracy: 0.8739\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1310 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1181 - accuracy: 0.9615 - val_loss: 0.5186 - val_accuracy: 0.8649\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1322 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1113 - accuracy: 0.9638 - val_loss: 0.6662 - val_accuracy: 0.8649\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0575 - accuracy: 1.00 - 0s 4ms/step - loss: 0.1086 - accuracy: 0.9661 - val_loss: 0.4272 - val_accuracy: 0.8559\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1097 - accuracy: 0.98 - 0s 5ms/step - loss: 0.1054 - accuracy: 0.9706 - val_loss: 0.5471 - val_accuracy: 0.8739\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0901 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1126 - accuracy: 0.9661 - val_loss: 0.5631 - val_accuracy: 0.8559\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0743 - accuracy: 0.98 - 0s 5ms/step - loss: 0.1046 - accuracy: 0.9661 - val_loss: 0.6760 - val_accuracy: 0.8378\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1607 - accuracy: 0.93 - 0s 5ms/step - loss: 0.1051 - accuracy: 0.9638 - val_loss: 0.6337 - val_accuracy: 0.8468\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1270 - accuracy: 0.95 - 0s 5ms/step - loss: 0.0951 - accuracy: 0.9706 - val_loss: 0.4956 - val_accuracy: 0.8468\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1278 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1033 - accuracy: 0.9683 - val_loss: 0.5442 - val_accuracy: 0.8468\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0360 - accuracy: 1.00 - 0s 5ms/step - loss: 0.1051 - accuracy: 0.9661 - val_loss: 0.7649 - val_accuracy: 0.8468\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1295 - accuracy: 0.95 - 0s 5ms/step - loss: 0.1071 - accuracy: 0.9638 - val_loss: 0.9081 - val_accuracy: 0.8649\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN59\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  36%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                             | 60/169 [06:26<11:35,  6.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_60\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_240 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_241 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_242 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_243 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.8303 - accuracy: 0.37 - 0s 19ms/step - loss: 0.6737 - accuracy: 0.5965 - val_loss: 0.5964 - val_accuracy: 0.6667\n",
      "Epoch 2/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.6538 - accuracy: 0.62 - 0s 4ms/step - loss: 0.4927 - accuracy: 0.7600 - val_loss: 0.5050 - val_accuracy: 0.7847\n",
      "Epoch 3/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.4126 - accuracy: 0.76 - 0s 4ms/step - loss: 0.3739 - accuracy: 0.8383 - val_loss: 0.4706 - val_accuracy: 0.7847\n",
      "Epoch 4/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.3168 - accuracy: 0.85 - 0s 4ms/step - loss: 0.3190 - accuracy: 0.8574 - val_loss: 0.4833 - val_accuracy: 0.7917\n",
      "Epoch 5/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2620 - accuracy: 0.87 - 0s 5ms/step - loss: 0.2687 - accuracy: 0.8783 - val_loss: 0.6036 - val_accuracy: 0.7708\n",
      "Epoch 6/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2052 - accuracy: 0.95 - 0s 5ms/step - loss: 0.2310 - accuracy: 0.9026 - val_loss: 0.7187 - val_accuracy: 0.8056\n",
      "Epoch 7/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1869 - accuracy: 0.89 - 0s 5ms/step - loss: 0.2051 - accuracy: 0.9200 - val_loss: 0.9004 - val_accuracy: 0.7569\n",
      "Epoch 8/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1785 - accuracy: 0.92 - 0s 4ms/step - loss: 0.2336 - accuracy: 0.9078 - val_loss: 0.7973 - val_accuracy: 0.7500\n",
      "Epoch 9/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2318 - accuracy: 0.90 - 0s 5ms/step - loss: 0.1934 - accuracy: 0.9252 - val_loss: 0.7602 - val_accuracy: 0.7431\n",
      "Epoch 10/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1915 - accuracy: 0.90 - 0s 4ms/step - loss: 0.1433 - accuracy: 0.9391 - val_loss: 1.2729 - val_accuracy: 0.7708\n",
      "Epoch 11/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0840 - accuracy: 0.95 - 0s 5ms/step - loss: 0.0964 - accuracy: 0.9530 - val_loss: 1.6705 - val_accuracy: 0.7361\n",
      "Epoch 12/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1089 - accuracy: 0.96 - 0s 5ms/step - loss: 0.1022 - accuracy: 0.9583 - val_loss: 1.5374 - val_accuracy: 0.7569\n",
      "Epoch 13/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0708 - accuracy: 0.98 - 0s 6ms/step - loss: 0.1127 - accuracy: 0.9409 - val_loss: 2.1129 - val_accuracy: 0.7153\n",
      "Epoch 14/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.3641 - accuracy: 0.96 - 0s 6ms/step - loss: 0.1995 - accuracy: 0.9391 - val_loss: 1.3741 - val_accuracy: 0.7361\n",
      "Epoch 15/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1240 - accuracy: 0.95 - 0s 7ms/step - loss: 0.1486 - accuracy: 0.9304 - val_loss: 1.1155 - val_accuracy: 0.7639\n",
      "Epoch 16/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2443 - accuracy: 0.90 - 0s 6ms/step - loss: 0.1502 - accuracy: 0.9374 - val_loss: 0.9095 - val_accuracy: 0.7639\n",
      "Epoch 17/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0960 - accuracy: 0.95 - 0s 5ms/step - loss: 0.0995 - accuracy: 0.9530 - val_loss: 1.3811 - val_accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0516 - accuracy: 0.98 - 0s 5ms/step - loss: 0.1000 - accuracy: 0.9583 - val_loss: 1.8079 - val_accuracy: 0.7292\n",
      "Epoch 19/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0797 - accuracy: 0.96 - 0s 6ms/step - loss: 0.1079 - accuracy: 0.9478 - val_loss: 1.6146 - val_accuracy: 0.7500\n",
      "Epoch 20/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1526 - accuracy: 0.92 - 0s 5ms/step - loss: 0.1013 - accuracy: 0.9548 - val_loss: 1.3317 - val_accuracy: 0.7431\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN60\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  36%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                            | 61/169 [06:33<12:05,  6.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_61\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_244 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_245 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_246 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_247 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.6772 - accuracy: 0.53 - 0s 18ms/step - loss: 0.5885 - accuracy: 0.6931 - val_loss: 0.4869 - val_accuracy: 0.7842\n",
      "Epoch 2/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.4681 - accuracy: 0.76 - 0s 4ms/step - loss: 0.4741 - accuracy: 0.7581 - val_loss: 0.4805 - val_accuracy: 0.7770\n",
      "Epoch 3/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.3414 - accuracy: 0.81 - 0s 4ms/step - loss: 0.4173 - accuracy: 0.7870 - val_loss: 0.4930 - val_accuracy: 0.7842\n",
      "Epoch 4/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.4472 - accuracy: 0.79 - 0s 4ms/step - loss: 0.4001 - accuracy: 0.7996 - val_loss: 0.5032 - val_accuracy: 0.7770\n",
      "Epoch 5/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.3792 - accuracy: 0.79 - 0s 4ms/step - loss: 0.3690 - accuracy: 0.8231 - val_loss: 0.5288 - val_accuracy: 0.7842\n",
      "Epoch 6/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.3112 - accuracy: 0.84 - 0s 4ms/step - loss: 0.3463 - accuracy: 0.8249 - val_loss: 0.5636 - val_accuracy: 0.8129\n",
      "Epoch 7/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2717 - accuracy: 0.84 - 0s 5ms/step - loss: 0.3176 - accuracy: 0.8339 - val_loss: 0.6159 - val_accuracy: 0.8058\n",
      "Epoch 8/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.4184 - accuracy: 0.75 - 0s 4ms/step - loss: 0.2883 - accuracy: 0.8538 - val_loss: 0.6223 - val_accuracy: 0.7698\n",
      "Epoch 9/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2172 - accuracy: 0.89 - 0s 4ms/step - loss: 0.2936 - accuracy: 0.8755 - val_loss: 0.6839 - val_accuracy: 0.7842\n",
      "Epoch 10/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1809 - accuracy: 0.92 - 0s 4ms/step - loss: 0.2354 - accuracy: 0.8736 - val_loss: 0.7603 - val_accuracy: 0.7338\n",
      "Epoch 11/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1952 - accuracy: 0.90 - 0s 4ms/step - loss: 0.2698 - accuracy: 0.8791 - val_loss: 0.8152 - val_accuracy: 0.7266\n",
      "Epoch 12/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2233 - accuracy: 0.90 - 0s 4ms/step - loss: 0.2705 - accuracy: 0.8736 - val_loss: 0.5842 - val_accuracy: 0.7842\n",
      "Epoch 13/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2715 - accuracy: 0.85 - 0s 3ms/step - loss: 0.2337 - accuracy: 0.8899 - val_loss: 0.7676 - val_accuracy: 0.7266\n",
      "Epoch 14/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2095 - accuracy: 0.92 - 0s 4ms/step - loss: 0.1831 - accuracy: 0.9188 - val_loss: 0.8931 - val_accuracy: 0.7338\n",
      "Epoch 15/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1867 - accuracy: 0.90 - 0s 4ms/step - loss: 0.1813 - accuracy: 0.9061 - val_loss: 1.0325 - val_accuracy: 0.7626\n",
      "Epoch 16/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2559 - accuracy: 0.89 - 0s 4ms/step - loss: 0.2103 - accuracy: 0.9025 - val_loss: 1.1687 - val_accuracy: 0.7770\n",
      "Epoch 17/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1132 - accuracy: 0.93 - 0s 4ms/step - loss: 0.2785 - accuracy: 0.8791 - val_loss: 1.0847 - val_accuracy: 0.7554\n",
      "Epoch 18/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.4311 - accuracy: 0.87 - 0s 4ms/step - loss: 0.2574 - accuracy: 0.8845 - val_loss: 0.9147 - val_accuracy: 0.7266\n",
      "Epoch 19/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2234 - accuracy: 0.89 - 0s 4ms/step - loss: 0.2104 - accuracy: 0.9043 - val_loss: 1.0085 - val_accuracy: 0.7338\n",
      "Epoch 20/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1587 - accuracy: 0.89 - 0s 4ms/step - loss: 0.1653 - accuracy: 0.9260 - val_loss: 1.1342 - val_accuracy: 0.7410\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN61\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  37%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                            | 62/169 [06:40<12:05,  6.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_62\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_248 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_249 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_250 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_251 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.7380 - accuracy: 0.59 - 0s 18ms/step - loss: 0.6380 - accuracy: 0.6291 - val_loss: 0.5302 - val_accuracy: 0.6336\n",
      "Epoch 2/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.4716 - accuracy: 0.71 - 0s 4ms/step - loss: 0.4850 - accuracy: 0.7725 - val_loss: 0.4273 - val_accuracy: 0.8550\n",
      "Epoch 3/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.3805 - accuracy: 0.87 - 0s 4ms/step - loss: 0.4053 - accuracy: 0.8203 - val_loss: 0.4619 - val_accuracy: 0.8855\n",
      "Epoch 4/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.3892 - accuracy: 0.85 - 0s 4ms/step - loss: 0.3529 - accuracy: 0.8432 - val_loss: 0.3968 - val_accuracy: 0.8931\n",
      "Epoch 5/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.3221 - accuracy: 0.87 - 0s 4ms/step - loss: 0.3060 - accuracy: 0.8681 - val_loss: 0.5121 - val_accuracy: 0.8855\n",
      "Epoch 6/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1691 - accuracy: 0.95 - 0s 4ms/step - loss: 0.2970 - accuracy: 0.8987 - val_loss: 0.3871 - val_accuracy: 0.8626\n",
      "Epoch 7/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2373 - accuracy: 0.93 - 0s 4ms/step - loss: 0.3187 - accuracy: 0.8642 - val_loss: 0.6529 - val_accuracy: 0.8550\n",
      "Epoch 8/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2472 - accuracy: 0.90 - 0s 4ms/step - loss: 0.2970 - accuracy: 0.8910 - val_loss: 0.4236 - val_accuracy: 0.8702\n",
      "Epoch 9/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2945 - accuracy: 0.87 - 0s 4ms/step - loss: 0.2683 - accuracy: 0.8948 - val_loss: 0.6602 - val_accuracy: 0.8779\n",
      "Epoch 10/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1783 - accuracy: 0.95 - 0s 4ms/step - loss: 0.2594 - accuracy: 0.8967 - val_loss: 0.6498 - val_accuracy: 0.8321\n",
      "Epoch 11/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1867 - accuracy: 0.92 - 0s 4ms/step - loss: 0.2612 - accuracy: 0.8987 - val_loss: 0.9050 - val_accuracy: 0.8626\n",
      "Epoch 12/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.3248 - accuracy: 0.87 - 0s 5ms/step - loss: 0.2281 - accuracy: 0.9101 - val_loss: 0.6576 - val_accuracy: 0.8626\n",
      "Epoch 13/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1718 - accuracy: 0.93 - 0s 5ms/step - loss: 0.2659 - accuracy: 0.8872 - val_loss: 0.6524 - val_accuracy: 0.8550\n",
      "Epoch 14/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2803 - accuracy: 0.90 - 0s 4ms/step - loss: 0.2530 - accuracy: 0.8967 - val_loss: 0.7331 - val_accuracy: 0.8244\n",
      "Epoch 15/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1580 - accuracy: 0.96 - 0s 4ms/step - loss: 0.2231 - accuracy: 0.9235 - val_loss: 0.7274 - val_accuracy: 0.8397\n",
      "Epoch 16/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2302 - accuracy: 0.92 - 0s 4ms/step - loss: 0.1996 - accuracy: 0.9312 - val_loss: 0.7934 - val_accuracy: 0.8321\n",
      "Epoch 17/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1433 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1827 - accuracy: 0.9369 - val_loss: 0.9764 - val_accuracy: 0.8397\n",
      "Epoch 18/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1476 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1797 - accuracy: 0.9407 - val_loss: 1.1320 - val_accuracy: 0.8397\n",
      "Epoch 19/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1860 - accuracy: 0.93 - 0s 4ms/step - loss: 0.1892 - accuracy: 0.9312 - val_loss: 1.0943 - val_accuracy: 0.8473\n",
      "Epoch 20/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1190 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1717 - accuracy: 0.9426 - val_loss: 1.0698 - val_accuracy: 0.8321\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN62\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  37%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                            | 63/169 [06:47<12:02,  6.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_63\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_252 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_253 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_254 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_255 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.6806 - accuracy: 0.60 - 0s 17ms/step - loss: 0.5703 - accuracy: 0.6358 - val_loss: 0.5332 - val_accuracy: 0.7462\n",
      "Epoch 2/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.3369 - accuracy: 0.85 - 0s 4ms/step - loss: 0.4297 - accuracy: 0.8266 - val_loss: 0.6052 - val_accuracy: 0.7308\n",
      "Epoch 3/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.3613 - accuracy: 0.89 - 0s 4ms/step - loss: 0.3617 - accuracy: 0.8709 - val_loss: 0.4519 - val_accuracy: 0.8385\n",
      "Epoch 4/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2710 - accuracy: 0.92 - 0s 4ms/step - loss: 0.3237 - accuracy: 0.8728 - val_loss: 0.5115 - val_accuracy: 0.7846\n",
      "Epoch 5/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2440 - accuracy: 0.92 - 0s 4ms/step - loss: 0.2854 - accuracy: 0.8960 - val_loss: 0.4351 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2692 - accuracy: 0.90 - 0s 4ms/step - loss: 0.2440 - accuracy: 0.9114 - val_loss: 0.4306 - val_accuracy: 0.8077\n",
      "Epoch 7/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2058 - accuracy: 0.93 - 0s 4ms/step - loss: 0.2136 - accuracy: 0.9210 - val_loss: 0.4295 - val_accuracy: 0.8000\n",
      "Epoch 8/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2276 - accuracy: 0.90 - 0s 4ms/step - loss: 0.1759 - accuracy: 0.9461 - val_loss: 0.5651 - val_accuracy: 0.8231\n",
      "Epoch 9/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2071 - accuracy: 0.92 - 0s 4ms/step - loss: 0.1861 - accuracy: 0.9403 - val_loss: 0.5434 - val_accuracy: 0.8077\n",
      "Epoch 10/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1881 - accuracy: 0.92 - 0s 4ms/step - loss: 0.3070 - accuracy: 0.8882 - val_loss: 0.6597 - val_accuracy: 0.7846\n",
      "Epoch 11/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.3470 - accuracy: 0.85 - 0s 4ms/step - loss: 0.2676 - accuracy: 0.8979 - val_loss: 0.5250 - val_accuracy: 0.8077\n",
      "Epoch 12/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1591 - accuracy: 0.95 - 0s 4ms/step - loss: 0.2355 - accuracy: 0.9152 - val_loss: 0.4429 - val_accuracy: 0.8231\n",
      "Epoch 13/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2286 - accuracy: 0.90 - 0s 4ms/step - loss: 0.1850 - accuracy: 0.9287 - val_loss: 0.5814 - val_accuracy: 0.8154\n",
      "Epoch 14/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2326 - accuracy: 0.92 - 0s 4ms/step - loss: 0.2375 - accuracy: 0.9075 - val_loss: 0.6046 - val_accuracy: 0.8000\n",
      "Epoch 15/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1505 - accuracy: 0.95 - 0s 4ms/step - loss: 0.2382 - accuracy: 0.9210 - val_loss: 0.5022 - val_accuracy: 0.8462\n",
      "Epoch 16/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1782 - accuracy: 0.93 - 0s 4ms/step - loss: 0.1885 - accuracy: 0.9364 - val_loss: 0.4619 - val_accuracy: 0.8154\n",
      "Epoch 17/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2393 - accuracy: 0.93 - 0s 4ms/step - loss: 0.1693 - accuracy: 0.9480 - val_loss: 0.5337 - val_accuracy: 0.8077\n",
      "Epoch 18/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1565 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1450 - accuracy: 0.9557 - val_loss: 0.5590 - val_accuracy: 0.8231\n",
      "Epoch 19/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1911 - accuracy: 0.92 - 0s 4ms/step - loss: 0.1417 - accuracy: 0.9538 - val_loss: 0.6678 - val_accuracy: 0.8154\n",
      "Epoch 20/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1714 - accuracy: 0.93 - 0s 4ms/step - loss: 0.1263 - accuracy: 0.9595 - val_loss: 0.6727 - val_accuracy: 0.8000\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN63\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                           | 64/169 [06:54<11:59,  6.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_64\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_256 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_257 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_258 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_259 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.9125 - accuracy: 0.40 - 0s 23ms/step - loss: 0.6923 - accuracy: 0.6980 - val_loss: 0.6179 - val_accuracy: 0.7478\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.6055 - accuracy: 0.78 - 0s 5ms/step - loss: 0.6035 - accuracy: 0.7440 - val_loss: 0.5790 - val_accuracy: 0.7478\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.5664 - accuracy: 0.76 - 0s 5ms/step - loss: 0.5751 - accuracy: 0.7440 - val_loss: 0.5663 - val_accuracy: 0.7478\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.5342 - accuracy: 0.78 - 0s 5ms/step - loss: 0.5696 - accuracy: 0.7440 - val_loss: 0.5648 - val_accuracy: 0.7478\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.6322 - accuracy: 0.68 - 0s 5ms/step - loss: 0.5694 - accuracy: 0.7440 - val_loss: 0.5654 - val_accuracy: 0.7478\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.5813 - accuracy: 0.73 - 0s 5ms/step - loss: 0.5700 - accuracy: 0.7440 - val_loss: 0.5652 - val_accuracy: 0.7478\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.6168 - accuracy: 0.70 - 0s 4ms/step - loss: 0.5696 - accuracy: 0.7440 - val_loss: 0.5650 - val_accuracy: 0.7478\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.5269 - accuracy: 0.78 - 0s 5ms/step - loss: 0.5690 - accuracy: 0.7440 - val_loss: 0.5647 - val_accuracy: 0.7478\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.5795 - accuracy: 0.73 - 0s 5ms/step - loss: 0.5695 - accuracy: 0.7440 - val_loss: 0.5650 - val_accuracy: 0.7478\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.6275 - accuracy: 0.68 - 0s 5ms/step - loss: 0.5689 - accuracy: 0.7440 - val_loss: 0.5648 - val_accuracy: 0.7478\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.5293 - accuracy: 0.78 - 0s 5ms/step - loss: 0.5698 - accuracy: 0.7440 - val_loss: 0.5648 - val_accuracy: 0.7478\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.4925 - accuracy: 0.81 - 0s 5ms/step - loss: 0.5687 - accuracy: 0.7440 - val_loss: 0.5647 - val_accuracy: 0.7478\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.5960 - accuracy: 0.71 - 0s 4ms/step - loss: 0.5694 - accuracy: 0.7440 - val_loss: 0.5653 - val_accuracy: 0.7478\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.5002 - accuracy: 0.81 - 0s 4ms/step - loss: 0.5693 - accuracy: 0.7440 - val_loss: 0.5653 - val_accuracy: 0.7478\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.5632 - accuracy: 0.75 - 0s 5ms/step - loss: 0.5697 - accuracy: 0.7440 - val_loss: 0.5658 - val_accuracy: 0.7478\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.5943 - accuracy: 0.71 - 0s 5ms/step - loss: 0.5690 - accuracy: 0.7440 - val_loss: 0.5649 - val_accuracy: 0.7478\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.6279 - accuracy: 0.68 - 0s 6ms/step - loss: 0.5683 - accuracy: 0.7440 - val_loss: 0.5648 - val_accuracy: 0.7478\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.5797 - accuracy: 0.73 - 0s 6ms/step - loss: 0.5702 - accuracy: 0.7440 - val_loss: 0.5656 - val_accuracy: 0.7478\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.6000 - accuracy: 0.71 - 0s 6ms/step - loss: 0.5702 - accuracy: 0.7440 - val_loss: 0.5651 - val_accuracy: 0.7478\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.5626 - accuracy: 0.75 - 0s 6ms/step - loss: 0.5695 - accuracy: 0.7440 - val_loss: 0.5649 - val_accuracy: 0.7478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN64\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                           | 65/169 [07:02<12:17,  7.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_65\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_260 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_261 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_262 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_263 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.7137 - accuracy: 0.51 - 0s 49ms/step - loss: 0.5202 - accuracy: 0.7020 - val_loss: 0.4151 - val_accuracy: 0.7734\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.4076 - accuracy: 0.85 - 0s 3ms/step - loss: 0.3359 - accuracy: 0.8471 - val_loss: 0.4117 - val_accuracy: 0.8047\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.3114 - accuracy: 0.82 - 0s 4ms/step - loss: 0.2663 - accuracy: 0.8765 - val_loss: 0.4251 - val_accuracy: 0.8359\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2433 - accuracy: 0.81 - 0s 4ms/step - loss: 0.2164 - accuracy: 0.8902 - val_loss: 0.4310 - val_accuracy: 0.8281\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2020 - accuracy: 0.90 - 0s 4ms/step - loss: 0.1970 - accuracy: 0.9118 - val_loss: 0.4682 - val_accuracy: 0.8359\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1120 - accuracy: 0.93 - 0s 3ms/step - loss: 0.1490 - accuracy: 0.9314 - val_loss: 0.6576 - val_accuracy: 0.8203\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1701 - accuracy: 0.90 - 0s 3ms/step - loss: 0.1556 - accuracy: 0.9275 - val_loss: 0.6541 - val_accuracy: 0.8359\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1314 - accuracy: 0.92 - 0s 4ms/step - loss: 0.1483 - accuracy: 0.9294 - val_loss: 0.6446 - val_accuracy: 0.8438\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1115 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1081 - accuracy: 0.9431 - val_loss: 0.7668 - val_accuracy: 0.8359\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0670 - accuracy: 0.98 - 0s 3ms/step - loss: 0.1272 - accuracy: 0.9490 - val_loss: 0.7607 - val_accuracy: 0.8281\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1870 - accuracy: 0.92 - 0s 3ms/step - loss: 0.1187 - accuracy: 0.9471 - val_loss: 0.9502 - val_accuracy: 0.8125\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0631 - accuracy: 0.98 - 0s 3ms/step - loss: 0.1005 - accuracy: 0.9549 - val_loss: 0.9334 - val_accuracy: 0.8281\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0881 - accuracy: 0.95 - 0s 3ms/step - loss: 0.0778 - accuracy: 0.9627 - val_loss: 1.0431 - val_accuracy: 0.8203\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0682 - accuracy: 0.95 - 0s 4ms/step - loss: 0.0659 - accuracy: 0.9686 - val_loss: 1.4095 - val_accuracy: 0.7969\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0398 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0990 - accuracy: 0.9765 - val_loss: 1.4961 - val_accuracy: 0.8281\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0275 - accuracy: 1.00 - 0s 4ms/step - loss: 0.1152 - accuracy: 0.9490 - val_loss: 0.7918 - val_accuracy: 0.8359\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1069 - accuracy: 0.93 - 0s 3ms/step - loss: 0.0957 - accuracy: 0.9549 - val_loss: 0.8229 - val_accuracy: 0.8359\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1012 - accuracy: 0.95 - 0s 3ms/step - loss: 0.0882 - accuracy: 0.9549 - val_loss: 1.0407 - val_accuracy: 0.8438\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0466 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0518 - accuracy: 0.9804 - val_loss: 1.2766 - val_accuracy: 0.8438\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0385 - accuracy: 0.98 - 0s 3ms/step - loss: 0.0383 - accuracy: 0.9922 - val_loss: 1.7835 - val_accuracy: 0.8281\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN65\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  39%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                          | 66/169 [07:09<12:01,  7.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_66\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_264 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_265 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_266 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_267 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 1.1112 - accuracy: 0.31 - 0s 21ms/step - loss: 0.6869 - accuracy: 0.6362 - val_loss: 0.4900 - val_accuracy: 0.7000\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.5423 - accuracy: 0.64 - 0s 4ms/step - loss: 0.4501 - accuracy: 0.7002 - val_loss: 0.3743 - val_accuracy: 0.7000\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.4381 - accuracy: 0.67 - 0s 4ms/step - loss: 0.3520 - accuracy: 0.7002 - val_loss: 0.3258 - val_accuracy: 0.7000\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.3029 - accuracy: 0.73 - 0s 4ms/step - loss: 0.3026 - accuracy: 0.8261 - val_loss: 0.2938 - val_accuracy: 0.9000\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2922 - accuracy: 0.95 - 0s 4ms/step - loss: 0.2677 - accuracy: 0.8993 - val_loss: 0.2326 - val_accuracy: 0.9091\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2334 - accuracy: 0.89 - 0s 4ms/step - loss: 0.2332 - accuracy: 0.8993 - val_loss: 0.2004 - val_accuracy: 0.9182\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2289 - accuracy: 0.87 - 0s 4ms/step - loss: 0.2223 - accuracy: 0.9016 - val_loss: 0.2150 - val_accuracy: 0.8909\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1737 - accuracy: 0.89 - 0s 4ms/step - loss: 0.1967 - accuracy: 0.9153 - val_loss: 0.1610 - val_accuracy: 0.9273\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1042 - accuracy: 0.96 - 0s 4ms/step - loss: 0.2103 - accuracy: 0.9085 - val_loss: 0.1878 - val_accuracy: 0.9091\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1917 - accuracy: 0.90 - 0s 5ms/step - loss: 0.1917 - accuracy: 0.9176 - val_loss: 0.1934 - val_accuracy: 0.9091\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1676 - accuracy: 0.90 - 0s 4ms/step - loss: 0.1740 - accuracy: 0.9153 - val_loss: 0.2160 - val_accuracy: 0.9091\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1369 - accuracy: 0.93 - 0s 4ms/step - loss: 0.1419 - accuracy: 0.9382 - val_loss: 0.1458 - val_accuracy: 0.9273\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1445 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1109 - accuracy: 0.9611 - val_loss: 0.1673 - val_accuracy: 0.9091\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0840 - accuracy: 0.96 - 0s 4ms/step - loss: 0.0816 - accuracy: 0.9611 - val_loss: 0.1780 - val_accuracy: 0.9182\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0979 - accuracy: 0.95 - 0s 4ms/step - loss: 0.0549 - accuracy: 0.9725 - val_loss: 0.1777 - val_accuracy: 0.9364\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0491 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0527 - accuracy: 0.9771 - val_loss: 0.3751 - val_accuracy: 0.9000\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0534 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0575 - accuracy: 0.9725 - val_loss: 0.3223 - val_accuracy: 0.9091\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0355 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0654 - accuracy: 0.9748 - val_loss: 0.3049 - val_accuracy: 0.9182\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0238 - accuracy: 0.98 - 0s 5ms/step - loss: 0.0639 - accuracy: 0.9725 - val_loss: 0.2785 - val_accuracy: 0.8909\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0287 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0633 - accuracy: 0.9703 - val_loss: 0.2692 - val_accuracy: 0.8909\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN66\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                          | 67/169 [07:15<11:24,  6.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_67\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_268 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_269 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_270 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_271 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.8322 - accuracy: 0.39 - 0s 15ms/step - loss: 0.6375 - accuracy: 0.6641 - val_loss: 0.4181 - val_accuracy: 0.8106\n",
      "Epoch 2/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.4247 - accuracy: 0.79 - 0s 3ms/step - loss: 0.4294 - accuracy: 0.8130 - val_loss: 0.4544 - val_accuracy: 0.8258\n",
      "Epoch 3/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2126 - accuracy: 0.92 - 0s 3ms/step - loss: 0.3369 - accuracy: 0.8492 - val_loss: 0.4316 - val_accuracy: 0.8485\n",
      "Epoch 4/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2990 - accuracy: 0.87 - 0s 3ms/step - loss: 0.2971 - accuracy: 0.8721 - val_loss: 0.4704 - val_accuracy: 0.8561\n",
      "Epoch 5/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2682 - accuracy: 0.89 - 0s 3ms/step - loss: 0.2428 - accuracy: 0.8969 - val_loss: 0.4532 - val_accuracy: 0.8485\n",
      "Epoch 6/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1271 - accuracy: 0.95 - 0s 3ms/step - loss: 0.2253 - accuracy: 0.8950 - val_loss: 0.4992 - val_accuracy: 0.8258\n",
      "Epoch 7/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1535 - accuracy: 0.90 - 0s 3ms/step - loss: 0.2172 - accuracy: 0.9084 - val_loss: 0.5580 - val_accuracy: 0.8712\n",
      "Epoch 8/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1442 - accuracy: 0.95 - 0s 3ms/step - loss: 0.1647 - accuracy: 0.9332 - val_loss: 0.6718 - val_accuracy: 0.8409\n",
      "Epoch 9/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1319 - accuracy: 0.93 - 0s 4ms/step - loss: 0.1604 - accuracy: 0.9389 - val_loss: 0.6533 - val_accuracy: 0.8333\n",
      "Epoch 10/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1114 - accuracy: 0.93 - 0s 3ms/step - loss: 0.1241 - accuracy: 0.9504 - val_loss: 0.7177 - val_accuracy: 0.8636\n",
      "Epoch 11/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1544 - accuracy: 0.93 - 0s 3ms/step - loss: 0.1156 - accuracy: 0.9637 - val_loss: 0.7701 - val_accuracy: 0.8182\n",
      "Epoch 12/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1784 - accuracy: 0.92 - 0s 3ms/step - loss: 0.2410 - accuracy: 0.9218 - val_loss: 0.6132 - val_accuracy: 0.7803\n",
      "Epoch 13/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1374 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1785 - accuracy: 0.9256 - val_loss: 0.5940 - val_accuracy: 0.8485\n",
      "Epoch 14/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1339 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1473 - accuracy: 0.9351 - val_loss: 0.9009 - val_accuracy: 0.8258\n",
      "Epoch 15/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0878 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1507 - accuracy: 0.9313 - val_loss: 0.9717 - val_accuracy: 0.8864\n",
      "Epoch 16/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1170 - accuracy: 0.93 - 0s 4ms/step - loss: 0.1305 - accuracy: 0.9389 - val_loss: 0.9169 - val_accuracy: 0.8636\n",
      "Epoch 17/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1763 - accuracy: 0.92 - 0s 4ms/step - loss: 0.1138 - accuracy: 0.9542 - val_loss: 0.9596 - val_accuracy: 0.8485\n",
      "Epoch 18/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0932 - accuracy: 0.95 - 0s 5ms/step - loss: 0.0924 - accuracy: 0.9618 - val_loss: 1.2305 - val_accuracy: 0.8258\n",
      "Epoch 19/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0126 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0881 - accuracy: 0.9580 - val_loss: 1.2794 - val_accuracy: 0.8409\n",
      "Epoch 20/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1021 - accuracy: 0.93 - 0s 4ms/step - loss: 0.1177 - accuracy: 0.9408 - val_loss: 1.0400 - val_accuracy: 0.7879\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN67\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                         | 68/169 [07:21<11:08,  6.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_68\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_272 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_273 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_274 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_275 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.7762 - accuracy: 0.42 - 0s 13ms/step - loss: 0.5876 - accuracy: 0.6938 - val_loss: 0.4312 - val_accuracy: 0.7857\n",
      "Epoch 2/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.4415 - accuracy: 0.82 - 0s 3ms/step - loss: 0.4262 - accuracy: 0.8179 - val_loss: 0.4132 - val_accuracy: 0.7857\n",
      "Epoch 3/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.3902 - accuracy: 0.85 - 0s 3ms/step - loss: 0.3774 - accuracy: 0.8317 - val_loss: 0.4136 - val_accuracy: 0.7912\n",
      "Epoch 4/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.3581 - accuracy: 0.79 - 0s 3ms/step - loss: 0.3514 - accuracy: 0.8538 - val_loss: 0.4624 - val_accuracy: 0.8022\n",
      "Epoch 5/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.3807 - accuracy: 0.81 - 0s 3ms/step - loss: 0.3198 - accuracy: 0.8621 - val_loss: 0.4005 - val_accuracy: 0.8242\n",
      "Epoch 6/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.3036 - accuracy: 0.89 - 0s 3ms/step - loss: 0.2888 - accuracy: 0.8731 - val_loss: 0.4605 - val_accuracy: 0.8022\n",
      "Epoch 7/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2611 - accuracy: 0.85 - 0s 3ms/step - loss: 0.2707 - accuracy: 0.8703 - val_loss: 0.5048 - val_accuracy: 0.8077\n",
      "Epoch 8/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.3029 - accuracy: 0.87 - 0s 4ms/step - loss: 0.2467 - accuracy: 0.8897 - val_loss: 0.6285 - val_accuracy: 0.7912\n",
      "Epoch 9/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2112 - accuracy: 0.87 - 0s 3ms/step - loss: 0.2462 - accuracy: 0.9007 - val_loss: 0.5590 - val_accuracy: 0.7967\n",
      "Epoch 10/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.1984 - accuracy: 0.92 - 0s 4ms/step - loss: 0.2813 - accuracy: 0.8717 - val_loss: 0.4879 - val_accuracy: 0.8132\n",
      "Epoch 11/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2447 - accuracy: 0.84 - 0s 4ms/step - loss: 0.2747 - accuracy: 0.8690 - val_loss: 0.5556 - val_accuracy: 0.7857\n",
      "Epoch 12/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2952 - accuracy: 0.82 - 0s 3ms/step - loss: 0.2416 - accuracy: 0.8786 - val_loss: 0.5248 - val_accuracy: 0.8077\n",
      "Epoch 13/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2238 - accuracy: 0.90 - 0s 3ms/step - loss: 0.2374 - accuracy: 0.8814 - val_loss: 0.5439 - val_accuracy: 0.7857\n",
      "Epoch 14/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2157 - accuracy: 0.90 - 0s 4ms/step - loss: 0.2300 - accuracy: 0.8952 - val_loss: 0.6921 - val_accuracy: 0.8022\n",
      "Epoch 15/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.1951 - accuracy: 0.89 - 0s 3ms/step - loss: 0.2105 - accuracy: 0.8979 - val_loss: 0.7282 - val_accuracy: 0.7747\n",
      "Epoch 16/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.1842 - accuracy: 0.92 - 0s 3ms/step - loss: 0.1987 - accuracy: 0.8979 - val_loss: 0.7742 - val_accuracy: 0.7692\n",
      "Epoch 17/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.1470 - accuracy: 0.90 - 0s 3ms/step - loss: 0.2197 - accuracy: 0.8897 - val_loss: 0.6756 - val_accuracy: 0.7582\n",
      "Epoch 18/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.1201 - accuracy: 0.93 - 0s 3ms/step - loss: 0.1643 - accuracy: 0.9103 - val_loss: 0.8448 - val_accuracy: 0.7747\n",
      "Epoch 19/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.1484 - accuracy: 0.90 - 0s 3ms/step - loss: 0.1921 - accuracy: 0.9103 - val_loss: 0.7744 - val_accuracy: 0.7637\n",
      "Epoch 20/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.1721 - accuracy: 0.92 - 0s 3ms/step - loss: 0.1743 - accuracy: 0.9117 - val_loss: 0.6174 - val_accuracy: 0.7253\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN68\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                         | 69/169 [07:28<11:17,  6.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_69\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_276 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_277 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_278 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_279 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.7399 - accuracy: 0.28 - 0s 20ms/step - loss: 0.6319 - accuracy: 0.6598 - val_loss: 0.5537 - val_accuracy: 0.7273\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.6611 - accuracy: 0.62 - 0s 4ms/step - loss: 0.4573 - accuracy: 0.7306 - val_loss: 0.5059 - val_accuracy: 0.7273\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.4493 - accuracy: 0.68 - 0s 4ms/step - loss: 0.3840 - accuracy: 0.7534 - val_loss: 0.5321 - val_accuracy: 0.7727\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1278 - accuracy: 0.95 - 0s 4ms/step - loss: 0.2755 - accuracy: 0.8767 - val_loss: 0.5108 - val_accuracy: 0.8091\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2500 - accuracy: 0.90 - 0s 4ms/step - loss: 0.2276 - accuracy: 0.9041 - val_loss: 0.4885 - val_accuracy: 0.8182\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2260 - accuracy: 0.89 - 0s 4ms/step - loss: 0.1910 - accuracy: 0.9269 - val_loss: 0.6331 - val_accuracy: 0.8000\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1820 - accuracy: 0.92 - 0s 5ms/step - loss: 0.1501 - accuracy: 0.9475 - val_loss: 0.6607 - val_accuracy: 0.8000\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1059 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1261 - accuracy: 0.9498 - val_loss: 0.7437 - val_accuracy: 0.8364\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1038 - accuracy: 0.95 - 0s 5ms/step - loss: 0.0943 - accuracy: 0.9566 - val_loss: 0.8171 - val_accuracy: 0.8091\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0670 - accuracy: 0.96 - 0s 5ms/step - loss: 0.0909 - accuracy: 0.9543 - val_loss: 1.0262 - val_accuracy: 0.8182\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0761 - accuracy: 0.96 - 0s 4ms/step - loss: 0.0890 - accuracy: 0.9612 - val_loss: 1.2612 - val_accuracy: 0.8182\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0287 - accuracy: 1.00 - 0s 5ms/step - loss: 0.1200 - accuracy: 0.9566 - val_loss: 1.4912 - val_accuracy: 0.8091\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1260 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1202 - accuracy: 0.9452 - val_loss: 1.1555 - val_accuracy: 0.8000\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0913 - accuracy: 0.96 - 0s 4ms/step - loss: 0.0773 - accuracy: 0.9703 - val_loss: 0.9746 - val_accuracy: 0.8273\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0641 - accuracy: 0.98 - 0s 6ms/step - loss: 0.0766 - accuracy: 0.9749 - val_loss: 1.3400 - val_accuracy: 0.8091\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0460 - accuracy: 0.96 - 0s 5ms/step - loss: 0.0262 - accuracy: 0.9863 - val_loss: 1.5291 - val_accuracy: 0.7818\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0070 - accuracy: 1.00 - 0s 5ms/step - loss: 0.0488 - accuracy: 0.9795 - val_loss: 1.5254 - val_accuracy: 0.8182\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0638 - accuracy: 0.95 - 0s 5ms/step - loss: 0.0509 - accuracy: 0.9772 - val_loss: 1.6871 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0045 - accuracy: 1.00 - 0s 5ms/step - loss: 0.0615 - accuracy: 0.9840 - val_loss: 2.0757 - val_accuracy: 0.7545\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0278 - accuracy: 0.98 - 0s 6ms/step - loss: 0.0623 - accuracy: 0.9840 - val_loss: 1.8740 - val_accuracy: 0.7909\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN69\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                         | 70/169 [07:35<11:13,  6.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_70\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_280 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_281 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_282 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_283 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 0.6607 - accuracy: 0.8750WARNING:tensorflow:Callbacks method `on_test_batch_begin` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_begin` time: 0.0010s). Check your callbacks.\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.3406 - accuracy: 0.8910 - val_loss: 0.1200 - val_accuracy: 0.9574\n",
      "Epoch 2/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1402 - accuracy: 0.92 - 0s 5ms/step - loss: 0.1115 - accuracy: 0.9574 - val_loss: 0.1481 - val_accuracy: 0.9468\n",
      "Epoch 3/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.2739 - accuracy: 0.90 - 0s 5ms/step - loss: 0.0941 - accuracy: 0.9707 - val_loss: 0.1098 - val_accuracy: 0.9362\n",
      "Epoch 4/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0392 - accuracy: 1.00 - 0s 5ms/step - loss: 0.0669 - accuracy: 0.9734 - val_loss: 0.1222 - val_accuracy: 0.9362\n",
      "Epoch 5/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0571 - accuracy: 0.96 - 0s 6ms/step - loss: 0.0560 - accuracy: 0.9814 - val_loss: 0.1172 - val_accuracy: 0.9468\n",
      "Epoch 6/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0095 - accuracy: 1.00 - 0s 5ms/step - loss: 0.0414 - accuracy: 0.9894 - val_loss: 0.1300 - val_accuracy: 0.9468\n",
      "Epoch 7/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0583 - accuracy: 0.98 - 0s 5ms/step - loss: 0.0302 - accuracy: 0.9947 - val_loss: 0.2097 - val_accuracy: 0.9468\n",
      "Epoch 8/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0464 - accuracy: 0.98 - 0s 5ms/step - loss: 0.0311 - accuracy: 0.9920 - val_loss: 0.1869 - val_accuracy: 0.9043\n",
      "Epoch 9/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0512 - accuracy: 0.96 - 0s 5ms/step - loss: 0.0221 - accuracy: 0.9894 - val_loss: 0.2840 - val_accuracy: 0.9362\n",
      "Epoch 10/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0086 - accuracy: 1.00 - 0s 5ms/step - loss: 0.0156 - accuracy: 0.9947 - val_loss: 0.3842 - val_accuracy: 0.9468\n",
      "Epoch 11/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0106 - accuracy: 1.00 - 0s 5ms/step - loss: 0.0251 - accuracy: 0.9867 - val_loss: 0.3675 - val_accuracy: 0.9255\n",
      "Epoch 12/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0604 - accuracy: 0.98 - 0s 5ms/step - loss: 0.0280 - accuracy: 0.9840 - val_loss: 0.4729 - val_accuracy: 0.9043\n",
      "Epoch 13/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0121 - accuracy: 1.00 - 0s 5ms/step - loss: 0.0325 - accuracy: 0.9867 - val_loss: 0.3381 - val_accuracy: 0.9468\n",
      "Epoch 14/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0184 - accuracy: 0.98 - 0s 5ms/step - loss: 0.0480 - accuracy: 0.9840 - val_loss: 0.2848 - val_accuracy: 0.9255\n",
      "Epoch 15/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0310 - accuracy: 0.98 - 0s 5ms/step - loss: 0.0162 - accuracy: 0.9920 - val_loss: 0.2817 - val_accuracy: 0.9149\n",
      "Epoch 16/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0170 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0058 - accuracy: 0.9973 - val_loss: 0.3259 - val_accuracy: 0.9255\n",
      "Epoch 17/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 1.00 - 0s 5ms/step - loss: 0.0060 - accuracy: 0.9973 - val_loss: 0.3622 - val_accuracy: 0.9255\n",
      "Epoch 18/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0059 - accuracy: 0.9947 - val_loss: 0.4098 - val_accuracy: 0.9255\n",
      "Epoch 19/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 1.00 - 0s 5ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4749 - val_accuracy: 0.9149\n",
      "Epoch 20/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 1.00 - 0s 5ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.5371 - val_accuracy: 0.9043\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN70\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                        | 71/169 [07:42<10:59,  6.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_71\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_284 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_285 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_286 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_287 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.6319 - accuracy: 0.62 - 0s 20ms/step - loss: 0.3191 - accuracy: 0.8305 - val_loss: 0.1390 - val_accuracy: 0.8846\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1141 - accuracy: 0.90 - 0s 4ms/step - loss: 0.1407 - accuracy: 0.8959 - val_loss: 0.1038 - val_accuracy: 0.9808\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1226 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1108 - accuracy: 0.9588 - val_loss: 0.1136 - val_accuracy: 0.9423\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0722 - accuracy: 0.96 - 0s 5ms/step - loss: 0.0866 - accuracy: 0.9637 - val_loss: 0.0704 - val_accuracy: 1.0000\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0652 - accuracy: 0.96 - 0s 5ms/step - loss: 0.0797 - accuracy: 0.9661 - val_loss: 0.0832 - val_accuracy: 0.9615\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0158 - accuracy: 1.00 - 0s 5ms/step - loss: 0.0525 - accuracy: 0.9855 - val_loss: 0.1068 - val_accuracy: 0.9327\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0465 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0489 - accuracy: 0.9855 - val_loss: 0.1286 - val_accuracy: 0.9327\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0413 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0441 - accuracy: 0.9831 - val_loss: 0.1311 - val_accuracy: 0.9519\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0324 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0340 - accuracy: 0.9855 - val_loss: 0.1451 - val_accuracy: 0.9423\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0057 - accuracy: 1.00 - 0s 5ms/step - loss: 0.0321 - accuracy: 0.9855 - val_loss: 0.1244 - val_accuracy: 0.9615\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0070 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0346 - accuracy: 0.9831 - val_loss: 0.1337 - val_accuracy: 0.9519\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0180 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0282 - accuracy: 0.9855 - val_loss: 0.1414 - val_accuracy: 0.9519\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0234 - accuracy: 1.00 - 0s 5ms/step - loss: 0.0226 - accuracy: 0.9903 - val_loss: 0.1117 - val_accuracy: 0.9615\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0070 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0257 - accuracy: 0.9855 - val_loss: 0.1239 - val_accuracy: 0.9615\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0061 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0182 - accuracy: 0.9903 - val_loss: 0.1358 - val_accuracy: 0.9519\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0114 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0157 - accuracy: 0.9927 - val_loss: 0.1713 - val_accuracy: 0.9519\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0292 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0123 - accuracy: 0.9927 - val_loss: 0.2406 - val_accuracy: 0.9519\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0127 - accuracy: 0.9927 - val_loss: 0.2305 - val_accuracy: 0.9615\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0124 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0315 - accuracy: 0.9855 - val_loss: 0.6909 - val_accuracy: 0.9038\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0059 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0684 - accuracy: 0.9831 - val_loss: 0.1808 - val_accuracy: 0.9615\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN71\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                        | 72/169 [07:48<10:52,  6.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_72\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_288 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_289 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_290 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_291 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.7055 - accuracy: 0.53 - 0s 21ms/step - loss: 0.4375 - accuracy: 0.7485 - val_loss: 0.2757 - val_accuracy: 0.9187\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.3164 - accuracy: 0.96 - 0s 3ms/step - loss: 0.2382 - accuracy: 0.9530 - val_loss: 0.4249 - val_accuracy: 0.9431\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1306 - accuracy: 1.00 - 0s 4ms/step - loss: 0.1921 - accuracy: 0.9571 - val_loss: 0.5156 - val_accuracy: 0.9431\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2053 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1615 - accuracy: 0.9611 - val_loss: 0.4327 - val_accuracy: 0.9350\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1225 - accuracy: 0.98 - 0s 4ms/step - loss: 0.1421 - accuracy: 0.9611 - val_loss: 0.5311 - val_accuracy: 0.9268\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1427 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1280 - accuracy: 0.9652 - val_loss: 0.6509 - val_accuracy: 0.9268\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1258 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1348 - accuracy: 0.9652 - val_loss: 0.6487 - val_accuracy: 0.9268\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0554 - accuracy: 1.00 - 0s 4ms/step - loss: 0.1228 - accuracy: 0.9632 - val_loss: 0.5339 - val_accuracy: 0.9350\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1097 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1340 - accuracy: 0.9571 - val_loss: 0.5300 - val_accuracy: 0.9350\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1413 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1335 - accuracy: 0.9571 - val_loss: 0.6706 - val_accuracy: 0.9350\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1319 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1272 - accuracy: 0.9591 - val_loss: 0.8693 - val_accuracy: 0.9512\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0902 - accuracy: 0.98 - 0s 4ms/step - loss: 0.1420 - accuracy: 0.9673 - val_loss: 0.5553 - val_accuracy: 0.9512\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0670 - accuracy: 0.98 - 0s 4ms/step - loss: 0.1224 - accuracy: 0.9611 - val_loss: 0.3657 - val_accuracy: 0.9350\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1084 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1178 - accuracy: 0.9632 - val_loss: 0.4642 - val_accuracy: 0.9431\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1064 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1154 - accuracy: 0.9652 - val_loss: 0.5486 - val_accuracy: 0.9431\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1408 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1151 - accuracy: 0.9652 - val_loss: 0.5988 - val_accuracy: 0.9512\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1344 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1150 - accuracy: 0.9652 - val_loss: 0.6222 - val_accuracy: 0.9512\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0752 - accuracy: 0.98 - 0s 5ms/step - loss: 0.1150 - accuracy: 0.9652 - val_loss: 0.6325 - val_accuracy: 0.9512\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2035 - accuracy: 0.92 - 0s 4ms/step - loss: 0.1150 - accuracy: 0.9652 - val_loss: 0.6377 - val_accuracy: 0.9512\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0699 - accuracy: 0.98 - 0s 4ms/step - loss: 0.1149 - accuracy: 0.9652 - val_loss: 0.6398 - val_accuracy: 0.9512\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN72\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                       | 73/169 [07:55<10:42,  6.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_73\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_292 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_293 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_294 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_295 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.4117 - accuracy: 0.85 - 0s 23ms/step - loss: 0.2541 - accuracy: 0.8668 - val_loss: 0.1979 - val_accuracy: 0.8646\n",
      "Epoch 2/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1367 - accuracy: 0.89 - 0s 4ms/step - loss: 0.1553 - accuracy: 0.9164 - val_loss: 0.2142 - val_accuracy: 0.9375\n",
      "Epoch 3/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1557 - accuracy: 0.92 - 0s 4ms/step - loss: 0.1347 - accuracy: 0.9399 - val_loss: 0.2363 - val_accuracy: 0.9479\n",
      "Epoch 4/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1644 - accuracy: 0.92 - 0s 4ms/step - loss: 0.1044 - accuracy: 0.9530 - val_loss: 0.2984 - val_accuracy: 0.9167\n",
      "Epoch 5/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0709 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1111 - accuracy: 0.9530 - val_loss: 0.2753 - val_accuracy: 0.9583\n",
      "Epoch 6/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0500 - accuracy: 0.98 - 0s 5ms/step - loss: 0.0865 - accuracy: 0.9634 - val_loss: 0.2741 - val_accuracy: 0.9271\n",
      "Epoch 7/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0465 - accuracy: 0.98 - 0s 5ms/step - loss: 0.0874 - accuracy: 0.9608 - val_loss: 0.2746 - val_accuracy: 0.9375\n",
      "Epoch 8/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0825 - accuracy: 0.96 - 0s 5ms/step - loss: 0.0678 - accuracy: 0.9713 - val_loss: 0.2237 - val_accuracy: 0.9375\n",
      "Epoch 9/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0512 - accuracy: 0.98 - 0s 6ms/step - loss: 0.0580 - accuracy: 0.9739 - val_loss: 0.2270 - val_accuracy: 0.9479\n",
      "Epoch 10/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0606 - accuracy: 0.95 - 0s 5ms/step - loss: 0.0475 - accuracy: 0.9791 - val_loss: 0.2683 - val_accuracy: 0.9479\n",
      "Epoch 11/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0365 - accuracy: 1.00 - 0s 6ms/step - loss: 0.0332 - accuracy: 0.9817 - val_loss: 0.3121 - val_accuracy: 0.9479\n",
      "Epoch 12/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0370 - accuracy: 0.98 - 0s 5ms/step - loss: 0.0349 - accuracy: 0.9791 - val_loss: 0.3442 - val_accuracy: 0.9583\n",
      "Epoch 13/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0475 - accuracy: 0.96 - 0s 5ms/step - loss: 0.0276 - accuracy: 0.9817 - val_loss: 0.4093 - val_accuracy: 0.9583\n",
      "Epoch 14/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0357 - accuracy: 0.98 - 0s 5ms/step - loss: 0.0253 - accuracy: 0.9817 - val_loss: 0.4271 - val_accuracy: 0.9583\n",
      "Epoch 15/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0494 - accuracy: 0.95 - 0s 5ms/step - loss: 0.0228 - accuracy: 0.9765 - val_loss: 0.4137 - val_accuracy: 0.9271\n",
      "Epoch 16/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0130 - accuracy: 1.00 - 0s 6ms/step - loss: 0.0234 - accuracy: 0.9843 - val_loss: 0.4780 - val_accuracy: 0.9479\n",
      "Epoch 17/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 2.2789e-04 - accuracy: 1.00 - 0s 5ms/step - loss: 0.0262 - accuracy: 0.9896 - val_loss: 0.4383 - val_accuracy: 0.9271\n",
      "Epoch 18/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0161 - accuracy: 1.00 - 0s 5ms/step - loss: 0.0247 - accuracy: 0.9869 - val_loss: 0.4044 - val_accuracy: 0.9271\n",
      "Epoch 19/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0147 - accuracy: 0.98 - 0s 5ms/step - loss: 0.0233 - accuracy: 0.9896 - val_loss: 0.5109 - val_accuracy: 0.9167\n",
      "Epoch 20/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0270 - accuracy: 0.98 - 0s 5ms/step - loss: 0.0221 - accuracy: 0.9896 - val_loss: 0.5888 - val_accuracy: 0.9375\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN73\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                       | 74/169 [08:02<10:40,  6.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_74\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_296 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_297 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_298 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_299 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.6638 - accuracy: 0.60 - 0s 20ms/step - loss: 0.3833 - accuracy: 0.7830 - val_loss: 0.2367 - val_accuracy: 0.8224\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2084 - accuracy: 0.79 - 0s 4ms/step - loss: 0.2193 - accuracy: 0.8278 - val_loss: 0.2003 - val_accuracy: 0.8224\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1794 - accuracy: 0.84 - 0s 4ms/step - loss: 0.1866 - accuracy: 0.8396 - val_loss: 0.2608 - val_accuracy: 0.9159\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2160 - accuracy: 0.89 - 0s 4ms/step - loss: 0.1797 - accuracy: 0.9269 - val_loss: 0.2161 - val_accuracy: 0.9159\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1392 - accuracy: 0.93 - 0s 4ms/step - loss: 0.1610 - accuracy: 0.9316 - val_loss: 0.2124 - val_accuracy: 0.9159\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1751 - accuracy: 0.90 - 0s 4ms/step - loss: 0.1583 - accuracy: 0.9245 - val_loss: 0.2073 - val_accuracy: 0.9159\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1779 - accuracy: 0.93 - 0s 4ms/step - loss: 0.1488 - accuracy: 0.9292 - val_loss: 0.1755 - val_accuracy: 0.9065\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1438 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1446 - accuracy: 0.9340 - val_loss: 0.1745 - val_accuracy: 0.9159\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1310 - accuracy: 0.92 - 0s 4ms/step - loss: 0.1415 - accuracy: 0.9340 - val_loss: 0.1762 - val_accuracy: 0.9159\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1228 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1416 - accuracy: 0.9340 - val_loss: 0.1743 - val_accuracy: 0.9159\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1173 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1407 - accuracy: 0.9340 - val_loss: 0.1751 - val_accuracy: 0.9159\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1757 - accuracy: 0.90 - 0s 4ms/step - loss: 0.1408 - accuracy: 0.9340 - val_loss: 0.1764 - val_accuracy: 0.9159\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1817 - accuracy: 0.90 - 0s 4ms/step - loss: 0.1407 - accuracy: 0.9340 - val_loss: 0.1781 - val_accuracy: 0.9065\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1107 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1407 - accuracy: 0.9340 - val_loss: 0.1795 - val_accuracy: 0.9065\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1620 - accuracy: 0.90 - 0s 5ms/step - loss: 0.1407 - accuracy: 0.9340 - val_loss: 0.1805 - val_accuracy: 0.9065\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1110 - accuracy: 0.93 - 0s 5ms/step - loss: 0.1407 - accuracy: 0.9340 - val_loss: 0.1812 - val_accuracy: 0.9065\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2067 - accuracy: 0.89 - 0s 5ms/step - loss: 0.1408 - accuracy: 0.9340 - val_loss: 0.1817 - val_accuracy: 0.9065\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1156 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1407 - accuracy: 0.9340 - val_loss: 0.1823 - val_accuracy: 0.9065\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1156 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1406 - accuracy: 0.9340 - val_loss: 0.1829 - val_accuracy: 0.9159\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1612 - accuracy: 0.92 - 0s 4ms/step - loss: 0.1359 - accuracy: 0.9363 - val_loss: 0.1742 - val_accuracy: 0.9065\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN74\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                       | 75/169 [08:08<10:23,  6.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_75\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_300 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_301 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_302 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_303 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.5740 - accuracy: 0.71 - 0s 20ms/step - loss: 0.2945 - accuracy: 0.8678 - val_loss: 0.1764 - val_accuracy: 0.8942\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1402 - accuracy: 0.87 - 0s 4ms/step - loss: 0.1553 - accuracy: 0.9231 - val_loss: 0.2027 - val_accuracy: 0.8750\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1109 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1137 - accuracy: 0.9471 - val_loss: 0.3058 - val_accuracy: 0.8942\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0661 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1022 - accuracy: 0.9519 - val_loss: 0.3577 - val_accuracy: 0.8846\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0841 - accuracy: 0.96 - 0s 4ms/step - loss: 0.0931 - accuracy: 0.9591 - val_loss: 0.3453 - val_accuracy: 0.8750\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0380 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0975 - accuracy: 0.9615 - val_loss: 0.3685 - val_accuracy: 0.8846\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0152 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0670 - accuracy: 0.9784 - val_loss: 0.3403 - val_accuracy: 0.9135\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1125 - accuracy: 0.93 - 0s 4ms/step - loss: 0.0671 - accuracy: 0.9736 - val_loss: 0.3430 - val_accuracy: 0.9231\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0118 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0555 - accuracy: 0.9784 - val_loss: 0.3432 - val_accuracy: 0.9135\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0318 - accuracy: 1.00 - 0s 5ms/step - loss: 0.0488 - accuracy: 0.9808 - val_loss: 0.3613 - val_accuracy: 0.9231\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0557 - accuracy: 0.95 - 0s 4ms/step - loss: 0.0420 - accuracy: 0.9784 - val_loss: 0.3982 - val_accuracy: 0.9135\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0261 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0371 - accuracy: 0.9808 - val_loss: 0.4833 - val_accuracy: 0.9135\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0316 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0298 - accuracy: 0.9856 - val_loss: 0.5678 - val_accuracy: 0.9038\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0188 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0359 - accuracy: 0.9832 - val_loss: 0.6414 - val_accuracy: 0.8942\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0205 - accuracy: 1.00 - 0s 4ms/step - loss: 0.1038 - accuracy: 0.9760 - val_loss: 0.4294 - val_accuracy: 0.9231\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0347 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0510 - accuracy: 0.9712 - val_loss: 0.4360 - val_accuracy: 0.9231\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0341 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0517 - accuracy: 0.9784 - val_loss: 0.4046 - val_accuracy: 0.9231\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0051 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0350 - accuracy: 0.9880 - val_loss: 0.4222 - val_accuracy: 0.9231\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0317 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0266 - accuracy: 0.9904 - val_loss: 0.5490 - val_accuracy: 0.9231\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0354 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0203 - accuracy: 0.9904 - val_loss: 0.5734 - val_accuracy: 0.9231\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN75\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                      | 76/169 [08:14<09:59,  6.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_76\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_304 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_305 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_306 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_307 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.7448 - accuracy: 0.39 - 0s 16ms/step - loss: 0.6345 - accuracy: 0.6975 - val_loss: 0.7102 - val_accuracy: 0.7319\n",
      "Epoch 2/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.4282 - accuracy: 0.90 - 0s 4ms/step - loss: 0.4360 - accuracy: 0.8152 - val_loss: 0.6101 - val_accuracy: 0.6884\n",
      "Epoch 3/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2304 - accuracy: 0.90 - 0s 3ms/step - loss: 0.3714 - accuracy: 0.8315 - val_loss: 0.5417 - val_accuracy: 0.7174\n",
      "Epoch 4/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2710 - accuracy: 0.87 - 0s 4ms/step - loss: 0.3202 - accuracy: 0.8424 - val_loss: 0.7427 - val_accuracy: 0.7246\n",
      "Epoch 5/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2192 - accuracy: 0.89 - 0s 4ms/step - loss: 0.2841 - accuracy: 0.8623 - val_loss: 0.7456 - val_accuracy: 0.7246\n",
      "Epoch 6/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.4036 - accuracy: 0.79 - 0s 4ms/step - loss: 0.2494 - accuracy: 0.8841 - val_loss: 0.6216 - val_accuracy: 0.7246\n",
      "Epoch 7/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2025 - accuracy: 0.90 - 0s 4ms/step - loss: 0.2096 - accuracy: 0.8877 - val_loss: 1.0987 - val_accuracy: 0.7391\n",
      "Epoch 8/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1557 - accuracy: 0.90 - 0s 4ms/step - loss: 0.2110 - accuracy: 0.8859 - val_loss: 0.8579 - val_accuracy: 0.7246\n",
      "Epoch 9/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1635 - accuracy: 0.92 - 0s 4ms/step - loss: 0.1655 - accuracy: 0.9149 - val_loss: 1.0615 - val_accuracy: 0.7464\n",
      "Epoch 10/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1282 - accuracy: 0.90 - 0s 3ms/step - loss: 0.1705 - accuracy: 0.9076 - val_loss: 1.0020 - val_accuracy: 0.7391\n",
      "Epoch 11/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1708 - accuracy: 0.95 - 0s 3ms/step - loss: 0.1774 - accuracy: 0.9275 - val_loss: 1.0713 - val_accuracy: 0.7464\n",
      "Epoch 12/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1409 - accuracy: 0.90 - 0s 3ms/step - loss: 0.1843 - accuracy: 0.9040 - val_loss: 1.1004 - val_accuracy: 0.6957\n",
      "Epoch 13/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2375 - accuracy: 0.82 - 0s 3ms/step - loss: 0.1796 - accuracy: 0.9076 - val_loss: 1.3837 - val_accuracy: 0.7464\n",
      "Epoch 14/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1155 - accuracy: 0.96 - 0s 3ms/step - loss: 0.1279 - accuracy: 0.9257 - val_loss: 1.5347 - val_accuracy: 0.7464\n",
      "Epoch 15/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1384 - accuracy: 0.89 - 0s 3ms/step - loss: 0.1199 - accuracy: 0.9348 - val_loss: 1.6982 - val_accuracy: 0.7536\n",
      "Epoch 16/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0852 - accuracy: 0.93 - 0s 3ms/step - loss: 0.1260 - accuracy: 0.9402 - val_loss: 1.5154 - val_accuracy: 0.7971\n",
      "Epoch 17/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1259 - accuracy: 0.93 - 0s 3ms/step - loss: 0.1337 - accuracy: 0.9420 - val_loss: 1.4151 - val_accuracy: 0.7754\n",
      "Epoch 18/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2006 - accuracy: 0.93 - 0s 4ms/step - loss: 0.1283 - accuracy: 0.9493 - val_loss: 1.5759 - val_accuracy: 0.7536\n",
      "Epoch 19/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0790 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0924 - accuracy: 0.9583 - val_loss: 1.7295 - val_accuracy: 0.7536\n",
      "Epoch 20/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0862 - accuracy: 0.95 - 0s 3ms/step - loss: 0.0826 - accuracy: 0.9638 - val_loss: 2.3755 - val_accuracy: 0.7464\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN76\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                      | 77/169 [08:21<09:51,  6.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_77\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_308 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_309 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_310 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_311 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.7377 - accuracy: 0.3438WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.5531 - accuracy: 0.6745 - val_loss: 0.4026 - val_accuracy: 0.7203\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.4205 - accuracy: 0.70 - 0s 3ms/step - loss: 0.3635 - accuracy: 0.7766 - val_loss: 0.4545 - val_accuracy: 0.7542\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2897 - accuracy: 0.89 - 0s 4ms/step - loss: 0.3121 - accuracy: 0.8319 - val_loss: 0.4084 - val_accuracy: 0.8051\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2876 - accuracy: 0.84 - 0s 4ms/step - loss: 0.2630 - accuracy: 0.8766 - val_loss: 0.3728 - val_accuracy: 0.8644\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2237 - accuracy: 0.89 - 0s 4ms/step - loss: 0.2232 - accuracy: 0.9000 - val_loss: 0.4263 - val_accuracy: 0.8644\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1817 - accuracy: 0.95 - 0s 4ms/step - loss: 0.2163 - accuracy: 0.9043 - val_loss: 0.4238 - val_accuracy: 0.8220\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1512 - accuracy: 0.90 - 0s 4ms/step - loss: 0.1788 - accuracy: 0.9106 - val_loss: 0.4248 - val_accuracy: 0.8644\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1613 - accuracy: 0.93 - 0s 4ms/step - loss: 0.1706 - accuracy: 0.9170 - val_loss: 0.4747 - val_accuracy: 0.8644\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2226 - accuracy: 0.92 - 0s 4ms/step - loss: 0.1371 - accuracy: 0.9255 - val_loss: 0.6473 - val_accuracy: 0.8220\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1230 - accuracy: 0.92 - 0s 4ms/step - loss: 0.1183 - accuracy: 0.9468 - val_loss: 0.7797 - val_accuracy: 0.7712\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1024 - accuracy: 0.93 - 0s 3ms/step - loss: 0.1300 - accuracy: 0.9404 - val_loss: 0.7559 - val_accuracy: 0.8220\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0903 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1442 - accuracy: 0.9468 - val_loss: 0.7238 - val_accuracy: 0.8136\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0598 - accuracy: 1.00 - 0s 4ms/step - loss: 0.1458 - accuracy: 0.9553 - val_loss: 0.7096 - val_accuracy: 0.7966\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1884 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1389 - accuracy: 0.9532 - val_loss: 0.6306 - val_accuracy: 0.8220\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1105 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1115 - accuracy: 0.9532 - val_loss: 0.6332 - val_accuracy: 0.8390\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1288 - accuracy: 0.93 - 0s 4ms/step - loss: 0.0861 - accuracy: 0.9638 - val_loss: 0.6475 - val_accuracy: 0.8390\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1712 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1122 - accuracy: 0.9596 - val_loss: 0.4849 - val_accuracy: 0.7966\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2417 - accuracy: 0.92 - 0s 4ms/step - loss: 0.1544 - accuracy: 0.9404 - val_loss: 0.5726 - val_accuracy: 0.8559\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0859 - accuracy: 0.95 - 0s 4ms/step - loss: 0.0864 - accuracy: 0.9723 - val_loss: 0.4392 - val_accuracy: 0.8559\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0719 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0687 - accuracy: 0.9681 - val_loss: 0.6154 - val_accuracy: 0.8220\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN77\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                     | 78/169 [08:27<09:34,  6.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_78\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_312 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_313 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_314 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_315 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.6698 - accuracy: 0.62 - 0s 24ms/step - loss: 0.5658 - accuracy: 0.6959 - val_loss: 0.4653 - val_accuracy: 0.7009\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.3787 - accuracy: 0.79 - 0s 4ms/step - loss: 0.4262 - accuracy: 0.7216 - val_loss: 0.4706 - val_accuracy: 0.7436\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.3331 - accuracy: 0.82 - 0s 5ms/step - loss: 0.3306 - accuracy: 0.8522 - val_loss: 0.4804 - val_accuracy: 0.7436\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2930 - accuracy: 0.87 - 0s 4ms/step - loss: 0.2642 - accuracy: 0.8865 - val_loss: 0.4602 - val_accuracy: 0.7521\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1564 - accuracy: 0.93 - 0s 4ms/step - loss: 0.2103 - accuracy: 0.9165 - val_loss: 0.4500 - val_accuracy: 0.7863\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1141 - accuracy: 0.93 - 0s 4ms/step - loss: 0.1628 - accuracy: 0.9358 - val_loss: 0.4483 - val_accuracy: 0.7863\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1560 - accuracy: 0.90 - 0s 4ms/step - loss: 0.1223 - accuracy: 0.9507 - val_loss: 0.6197 - val_accuracy: 0.8120\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1618 - accuracy: 0.93 - 0s 5ms/step - loss: 0.1344 - accuracy: 0.9529 - val_loss: 0.5696 - val_accuracy: 0.8120\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0657 - accuracy: 0.98 - 0s 6ms/step - loss: 0.1006 - accuracy: 0.9679 - val_loss: 0.5794 - val_accuracy: 0.8120\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0433 - accuracy: 0.98 - 0s 5ms/step - loss: 0.0596 - accuracy: 0.9807 - val_loss: 0.7561 - val_accuracy: 0.8034\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0171 - accuracy: 1.00 - 0s 5ms/step - loss: 0.0408 - accuracy: 0.9893 - val_loss: 0.8555 - val_accuracy: 0.8291\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0236 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0426 - accuracy: 0.9850 - val_loss: 1.1340 - val_accuracy: 0.7949\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0542 - accuracy: 0.96 - 0s 4ms/step - loss: 0.0601 - accuracy: 0.9829 - val_loss: 1.0607 - val_accuracy: 0.8034\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0057 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0790 - accuracy: 0.9829 - val_loss: 0.7048 - val_accuracy: 0.8376\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0408 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0589 - accuracy: 0.9743 - val_loss: 0.7819 - val_accuracy: 0.8205\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0398 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0604 - accuracy: 0.9764 - val_loss: 0.8704 - val_accuracy: 0.7949\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0413 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0708 - accuracy: 0.9786 - val_loss: 0.7856 - val_accuracy: 0.8291\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0607 - accuracy: 0.96 - 0s 4ms/step - loss: 0.0706 - accuracy: 0.9786 - val_loss: 0.8189 - val_accuracy: 0.8291\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0172 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0369 - accuracy: 0.9893 - val_loss: 0.9866 - val_accuracy: 0.8120\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0074 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0246 - accuracy: 0.9914 - val_loss: 0.9682 - val_accuracy: 0.8120\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN78\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                     | 79/169 [08:33<09:40,  6.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_79\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_316 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_317 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_318 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_319 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.9428 - accuracy: 0.51 - 0s 12ms/step - loss: 0.5383 - accuracy: 0.8125 - val_loss: 0.4201 - val_accuracy: 0.8985\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.4041 - accuracy: 0.92 - 0s 3ms/step - loss: 0.3167 - accuracy: 0.9184 - val_loss: 0.3948 - val_accuracy: 0.9036\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.2444 - accuracy: 0.96 - 0s 3ms/step - loss: 0.2458 - accuracy: 0.9311 - val_loss: 0.4511 - val_accuracy: 0.9036\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1579 - accuracy: 0.96 - 0s 3ms/step - loss: 0.2019 - accuracy: 0.9452 - val_loss: 0.4946 - val_accuracy: 0.8985\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1336 - accuracy: 0.96 - 0s 3ms/step - loss: 0.1964 - accuracy: 0.9413 - val_loss: 0.6152 - val_accuracy: 0.9036\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1401 - accuracy: 0.96 - 0s 3ms/step - loss: 0.2167 - accuracy: 0.9222 - val_loss: 0.4661 - val_accuracy: 0.9036\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1394 - accuracy: 0.93 - 0s 3ms/step - loss: 0.1809 - accuracy: 0.9413 - val_loss: 0.5760 - val_accuracy: 0.9086\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.0873 - accuracy: 0.98 - 0s 3ms/step - loss: 0.1590 - accuracy: 0.9490 - val_loss: 0.6756 - val_accuracy: 0.9086\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.0521 - accuracy: 1.00 - 0s 3ms/step - loss: 0.1417 - accuracy: 0.9566 - val_loss: 0.7449 - val_accuracy: 0.9086\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1324 - accuracy: 0.95 - 0s 3ms/step - loss: 0.1365 - accuracy: 0.9579 - val_loss: 0.7883 - val_accuracy: 0.9036\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1815 - accuracy: 0.92 - 0s 3ms/step - loss: 0.1249 - accuracy: 0.9579 - val_loss: 0.7802 - val_accuracy: 0.9086\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1505 - accuracy: 0.95 - 0s 3ms/step - loss: 0.1197 - accuracy: 0.9630 - val_loss: 0.8648 - val_accuracy: 0.9086\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1035 - accuracy: 0.96 - 0s 3ms/step - loss: 0.1158 - accuracy: 0.9617 - val_loss: 0.9659 - val_accuracy: 0.9036\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.4741 - accuracy: 0.84 - 0s 3ms/step - loss: 0.1746 - accuracy: 0.9541 - val_loss: 0.9381 - val_accuracy: 0.9086\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1201 - accuracy: 0.95 - 0s 3ms/step - loss: 0.1529 - accuracy: 0.9503 - val_loss: 0.5880 - val_accuracy: 0.9086\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.2090 - accuracy: 0.92 - 0s 3ms/step - loss: 0.1323 - accuracy: 0.9541 - val_loss: 0.7476 - val_accuracy: 0.9036\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1041 - accuracy: 0.96 - 0s 3ms/step - loss: 0.1121 - accuracy: 0.9643 - val_loss: 0.8425 - val_accuracy: 0.9137\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1200 - accuracy: 0.95 - 0s 3ms/step - loss: 0.1113 - accuracy: 0.9643 - val_loss: 0.8222 - val_accuracy: 0.9086\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.0920 - accuracy: 0.96 - 0s 3ms/step - loss: 0.1001 - accuracy: 0.9656 - val_loss: 1.0357 - val_accuracy: 0.9036\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1446 - accuracy: 0.93 - 0s 3ms/step - loss: 0.0966 - accuracy: 0.9668 - val_loss: 1.0947 - val_accuracy: 0.9086\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN79\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                    | 80/169 [08:40<09:41,  6.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_80\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_320 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_321 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_322 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_323 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 1.0158 - accuracy: 0.54 - 0s 15ms/step - loss: 0.7349 - accuracy: 0.5351 - val_loss: 0.6852 - val_accuracy: 0.5303\n",
      "Epoch 2/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.6776 - accuracy: 0.59 - 0s 3ms/step - loss: 0.6741 - accuracy: 0.5313 - val_loss: 0.6094 - val_accuracy: 0.5303\n",
      "Epoch 3/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.6034 - accuracy: 0.56 - 0s 3ms/step - loss: 0.5886 - accuracy: 0.5863 - val_loss: 0.5202 - val_accuracy: 0.7576\n",
      "Epoch 4/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.5590 - accuracy: 0.79 - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7799 - val_loss: 0.4810 - val_accuracy: 0.7652\n",
      "Epoch 5/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.4287 - accuracy: 0.84 - 0s 3ms/step - loss: 0.4746 - accuracy: 0.7837 - val_loss: 0.4753 - val_accuracy: 0.7879\n",
      "Epoch 6/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.4150 - accuracy: 0.79 - 0s 3ms/step - loss: 0.4184 - accuracy: 0.8065 - val_loss: 0.4840 - val_accuracy: 0.7803\n",
      "Epoch 7/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.3496 - accuracy: 0.87 - 0s 4ms/step - loss: 0.3994 - accuracy: 0.8254 - val_loss: 0.4991 - val_accuracy: 0.7652\n",
      "Epoch 8/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.4901 - accuracy: 0.79 - 0s 4ms/step - loss: 0.3940 - accuracy: 0.8368 - val_loss: 0.4985 - val_accuracy: 0.7727\n",
      "Epoch 9/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.3173 - accuracy: 0.89 - 0s 4ms/step - loss: 0.3790 - accuracy: 0.8387 - val_loss: 0.5289 - val_accuracy: 0.7803\n",
      "Epoch 10/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2341 - accuracy: 0.95 - 0s 3ms/step - loss: 0.3399 - accuracy: 0.8596 - val_loss: 0.5608 - val_accuracy: 0.7652\n",
      "Epoch 11/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2536 - accuracy: 0.92 - 0s 5ms/step - loss: 0.3478 - accuracy: 0.8501 - val_loss: 0.5437 - val_accuracy: 0.7727\n",
      "Epoch 12/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2652 - accuracy: 0.92 - 0s 5ms/step - loss: 0.3214 - accuracy: 0.8634 - val_loss: 0.5542 - val_accuracy: 0.7879\n",
      "Epoch 13/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.3237 - accuracy: 0.87 - 0s 4ms/step - loss: 0.3071 - accuracy: 0.8767 - val_loss: 0.5566 - val_accuracy: 0.7803\n",
      "Epoch 14/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.3295 - accuracy: 0.85 - 0s 4ms/step - loss: 0.3149 - accuracy: 0.8729 - val_loss: 0.6434 - val_accuracy: 0.7652\n",
      "Epoch 15/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.3407 - accuracy: 0.85 - 0s 4ms/step - loss: 0.2882 - accuracy: 0.8899 - val_loss: 0.6471 - val_accuracy: 0.7803\n",
      "Epoch 16/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.3549 - accuracy: 0.84 - 0s 3ms/step - loss: 0.3406 - accuracy: 0.8729 - val_loss: 0.4845 - val_accuracy: 0.8106\n",
      "Epoch 17/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.3241 - accuracy: 0.87 - 0s 4ms/step - loss: 0.3334 - accuracy: 0.8691 - val_loss: 0.5029 - val_accuracy: 0.8030\n",
      "Epoch 18/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2750 - accuracy: 0.89 - 0s 4ms/step - loss: 0.2927 - accuracy: 0.8767 - val_loss: 0.5092 - val_accuracy: 0.8182\n",
      "Epoch 19/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2026 - accuracy: 0.95 - 0s 4ms/step - loss: 0.2684 - accuracy: 0.9032 - val_loss: 0.4695 - val_accuracy: 0.8258\n",
      "Epoch 20/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2953 - accuracy: 0.89 - 0s 4ms/step - loss: 0.2446 - accuracy: 0.9146 - val_loss: 0.5990 - val_accuracy: 0.8030\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN80\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                    | 81/169 [08:46<09:26,  6.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_81\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_324 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_325 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_326 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_327 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.7570 - accuracy: 0.34 - 0s 17ms/step - loss: 0.4280 - accuracy: 0.7763 - val_loss: 0.3604 - val_accuracy: 0.8632\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1527 - accuracy: 0.93 - 0s 3ms/step - loss: 0.2132 - accuracy: 0.9032 - val_loss: 0.2834 - val_accuracy: 0.8632\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1730 - accuracy: 0.90 - 0s 4ms/step - loss: 0.1942 - accuracy: 0.9140 - val_loss: 0.3494 - val_accuracy: 0.8889\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2183 - accuracy: 0.93 - 0s 4ms/step - loss: 0.1609 - accuracy: 0.9269 - val_loss: 0.3137 - val_accuracy: 0.8803\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0784 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1280 - accuracy: 0.9505 - val_loss: 0.3617 - val_accuracy: 0.8632\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0683 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1010 - accuracy: 0.9527 - val_loss: 0.3946 - val_accuracy: 0.8632\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0701 - accuracy: 0.96 - 0s 5ms/step - loss: 0.0797 - accuracy: 0.9720 - val_loss: 0.5209 - val_accuracy: 0.8547\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0131 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0657 - accuracy: 0.9699 - val_loss: 0.6899 - val_accuracy: 0.8718\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0184 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0811 - accuracy: 0.9699 - val_loss: 0.7955 - val_accuracy: 0.8120\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0828 - accuracy: 0.96 - 0s 5ms/step - loss: 0.0651 - accuracy: 0.9742 - val_loss: 0.6854 - val_accuracy: 0.8547\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0285 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0392 - accuracy: 0.9828 - val_loss: 0.6565 - val_accuracy: 0.8547\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0184 - accuracy: 1.00 - 0s 3ms/step - loss: 0.0291 - accuracy: 0.9871 - val_loss: 0.7684 - val_accuracy: 0.8547\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0201 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0203 - accuracy: 0.9914 - val_loss: 1.0073 - val_accuracy: 0.8376\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0115 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0309 - accuracy: 0.9935 - val_loss: 1.2638 - val_accuracy: 0.8632\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1759 - accuracy: 0.96 - 0s 4ms/step - loss: 0.0966 - accuracy: 0.9892 - val_loss: 0.9638 - val_accuracy: 0.8632\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0331 - accuracy: 0.98 - 0s 5ms/step - loss: 0.0432 - accuracy: 0.9892 - val_loss: 0.6224 - val_accuracy: 0.8718\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0229 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0279 - accuracy: 0.9957 - val_loss: 0.7003 - val_accuracy: 0.8803\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0597 - accuracy: 0.98 - 0s 3ms/step - loss: 0.0283 - accuracy: 0.9871 - val_loss: 0.6221 - val_accuracy: 0.8718\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0209 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0309 - accuracy: 0.9849 - val_loss: 0.8117 - val_accuracy: 0.8376\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0047 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0292 - accuracy: 0.9892 - val_loss: 0.9266 - val_accuracy: 0.8205\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN81\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                    | 82/169 [08:52<09:06,  6.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_82\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_328 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_329 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_330 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_331 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.6878 - accuracy: 0.64 - ETA: 0s - loss: 0.4465 - accuracy: 0.71 - 0s 27ms/step - loss: 0.4465 - accuracy: 0.7127 - val_loss: 0.2980 - val_accuracy: 0.8407\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.3559 - accuracy: 0.75 - 0s 3ms/step - loss: 0.2869 - accuracy: 0.8753 - val_loss: 0.2764 - val_accuracy: 0.9204\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2900 - accuracy: 0.89 - 0s 3ms/step - loss: 0.2546 - accuracy: 0.9020 - val_loss: 0.3326 - val_accuracy: 0.8850\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2347 - accuracy: 0.93 - 0s 4ms/step - loss: 0.2350 - accuracy: 0.9109 - val_loss: 0.3724 - val_accuracy: 0.8850\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2853 - accuracy: 0.87 - 0s 4ms/step - loss: 0.2197 - accuracy: 0.9131 - val_loss: 0.2679 - val_accuracy: 0.9115\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2251 - accuracy: 0.93 - 0s 3ms/step - loss: 0.2115 - accuracy: 0.9131 - val_loss: 0.2438 - val_accuracy: 0.9027\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1717 - accuracy: 0.95 - 0s 4ms/step - loss: 0.2205 - accuracy: 0.9109 - val_loss: 0.2551 - val_accuracy: 0.8850\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2122 - accuracy: 0.92 - 0s 3ms/step - loss: 0.1971 - accuracy: 0.9198 - val_loss: 0.5282 - val_accuracy: 0.8938\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2004 - accuracy: 0.92 - 0s 3ms/step - loss: 0.2013 - accuracy: 0.9154 - val_loss: 0.3290 - val_accuracy: 0.8850\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1913 - accuracy: 0.90 - 0s 4ms/step - loss: 0.1971 - accuracy: 0.9198 - val_loss: 0.5570 - val_accuracy: 0.9204\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1450 - accuracy: 0.93 - 0s 4ms/step - loss: 0.1974 - accuracy: 0.9220 - val_loss: 0.5767 - val_accuracy: 0.9204\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1523 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1796 - accuracy: 0.9287 - val_loss: 0.5687 - val_accuracy: 0.9292\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1961 - accuracy: 0.92 - 0s 5ms/step - loss: 0.1590 - accuracy: 0.9443 - val_loss: 0.5801 - val_accuracy: 0.9381\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2868 - accuracy: 0.85 - 0s 3ms/step - loss: 0.1522 - accuracy: 0.9443 - val_loss: 0.5960 - val_accuracy: 0.9469\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1068 - accuracy: 0.96 - 0s 3ms/step - loss: 0.1498 - accuracy: 0.9465 - val_loss: 0.6296 - val_accuracy: 0.9292\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1300 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1505 - accuracy: 0.9465 - val_loss: 0.7504 - val_accuracy: 0.9204\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2215 - accuracy: 0.90 - 0s 4ms/step - loss: 0.1599 - accuracy: 0.9421 - val_loss: 0.5919 - val_accuracy: 0.9115\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1776 - accuracy: 0.93 - 0s 4ms/step - loss: 0.1634 - accuracy: 0.9376 - val_loss: 0.8070 - val_accuracy: 0.9027\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1549 - accuracy: 0.93 - 0s 4ms/step - loss: 0.1618 - accuracy: 0.9399 - val_loss: 0.5539 - val_accuracy: 0.9292\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0770 - accuracy: 0.98 - 0s 4ms/step - loss: 0.1629 - accuracy: 0.9399 - val_loss: 0.5406 - val_accuracy: 0.9292\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN82\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                   | 83/169 [08:59<09:01,  6.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_83\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_332 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_333 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_334 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_335 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.6582 - accuracy: 0.71 - 0s 21ms/step - loss: 0.4616 - accuracy: 0.7915 - val_loss: 0.3284 - val_accuracy: 0.8548\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.3830 - accuracy: 0.79 - 0s 4ms/step - loss: 0.2572 - accuracy: 0.8826 - val_loss: 0.3572 - val_accuracy: 0.8710\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1513 - accuracy: 0.92 - 0s 4ms/step - loss: 0.2308 - accuracy: 0.9089 - val_loss: 0.3084 - val_accuracy: 0.8710\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1464 - accuracy: 0.93 - 0s 4ms/step - loss: 0.1789 - accuracy: 0.9231 - val_loss: 0.3511 - val_accuracy: 0.8548\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1845 - accuracy: 0.92 - 0s 4ms/step - loss: 0.1545 - accuracy: 0.9291 - val_loss: 0.3458 - val_accuracy: 0.8710\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1221 - accuracy: 0.93 - 0s 4ms/step - loss: 0.1186 - accuracy: 0.9433 - val_loss: 0.4072 - val_accuracy: 0.8629\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0484 - accuracy: 0.98 - 0s 3ms/step - loss: 0.1163 - accuracy: 0.9514 - val_loss: 0.4482 - val_accuracy: 0.8629\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0739 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1098 - accuracy: 0.9555 - val_loss: 0.5129 - val_accuracy: 0.8387\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2195 - accuracy: 0.89 - 0s 4ms/step - loss: 0.1165 - accuracy: 0.9514 - val_loss: 0.3623 - val_accuracy: 0.8548\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0907 - accuracy: 0.96 - 0s 5ms/step - loss: 0.0968 - accuracy: 0.9737 - val_loss: 0.4579 - val_accuracy: 0.8790\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0465 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0882 - accuracy: 0.9696 - val_loss: 0.4490 - val_accuracy: 0.8871\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0668 - accuracy: 0.98 - 0s 5ms/step - loss: 0.0784 - accuracy: 0.9737 - val_loss: 0.3885 - val_accuracy: 0.8871\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0696 - accuracy: 0.96 - 0s 4ms/step - loss: 0.0727 - accuracy: 0.9757 - val_loss: 0.3961 - val_accuracy: 0.8871\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0993 - accuracy: 0.96 - 0s 4ms/step - loss: 0.0732 - accuracy: 0.9777 - val_loss: 0.5796 - val_accuracy: 0.8790\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0241 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0600 - accuracy: 0.9717 - val_loss: 0.5328 - val_accuracy: 0.8952\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0203 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0508 - accuracy: 0.9798 - val_loss: 0.6515 - val_accuracy: 0.9032\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0148 - accuracy: 1.00 - 0s 3ms/step - loss: 0.0886 - accuracy: 0.9818 - val_loss: 0.6702 - val_accuracy: 0.8790\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1414 - accuracy: 0.95 - 0s 4ms/step - loss: 0.0766 - accuracy: 0.9757 - val_loss: 0.6513 - val_accuracy: 0.8629\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0858 - accuracy: 0.96 - 0s 4ms/step - loss: 0.0677 - accuracy: 0.9777 - val_loss: 0.4462 - val_accuracy: 0.8790\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0683 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1047 - accuracy: 0.9737 - val_loss: 0.5755 - val_accuracy: 0.8548\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN83\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                   | 84/169 [09:05<08:51,  6.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_84\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_336 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_337 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_338 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_339 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.7685 - accuracy: 0.42 - 0s 17ms/step - loss: 0.4980 - accuracy: 0.7113 - val_loss: 0.4814 - val_accuracy: 0.8279\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2001 - accuracy: 0.93 - 0s 4ms/step - loss: 0.2840 - accuracy: 0.8845 - val_loss: 0.6863 - val_accuracy: 0.8443\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2134 - accuracy: 0.93 - 0s 4ms/step - loss: 0.2389 - accuracy: 0.8990 - val_loss: 0.7196 - val_accuracy: 0.8361\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2050 - accuracy: 0.93 - 0s 3ms/step - loss: 0.2104 - accuracy: 0.9196 - val_loss: 0.8023 - val_accuracy: 0.8279\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2717 - accuracy: 0.89 - 0s 4ms/step - loss: 0.1869 - accuracy: 0.9278 - val_loss: 1.1063 - val_accuracy: 0.8279\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2073 - accuracy: 0.89 - 0s 4ms/step - loss: 0.1715 - accuracy: 0.9361 - val_loss: 1.3278 - val_accuracy: 0.8361\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1025 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1523 - accuracy: 0.9423 - val_loss: 1.5676 - val_accuracy: 0.8443\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1822 - accuracy: 0.92 - 0s 3ms/step - loss: 0.1523 - accuracy: 0.9402 - val_loss: 1.6226 - val_accuracy: 0.8525\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1313 - accuracy: 0.93 - 0s 4ms/step - loss: 0.1488 - accuracy: 0.9443 - val_loss: 2.1494 - val_accuracy: 0.8361\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1145 - accuracy: 0.95 - 0s 3ms/step - loss: 0.1824 - accuracy: 0.9299 - val_loss: 1.8021 - val_accuracy: 0.8279\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2109 - accuracy: 0.89 - 0s 3ms/step - loss: 0.1915 - accuracy: 0.9278 - val_loss: 1.7427 - val_accuracy: 0.8115\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1302 - accuracy: 0.93 - 0s 4ms/step - loss: 0.1787 - accuracy: 0.9299 - val_loss: 1.0580 - val_accuracy: 0.8197\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1593 - accuracy: 0.90 - 0s 4ms/step - loss: 0.1397 - accuracy: 0.9381 - val_loss: 1.4843 - val_accuracy: 0.7951\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0712 - accuracy: 0.98 - 0s 4ms/step - loss: 0.1146 - accuracy: 0.9526 - val_loss: 1.8152 - val_accuracy: 0.8197\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1965 - accuracy: 0.90 - 0s 4ms/step - loss: 0.0976 - accuracy: 0.9588 - val_loss: 1.7383 - val_accuracy: 0.8197\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1005 - accuracy: 0.95 - 0s 4ms/step - loss: 0.0744 - accuracy: 0.9649 - val_loss: 2.0974 - val_accuracy: 0.8279\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1158 - accuracy: 0.92 - 0s 4ms/step - loss: 0.0635 - accuracy: 0.9670 - val_loss: 2.2558 - val_accuracy: 0.8279\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0736 - accuracy: 0.95 - 0s 4ms/step - loss: 0.0603 - accuracy: 0.9691 - val_loss: 2.4783 - val_accuracy: 0.8197\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0784 - accuracy: 0.96 - 0s 4ms/step - loss: 0.0663 - accuracy: 0.9711 - val_loss: 2.3895 - val_accuracy: 0.7951\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0244 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0543 - accuracy: 0.9773 - val_loss: 3.0481 - val_accuracy: 0.8361\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN84\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                  | 85/169 [09:11<08:47,  6.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_85\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_340 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_341 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_342 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_343 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.7206 - accuracy: 0.56 - 0s 15ms/step - loss: 0.3823 - accuracy: 0.8231 - val_loss: 0.2137 - val_accuracy: 0.9077\n",
      "Epoch 2/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2429 - accuracy: 0.87 - 0s 3ms/step - loss: 0.2581 - accuracy: 0.9096 - val_loss: 0.2526 - val_accuracy: 0.9000\n",
      "Epoch 3/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1213 - accuracy: 0.98 - 0s 3ms/step - loss: 0.1746 - accuracy: 0.9365 - val_loss: 0.2244 - val_accuracy: 0.9077\n",
      "Epoch 4/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2662 - accuracy: 0.87 - 0s 4ms/step - loss: 0.1551 - accuracy: 0.9385 - val_loss: 0.2309 - val_accuracy: 0.9077\n",
      "Epoch 5/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0267 - accuracy: 1.00 - 0s 3ms/step - loss: 0.1191 - accuracy: 0.9596 - val_loss: 0.2448 - val_accuracy: 0.9154\n",
      "Epoch 6/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1270 - accuracy: 0.93 - 0s 3ms/step - loss: 0.1161 - accuracy: 0.9615 - val_loss: 0.2290 - val_accuracy: 0.9077\n",
      "Epoch 7/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0434 - accuracy: 1.00 - 0s 3ms/step - loss: 0.1068 - accuracy: 0.9692 - val_loss: 0.2406 - val_accuracy: 0.9154\n",
      "Epoch 8/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0651 - accuracy: 0.96 - 0s 3ms/step - loss: 0.1032 - accuracy: 0.9577 - val_loss: 0.1958 - val_accuracy: 0.9077\n",
      "Epoch 9/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1283 - accuracy: 0.93 - 0s 4ms/step - loss: 0.0826 - accuracy: 0.9712 - val_loss: 0.2810 - val_accuracy: 0.9231\n",
      "Epoch 10/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1209 - accuracy: 0.95 - 0s 3ms/step - loss: 0.0668 - accuracy: 0.9788 - val_loss: 0.2810 - val_accuracy: 0.9154\n",
      "Epoch 11/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1343 - accuracy: 0.93 - 0s 4ms/step - loss: 0.0648 - accuracy: 0.9788 - val_loss: 0.3313 - val_accuracy: 0.9154\n",
      "Epoch 12/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0458 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0638 - accuracy: 0.9788 - val_loss: 0.3300 - val_accuracy: 0.9154\n",
      "Epoch 13/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0638 - accuracy: 0.96 - 0s 3ms/step - loss: 0.0557 - accuracy: 0.9788 - val_loss: 0.3138 - val_accuracy: 0.9231\n",
      "Epoch 14/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0853 - accuracy: 0.96 - 0s 4ms/step - loss: 0.0575 - accuracy: 0.9788 - val_loss: 0.3035 - val_accuracy: 0.9077\n",
      "Epoch 15/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0780 - accuracy: 0.96 - 0s 4ms/step - loss: 0.0647 - accuracy: 0.9769 - val_loss: 0.3509 - val_accuracy: 0.9231\n",
      "Epoch 16/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 1.00 - 0s 4ms/step - loss: 0.1011 - accuracy: 0.9712 - val_loss: 0.3739 - val_accuracy: 0.8846\n",
      "Epoch 17/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0355 - accuracy: 0.98 - 0s 4ms/step - loss: 0.1950 - accuracy: 0.9538 - val_loss: 0.4233 - val_accuracy: 0.9077\n",
      "Epoch 18/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0797 - accuracy: 0.96 - 0s 3ms/step - loss: 0.1304 - accuracy: 0.9596 - val_loss: 0.3301 - val_accuracy: 0.9231\n",
      "Epoch 19/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1019 - accuracy: 0.95 - 0s 3ms/step - loss: 0.1124 - accuracy: 0.9596 - val_loss: 0.3114 - val_accuracy: 0.9154\n",
      "Epoch 20/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0496 - accuracy: 0.98 - 0s 3ms/step - loss: 0.0852 - accuracy: 0.9673 - val_loss: 0.4444 - val_accuracy: 0.9154\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN85\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                  | 86/169 [09:17<08:33,  6.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_86\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_344 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_345 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_346 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_347 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.6816 - accuracy: 0.54 - 0s 19ms/step - loss: 0.3977 - accuracy: 0.7938 - val_loss: 0.3070 - val_accuracy: 0.8265\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2657 - accuracy: 0.79 - 0s 4ms/step - loss: 0.2271 - accuracy: 0.8325 - val_loss: 0.3141 - val_accuracy: 0.8776\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2305 - accuracy: 0.84 - 0s 4ms/step - loss: 0.1569 - accuracy: 0.9304 - val_loss: 0.3320 - val_accuracy: 0.9082\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0390 - accuracy: 1.00 - 0s 4ms/step - loss: 0.1418 - accuracy: 0.9459 - val_loss: 0.3452 - val_accuracy: 0.9286\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0462 - accuracy: 0.98 - 0s 4ms/step - loss: 0.1140 - accuracy: 0.9562 - val_loss: 0.5585 - val_accuracy: 0.9082\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0640 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0948 - accuracy: 0.9639 - val_loss: 0.3865 - val_accuracy: 0.8878\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0785 - accuracy: 1.00 - 0s 4ms/step - loss: 0.1179 - accuracy: 0.9536 - val_loss: 0.3925 - val_accuracy: 0.9184\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0916 - accuracy: 0.96 - 0s 4ms/step - loss: 0.0894 - accuracy: 0.9691 - val_loss: 0.4584 - val_accuracy: 0.9286\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0793 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0833 - accuracy: 0.9742 - val_loss: 0.4147 - val_accuracy: 0.9388\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0791 - accuracy: 0.96 - 0s 4ms/step - loss: 0.0727 - accuracy: 0.9768 - val_loss: 0.4997 - val_accuracy: 0.9286\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0410 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0646 - accuracy: 0.9768 - val_loss: 0.8185 - val_accuracy: 0.9082\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0196 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0493 - accuracy: 0.9768 - val_loss: 0.7493 - val_accuracy: 0.9082\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0266 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0363 - accuracy: 0.9820 - val_loss: 0.7561 - val_accuracy: 0.9184\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0376 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0340 - accuracy: 0.9897 - val_loss: 0.7885 - val_accuracy: 0.9082\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0146 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0147 - accuracy: 0.9948 - val_loss: 0.7278 - val_accuracy: 0.9184\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0055 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0136 - accuracy: 0.9948 - val_loss: 0.7485 - val_accuracy: 0.9184\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0251 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0103 - accuracy: 0.9948 - val_loss: 0.7857 - val_accuracy: 0.9184\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.7986 - val_accuracy: 0.9184\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.8220 - val_accuracy: 0.9184\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 1.00 - 0s 5ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8398 - val_accuracy: 0.9184\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN86\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                  | 87/169 [09:23<08:18,  6.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_87\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_348 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_349 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_350 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_351 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 1.4156 - accuracy: 0.20 - 0s 20ms/step - loss: 0.6803 - accuracy: 0.7143 - val_loss: 0.3555 - val_accuracy: 0.8476\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.4238 - accuracy: 0.79 - 0s 5ms/step - loss: 0.3093 - accuracy: 0.8429 - val_loss: 0.2756 - val_accuracy: 0.8476\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2317 - accuracy: 0.84 - 0s 4ms/step - loss: 0.2398 - accuracy: 0.8429 - val_loss: 0.2622 - val_accuracy: 0.8476\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2132 - accuracy: 0.87 - 0s 4ms/step - loss: 0.2037 - accuracy: 0.8429 - val_loss: 0.2409 - val_accuracy: 0.8476\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1091 - accuracy: 0.90 - 0s 4ms/step - loss: 0.1919 - accuracy: 0.8429 - val_loss: 0.2348 - val_accuracy: 0.8476\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1290 - accuracy: 0.87 - 0s 4ms/step - loss: 0.1716 - accuracy: 0.8429 - val_loss: 0.2226 - val_accuracy: 0.8476\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1336 - accuracy: 0.84 - 0s 4ms/step - loss: 0.1623 - accuracy: 0.8476 - val_loss: 0.2163 - val_accuracy: 0.9238\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1621 - accuracy: 0.92 - 0s 5ms/step - loss: 0.1499 - accuracy: 0.9405 - val_loss: 0.1988 - val_accuracy: 0.9238\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1759 - accuracy: 0.87 - 0s 4ms/step - loss: 0.1447 - accuracy: 0.9357 - val_loss: 0.2087 - val_accuracy: 0.9238\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1233 - accuracy: 0.93 - 0s 5ms/step - loss: 0.1333 - accuracy: 0.9452 - val_loss: 0.2233 - val_accuracy: 0.9143\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1309 - accuracy: 0.92 - 0s 4ms/step - loss: 0.1295 - accuracy: 0.9476 - val_loss: 0.2340 - val_accuracy: 0.9143\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1866 - accuracy: 0.92 - 0s 4ms/step - loss: 0.1286 - accuracy: 0.9452 - val_loss: 0.2473 - val_accuracy: 0.9143\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1727 - accuracy: 0.90 - 0s 4ms/step - loss: 0.1244 - accuracy: 0.9452 - val_loss: 0.1894 - val_accuracy: 0.9238\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0639 - accuracy: 0.98 - 0s 4ms/step - loss: 0.1226 - accuracy: 0.9476 - val_loss: 0.1652 - val_accuracy: 0.9238\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1258 - accuracy: 0.93 - 0s 4ms/step - loss: 0.1248 - accuracy: 0.9429 - val_loss: 0.1581 - val_accuracy: 0.9238\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1052 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1203 - accuracy: 0.9500 - val_loss: 0.2757 - val_accuracy: 0.9048\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1006 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1342 - accuracy: 0.9429 - val_loss: 0.2404 - val_accuracy: 0.9143\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1251 - accuracy: 0.92 - 0s 4ms/step - loss: 0.1310 - accuracy: 0.9429 - val_loss: 0.2374 - val_accuracy: 0.8952\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1246 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1305 - accuracy: 0.9405 - val_loss: 0.2579 - val_accuracy: 0.9048\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1165 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1256 - accuracy: 0.9381 - val_loss: 0.2373 - val_accuracy: 0.9048\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN87\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                 | 88/169 [09:29<08:18,  6.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_88\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_352 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_353 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_354 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_355 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.7163 - accuracy: 0.45 - 0s 18ms/step - loss: 0.4652 - accuracy: 0.7763 - val_loss: 0.2318 - val_accuracy: 0.8455\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2272 - accuracy: 0.92 - 0s 4ms/step - loss: 0.2345 - accuracy: 0.8493 - val_loss: 0.2021 - val_accuracy: 0.8455\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2226 - accuracy: 0.85 - 0s 4ms/step - loss: 0.2060 - accuracy: 0.8493 - val_loss: 0.2127 - val_accuracy: 0.8455\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1518 - accuracy: 0.87 - 0s 4ms/step - loss: 0.1708 - accuracy: 0.8493 - val_loss: 0.2315 - val_accuracy: 0.8455\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1266 - accuracy: 0.89 - 0s 4ms/step - loss: 0.1631 - accuracy: 0.8493 - val_loss: 0.2244 - val_accuracy: 0.8455\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1212 - accuracy: 0.87 - 0s 4ms/step - loss: 0.1458 - accuracy: 0.9201 - val_loss: 0.2130 - val_accuracy: 0.9273\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1506 - accuracy: 0.93 - 0s 4ms/step - loss: 0.1396 - accuracy: 0.9429 - val_loss: 0.2356 - val_accuracy: 0.8818\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0893 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1319 - accuracy: 0.9452 - val_loss: 0.2700 - val_accuracy: 0.9000\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1075 - accuracy: 0.93 - 0s 4ms/step - loss: 0.1271 - accuracy: 0.9475 - val_loss: 0.2332 - val_accuracy: 0.9091\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0966 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1198 - accuracy: 0.9521 - val_loss: 0.2483 - val_accuracy: 0.9000\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0800 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1163 - accuracy: 0.9521 - val_loss: 0.3380 - val_accuracy: 0.9000\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1726 - accuracy: 0.92 - 0s 4ms/step - loss: 0.1093 - accuracy: 0.9566 - val_loss: 0.3330 - val_accuracy: 0.9000\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0800 - accuracy: 0.98 - 0s 4ms/step - loss: 0.1052 - accuracy: 0.9589 - val_loss: 0.2868 - val_accuracy: 0.9000\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0814 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1018 - accuracy: 0.9589 - val_loss: 0.3279 - val_accuracy: 0.9182\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1009 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1023 - accuracy: 0.9566 - val_loss: 0.3136 - val_accuracy: 0.9182\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0930 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1054 - accuracy: 0.9566 - val_loss: 0.4239 - val_accuracy: 0.9182\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1271 - accuracy: 0.92 - 0s 4ms/step - loss: 0.1082 - accuracy: 0.9543 - val_loss: 0.4111 - val_accuracy: 0.9091\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1099 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1086 - accuracy: 0.9543 - val_loss: 0.3038 - val_accuracy: 0.8909\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1732 - accuracy: 0.90 - 0s 4ms/step - loss: 0.1354 - accuracy: 0.9543 - val_loss: 0.3061 - val_accuracy: 0.9000\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1383 - accuracy: 0.93 - 0s 4ms/step - loss: 0.1054 - accuracy: 0.9566 - val_loss: 0.2853 - val_accuracy: 0.9000\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN88\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                 | 89/169 [09:35<08:05,  6.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_89\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_356 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_357 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_358 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_359 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.8270 - accuracy: 0.15 - 0s 16ms/step - loss: 0.6841 - accuracy: 0.6342 - val_loss: 0.6214 - val_accuracy: 0.7328\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.5752 - accuracy: 0.82 - 0s 3ms/step - loss: 0.5495 - accuracy: 0.7294 - val_loss: 0.3792 - val_accuracy: 0.7328\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.3792 - accuracy: 0.68 - 0s 3ms/step - loss: 0.3730 - accuracy: 0.7294 - val_loss: 0.3299 - val_accuracy: 0.7328\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.3966 - accuracy: 0.68 - 0s 3ms/step - loss: 0.3237 - accuracy: 0.7294 - val_loss: 0.2920 - val_accuracy: 0.7328\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.3391 - accuracy: 0.67 - 0s 3ms/step - loss: 0.2820 - accuracy: 0.7294 - val_loss: 0.3729 - val_accuracy: 0.7328\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2261 - accuracy: 0.76 - 0s 3ms/step - loss: 0.2452 - accuracy: 0.8074 - val_loss: 0.4971 - val_accuracy: 0.9138\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1539 - accuracy: 0.93 - 0s 3ms/step - loss: 0.2184 - accuracy: 0.9351 - val_loss: 0.5649 - val_accuracy: 0.9310\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2795 - accuracy: 0.85 - 0s 3ms/step - loss: 0.1935 - accuracy: 0.9329 - val_loss: 0.3814 - val_accuracy: 0.9397\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2180 - accuracy: 0.90 - 0s 4ms/step - loss: 0.1784 - accuracy: 0.9351 - val_loss: 0.3360 - val_accuracy: 0.9397\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0914 - accuracy: 1.00 - 0s 3ms/step - loss: 0.1658 - accuracy: 0.9372 - val_loss: 0.3547 - val_accuracy: 0.9483\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0770 - accuracy: 0.98 - 0s 3ms/step - loss: 0.1523 - accuracy: 0.9437 - val_loss: 0.3593 - val_accuracy: 0.9224\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1873 - accuracy: 0.92 - 0s 3ms/step - loss: 0.1293 - accuracy: 0.9610 - val_loss: 0.2327 - val_accuracy: 0.9397\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0721 - accuracy: 1.00 - 0s 3ms/step - loss: 0.1283 - accuracy: 0.9589 - val_loss: 0.2590 - val_accuracy: 0.9138\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0911 - accuracy: 0.98 - 0s 4ms/step - loss: 0.1253 - accuracy: 0.9589 - val_loss: 0.2724 - val_accuracy: 0.9052\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1003 - accuracy: 0.96 - 0s 3ms/step - loss: 0.1225 - accuracy: 0.9589 - val_loss: 0.2934 - val_accuracy: 0.9052\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0834 - accuracy: 0.98 - 0s 3ms/step - loss: 0.1215 - accuracy: 0.9589 - val_loss: 0.2944 - val_accuracy: 0.9052\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0844 - accuracy: 0.98 - 0s 3ms/step - loss: 0.1189 - accuracy: 0.9610 - val_loss: 0.2994 - val_accuracy: 0.8966\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1476 - accuracy: 0.93 - 0s 4ms/step - loss: 0.1225 - accuracy: 0.9589 - val_loss: 0.2982 - val_accuracy: 0.8966\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1031 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1185 - accuracy: 0.9610 - val_loss: 0.2705 - val_accuracy: 0.9138\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1821 - accuracy: 0.92 - 0s 4ms/step - loss: 0.1177 - accuracy: 0.9610 - val_loss: 0.2536 - val_accuracy: 0.9224\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN89\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                | 90/169 [09:41<07:51,  5.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_90\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_360 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_361 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_362 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_363 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.8774 - accuracy: 0.12 - 0s 19ms/step - loss: 0.4952 - accuracy: 0.7167 - val_loss: 0.2890 - val_accuracy: 0.8431\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2327 - accuracy: 0.85 - 0s 4ms/step - loss: 0.2368 - accuracy: 0.8473 - val_loss: 0.3185 - val_accuracy: 0.8431\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1991 - accuracy: 0.81 - 0s 4ms/step - loss: 0.1780 - accuracy: 0.8473 - val_loss: 0.3019 - val_accuracy: 0.8431\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1460 - accuracy: 0.85 - 0s 4ms/step - loss: 0.1635 - accuracy: 0.8473 - val_loss: 0.3569 - val_accuracy: 0.8431\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1438 - accuracy: 0.87 - 0s 4ms/step - loss: 0.1631 - accuracy: 0.8473 - val_loss: 0.2967 - val_accuracy: 0.9020\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1526 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1537 - accuracy: 0.9360 - val_loss: 0.3108 - val_accuracy: 0.9118\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1241 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1373 - accuracy: 0.9458 - val_loss: 0.4103 - val_accuracy: 0.9020\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1544 - accuracy: 0.92 - 0s 4ms/step - loss: 0.1506 - accuracy: 0.9483 - val_loss: 0.3858 - val_accuracy: 0.9118\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0892 - accuracy: 0.98 - 0s 4ms/step - loss: 0.1361 - accuracy: 0.9409 - val_loss: 0.3772 - val_accuracy: 0.9020\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0978 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1324 - accuracy: 0.9384 - val_loss: 0.3859 - val_accuracy: 0.9020\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1016 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1292 - accuracy: 0.9409 - val_loss: 0.3982 - val_accuracy: 0.9118\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1069 - accuracy: 0.93 - 0s 4ms/step - loss: 0.1258 - accuracy: 0.9409 - val_loss: 0.4552 - val_accuracy: 0.9118\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1373 - accuracy: 0.93 - 0s 4ms/step - loss: 0.1271 - accuracy: 0.9409 - val_loss: 0.4810 - val_accuracy: 0.9118\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1141 - accuracy: 0.93 - 0s 4ms/step - loss: 0.1176 - accuracy: 0.9483 - val_loss: 0.4513 - val_accuracy: 0.9118\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1610 - accuracy: 0.92 - 0s 4ms/step - loss: 0.1139 - accuracy: 0.9532 - val_loss: 0.5058 - val_accuracy: 0.9216\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0956 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1097 - accuracy: 0.9532 - val_loss: 0.5861 - val_accuracy: 0.9216\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1056 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1106 - accuracy: 0.9507 - val_loss: 0.6296 - val_accuracy: 0.9216\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0700 - accuracy: 1.00 - 0s 4ms/step - loss: 0.1077 - accuracy: 0.9532 - val_loss: 0.6697 - val_accuracy: 0.9216\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1111 - accuracy: 0.93 - 0s 4ms/step - loss: 0.1032 - accuracy: 0.9581 - val_loss: 0.7600 - val_accuracy: 0.9216\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0761 - accuracy: 0.98 - 0s 4ms/step - loss: 0.1006 - accuracy: 0.9606 - val_loss: 0.6542 - val_accuracy: 0.9216\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN90\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                | 91/169 [09:47<07:41,  5.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_91\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_364 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_365 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_366 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_367 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.8464 - accuracy: 0.20 - 0s 18ms/step - loss: 0.5295 - accuracy: 0.7380 - val_loss: 0.3276 - val_accuracy: 0.8269\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2797 - accuracy: 0.82 - 0s 4ms/step - loss: 0.2867 - accuracy: 0.8293 - val_loss: 0.2702 - val_accuracy: 0.8269\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2606 - accuracy: 0.81 - 0s 4ms/step - loss: 0.2395 - accuracy: 0.8293 - val_loss: 0.2388 - val_accuracy: 0.8269\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1870 - accuracy: 0.84 - 0s 4ms/step - loss: 0.2007 - accuracy: 0.8293 - val_loss: 0.2295 - val_accuracy: 0.8269\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1186 - accuracy: 0.89 - 0s 4ms/step - loss: 0.1710 - accuracy: 0.9087 - val_loss: 0.2273 - val_accuracy: 0.9135\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1041 - accuracy: 1.00 - 0s 4ms/step - loss: 0.1475 - accuracy: 0.9495 - val_loss: 0.2452 - val_accuracy: 0.8942\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1179 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1279 - accuracy: 0.9615 - val_loss: 0.2683 - val_accuracy: 0.9038\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0668 - accuracy: 1.00 - 0s 4ms/step - loss: 0.1158 - accuracy: 0.9591 - val_loss: 0.2571 - val_accuracy: 0.9038\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2208 - accuracy: 0.92 - 0s 4ms/step - loss: 0.1194 - accuracy: 0.9567 - val_loss: 0.2212 - val_accuracy: 0.8942\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1582 - accuracy: 0.93 - 0s 4ms/step - loss: 0.0990 - accuracy: 0.9712 - val_loss: 0.2531 - val_accuracy: 0.8846\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0750 - accuracy: 0.96 - 0s 4ms/step - loss: 0.0959 - accuracy: 0.9688 - val_loss: 0.2407 - val_accuracy: 0.8846\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0990 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0916 - accuracy: 0.9688 - val_loss: 0.2344 - val_accuracy: 0.8942\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1080 - accuracy: 0.95 - 0s 4ms/step - loss: 0.0838 - accuracy: 0.9712 - val_loss: 0.2472 - val_accuracy: 0.8846\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1097 - accuracy: 0.95 - 0s 4ms/step - loss: 0.0829 - accuracy: 0.9736 - val_loss: 0.2467 - val_accuracy: 0.8846\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1282 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1022 - accuracy: 0.9615 - val_loss: 0.2820 - val_accuracy: 0.8846\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0383 - accuracy: 1.00 - 0s 4ms/step - loss: 0.1047 - accuracy: 0.9615 - val_loss: 0.3279 - val_accuracy: 0.8846\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1084 - accuracy: 0.95 - 0s 3ms/step - loss: 0.0966 - accuracy: 0.9639 - val_loss: 0.3312 - val_accuracy: 0.8558\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0973 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1225 - accuracy: 0.9567 - val_loss: 0.3848 - val_accuracy: 0.8462\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0535 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0958 - accuracy: 0.9639 - val_loss: 0.4299 - val_accuracy: 0.9038\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0737 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0870 - accuracy: 0.9688 - val_loss: 0.4385 - val_accuracy: 0.8942\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN91\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                | 92/169 [09:52<07:28,  5.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_92\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_368 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_369 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_370 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_371 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.7190 - accuracy: 0.67 - 0s 19ms/step - loss: 0.4256 - accuracy: 0.7883 - val_loss: 0.2140 - val_accuracy: 0.8125\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2032 - accuracy: 0.82 - 0s 4ms/step - loss: 0.2045 - accuracy: 0.8131 - val_loss: 0.1943 - val_accuracy: 0.8125\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1892 - accuracy: 0.76 - 0s 4ms/step - loss: 0.1759 - accuracy: 0.8131 - val_loss: 0.2137 - val_accuracy: 0.8125\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1786 - accuracy: 0.82 - 0s 4ms/step - loss: 0.1657 - accuracy: 0.8761 - val_loss: 0.1871 - val_accuracy: 0.9196\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0911 - accuracy: 0.98 - 0s 4ms/step - loss: 0.1527 - accuracy: 0.9505 - val_loss: 0.1662 - val_accuracy: 0.9375\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1341 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1392 - accuracy: 0.9527 - val_loss: 0.1731 - val_accuracy: 0.9196\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1066 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1793 - accuracy: 0.9527 - val_loss: 0.1704 - val_accuracy: 0.9196\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1694 - accuracy: 0.93 - 0s 4ms/step - loss: 0.1241 - accuracy: 0.9550 - val_loss: 0.2015 - val_accuracy: 0.8929\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1142 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1228 - accuracy: 0.9527 - val_loss: 0.1640 - val_accuracy: 0.9286\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1107 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1159 - accuracy: 0.9550 - val_loss: 0.1561 - val_accuracy: 0.9286\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1071 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1136 - accuracy: 0.9572 - val_loss: 0.1719 - val_accuracy: 0.9196\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1003 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1123 - accuracy: 0.9572 - val_loss: 0.1770 - val_accuracy: 0.9196\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1332 - accuracy: 0.93 - 0s 4ms/step - loss: 0.1116 - accuracy: 0.9572 - val_loss: 0.1774 - val_accuracy: 0.9196\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1213 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1110 - accuracy: 0.9572 - val_loss: 0.1736 - val_accuracy: 0.9196\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0928 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1109 - accuracy: 0.9572 - val_loss: 0.1712 - val_accuracy: 0.9196\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0912 - accuracy: 0.98 - 0s 4ms/step - loss: 0.1108 - accuracy: 0.9572 - val_loss: 0.1700 - val_accuracy: 0.9196\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0593 - accuracy: 0.98 - 0s 4ms/step - loss: 0.1105 - accuracy: 0.9572 - val_loss: 0.1686 - val_accuracy: 0.9196\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1018 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1107 - accuracy: 0.9572 - val_loss: 0.1680 - val_accuracy: 0.9196\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1693 - accuracy: 0.92 - 0s 4ms/step - loss: 0.1105 - accuracy: 0.9572 - val_loss: 0.1670 - val_accuracy: 0.9196\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0431 - accuracy: 1.00 - 0s 4ms/step - loss: 0.1106 - accuracy: 0.9572 - val_loss: 0.1670 - val_accuracy: 0.9286\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN92\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                               | 93/169 [09:58<07:16,  5.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_93\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_372 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_373 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_374 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_375 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 0.6618 - accuracy: 0.6250WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0010s). Check your callbacks.\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.3576 - accuracy: 0.8115 - val_loss: 0.2306 - val_accuracy: 0.8333\n",
      "Epoch 2/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1740 - accuracy: 0.82 - 0s 4ms/step - loss: 0.1841 - accuracy: 0.8560 - val_loss: 0.2017 - val_accuracy: 0.9583\n",
      "Epoch 3/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1519 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1307 - accuracy: 0.9424 - val_loss: 0.2313 - val_accuracy: 0.9375\n",
      "Epoch 4/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1418 - accuracy: 0.92 - 0s 4ms/step - loss: 0.1012 - accuracy: 0.9607 - val_loss: 0.2877 - val_accuracy: 0.9375\n",
      "Epoch 5/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1302 - accuracy: 0.92 - 0s 4ms/step - loss: 0.0780 - accuracy: 0.9686 - val_loss: 0.3320 - val_accuracy: 0.9271\n",
      "Epoch 6/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0464 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0650 - accuracy: 0.9738 - val_loss: 0.3406 - val_accuracy: 0.9167\n",
      "Epoch 7/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0941 - accuracy: 0.95 - 0s 5ms/step - loss: 0.0554 - accuracy: 0.9764 - val_loss: 0.3106 - val_accuracy: 0.9375\n",
      "Epoch 8/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0337 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0435 - accuracy: 0.9869 - val_loss: 0.3570 - val_accuracy: 0.9375\n",
      "Epoch 9/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0086 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0327 - accuracy: 0.9869 - val_loss: 0.4053 - val_accuracy: 0.9375\n",
      "Epoch 10/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0115 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0265 - accuracy: 0.9895 - val_loss: 0.5019 - val_accuracy: 0.9375\n",
      "Epoch 11/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0086 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0143 - accuracy: 0.9948 - val_loss: 0.6908 - val_accuracy: 0.9375\n",
      "Epoch 12/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0125 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0422 - accuracy: 0.9843 - val_loss: 0.5226 - val_accuracy: 0.9167\n",
      "Epoch 13/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0328 - accuracy: 0.9948 - val_loss: 0.6159 - val_accuracy: 0.9167\n",
      "Epoch 14/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0291 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0289 - accuracy: 0.9869 - val_loss: 0.4752 - val_accuracy: 0.9062\n",
      "Epoch 15/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0059 - accuracy: 0.9974 - val_loss: 0.4463 - val_accuracy: 0.9167\n",
      "Epoch 16/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0041 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0091 - accuracy: 0.9974 - val_loss: 0.3949 - val_accuracy: 0.9167\n",
      "Epoch 17/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0050 - accuracy: 0.9974 - val_loss: 0.3977 - val_accuracy: 0.9271\n",
      "Epoch 18/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0026 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0036 - accuracy: 0.9974 - val_loss: 0.4237 - val_accuracy: 0.9375\n",
      "Epoch 19/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4174 - val_accuracy: 0.9271\n",
      "Epoch 20/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0010 - accuracy: 1.00 - 0s 4ms/step - loss: 9.3298e-04 - accuracy: 1.0000 - val_loss: 0.4304 - val_accuracy: 0.9271\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN93\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                               | 94/169 [10:03<07:03,  5.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_94\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_376 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_377 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_378 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_379 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.6606 - accuracy: 0.64 - 0s 49ms/step - loss: 0.5934 - accuracy: 0.7594 - val_loss: 0.4465 - val_accuracy: 0.7925\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.4601 - accuracy: 0.73 - 0s 4ms/step - loss: 0.4117 - accuracy: 0.7877 - val_loss: 0.3717 - val_accuracy: 0.7925\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2661 - accuracy: 0.84 - 0s 4ms/step - loss: 0.3685 - accuracy: 0.7877 - val_loss: 0.3695 - val_accuracy: 0.7925\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.3426 - accuracy: 0.78 - 0s 4ms/step - loss: 0.3470 - accuracy: 0.7877 - val_loss: 0.3699 - val_accuracy: 0.7925\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2298 - accuracy: 0.78 - 0s 4ms/step - loss: 0.2929 - accuracy: 0.8302 - val_loss: 0.3707 - val_accuracy: 0.8774\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2927 - accuracy: 0.82 - 0s 4ms/step - loss: 0.2558 - accuracy: 0.8892 - val_loss: 0.3982 - val_accuracy: 0.8585\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2140 - accuracy: 0.90 - 0s 4ms/step - loss: 0.2344 - accuracy: 0.9104 - val_loss: 0.3981 - val_accuracy: 0.8868\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.3261 - accuracy: 0.84 - 0s 4ms/step - loss: 0.2262 - accuracy: 0.9057 - val_loss: 0.4268 - val_accuracy: 0.8868\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2190 - accuracy: 0.90 - 0s 4ms/step - loss: 0.2238 - accuracy: 0.9151 - val_loss: 0.5719 - val_accuracy: 0.8585\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2099 - accuracy: 0.92 - 0s 4ms/step - loss: 0.2445 - accuracy: 0.8962 - val_loss: 0.5072 - val_accuracy: 0.7925\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2768 - accuracy: 0.89 - 0s 5ms/step - loss: 0.2625 - accuracy: 0.8703 - val_loss: 0.6437 - val_accuracy: 0.8396\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.3032 - accuracy: 0.82 - 0s 4ms/step - loss: 0.2574 - accuracy: 0.8774 - val_loss: 0.5839 - val_accuracy: 0.8208\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2066 - accuracy: 0.92 - 0s 4ms/step - loss: 0.2594 - accuracy: 0.8726 - val_loss: 0.5359 - val_accuracy: 0.8302\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2177 - accuracy: 0.92 - 0s 4ms/step - loss: 0.2015 - accuracy: 0.9104 - val_loss: 0.5124 - val_accuracy: 0.8585\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1659 - accuracy: 0.92 - 0s 4ms/step - loss: 0.1903 - accuracy: 0.9245 - val_loss: 0.5155 - val_accuracy: 0.8868\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1446 - accuracy: 0.93 - 0s 4ms/step - loss: 0.1691 - accuracy: 0.9292 - val_loss: 0.5186 - val_accuracy: 0.8774\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1974 - accuracy: 0.87 - 0s 4ms/step - loss: 0.1598 - accuracy: 0.9340 - val_loss: 0.6047 - val_accuracy: 0.8491\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1529 - accuracy: 0.93 - 0s 4ms/step - loss: 0.1545 - accuracy: 0.9363 - val_loss: 0.6230 - val_accuracy: 0.8491\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1130 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1477 - accuracy: 0.9387 - val_loss: 0.6956 - val_accuracy: 0.8585\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1310 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1691 - accuracy: 0.9340 - val_loss: 0.7351 - val_accuracy: 0.8679\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN94\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                              | 95/169 [10:09<07:04,  5.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_95\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_380 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_381 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_382 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_383 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.5640 - accuracy: 0.78 - 0s 19ms/step - loss: 0.4218 - accuracy: 0.8000 - val_loss: 0.2825 - val_accuracy: 0.8039\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2474 - accuracy: 0.82 - 0s 3ms/step - loss: 0.2720 - accuracy: 0.8074 - val_loss: 0.2783 - val_accuracy: 0.8039\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.3260 - accuracy: 0.68 - 0s 4ms/step - loss: 0.2244 - accuracy: 0.8667 - val_loss: 0.2541 - val_accuracy: 0.8824\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1700 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1881 - accuracy: 0.9235 - val_loss: 0.2811 - val_accuracy: 0.8725\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1675 - accuracy: 0.95 - 0s 4ms/step - loss: 0.2034 - accuracy: 0.9259 - val_loss: 0.2718 - val_accuracy: 0.8725\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1882 - accuracy: 0.93 - 0s 4ms/step - loss: 0.1759 - accuracy: 0.9259 - val_loss: 0.2883 - val_accuracy: 0.8725\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1125 - accuracy: 0.98 - 0s 4ms/step - loss: 0.1427 - accuracy: 0.9457 - val_loss: 0.4777 - val_accuracy: 0.8922\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2274 - accuracy: 0.89 - 0s 4ms/step - loss: 0.1427 - accuracy: 0.9481 - val_loss: 0.3794 - val_accuracy: 0.8627\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1760 - accuracy: 0.93 - 0s 4ms/step - loss: 0.1151 - accuracy: 0.9654 - val_loss: 0.5321 - val_accuracy: 0.8725\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0818 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1010 - accuracy: 0.9630 - val_loss: 0.5444 - val_accuracy: 0.8725\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0731 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0882 - accuracy: 0.9728 - val_loss: 0.5708 - val_accuracy: 0.8824\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0493 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0845 - accuracy: 0.9753 - val_loss: 0.6902 - val_accuracy: 0.8725\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1209 - accuracy: 0.95 - 0s 4ms/step - loss: 0.0780 - accuracy: 0.9778 - val_loss: 0.7400 - val_accuracy: 0.8725\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0366 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0756 - accuracy: 0.9778 - val_loss: 0.7584 - val_accuracy: 0.8725\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0729 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0759 - accuracy: 0.9753 - val_loss: 0.7720 - val_accuracy: 0.8725\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0497 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0783 - accuracy: 0.9753 - val_loss: 0.7845 - val_accuracy: 0.8824\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1288 - accuracy: 0.95 - 0s 4ms/step - loss: 0.0777 - accuracy: 0.9753 - val_loss: 0.8410 - val_accuracy: 0.8824\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1220 - accuracy: 0.95 - 0s 4ms/step - loss: 0.0771 - accuracy: 0.9753 - val_loss: 0.8717 - val_accuracy: 0.8824\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0816 - accuracy: 0.96 - 0s 4ms/step - loss: 0.0772 - accuracy: 0.9753 - val_loss: 0.8863 - val_accuracy: 0.8824\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0902 - accuracy: 0.96 - 0s 4ms/step - loss: 0.0770 - accuracy: 0.9753 - val_loss: 0.8960 - val_accuracy: 0.8824\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN95\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                              | 96/169 [10:15<06:59,  5.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_96\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_384 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_385 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_386 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_387 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.7695 - accuracy: 0.43 - 0s 17ms/step - loss: 0.4490 - accuracy: 0.7996 - val_loss: 0.2423 - val_accuracy: 0.8684\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1462 - accuracy: 0.90 - 0s 3ms/step - loss: 0.1989 - accuracy: 0.8722 - val_loss: 0.2449 - val_accuracy: 0.8684\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1596 - accuracy: 0.84 - 0s 4ms/step - loss: 0.1708 - accuracy: 0.8722 - val_loss: 0.3033 - val_accuracy: 0.8684\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1056 - accuracy: 0.89 - 0s 3ms/step - loss: 0.1508 - accuracy: 0.8722 - val_loss: 0.2927 - val_accuracy: 0.8684\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1282 - accuracy: 0.89 - 0s 3ms/step - loss: 0.1353 - accuracy: 0.8722 - val_loss: 0.3870 - val_accuracy: 0.8684\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0994 - accuracy: 0.89 - 0s 4ms/step - loss: 0.1257 - accuracy: 0.9185 - val_loss: 0.4401 - val_accuracy: 0.9035\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0592 - accuracy: 1.00 - 0s 3ms/step - loss: 0.1182 - accuracy: 0.9559 - val_loss: 0.4615 - val_accuracy: 0.9035\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1423 - accuracy: 0.93 - 0s 3ms/step - loss: 0.1181 - accuracy: 0.9471 - val_loss: 0.4311 - val_accuracy: 0.8947\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1487 - accuracy: 0.93 - 0s 3ms/step - loss: 0.1022 - accuracy: 0.9670 - val_loss: 0.5000 - val_accuracy: 0.8860\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0945 - accuracy: 0.95 - 0s 4ms/step - loss: 0.0955 - accuracy: 0.9692 - val_loss: 0.5230 - val_accuracy: 0.8860\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1072 - accuracy: 0.93 - 0s 3ms/step - loss: 0.0818 - accuracy: 0.9736 - val_loss: 0.6007 - val_accuracy: 0.8947\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1094 - accuracy: 0.95 - 0s 3ms/step - loss: 0.0807 - accuracy: 0.9714 - val_loss: 0.5577 - val_accuracy: 0.8772\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0859 - accuracy: 0.96 - 0s 3ms/step - loss: 0.0848 - accuracy: 0.9692 - val_loss: 0.7289 - val_accuracy: 0.8772\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0846 - accuracy: 0.96 - 0s 3ms/step - loss: 0.0833 - accuracy: 0.9670 - val_loss: 0.5541 - val_accuracy: 0.8772\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1200 - accuracy: 0.95 - 0s 3ms/step - loss: 0.1144 - accuracy: 0.9471 - val_loss: 0.4390 - val_accuracy: 0.8860\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1512 - accuracy: 0.92 - 0s 3ms/step - loss: 0.1204 - accuracy: 0.9449 - val_loss: 0.3881 - val_accuracy: 0.8947\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1754 - accuracy: 0.90 - 0s 4ms/step - loss: 0.1149 - accuracy: 0.9449 - val_loss: 0.3430 - val_accuracy: 0.9035\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1285 - accuracy: 0.93 - 0s 4ms/step - loss: 0.1106 - accuracy: 0.9471 - val_loss: 0.3700 - val_accuracy: 0.9035\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0970 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1024 - accuracy: 0.9537 - val_loss: 0.4638 - val_accuracy: 0.8947\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1132 - accuracy: 0.93 - 0s 5ms/step - loss: 0.1217 - accuracy: 0.9604 - val_loss: 0.2898 - val_accuracy: 0.9123\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN96\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                             | 97/169 [10:21<06:56,  5.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_97\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_388 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_389 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_390 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_391 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.4862 - accuracy: 0.89 - 0s 22ms/step - loss: 0.2804 - accuracy: 0.8474 - val_loss: 0.1472 - val_accuracy: 0.8438\n",
      "Epoch 2/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1083 - accuracy: 0.89 - 0s 5ms/step - loss: 0.1336 - accuracy: 0.8816 - val_loss: 0.1370 - val_accuracy: 0.9688\n",
      "Epoch 3/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1564 - accuracy: 1.00 - 0s 4ms/step - loss: 0.1213 - accuracy: 0.9658 - val_loss: 0.1304 - val_accuracy: 0.9583\n",
      "Epoch 4/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1741 - accuracy: 0.93 - 0s 4ms/step - loss: 0.1051 - accuracy: 0.9658 - val_loss: 0.1237 - val_accuracy: 0.9583\n",
      "Epoch 5/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1220 - accuracy: 0.93 - 0s 5ms/step - loss: 0.0846 - accuracy: 0.9684 - val_loss: 0.1596 - val_accuracy: 0.9688\n",
      "Epoch 6/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0928 - accuracy: 0.96 - 0s 4ms/step - loss: 0.0780 - accuracy: 0.9711 - val_loss: 0.1087 - val_accuracy: 0.9688\n",
      "Epoch 7/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0446 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0729 - accuracy: 0.9711 - val_loss: 0.1137 - val_accuracy: 0.9688\n",
      "Epoch 8/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0295 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0648 - accuracy: 0.9763 - val_loss: 0.1541 - val_accuracy: 0.9583\n",
      "Epoch 9/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1036 - accuracy: 0.95 - 0s 4ms/step - loss: 0.0775 - accuracy: 0.9737 - val_loss: 0.1609 - val_accuracy: 0.9583\n",
      "Epoch 10/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0816 - accuracy: 0.96 - 0s 5ms/step - loss: 0.0596 - accuracy: 0.9763 - val_loss: 0.1786 - val_accuracy: 0.9583\n",
      "Epoch 11/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0548 - accuracy: 0.96 - 0s 5ms/step - loss: 0.0570 - accuracy: 0.9789 - val_loss: 0.1615 - val_accuracy: 0.9583\n",
      "Epoch 12/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0215 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0503 - accuracy: 0.9842 - val_loss: 0.2055 - val_accuracy: 0.9583\n",
      "Epoch 13/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0240 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0454 - accuracy: 0.9842 - val_loss: 0.3243 - val_accuracy: 0.9583\n",
      "Epoch 14/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0082 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0388 - accuracy: 0.9895 - val_loss: 0.3221 - val_accuracy: 0.9688\n",
      "Epoch 15/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0219 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0324 - accuracy: 0.9895 - val_loss: 0.3194 - val_accuracy: 0.9688\n",
      "Epoch 16/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0128 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0416 - accuracy: 0.9842 - val_loss: 0.3120 - val_accuracy: 0.9688\n",
      "Epoch 17/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0330 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0240 - accuracy: 0.9947 - val_loss: 0.2993 - val_accuracy: 0.9688\n",
      "Epoch 18/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0112 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0241 - accuracy: 0.9921 - val_loss: 0.4901 - val_accuracy: 0.9688\n",
      "Epoch 19/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0423 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0253 - accuracy: 0.9921 - val_loss: 0.6174 - val_accuracy: 0.9479\n",
      "Epoch 20/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0334 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0335 - accuracy: 0.9868 - val_loss: 0.6389 - val_accuracy: 0.9583\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN97\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                             | 98/169 [10:26<06:46,  5.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_98\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_392 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_393 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_394 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_395 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.9760 - accuracy: 0.21 - 0s 19ms/step - loss: 0.4370 - accuracy: 0.7730 - val_loss: 0.1776 - val_accuracy: 0.8878\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1149 - accuracy: 0.90 - 0s 4ms/step - loss: 0.1220 - accuracy: 0.9031 - val_loss: 0.1359 - val_accuracy: 0.9184\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0729 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1007 - accuracy: 0.9541 - val_loss: 0.1740 - val_accuracy: 0.9184\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0580 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0885 - accuracy: 0.9617 - val_loss: 0.2474 - val_accuracy: 0.9184\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1450 - accuracy: 0.95 - 0s 4ms/step - loss: 0.0896 - accuracy: 0.9617 - val_loss: 0.3196 - val_accuracy: 0.9286\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1195 - accuracy: 0.89 - 0s 4ms/step - loss: 0.0841 - accuracy: 0.9617 - val_loss: 0.3591 - val_accuracy: 0.9388\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0930 - accuracy: 0.95 - 0s 4ms/step - loss: 0.0725 - accuracy: 0.9643 - val_loss: 0.3731 - val_accuracy: 0.9286\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0491 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0798 - accuracy: 0.9694 - val_loss: 0.3761 - val_accuracy: 0.9286\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0574 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0718 - accuracy: 0.9668 - val_loss: 0.3172 - val_accuracy: 0.9388\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0784 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0719 - accuracy: 0.9694 - val_loss: 0.3218 - val_accuracy: 0.9388\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0871 - accuracy: 0.96 - 0s 4ms/step - loss: 0.0744 - accuracy: 0.9668 - val_loss: 0.4190 - val_accuracy: 0.9286\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0917 - accuracy: 0.95 - 0s 4ms/step - loss: 0.0655 - accuracy: 0.9694 - val_loss: 0.5775 - val_accuracy: 0.9184\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0892 - accuracy: 0.92 - 0s 4ms/step - loss: 0.0818 - accuracy: 0.9617 - val_loss: 0.4710 - val_accuracy: 0.9082\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0459 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0606 - accuracy: 0.9694 - val_loss: 0.4549 - val_accuracy: 0.9184\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0195 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0622 - accuracy: 0.9694 - val_loss: 0.4484 - val_accuracy: 0.9184\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0782 - accuracy: 0.96 - 0s 4ms/step - loss: 0.0682 - accuracy: 0.9668 - val_loss: 0.4531 - val_accuracy: 0.9286\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1029 - accuracy: 0.96 - 0s 4ms/step - loss: 0.0692 - accuracy: 0.9643 - val_loss: 0.4934 - val_accuracy: 0.9184\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0734 - accuracy: 0.95 - 0s 4ms/step - loss: 0.0592 - accuracy: 0.9694 - val_loss: 0.6461 - val_accuracy: 0.9184\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0248 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0656 - accuracy: 0.9694 - val_loss: 0.7193 - val_accuracy: 0.9082\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0253 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0542 - accuracy: 0.9745 - val_loss: 0.8218 - val_accuracy: 0.9082\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN98\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                             | 99/169 [10:32<06:39,  5.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_99\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_396 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_397 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_398 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_399 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.7580 - accuracy: 0.53 - 0s 25ms/step - loss: 0.3120 - accuracy: 0.8759 - val_loss: 0.3406 - val_accuracy: 0.8485\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1451 - accuracy: 0.93 - 0s 5ms/step - loss: 0.1663 - accuracy: 0.9114 - val_loss: 0.3294 - val_accuracy: 0.9192\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2948 - accuracy: 0.90 - 0s 5ms/step - loss: 0.1410 - accuracy: 0.9443 - val_loss: 0.2269 - val_accuracy: 0.9495\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0936 - accuracy: 0.95 - 0s 5ms/step - loss: 0.0810 - accuracy: 0.9722 - val_loss: 0.2322 - val_accuracy: 0.9495\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0883 - accuracy: 0.96 - 0s 5ms/step - loss: 0.0786 - accuracy: 0.9595 - val_loss: 0.2616 - val_accuracy: 0.9495\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0764 - accuracy: 0.95 - 0s 5ms/step - loss: 0.0791 - accuracy: 0.9646 - val_loss: 0.2485 - val_accuracy: 0.9495\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0461 - accuracy: 0.98 - 0s 5ms/step - loss: 0.0739 - accuracy: 0.9696 - val_loss: 0.2528 - val_accuracy: 0.9495\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0234 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0662 - accuracy: 0.9722 - val_loss: 0.2698 - val_accuracy: 0.9495\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0834 - accuracy: 0.95 - 0s 4ms/step - loss: 0.0637 - accuracy: 0.9747 - val_loss: 0.2747 - val_accuracy: 0.9495\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0363 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0672 - accuracy: 0.9722 - val_loss: 0.2909 - val_accuracy: 0.9394\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0588 - accuracy: 0.98 - 0s 5ms/step - loss: 0.0726 - accuracy: 0.9747 - val_loss: 0.2593 - val_accuracy: 0.9394\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0669 - accuracy: 0.95 - 0s 4ms/step - loss: 0.0731 - accuracy: 0.9696 - val_loss: 0.2616 - val_accuracy: 0.9394\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1109 - accuracy: 0.93 - 0s 4ms/step - loss: 0.0676 - accuracy: 0.9722 - val_loss: 0.2944 - val_accuracy: 0.9394\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0242 - accuracy: 1.00 - 0s 5ms/step - loss: 0.0673 - accuracy: 0.9722 - val_loss: 0.3083 - val_accuracy: 0.9394\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0214 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0590 - accuracy: 0.9747 - val_loss: 0.3124 - val_accuracy: 0.9394\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0601 - accuracy: 0.95 - 0s 4ms/step - loss: 0.0568 - accuracy: 0.9722 - val_loss: 0.3301 - val_accuracy: 0.9394\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0313 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0541 - accuracy: 0.9823 - val_loss: 0.3502 - val_accuracy: 0.9394\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0266 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0511 - accuracy: 0.9823 - val_loss: 0.3596 - val_accuracy: 0.9293\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0362 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0523 - accuracy: 0.9747 - val_loss: 0.3893 - val_accuracy: 0.9495\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0643 - accuracy: 0.96 - 0s 5ms/step - loss: 0.0431 - accuracy: 0.9823 - val_loss: 0.4378 - val_accuracy: 0.9495\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN99\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                            | 100/169 [10:38<06:37,  5.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_100\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_400 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_401 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_402 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_403 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.8313 - accuracy: 0.20 - 0s 19ms/step - loss: 0.6705 - accuracy: 0.7384 - val_loss: 0.5908 - val_accuracy: 0.8440\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.5909 - accuracy: 0.84 - 0s 4ms/step - loss: 0.5596 - accuracy: 0.8403 - val_loss: 0.5200 - val_accuracy: 0.8440\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.5407 - accuracy: 0.81 - 0s 4ms/step - loss: 0.5007 - accuracy: 0.8403 - val_loss: 0.4757 - val_accuracy: 0.8440\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.4612 - accuracy: 0.85 - 0s 4ms/step - loss: 0.4688 - accuracy: 0.8403 - val_loss: 0.4507 - val_accuracy: 0.8440\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.4697 - accuracy: 0.82 - 0s 5ms/step - loss: 0.4503 - accuracy: 0.8403 - val_loss: 0.4394 - val_accuracy: 0.8440\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.4182 - accuracy: 0.85 - 0s 5ms/step - loss: 0.4425 - accuracy: 0.8403 - val_loss: 0.4348 - val_accuracy: 0.8440\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.4828 - accuracy: 0.81 - 0s 4ms/step - loss: 0.4390 - accuracy: 0.8403 - val_loss: 0.4334 - val_accuracy: 0.8440\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.3589 - accuracy: 0.89 - 0s 4ms/step - loss: 0.4394 - accuracy: 0.8403 - val_loss: 0.4329 - val_accuracy: 0.8440\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.3031 - accuracy: 0.92 - 0s 4ms/step - loss: 0.4398 - accuracy: 0.8403 - val_loss: 0.4330 - val_accuracy: 0.8440\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.3532 - accuracy: 0.89 - 0s 4ms/step - loss: 0.4395 - accuracy: 0.8403 - val_loss: 0.4329 - val_accuracy: 0.8440\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.4868 - accuracy: 0.81 - 0s 5ms/step - loss: 0.4394 - accuracy: 0.8403 - val_loss: 0.4329 - val_accuracy: 0.8440\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.4868 - accuracy: 0.81 - 0s 5ms/step - loss: 0.4397 - accuracy: 0.8403 - val_loss: 0.4329 - val_accuracy: 0.8440\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.4071 - accuracy: 0.85 - 0s 6ms/step - loss: 0.4393 - accuracy: 0.8403 - val_loss: 0.4329 - val_accuracy: 0.8440\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.4334 - accuracy: 0.84 - 0s 6ms/step - loss: 0.4392 - accuracy: 0.8403 - val_loss: 0.4329 - val_accuracy: 0.8440\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.4859 - accuracy: 0.81 - 0s 5ms/step - loss: 0.4393 - accuracy: 0.8403 - val_loss: 0.4330 - val_accuracy: 0.8440\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.4075 - accuracy: 0.85 - 0s 5ms/step - loss: 0.4392 - accuracy: 0.8403 - val_loss: 0.4330 - val_accuracy: 0.8440\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.3040 - accuracy: 0.92 - 0s 5ms/step - loss: 0.4394 - accuracy: 0.8403 - val_loss: 0.4329 - val_accuracy: 0.8440\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.3812 - accuracy: 0.87 - 0s 6ms/step - loss: 0.4392 - accuracy: 0.8403 - val_loss: 0.4330 - val_accuracy: 0.8440\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.3295 - accuracy: 0.90 - 0s 6ms/step - loss: 0.4392 - accuracy: 0.8403 - val_loss: 0.4330 - val_accuracy: 0.8440\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.4852 - accuracy: 0.81 - 0s 5ms/step - loss: 0.4392 - accuracy: 0.8403 - val_loss: 0.4330 - val_accuracy: 0.8440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                           | 101/169 [10:45<07:04,  6.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_101\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_404 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_405 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_406 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_407 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 1.8603 - accuracy: 0.14 - 0s 26ms/step - loss: 0.7738 - accuracy: 0.6931 - val_loss: 0.2201 - val_accuracy: 0.8922\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.3540 - accuracy: 0.82 - 0s 5ms/step - loss: 0.1556 - accuracy: 0.8936 - val_loss: 0.1085 - val_accuracy: 0.8922\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0834 - accuracy: 0.96 - 0s 5ms/step - loss: 0.1287 - accuracy: 0.8936 - val_loss: 0.1097 - val_accuracy: 0.8922\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1284 - accuracy: 0.90 - 0s 10ms/step - loss: 0.1279 - accuracy: 0.8936 - val_loss: 0.1076 - val_accuracy: 0.8922\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1275 - accuracy: 0.90 - 0s 8ms/step - loss: 0.1256 - accuracy: 0.8936 - val_loss: 0.1035 - val_accuracy: 0.8922\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0713 - accuracy: 0.92 - 0s 5ms/step - loss: 0.1223 - accuracy: 0.8936 - val_loss: 0.0983 - val_accuracy: 0.8922\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0661 - accuracy: 0.95 - 0s 5ms/step - loss: 0.1185 - accuracy: 0.8936 - val_loss: 0.0929 - val_accuracy: 0.8922\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0966 - accuracy: 0.93 - 0s 5ms/step - loss: 0.1155 - accuracy: 0.8936 - val_loss: 0.0876 - val_accuracy: 0.8922\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1495 - accuracy: 0.82 - 0s 5ms/step - loss: 0.1124 - accuracy: 0.8936 - val_loss: 0.0831 - val_accuracy: 0.8922\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0982 - accuracy: 0.90 - 0s 4ms/step - loss: 0.1099 - accuracy: 0.9158 - val_loss: 0.0789 - val_accuracy: 0.9902\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0963 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1077 - accuracy: 0.9480 - val_loss: 0.0752 - val_accuracy: 0.9902\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1122 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1060 - accuracy: 0.9480 - val_loss: 0.0725 - val_accuracy: 0.9902\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0779 - accuracy: 0.93 - 0s 4ms/step - loss: 0.1048 - accuracy: 0.9480 - val_loss: 0.0706 - val_accuracy: 0.9902\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1057 - accuracy: 0.93 - 0s 4ms/step - loss: 0.1041 - accuracy: 0.9480 - val_loss: 0.0682 - val_accuracy: 0.9902\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0834 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1030 - accuracy: 0.9480 - val_loss: 0.0660 - val_accuracy: 0.9902\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0941 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1024 - accuracy: 0.9480 - val_loss: 0.0637 - val_accuracy: 0.9902\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1563 - accuracy: 0.89 - 0s 7ms/step - loss: 0.1017 - accuracy: 0.9480 - val_loss: 0.0624 - val_accuracy: 0.9902\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1347 - accuracy: 0.90 - 0s 4ms/step - loss: 0.1013 - accuracy: 0.9480 - val_loss: 0.0611 - val_accuracy: 0.9902\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0826 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1011 - accuracy: 0.9480 - val_loss: 0.0599 - val_accuracy: 0.9902\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0437 - accuracy: 1.00 - 0s 4ms/step - loss: 0.1009 - accuracy: 0.9480 - val_loss: 0.0588 - val_accuracy: 0.9902\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN101\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                           | 102/169 [10:52<07:05,  6.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_102\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_408 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_409 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_410 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_411 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.7166 - accuracy: 0.35 - 0s 19ms/step - loss: 0.4743 - accuracy: 0.7596 - val_loss: 0.2370 - val_accuracy: 0.8476\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2271 - accuracy: 0.85 - 0s 4ms/step - loss: 0.1916 - accuracy: 0.8462 - val_loss: 0.1847 - val_accuracy: 0.8476\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1569 - accuracy: 0.85 - 0s 4ms/step - loss: 0.1600 - accuracy: 0.8462 - val_loss: 0.1810 - val_accuracy: 0.8476\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1648 - accuracy: 0.84 - 0s 4ms/step - loss: 0.1489 - accuracy: 0.8462 - val_loss: 0.1888 - val_accuracy: 0.8476\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1493 - accuracy: 0.82 - 0s 4ms/step - loss: 0.1370 - accuracy: 0.8702 - val_loss: 0.1938 - val_accuracy: 0.9429\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1442 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1279 - accuracy: 0.9591 - val_loss: 0.1308 - val_accuracy: 0.9429\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0896 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1208 - accuracy: 0.9567 - val_loss: 0.1316 - val_accuracy: 0.9429\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1192 - accuracy: 0.98 - 0s 4ms/step - loss: 0.1151 - accuracy: 0.9567 - val_loss: 0.1280 - val_accuracy: 0.9429\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1111 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1103 - accuracy: 0.9591 - val_loss: 0.1241 - val_accuracy: 0.9524\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0938 - accuracy: 0.98 - 0s 4ms/step - loss: 0.1043 - accuracy: 0.9615 - val_loss: 0.1156 - val_accuracy: 0.9524\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0756 - accuracy: 0.98 - 0s 4ms/step - loss: 0.1012 - accuracy: 0.9615 - val_loss: 0.1175 - val_accuracy: 0.9429\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1273 - accuracy: 0.95 - 0s 4ms/step - loss: 0.0997 - accuracy: 0.9615 - val_loss: 0.1171 - val_accuracy: 0.9429\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0648 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0987 - accuracy: 0.9615 - val_loss: 0.1155 - val_accuracy: 0.9429\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1526 - accuracy: 0.92 - 0s 4ms/step - loss: 0.0977 - accuracy: 0.9615 - val_loss: 0.1147 - val_accuracy: 0.9524\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0969 - accuracy: 0.96 - 0s 4ms/step - loss: 0.0974 - accuracy: 0.9615 - val_loss: 0.1139 - val_accuracy: 0.9524\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1238 - accuracy: 0.93 - 0s 4ms/step - loss: 0.0968 - accuracy: 0.9615 - val_loss: 0.1136 - val_accuracy: 0.9524\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1221 - accuracy: 0.95 - 0s 4ms/step - loss: 0.0967 - accuracy: 0.9615 - val_loss: 0.1132 - val_accuracy: 0.9524\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0978 - accuracy: 0.95 - 0s 4ms/step - loss: 0.0965 - accuracy: 0.9615 - val_loss: 0.1127 - val_accuracy: 0.9524\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0942 - accuracy: 0.95 - 0s 4ms/step - loss: 0.0964 - accuracy: 0.9615 - val_loss: 0.1123 - val_accuracy: 0.9524\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0935 - accuracy: 0.96 - 0s 4ms/step - loss: 0.0964 - accuracy: 0.9615 - val_loss: 0.1118 - val_accuracy: 0.9524\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN102\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                           | 103/169 [10:58<06:48,  6.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_103\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_412 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_413 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_414 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_415 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.7681 - accuracy: 0.31 - 0s 22ms/step - loss: 0.4644 - accuracy: 0.7580 - val_loss: 0.3029 - val_accuracy: 0.8511\n",
      "Epoch 2/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.3210 - accuracy: 0.81 - 0s 4ms/step - loss: 0.1814 - accuracy: 0.8511 - val_loss: 0.3247 - val_accuracy: 0.8511\n",
      "Epoch 3/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.2370 - accuracy: 0.75 - 0s 4ms/step - loss: 0.1340 - accuracy: 0.8883 - val_loss: 0.3722 - val_accuracy: 0.9468\n",
      "Epoch 4/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1350 - accuracy: 0.92 - 0s 4ms/step - loss: 0.0920 - accuracy: 0.9654 - val_loss: 0.4667 - val_accuracy: 0.9468\n",
      "Epoch 5/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1451 - accuracy: 0.95 - 0s 5ms/step - loss: 0.0917 - accuracy: 0.9681 - val_loss: 0.7191 - val_accuracy: 0.9362\n",
      "Epoch 6/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1107 - accuracy: 0.95 - 0s 5ms/step - loss: 0.0815 - accuracy: 0.9681 - val_loss: 0.8909 - val_accuracy: 0.9255\n",
      "Epoch 7/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0887 - accuracy: 0.96 - 0s 5ms/step - loss: 0.0736 - accuracy: 0.9707 - val_loss: 0.9476 - val_accuracy: 0.9255\n",
      "Epoch 8/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0841 - accuracy: 0.95 - 0s 4ms/step - loss: 0.0693 - accuracy: 0.9734 - val_loss: 1.1063 - val_accuracy: 0.9255\n",
      "Epoch 9/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0889 - accuracy: 0.96 - 0s 4ms/step - loss: 0.0675 - accuracy: 0.9681 - val_loss: 1.2481 - val_accuracy: 0.9255\n",
      "Epoch 10/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0208 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0605 - accuracy: 0.9761 - val_loss: 1.4611 - val_accuracy: 0.9255\n",
      "Epoch 11/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0151 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0560 - accuracy: 0.9761 - val_loss: 1.5673 - val_accuracy: 0.9255\n",
      "Epoch 12/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0414 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0520 - accuracy: 0.9761 - val_loss: 1.6008 - val_accuracy: 0.9255\n",
      "Epoch 13/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0374 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0551 - accuracy: 0.9734 - val_loss: 1.6646 - val_accuracy: 0.9149\n",
      "Epoch 14/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0162 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0445 - accuracy: 0.9761 - val_loss: 1.7194 - val_accuracy: 0.9043\n",
      "Epoch 15/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0250 - accuracy: 0.98 - 0s 5ms/step - loss: 0.0422 - accuracy: 0.9814 - val_loss: 1.8652 - val_accuracy: 0.9043\n",
      "Epoch 16/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0506 - accuracy: 0.96 - 0s 4ms/step - loss: 0.0372 - accuracy: 0.9787 - val_loss: 1.9747 - val_accuracy: 0.8936\n",
      "Epoch 17/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0292 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0323 - accuracy: 0.9840 - val_loss: 2.1442 - val_accuracy: 0.8936\n",
      "Epoch 18/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0217 - accuracy: 1.00 - 0s 5ms/step - loss: 0.0283 - accuracy: 0.9973 - val_loss: 2.3798 - val_accuracy: 0.8936\n",
      "Epoch 19/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0200 - accuracy: 1.00 - 0s 5ms/step - loss: 0.0268 - accuracy: 0.9840 - val_loss: 2.4590 - val_accuracy: 0.8936\n",
      "Epoch 20/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0244 - accuracy: 0.98 - 0s 5ms/step - loss: 0.0218 - accuracy: 0.9920 - val_loss: 2.4736 - val_accuracy: 0.9043\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN103\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                          | 104/169 [11:03<06:32,  6.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_104\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_416 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_417 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_418 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_419 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.6997 - accuracy: 0.60 - 0s 15ms/step - loss: 0.6604 - accuracy: 0.6061 - val_loss: 0.5955 - val_accuracy: 0.6043\n",
      "Epoch 2/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.5842 - accuracy: 0.51 - 0s 3ms/step - loss: 0.5663 - accuracy: 0.6061 - val_loss: 0.5411 - val_accuracy: 0.7626\n",
      "Epoch 3/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.4593 - accuracy: 0.81 - 0s 3ms/step - loss: 0.5006 - accuracy: 0.7572 - val_loss: 0.5465 - val_accuracy: 0.7122\n",
      "Epoch 4/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.4358 - accuracy: 0.75 - 0s 4ms/step - loss: 0.4457 - accuracy: 0.8022 - val_loss: 0.4971 - val_accuracy: 0.7410\n",
      "Epoch 5/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.3716 - accuracy: 0.87 - 0s 3ms/step - loss: 0.4197 - accuracy: 0.8201 - val_loss: 0.5093 - val_accuracy: 0.7554\n",
      "Epoch 6/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.4336 - accuracy: 0.76 - 0s 3ms/step - loss: 0.3686 - accuracy: 0.8417 - val_loss: 0.6094 - val_accuracy: 0.7410\n",
      "Epoch 7/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.4094 - accuracy: 0.81 - 0s 3ms/step - loss: 0.3429 - accuracy: 0.8561 - val_loss: 0.5945 - val_accuracy: 0.7266\n",
      "Epoch 8/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.4424 - accuracy: 0.78 - 0s 3ms/step - loss: 0.3930 - accuracy: 0.8327 - val_loss: 0.5473 - val_accuracy: 0.7626\n",
      "Epoch 9/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.3227 - accuracy: 0.87 - 0s 3ms/step - loss: 0.3555 - accuracy: 0.8399 - val_loss: 0.4666 - val_accuracy: 0.8058\n",
      "Epoch 10/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.3201 - accuracy: 0.84 - 0s 3ms/step - loss: 0.4371 - accuracy: 0.8309 - val_loss: 0.5266 - val_accuracy: 0.7194\n",
      "Epoch 11/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.3643 - accuracy: 0.81 - 0s 4ms/step - loss: 0.3834 - accuracy: 0.8237 - val_loss: 0.5951 - val_accuracy: 0.7266\n",
      "Epoch 12/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.3892 - accuracy: 0.79 - 0s 4ms/step - loss: 0.3661 - accuracy: 0.8417 - val_loss: 0.4867 - val_accuracy: 0.7770\n",
      "Epoch 13/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.3828 - accuracy: 0.81 - 0s 3ms/step - loss: 0.3603 - accuracy: 0.8291 - val_loss: 0.4810 - val_accuracy: 0.7842\n",
      "Epoch 14/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.3112 - accuracy: 0.87 - 0s 3ms/step - loss: 0.3181 - accuracy: 0.8561 - val_loss: 0.4876 - val_accuracy: 0.7626\n",
      "Epoch 15/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.3189 - accuracy: 0.82 - 0s 4ms/step - loss: 0.3027 - accuracy: 0.8687 - val_loss: 0.5898 - val_accuracy: 0.7698\n",
      "Epoch 16/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2616 - accuracy: 0.90 - 0s 3ms/step - loss: 0.2823 - accuracy: 0.8813 - val_loss: 0.5949 - val_accuracy: 0.7698\n",
      "Epoch 17/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.3214 - accuracy: 0.84 - 0s 3ms/step - loss: 0.2795 - accuracy: 0.8849 - val_loss: 0.5544 - val_accuracy: 0.8129\n",
      "Epoch 18/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.3229 - accuracy: 0.84 - 0s 3ms/step - loss: 0.2723 - accuracy: 0.8885 - val_loss: 0.6477 - val_accuracy: 0.7842\n",
      "Epoch 19/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2435 - accuracy: 0.90 - 0s 3ms/step - loss: 0.2552 - accuracy: 0.8993 - val_loss: 0.6456 - val_accuracy: 0.7842\n",
      "Epoch 20/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2848 - accuracy: 0.87 - 0s 3ms/step - loss: 0.2531 - accuracy: 0.9011 - val_loss: 0.9791 - val_accuracy: 0.7914\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN104\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                          | 105/169 [11:09<06:19,  5.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_105\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_420 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_421 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_422 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_423 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 1.0312 - accuracy: 0.32 - 0s 17ms/step - loss: 0.6974 - accuracy: 0.7263 - val_loss: 0.5978 - val_accuracy: 0.7949\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.5780 - accuracy: 0.84 - 0s 3ms/step - loss: 0.5683 - accuracy: 0.8082 - val_loss: 0.5143 - val_accuracy: 0.8462\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.4567 - accuracy: 0.90 - 0s 3ms/step - loss: 0.4904 - accuracy: 0.8276 - val_loss: 0.4416 - val_accuracy: 0.8547\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.4843 - accuracy: 0.82 - 0s 3ms/step - loss: 0.4326 - accuracy: 0.8534 - val_loss: 0.4854 - val_accuracy: 0.8718\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.3840 - accuracy: 0.87 - 0s 3ms/step - loss: 0.4408 - accuracy: 0.8513 - val_loss: 0.4397 - val_accuracy: 0.8120\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.3771 - accuracy: 0.89 - 0s 3ms/step - loss: 0.4190 - accuracy: 0.8556 - val_loss: 0.4068 - val_accuracy: 0.8547\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.4023 - accuracy: 0.84 - 0s 3ms/step - loss: 0.3519 - accuracy: 0.8879 - val_loss: 0.4209 - val_accuracy: 0.8376\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.4205 - accuracy: 0.85 - 0s 3ms/step - loss: 0.3405 - accuracy: 0.8901 - val_loss: 0.3959 - val_accuracy: 0.8632\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.4932 - accuracy: 0.79 - 0s 3ms/step - loss: 0.3183 - accuracy: 0.9009 - val_loss: 0.4090 - val_accuracy: 0.8718\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.3720 - accuracy: 0.87 - 0s 3ms/step - loss: 0.3072 - accuracy: 0.9030 - val_loss: 0.4474 - val_accuracy: 0.8632\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2751 - accuracy: 0.90 - 0s 3ms/step - loss: 0.2991 - accuracy: 0.9030 - val_loss: 0.4310 - val_accuracy: 0.8462\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1976 - accuracy: 0.95 - 0s 3ms/step - loss: 0.2913 - accuracy: 0.9116 - val_loss: 0.4719 - val_accuracy: 0.8547\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2687 - accuracy: 0.92 - 0s 3ms/step - loss: 0.2870 - accuracy: 0.9116 - val_loss: 0.4814 - val_accuracy: 0.8632\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1632 - accuracy: 0.96 - 0s 3ms/step - loss: 0.3148 - accuracy: 0.9030 - val_loss: 0.4583 - val_accuracy: 0.8376\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.3146 - accuracy: 0.89 - 0s 3ms/step - loss: 0.3185 - accuracy: 0.8966 - val_loss: 0.5377 - val_accuracy: 0.8291\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2231 - accuracy: 0.93 - 0s 3ms/step - loss: 0.3212 - accuracy: 0.8944 - val_loss: 0.4616 - val_accuracy: 0.8462\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.3241 - accuracy: 0.89 - 0s 3ms/step - loss: 0.2939 - accuracy: 0.9073 - val_loss: 0.4457 - val_accuracy: 0.8718\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.3334 - accuracy: 0.89 - 0s 4ms/step - loss: 0.2989 - accuracy: 0.9095 - val_loss: 0.4376 - val_accuracy: 0.8803\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2321 - accuracy: 0.93 - 0s 3ms/step - loss: 0.2830 - accuracy: 0.9116 - val_loss: 0.4810 - val_accuracy: 0.8632\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2411 - accuracy: 0.93 - 0s 3ms/step - loss: 0.2814 - accuracy: 0.9116 - val_loss: 0.4891 - val_accuracy: 0.8632\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN105\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                         | 106/169 [11:15<06:10,  5.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_106\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_424 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_425 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_426 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_427 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.7213 - accuracy: 0.51 - 0s 16ms/step - loss: 0.4886 - accuracy: 0.7576 - val_loss: 0.3695 - val_accuracy: 0.7826\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.3371 - accuracy: 0.79 - 0s 3ms/step - loss: 0.2979 - accuracy: 0.7838 - val_loss: 0.3695 - val_accuracy: 0.7826\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2638 - accuracy: 0.73 - 0s 3ms/step - loss: 0.2403 - accuracy: 0.8384 - val_loss: 0.4894 - val_accuracy: 0.8522\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1676 - accuracy: 0.96 - 0s 3ms/step - loss: 0.2131 - accuracy: 0.9170 - val_loss: 0.4583 - val_accuracy: 0.8609\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1128 - accuracy: 0.98 - 0s 4ms/step - loss: 0.1749 - accuracy: 0.9345 - val_loss: 0.4962 - val_accuracy: 0.8870\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2609 - accuracy: 0.89 - 0s 4ms/step - loss: 0.1531 - accuracy: 0.9345 - val_loss: 0.6438 - val_accuracy: 0.8522\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1820 - accuracy: 0.90 - 0s 4ms/step - loss: 0.1382 - accuracy: 0.9476 - val_loss: 0.6966 - val_accuracy: 0.8435\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1800 - accuracy: 0.92 - 0s 4ms/step - loss: 0.1144 - accuracy: 0.9520 - val_loss: 0.7519 - val_accuracy: 0.8609\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1047 - accuracy: 0.96 - 0s 3ms/step - loss: 0.1224 - accuracy: 0.9498 - val_loss: 0.9805 - val_accuracy: 0.8522\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0924 - accuracy: 0.98 - 0s 4ms/step - loss: 0.1456 - accuracy: 0.9563 - val_loss: 0.4808 - val_accuracy: 0.8348\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0971 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1094 - accuracy: 0.9607 - val_loss: 0.9115 - val_accuracy: 0.8609\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0313 - accuracy: 1.00 - 0s 3ms/step - loss: 0.1546 - accuracy: 0.9541 - val_loss: 0.5630 - val_accuracy: 0.8435\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1185 - accuracy: 0.93 - 0s 3ms/step - loss: 0.1050 - accuracy: 0.9563 - val_loss: 0.5570 - val_accuracy: 0.8522\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0923 - accuracy: 0.95 - 0s 4ms/step - loss: 0.0708 - accuracy: 0.9672 - val_loss: 0.7808 - val_accuracy: 0.8696\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0331 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0557 - accuracy: 0.9803 - val_loss: 0.8314 - val_accuracy: 0.8609\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0764 - accuracy: 0.96 - 0s 4ms/step - loss: 0.0487 - accuracy: 0.9803 - val_loss: 0.9472 - val_accuracy: 0.8522\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0987 - accuracy: 0.95 - 0s 4ms/step - loss: 0.0373 - accuracy: 0.9869 - val_loss: 1.0201 - val_accuracy: 0.8696\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0107 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0251 - accuracy: 0.9913 - val_loss: 1.0789 - val_accuracy: 0.8609\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0409 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0217 - accuracy: 0.9913 - val_loss: 1.3229 - val_accuracy: 0.8522\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0207 - accuracy: 1.00 - 0s 3ms/step - loss: 0.0157 - accuracy: 0.9956 - val_loss: 1.3337 - val_accuracy: 0.8522\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN106\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                         | 107/169 [11:20<05:59,  5.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_107\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_428 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_429 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_430 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_431 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.6505 - accuracy: 0.65 - 0s 18ms/step - loss: 0.5278 - accuracy: 0.7354 - val_loss: 0.4576 - val_accuracy: 0.7944\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.4300 - accuracy: 0.82 - 0s 4ms/step - loss: 0.4108 - accuracy: 0.8244 - val_loss: 0.4171 - val_accuracy: 0.8318\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.3721 - accuracy: 0.76 - 0s 4ms/step - loss: 0.3179 - accuracy: 0.8501 - val_loss: 0.4075 - val_accuracy: 0.8224\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2486 - accuracy: 0.90 - 0s 4ms/step - loss: 0.2797 - accuracy: 0.8829 - val_loss: 0.5134 - val_accuracy: 0.8411\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2096 - accuracy: 0.92 - 0s 4ms/step - loss: 0.2275 - accuracy: 0.9110 - val_loss: 0.6326 - val_accuracy: 0.8131\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1217 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1959 - accuracy: 0.9251 - val_loss: 0.7322 - val_accuracy: 0.8318\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1755 - accuracy: 0.92 - 0s 4ms/step - loss: 0.1574 - accuracy: 0.9344 - val_loss: 0.9007 - val_accuracy: 0.8318\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0959 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1161 - accuracy: 0.9461 - val_loss: 0.8949 - val_accuracy: 0.8224\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1754 - accuracy: 0.93 - 0s 4ms/step - loss: 0.1098 - accuracy: 0.9602 - val_loss: 1.0186 - val_accuracy: 0.8411\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0584 - accuracy: 0.96 - 0s 4ms/step - loss: 0.0868 - accuracy: 0.9508 - val_loss: 0.9275 - val_accuracy: 0.8318\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0580 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1149 - accuracy: 0.9555 - val_loss: 1.1889 - val_accuracy: 0.8411\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0296 - accuracy: 1.00 - 0s 4ms/step - loss: 0.1170 - accuracy: 0.9555 - val_loss: 0.9395 - val_accuracy: 0.8224\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0441 - accuracy: 1.00 - 0s 4ms/step - loss: 0.1222 - accuracy: 0.9649 - val_loss: 1.2805 - val_accuracy: 0.8598\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2134 - accuracy: 0.92 - 0s 5ms/step - loss: 0.1303 - accuracy: 0.9485 - val_loss: 1.4302 - val_accuracy: 0.8318\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0587 - accuracy: 0.96 - 0s 4ms/step - loss: 0.0973 - accuracy: 0.9532 - val_loss: 1.2897 - val_accuracy: 0.8411\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0875 - accuracy: 0.95 - 0s 4ms/step - loss: 0.0668 - accuracy: 0.9672 - val_loss: 1.7323 - val_accuracy: 0.8224\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0367 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0423 - accuracy: 0.9859 - val_loss: 1.7250 - val_accuracy: 0.8411\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0213 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0355 - accuracy: 0.9859 - val_loss: 1.9564 - val_accuracy: 0.8131\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0104 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0229 - accuracy: 0.9977 - val_loss: 2.1183 - val_accuracy: 0.8224\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0095 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0299 - accuracy: 0.9930 - val_loss: 2.0933 - val_accuracy: 0.8224\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN107\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                         | 108/169 [11:26<05:51,  5.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_108\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_432 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_433 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_434 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_435 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.6435 - accuracy: 0.6562WARNING:tensorflow:Callbacks method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_begin` time: 0.0010s). Check your callbacks.\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.4850 - accuracy: 0.7780 - val_loss: 0.3797 - val_accuracy: 0.7944\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.3554 - accuracy: 0.79 - 0s 4ms/step - loss: 0.3598 - accuracy: 0.7944 - val_loss: 0.3507 - val_accuracy: 0.7944\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2794 - accuracy: 0.82 - 0s 4ms/step - loss: 0.2913 - accuracy: 0.8271 - val_loss: 0.3456 - val_accuracy: 0.8224\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2128 - accuracy: 0.89 - 0s 4ms/step - loss: 0.2517 - accuracy: 0.8925 - val_loss: 0.3877 - val_accuracy: 0.7850\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2210 - accuracy: 0.92 - 0s 4ms/step - loss: 0.2121 - accuracy: 0.9206 - val_loss: 0.4180 - val_accuracy: 0.8131\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1815 - accuracy: 0.93 - 0s 4ms/step - loss: 0.1975 - accuracy: 0.9229 - val_loss: 0.4168 - val_accuracy: 0.8037\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1276 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1676 - accuracy: 0.9463 - val_loss: 0.4564 - val_accuracy: 0.8131\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1989 - accuracy: 0.92 - 0s 4ms/step - loss: 0.1439 - accuracy: 0.9509 - val_loss: 0.5111 - val_accuracy: 0.8224\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1582 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1312 - accuracy: 0.9579 - val_loss: 0.5174 - val_accuracy: 0.8131\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1151 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1286 - accuracy: 0.9556 - val_loss: 0.5101 - val_accuracy: 0.8224\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0869 - accuracy: 0.98 - 0s 4ms/step - loss: 0.1146 - accuracy: 0.9626 - val_loss: 0.4810 - val_accuracy: 0.8318\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0639 - accuracy: 1.00 - 0s 4ms/step - loss: 0.1298 - accuracy: 0.9626 - val_loss: 0.5820 - val_accuracy: 0.8131\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0865 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1336 - accuracy: 0.9556 - val_loss: 0.6191 - val_accuracy: 0.7944\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0971 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1188 - accuracy: 0.9579 - val_loss: 0.7427 - val_accuracy: 0.8131\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0813 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1131 - accuracy: 0.9579 - val_loss: 0.7594 - val_accuracy: 0.7850\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1651 - accuracy: 0.93 - 0s 4ms/step - loss: 0.0938 - accuracy: 0.9720 - val_loss: 0.7804 - val_accuracy: 0.7757\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1036 - accuracy: 0.96 - 0s 5ms/step - loss: 0.0799 - accuracy: 0.9790 - val_loss: 0.7912 - val_accuracy: 0.7383\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0696 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0786 - accuracy: 0.9766 - val_loss: 0.8068 - val_accuracy: 0.7570\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0652 - accuracy: 0.98 - 0s 5ms/step - loss: 0.1013 - accuracy: 0.9673 - val_loss: 0.7225 - val_accuracy: 0.7944\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1450 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1287 - accuracy: 0.9626 - val_loss: 0.8765 - val_accuracy: 0.7944\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN108\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                        | 109/169 [11:32<05:45,  5.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_109\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_436 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_437 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_438 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_439 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.7967 - accuracy: 0.32 - 0s 19ms/step - loss: 0.6011 - accuracy: 0.6425 - val_loss: 0.5505 - val_accuracy: 0.7222\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.4657 - accuracy: 0.68 - 0s 4ms/step - loss: 0.4159 - accuracy: 0.7220 - val_loss: 0.6030 - val_accuracy: 0.7222\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.4413 - accuracy: 0.62 - 0s 4ms/step - loss: 0.3684 - accuracy: 0.7220 - val_loss: 0.7244 - val_accuracy: 0.7222\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2441 - accuracy: 0.79 - 0s 5ms/step - loss: 0.3164 - accuracy: 0.8061 - val_loss: 0.8058 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2713 - accuracy: 0.87 - 0s 4ms/step - loss: 0.3015 - accuracy: 0.8621 - val_loss: 0.9161 - val_accuracy: 0.7315\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.3224 - accuracy: 0.82 - 0s 4ms/step - loss: 0.2688 - accuracy: 0.8832 - val_loss: 0.8969 - val_accuracy: 0.7500\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1874 - accuracy: 0.96 - 0s 5ms/step - loss: 0.2491 - accuracy: 0.9019 - val_loss: 1.0029 - val_accuracy: 0.7407\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1685 - accuracy: 0.93 - 0s 4ms/step - loss: 0.2050 - accuracy: 0.9182 - val_loss: 1.0750 - val_accuracy: 0.7593\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1857 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1837 - accuracy: 0.9346 - val_loss: 1.3224 - val_accuracy: 0.7407\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1876 - accuracy: 0.92 - 0s 4ms/step - loss: 0.1662 - accuracy: 0.9416 - val_loss: 1.4798 - val_accuracy: 0.7315\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1148 - accuracy: 0.98 - 0s 4ms/step - loss: 0.1630 - accuracy: 0.9416 - val_loss: 2.0601 - val_accuracy: 0.7407\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1857 - accuracy: 0.92 - 0s 4ms/step - loss: 0.2408 - accuracy: 0.9229 - val_loss: 1.8115 - val_accuracy: 0.7500\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1499 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1605 - accuracy: 0.9439 - val_loss: 1.7834 - val_accuracy: 0.7500\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1517 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1604 - accuracy: 0.9439 - val_loss: 1.9220 - val_accuracy: 0.7685\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0871 - accuracy: 0.98 - 0s 4ms/step - loss: 0.1423 - accuracy: 0.9486 - val_loss: 2.2166 - val_accuracy: 0.7407\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0480 - accuracy: 1.00 - 0s 4ms/step - loss: 0.1393 - accuracy: 0.9556 - val_loss: 2.1713 - val_accuracy: 0.7407\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0664 - accuracy: 0.98 - 0s 4ms/step - loss: 0.1354 - accuracy: 0.9533 - val_loss: 2.2871 - val_accuracy: 0.7593\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0777 - accuracy: 0.98 - 0s 4ms/step - loss: 0.1323 - accuracy: 0.9556 - val_loss: 2.5414 - val_accuracy: 0.7685\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0947 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1352 - accuracy: 0.9556 - val_loss: 2.8071 - val_accuracy: 0.7778\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1088 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1337 - accuracy: 0.9533 - val_loss: 2.8831 - val_accuracy: 0.7685\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN109\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                        | 110/169 [11:38<05:47,  5.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_110\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_440 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_441 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_442 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_443 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.6921 - accuracy: 0.53 - 0s 19ms/step - loss: 0.5454 - accuracy: 0.7678 - val_loss: 0.4243 - val_accuracy: 0.7982\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.3671 - accuracy: 0.85 - 0s 3ms/step - loss: 0.4023 - accuracy: 0.8000 - val_loss: 0.4491 - val_accuracy: 0.7982\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.3237 - accuracy: 0.81 - 0s 4ms/step - loss: 0.3258 - accuracy: 0.8000 - val_loss: 0.4717 - val_accuracy: 0.7982\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.3528 - accuracy: 0.76 - 0s 4ms/step - loss: 0.2956 - accuracy: 0.8000 - val_loss: 0.4982 - val_accuracy: 0.7982\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2209 - accuracy: 0.82 - 0s 4ms/step - loss: 0.2590 - accuracy: 0.8782 - val_loss: 0.5531 - val_accuracy: 0.8624\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2005 - accuracy: 0.90 - 0s 4ms/step - loss: 0.2123 - accuracy: 0.9195 - val_loss: 0.6147 - val_accuracy: 0.8716\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2377 - accuracy: 0.89 - 0s 4ms/step - loss: 0.1907 - accuracy: 0.9264 - val_loss: 0.7874 - val_accuracy: 0.8257\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1863 - accuracy: 0.92 - 0s 4ms/step - loss: 0.1913 - accuracy: 0.9195 - val_loss: 0.8840 - val_accuracy: 0.8532\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1767 - accuracy: 0.92 - 0s 4ms/step - loss: 0.1538 - accuracy: 0.9333 - val_loss: 0.8957 - val_accuracy: 0.8349\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1723 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1705 - accuracy: 0.9356 - val_loss: 1.2183 - val_accuracy: 0.8624\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1197 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1431 - accuracy: 0.9471 - val_loss: 1.4086 - val_accuracy: 0.8257\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1470 - accuracy: 0.93 - 0s 4ms/step - loss: 0.1578 - accuracy: 0.9356 - val_loss: 1.4812 - val_accuracy: 0.8807\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0930 - accuracy: 0.98 - 0s 4ms/step - loss: 0.1475 - accuracy: 0.9448 - val_loss: 1.3402 - val_accuracy: 0.8440\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1642 - accuracy: 0.93 - 0s 4ms/step - loss: 0.1373 - accuracy: 0.9517 - val_loss: 1.5809 - val_accuracy: 0.8440\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0811 - accuracy: 0.98 - 0s 4ms/step - loss: 0.1693 - accuracy: 0.9379 - val_loss: 1.3225 - val_accuracy: 0.8257\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0858 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1298 - accuracy: 0.9540 - val_loss: 1.2388 - val_accuracy: 0.8716\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0972 - accuracy: 0.98 - 0s 4ms/step - loss: 0.1113 - accuracy: 0.9632 - val_loss: 1.4893 - val_accuracy: 0.8349\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1292 - accuracy: 0.96 - 0s 4ms/step - loss: 0.0959 - accuracy: 0.9701 - val_loss: 1.6140 - val_accuracy: 0.8532\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1284 - accuracy: 0.95 - 0s 4ms/step - loss: 0.0956 - accuracy: 0.9724 - val_loss: 1.7320 - val_accuracy: 0.8349\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1114 - accuracy: 0.95 - 0s 4ms/step - loss: 0.0816 - accuracy: 0.9724 - val_loss: 1.9860 - val_accuracy: 0.8257\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN110\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                       | 111/169 [11:44<05:37,  5.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_111\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_444 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_445 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_446 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_447 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.8708 - accuracy: 0.32 - 0s 16ms/step - loss: 0.6866 - accuracy: 0.6537 - val_loss: 0.6269 - val_accuracy: 0.7054\n",
      "Epoch 2/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.6248 - accuracy: 0.73 - 0s 3ms/step - loss: 0.5919 - accuracy: 0.7626 - val_loss: 0.5443 - val_accuracy: 0.8062\n",
      "Epoch 3/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.4921 - accuracy: 0.81 - 0s 3ms/step - loss: 0.5068 - accuracy: 0.8171 - val_loss: 0.5333 - val_accuracy: 0.7442\n",
      "Epoch 4/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.5377 - accuracy: 0.71 - 0s 4ms/step - loss: 0.5047 - accuracy: 0.7685 - val_loss: 0.4941 - val_accuracy: 0.7674\n",
      "Epoch 5/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.5292 - accuracy: 0.70 - 0s 3ms/step - loss: 0.4659 - accuracy: 0.7918 - val_loss: 0.4483 - val_accuracy: 0.8062\n",
      "Epoch 6/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.4240 - accuracy: 0.84 - 0s 3ms/step - loss: 0.4243 - accuracy: 0.8288 - val_loss: 0.4796 - val_accuracy: 0.7674\n",
      "Epoch 7/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.4971 - accuracy: 0.81 - 0s 3ms/step - loss: 0.4126 - accuracy: 0.8327 - val_loss: 0.4591 - val_accuracy: 0.8062\n",
      "Epoch 8/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.3888 - accuracy: 0.84 - 0s 3ms/step - loss: 0.4270 - accuracy: 0.8463 - val_loss: 0.4823 - val_accuracy: 0.7752\n",
      "Epoch 9/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.3206 - accuracy: 0.87 - 0s 3ms/step - loss: 0.3879 - accuracy: 0.8521 - val_loss: 0.4721 - val_accuracy: 0.8062\n",
      "Epoch 10/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2778 - accuracy: 0.90 - 0s 3ms/step - loss: 0.3469 - accuracy: 0.8813 - val_loss: 0.4826 - val_accuracy: 0.7829\n",
      "Epoch 11/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2978 - accuracy: 0.90 - 0s 3ms/step - loss: 0.3087 - accuracy: 0.9008 - val_loss: 0.4668 - val_accuracy: 0.8295\n",
      "Epoch 12/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2918 - accuracy: 0.89 - 0s 4ms/step - loss: 0.2952 - accuracy: 0.9027 - val_loss: 0.4857 - val_accuracy: 0.7752\n",
      "Epoch 13/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2898 - accuracy: 0.90 - 0s 3ms/step - loss: 0.2672 - accuracy: 0.9222 - val_loss: 0.4949 - val_accuracy: 0.7984\n",
      "Epoch 14/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2801 - accuracy: 0.90 - 0s 3ms/step - loss: 0.2732 - accuracy: 0.9144 - val_loss: 0.5082 - val_accuracy: 0.7829\n",
      "Epoch 15/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1775 - accuracy: 0.96 - 0s 3ms/step - loss: 0.2658 - accuracy: 0.9105 - val_loss: 0.5327 - val_accuracy: 0.8140\n",
      "Epoch 16/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1768 - accuracy: 0.95 - 0s 3ms/step - loss: 0.2529 - accuracy: 0.9125 - val_loss: 0.5630 - val_accuracy: 0.7752\n",
      "Epoch 17/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2474 - accuracy: 0.93 - 0s 3ms/step - loss: 0.2448 - accuracy: 0.9280 - val_loss: 0.6561 - val_accuracy: 0.8372\n",
      "Epoch 18/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2648 - accuracy: 0.90 - 0s 3ms/step - loss: 0.2440 - accuracy: 0.9202 - val_loss: 0.5770 - val_accuracy: 0.7752\n",
      "Epoch 19/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.3203 - accuracy: 0.90 - 0s 3ms/step - loss: 0.2689 - accuracy: 0.9144 - val_loss: 0.6435 - val_accuracy: 0.7984\n",
      "Epoch 20/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.3793 - accuracy: 0.85 - 0s 3ms/step - loss: 0.2455 - accuracy: 0.9241 - val_loss: 0.5595 - val_accuracy: 0.7984\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN111\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                       | 112/169 [11:49<05:31,  5.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_112\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_448 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_449 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_450 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_451 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.6843 - accuracy: 0.57 - 0s 15ms/step - loss: 0.6404 - accuracy: 0.6131 - val_loss: 0.5928 - val_accuracy: 0.6138\n",
      "Epoch 2/20\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.4524 - accuracy: 0.71 - 0s 4ms/step - loss: 0.5006 - accuracy: 0.6926 - val_loss: 0.5315 - val_accuracy: 0.7724\n",
      "Epoch 3/20\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.4277 - accuracy: 0.76 - 0s 3ms/step - loss: 0.4353 - accuracy: 0.7807 - val_loss: 0.5060 - val_accuracy: 0.7586\n",
      "Epoch 4/20\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.4176 - accuracy: 0.78 - 0s 3ms/step - loss: 0.4116 - accuracy: 0.7772 - val_loss: 0.5704 - val_accuracy: 0.7379\n",
      "Epoch 5/20\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3573 - accuracy: 0.82 - 0s 3ms/step - loss: 0.3894 - accuracy: 0.8135 - val_loss: 0.5606 - val_accuracy: 0.7379\n",
      "Epoch 6/20\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3564 - accuracy: 0.82 - 0s 3ms/step - loss: 0.3855 - accuracy: 0.8066 - val_loss: 0.6026 - val_accuracy: 0.7724\n",
      "Epoch 7/20\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2711 - accuracy: 0.87 - 0s 3ms/step - loss: 0.3483 - accuracy: 0.8325 - val_loss: 0.5007 - val_accuracy: 0.7655\n",
      "Epoch 8/20\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3552 - accuracy: 0.84 - 0s 3ms/step - loss: 0.3307 - accuracy: 0.8256 - val_loss: 0.6452 - val_accuracy: 0.7310\n",
      "Epoch 9/20\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3181 - accuracy: 0.84 - 0s 3ms/step - loss: 0.2827 - accuracy: 0.8636 - val_loss: 0.6965 - val_accuracy: 0.7655\n",
      "Epoch 10/20\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2713 - accuracy: 0.89 - 0s 3ms/step - loss: 0.2586 - accuracy: 0.8826 - val_loss: 0.7160 - val_accuracy: 0.7862\n",
      "Epoch 11/20\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.4182 - accuracy: 0.82 - 0s 3ms/step - loss: 0.2592 - accuracy: 0.8722 - val_loss: 0.7545 - val_accuracy: 0.7655\n",
      "Epoch 12/20\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2387 - accuracy: 0.90 - 0s 4ms/step - loss: 0.2794 - accuracy: 0.8808 - val_loss: 0.7076 - val_accuracy: 0.7448\n",
      "Epoch 13/20\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1742 - accuracy: 0.92 - 0s 4ms/step - loss: 0.2559 - accuracy: 0.8929 - val_loss: 0.6913 - val_accuracy: 0.7655\n",
      "Epoch 14/20\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3375 - accuracy: 0.87 - 0s 4ms/step - loss: 0.2215 - accuracy: 0.9085 - val_loss: 0.7918 - val_accuracy: 0.7655\n",
      "Epoch 15/20\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1484 - accuracy: 0.92 - 0s 3ms/step - loss: 0.1664 - accuracy: 0.9223 - val_loss: 0.9130 - val_accuracy: 0.7517\n",
      "Epoch 16/20\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1104 - accuracy: 0.98 - 0s 3ms/step - loss: 0.1344 - accuracy: 0.9465 - val_loss: 1.3430 - val_accuracy: 0.7448\n",
      "Epoch 17/20\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1213 - accuracy: 0.95 - 0s 3ms/step - loss: 0.1545 - accuracy: 0.9396 - val_loss: 1.1615 - val_accuracy: 0.7241\n",
      "Epoch 18/20\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2006 - accuracy: 0.92 - 0s 3ms/step - loss: 0.1555 - accuracy: 0.9361 - val_loss: 1.5078 - val_accuracy: 0.7241\n",
      "Epoch 19/20\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0811 - accuracy: 0.96 - 0s 3ms/step - loss: 0.1513 - accuracy: 0.9378 - val_loss: 1.2660 - val_accuracy: 0.7172\n",
      "Epoch 20/20\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1442 - accuracy: 0.93 - 0s 3ms/step - loss: 0.1371 - accuracy: 0.9465 - val_loss: 1.4311 - val_accuracy: 0.7103\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN112\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                      | 113/169 [11:56<05:35,  5.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_113\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_452 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_453 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_454 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_455 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.6465 - accuracy: 0.70 - 0s 16ms/step - loss: 0.5916 - accuracy: 0.6979 - val_loss: 0.5264 - val_accuracy: 0.7015\n",
      "Epoch 2/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.5225 - accuracy: 0.73 - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7092 - val_loss: 0.5158 - val_accuracy: 0.7463\n",
      "Epoch 3/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.4045 - accuracy: 0.84 - 0s 3ms/step - loss: 0.4439 - accuracy: 0.7955 - val_loss: 0.5544 - val_accuracy: 0.7537\n",
      "Epoch 4/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.4781 - accuracy: 0.73 - 0s 3ms/step - loss: 0.4096 - accuracy: 0.8143 - val_loss: 0.6191 - val_accuracy: 0.7313\n",
      "Epoch 5/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.3974 - accuracy: 0.79 - 0s 3ms/step - loss: 0.3813 - accuracy: 0.8143 - val_loss: 0.5355 - val_accuracy: 0.7015\n",
      "Epoch 6/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.3697 - accuracy: 0.85 - 0s 3ms/step - loss: 0.3775 - accuracy: 0.8311 - val_loss: 0.7300 - val_accuracy: 0.7164\n",
      "Epoch 7/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.4247 - accuracy: 0.84 - 0s 3ms/step - loss: 0.3202 - accuracy: 0.8612 - val_loss: 0.5965 - val_accuracy: 0.7090\n",
      "Epoch 8/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.3148 - accuracy: 0.87 - 0s 3ms/step - loss: 0.3081 - accuracy: 0.8668 - val_loss: 0.6894 - val_accuracy: 0.7090\n",
      "Epoch 9/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2387 - accuracy: 0.93 - 0s 3ms/step - loss: 0.3255 - accuracy: 0.8518 - val_loss: 0.7192 - val_accuracy: 0.7015\n",
      "Epoch 10/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2601 - accuracy: 0.87 - 0s 3ms/step - loss: 0.2676 - accuracy: 0.8818 - val_loss: 0.8158 - val_accuracy: 0.7164\n",
      "Epoch 11/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2134 - accuracy: 0.92 - 0s 3ms/step - loss: 0.2171 - accuracy: 0.9193 - val_loss: 1.0368 - val_accuracy: 0.7164\n",
      "Epoch 12/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1404 - accuracy: 0.95 - 0s 3ms/step - loss: 0.1918 - accuracy: 0.9231 - val_loss: 0.8994 - val_accuracy: 0.7388\n",
      "Epoch 13/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1065 - accuracy: 0.98 - 0s 3ms/step - loss: 0.1723 - accuracy: 0.9418 - val_loss: 0.9688 - val_accuracy: 0.7239\n",
      "Epoch 14/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1814 - accuracy: 0.93 - 0s 3ms/step - loss: 0.1638 - accuracy: 0.9456 - val_loss: 1.1807 - val_accuracy: 0.7015\n",
      "Epoch 15/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1331 - accuracy: 0.95 - 0s 3ms/step - loss: 0.1986 - accuracy: 0.9343 - val_loss: 1.1026 - val_accuracy: 0.7015\n",
      "Epoch 16/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1794 - accuracy: 0.92 - 0s 3ms/step - loss: 0.2402 - accuracy: 0.8968 - val_loss: 0.9544 - val_accuracy: 0.7239\n",
      "Epoch 17/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1389 - accuracy: 0.96 - 0s 3ms/step - loss: 0.3248 - accuracy: 0.9062 - val_loss: 1.0245 - val_accuracy: 0.7164\n",
      "Epoch 18/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.3562 - accuracy: 0.84 - 0s 4ms/step - loss: 0.2850 - accuracy: 0.8780 - val_loss: 0.9808 - val_accuracy: 0.7090\n",
      "Epoch 19/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1987 - accuracy: 0.95 - 0s 3ms/step - loss: 0.2260 - accuracy: 0.9081 - val_loss: 0.9268 - val_accuracy: 0.7164\n",
      "Epoch 20/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1763 - accuracy: 0.93 - 0s 3ms/step - loss: 0.1946 - accuracy: 0.9306 - val_loss: 1.3199 - val_accuracy: 0.7388\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN113\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                      | 114/169 [12:02<05:26,  5.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_114\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_456 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_457 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_458 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_459 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.7092 - accuracy: 0.45 - 0s 17ms/step - loss: 0.5724 - accuracy: 0.6659 - val_loss: 0.5121 - val_accuracy: 0.7043\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.4763 - accuracy: 0.75 - 0s 3ms/step - loss: 0.4152 - accuracy: 0.7074 - val_loss: 0.6026 - val_accuracy: 0.7043\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.4117 - accuracy: 0.60 - 0s 4ms/step - loss: 0.3476 - accuracy: 0.7598 - val_loss: 0.6381 - val_accuracy: 0.8435\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2852 - accuracy: 0.85 - 0s 4ms/step - loss: 0.3028 - accuracy: 0.8799 - val_loss: 0.7768 - val_accuracy: 0.8696\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2692 - accuracy: 0.90 - 0s 4ms/step - loss: 0.2880 - accuracy: 0.8712 - val_loss: 0.5794 - val_accuracy: 0.8522\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2517 - accuracy: 0.85 - 0s 4ms/step - loss: 0.2704 - accuracy: 0.8624 - val_loss: 0.8577 - val_accuracy: 0.8348\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2320 - accuracy: 0.87 - 0s 4ms/step - loss: 0.2351 - accuracy: 0.8996 - val_loss: 0.9352 - val_accuracy: 0.8261\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1938 - accuracy: 0.95 - 0s 4ms/step - loss: 0.2141 - accuracy: 0.9148 - val_loss: 1.1735 - val_accuracy: 0.8261\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2315 - accuracy: 0.92 - 0s 4ms/step - loss: 0.1893 - accuracy: 0.9236 - val_loss: 1.1699 - val_accuracy: 0.8348\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1913 - accuracy: 0.92 - 0s 4ms/step - loss: 0.1895 - accuracy: 0.9279 - val_loss: 1.7948 - val_accuracy: 0.8522\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2495 - accuracy: 0.93 - 0s 4ms/step - loss: 0.2494 - accuracy: 0.9148 - val_loss: 0.7189 - val_accuracy: 0.8261\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1699 - accuracy: 0.93 - 0s 4ms/step - loss: 0.2155 - accuracy: 0.9148 - val_loss: 0.8820 - val_accuracy: 0.8522\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1791 - accuracy: 0.93 - 0s 3ms/step - loss: 0.1877 - accuracy: 0.9345 - val_loss: 0.7665 - val_accuracy: 0.8522\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0971 - accuracy: 0.98 - 0s 3ms/step - loss: 0.1595 - accuracy: 0.9476 - val_loss: 0.9686 - val_accuracy: 0.8522\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2036 - accuracy: 0.92 - 0s 3ms/step - loss: 0.1526 - accuracy: 0.9432 - val_loss: 1.1684 - val_accuracy: 0.8174\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1288 - accuracy: 0.96 - 0s 3ms/step - loss: 0.1554 - accuracy: 0.9432 - val_loss: 1.4503 - val_accuracy: 0.8087\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1701 - accuracy: 0.93 - 0s 3ms/step - loss: 0.1509 - accuracy: 0.9476 - val_loss: 1.8802 - val_accuracy: 0.8174\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1695 - accuracy: 0.93 - 0s 4ms/step - loss: 0.1681 - accuracy: 0.9389 - val_loss: 1.7605 - val_accuracy: 0.8261\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1426 - accuracy: 0.95 - 0s 3ms/step - loss: 0.2102 - accuracy: 0.9127 - val_loss: 1.5678 - val_accuracy: 0.8261\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2751 - accuracy: 0.87 - 0s 4ms/step - loss: 0.2153 - accuracy: 0.9323 - val_loss: 1.4336 - val_accuracy: 0.8348\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN114\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                      | 115/169 [12:07<05:18,  5.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_115\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_460 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_461 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_462 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_463 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.7012 - accuracy: 0.56 - 0s 20ms/step - loss: 0.5629 - accuracy: 0.6951 - val_loss: 0.5086 - val_accuracy: 0.7232\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.4892 - accuracy: 0.68 - 0s 4ms/step - loss: 0.4333 - accuracy: 0.7242 - val_loss: 0.5322 - val_accuracy: 0.7232\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.4514 - accuracy: 0.73 - 0s 4ms/step - loss: 0.3799 - accuracy: 0.7444 - val_loss: 0.4846 - val_accuracy: 0.8036\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.3255 - accuracy: 0.81 - 0s 4ms/step - loss: 0.3403 - accuracy: 0.8206 - val_loss: 0.4847 - val_accuracy: 0.8125\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.3417 - accuracy: 0.82 - 0s 4ms/step - loss: 0.3103 - accuracy: 0.8363 - val_loss: 0.5957 - val_accuracy: 0.8036\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2661 - accuracy: 0.84 - 0s 4ms/step - loss: 0.2907 - accuracy: 0.8408 - val_loss: 0.7144 - val_accuracy: 0.7500\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2263 - accuracy: 0.93 - 0s 4ms/step - loss: 0.2722 - accuracy: 0.8677 - val_loss: 0.7940 - val_accuracy: 0.7768\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2915 - accuracy: 0.85 - 0s 4ms/step - loss: 0.2617 - accuracy: 0.8655 - val_loss: 0.8754 - val_accuracy: 0.7857\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2566 - accuracy: 0.85 - 0s 4ms/step - loss: 0.2538 - accuracy: 0.8789 - val_loss: 0.8985 - val_accuracy: 0.7946\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2514 - accuracy: 0.92 - 0s 4ms/step - loss: 0.2636 - accuracy: 0.8677 - val_loss: 0.9722 - val_accuracy: 0.7857\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2801 - accuracy: 0.84 - 0s 4ms/step - loss: 0.2661 - accuracy: 0.8901 - val_loss: 0.7952 - val_accuracy: 0.7768\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2545 - accuracy: 0.89 - 0s 4ms/step - loss: 0.2404 - accuracy: 0.8812 - val_loss: 0.8538 - val_accuracy: 0.7768\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1924 - accuracy: 0.93 - 0s 4ms/step - loss: 0.2153 - accuracy: 0.9013 - val_loss: 0.9098 - val_accuracy: 0.7768\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2207 - accuracy: 0.90 - 0s 4ms/step - loss: 0.1991 - accuracy: 0.9103 - val_loss: 1.1445 - val_accuracy: 0.7946\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1968 - accuracy: 0.92 - 0s 4ms/step - loss: 0.1893 - accuracy: 0.9081 - val_loss: 1.3188 - val_accuracy: 0.7768\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1658 - accuracy: 0.90 - 0s 4ms/step - loss: 0.1713 - accuracy: 0.9148 - val_loss: 1.3447 - val_accuracy: 0.7679\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2002 - accuracy: 0.89 - 0s 4ms/step - loss: 0.1708 - accuracy: 0.9148 - val_loss: 1.5433 - val_accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1670 - accuracy: 0.92 - 0s 4ms/step - loss: 0.1693 - accuracy: 0.9103 - val_loss: 1.6896 - val_accuracy: 0.7946\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1261 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1581 - accuracy: 0.9215 - val_loss: 2.1803 - val_accuracy: 0.7679\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2053 - accuracy: 0.90 - 0s 4ms/step - loss: 0.1514 - accuracy: 0.9193 - val_loss: 2.0084 - val_accuracy: 0.7679\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN115\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                     | 116/169 [12:13<05:10,  5.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_116\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_464 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_465 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_466 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_467 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.7513 - accuracy: 0.31 - 0s 17ms/step - loss: 0.5167 - accuracy: 0.6930 - val_loss: 0.3868 - val_accuracy: 0.7544\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.3518 - accuracy: 0.76 - 0s 3ms/step - loss: 0.3428 - accuracy: 0.7566 - val_loss: 0.3617 - val_accuracy: 0.7544\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.3294 - accuracy: 0.71 - 0s 4ms/step - loss: 0.3030 - accuracy: 0.7566 - val_loss: 0.3576 - val_accuracy: 0.8509\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2571 - accuracy: 0.90 - 0s 4ms/step - loss: 0.2826 - accuracy: 0.8706 - val_loss: 0.4006 - val_accuracy: 0.8246\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2711 - accuracy: 0.87 - 0s 4ms/step - loss: 0.2635 - accuracy: 0.8640 - val_loss: 0.3768 - val_accuracy: 0.8246\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2552 - accuracy: 0.84 - 0s 4ms/step - loss: 0.2543 - accuracy: 0.8640 - val_loss: 0.4518 - val_accuracy: 0.8421\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2661 - accuracy: 0.85 - 0s 3ms/step - loss: 0.2474 - accuracy: 0.8706 - val_loss: 0.4393 - val_accuracy: 0.8421\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2222 - accuracy: 0.89 - 0s 4ms/step - loss: 0.2441 - accuracy: 0.8706 - val_loss: 0.4998 - val_accuracy: 0.8333\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1632 - accuracy: 0.92 - 0s 4ms/step - loss: 0.2481 - accuracy: 0.8772 - val_loss: 0.4679 - val_accuracy: 0.8158\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2190 - accuracy: 0.90 - 0s 4ms/step - loss: 0.2572 - accuracy: 0.8684 - val_loss: 0.4486 - val_accuracy: 0.8070\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2419 - accuracy: 0.87 - 0s 4ms/step - loss: 0.2427 - accuracy: 0.8794 - val_loss: 0.6312 - val_accuracy: 0.8333\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2148 - accuracy: 0.90 - 0s 4ms/step - loss: 0.2949 - accuracy: 0.8794 - val_loss: 0.3441 - val_accuracy: 0.8421\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2451 - accuracy: 0.87 - 0s 3ms/step - loss: 0.2445 - accuracy: 0.8947 - val_loss: 0.4359 - val_accuracy: 0.8333\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1859 - accuracy: 0.93 - 0s 4ms/step - loss: 0.2231 - accuracy: 0.9013 - val_loss: 0.5392 - val_accuracy: 0.8684\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2035 - accuracy: 0.90 - 0s 4ms/step - loss: 0.2025 - accuracy: 0.9013 - val_loss: 0.5019 - val_accuracy: 0.8596\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2438 - accuracy: 0.89 - 0s 4ms/step - loss: 0.1991 - accuracy: 0.9101 - val_loss: 0.4601 - val_accuracy: 0.8421\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1916 - accuracy: 0.92 - 0s 4ms/step - loss: 0.2080 - accuracy: 0.9079 - val_loss: 0.6675 - val_accuracy: 0.8333\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2665 - accuracy: 0.82 - 0s 4ms/step - loss: 0.2106 - accuracy: 0.9035 - val_loss: 0.8470 - val_accuracy: 0.8333\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2235 - accuracy: 0.90 - 0s 3ms/step - loss: 0.1920 - accuracy: 0.9145 - val_loss: 1.0129 - val_accuracy: 0.8246\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0896 - accuracy: 0.98 - 0s 3ms/step - loss: 0.2074 - accuracy: 0.9101 - val_loss: 0.8733 - val_accuracy: 0.8158\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN116\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                     | 117/169 [12:19<05:07,  5.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_117\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_468 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_469 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_470 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_471 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.6446 - accuracy: 0.71 - 0s 18ms/step - loss: 0.5136 - accuracy: 0.7741 - val_loss: 0.4905 - val_accuracy: 0.7757\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.3838 - accuracy: 0.81 - 0s 4ms/step - loss: 0.4200 - accuracy: 0.7765 - val_loss: 0.4767 - val_accuracy: 0.7757\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.3442 - accuracy: 0.78 - 0s 4ms/step - loss: 0.3591 - accuracy: 0.7765 - val_loss: 0.5292 - val_accuracy: 0.7757\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2096 - accuracy: 0.89 - 0s 4ms/step - loss: 0.3198 - accuracy: 0.7765 - val_loss: 0.5952 - val_accuracy: 0.7570\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2569 - accuracy: 0.87 - 0s 4ms/step - loss: 0.2797 - accuracy: 0.8824 - val_loss: 0.8562 - val_accuracy: 0.7383\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1901 - accuracy: 0.93 - 0s 4ms/step - loss: 0.2562 - accuracy: 0.8941 - val_loss: 0.6935 - val_accuracy: 0.7009\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2087 - accuracy: 0.95 - 0s 4ms/step - loss: 0.2436 - accuracy: 0.8988 - val_loss: 0.8573 - val_accuracy: 0.7290\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2249 - accuracy: 0.90 - 0s 4ms/step - loss: 0.1869 - accuracy: 0.9341 - val_loss: 1.1517 - val_accuracy: 0.7196\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1523 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1918 - accuracy: 0.9153 - val_loss: 1.0554 - val_accuracy: 0.6822\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1931 - accuracy: 0.90 - 0s 4ms/step - loss: 0.2689 - accuracy: 0.8729 - val_loss: 1.0177 - val_accuracy: 0.6636\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2485 - accuracy: 0.87 - 0s 4ms/step - loss: 0.2601 - accuracy: 0.8894 - val_loss: 1.3746 - val_accuracy: 0.7383\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1810 - accuracy: 0.92 - 0s 4ms/step - loss: 0.2296 - accuracy: 0.8965 - val_loss: 1.0951 - val_accuracy: 0.7196\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1816 - accuracy: 0.92 - 0s 4ms/step - loss: 0.2119 - accuracy: 0.9106 - val_loss: 1.4217 - val_accuracy: 0.7570\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2156 - accuracy: 0.89 - 0s 4ms/step - loss: 0.2203 - accuracy: 0.9153 - val_loss: 1.2391 - val_accuracy: 0.6636\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1316 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1816 - accuracy: 0.9318 - val_loss: 1.2974 - val_accuracy: 0.6822\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1446 - accuracy: 0.93 - 0s 4ms/step - loss: 0.1404 - accuracy: 0.9506 - val_loss: 1.2293 - val_accuracy: 0.7290\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1449 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1389 - accuracy: 0.9553 - val_loss: 1.3868 - val_accuracy: 0.6729\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1059 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1183 - accuracy: 0.9600 - val_loss: 1.5671 - val_accuracy: 0.7009\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0883 - accuracy: 0.98 - 0s 4ms/step - loss: 0.1096 - accuracy: 0.9647 - val_loss: 1.8087 - val_accuracy: 0.7103\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0995 - accuracy: 0.96 - 0s 4ms/step - loss: 0.0990 - accuracy: 0.9694 - val_loss: 1.6782 - val_accuracy: 0.7103\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN117\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                    | 118/169 [12:25<04:58,  5.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_118\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_472 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_473 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_474 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_475 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.7287 - accuracy: 0.56 - 0s 14ms/step - loss: 0.6514 - accuracy: 0.6927 - val_loss: 0.6286 - val_accuracy: 0.7081\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.4862 - accuracy: 0.84 - 0s 3ms/step - loss: 0.5335 - accuracy: 0.7754 - val_loss: 0.7683 - val_accuracy: 0.6832\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.5901 - accuracy: 0.75 - 0s 3ms/step - loss: 0.4938 - accuracy: 0.7972 - val_loss: 0.6407 - val_accuracy: 0.6894\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.4013 - accuracy: 0.85 - 0s 3ms/step - loss: 0.4386 - accuracy: 0.8268 - val_loss: 0.7992 - val_accuracy: 0.6894\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.3503 - accuracy: 0.84 - 0s 3ms/step - loss: 0.4141 - accuracy: 0.8440 - val_loss: 0.7480 - val_accuracy: 0.6584\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.4204 - accuracy: 0.81 - 0s 3ms/step - loss: 0.3860 - accuracy: 0.8502 - val_loss: 0.8860 - val_accuracy: 0.6522\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.3743 - accuracy: 0.81 - 0s 3ms/step - loss: 0.3605 - accuracy: 0.8596 - val_loss: 0.7213 - val_accuracy: 0.6770\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.3473 - accuracy: 0.89 - 0s 3ms/step - loss: 0.3134 - accuracy: 0.8830 - val_loss: 1.0449 - val_accuracy: 0.6460\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.2436 - accuracy: 0.92 - 0s 3ms/step - loss: 0.2857 - accuracy: 0.9033 - val_loss: 1.0191 - val_accuracy: 0.6832\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.2392 - accuracy: 0.93 - 0s 3ms/step - loss: 0.2649 - accuracy: 0.9017 - val_loss: 1.3053 - val_accuracy: 0.6770\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.2595 - accuracy: 0.92 - 0s 3ms/step - loss: 0.2652 - accuracy: 0.9095 - val_loss: 1.2258 - val_accuracy: 0.6646\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.2706 - accuracy: 0.87 - 0s 3ms/step - loss: 0.2556 - accuracy: 0.9142 - val_loss: 1.2993 - val_accuracy: 0.6708\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.1488 - accuracy: 0.96 - 0s 3ms/step - loss: 0.2441 - accuracy: 0.9236 - val_loss: 1.2139 - val_accuracy: 0.6957\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.1204 - accuracy: 0.95 - 0s 3ms/step - loss: 0.2180 - accuracy: 0.9251 - val_loss: 1.2638 - val_accuracy: 0.6832\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.1368 - accuracy: 0.98 - 0s 3ms/step - loss: 0.2453 - accuracy: 0.9282 - val_loss: 1.4801 - val_accuracy: 0.6957\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.2306 - accuracy: 0.92 - 0s 3ms/step - loss: 0.5099 - accuracy: 0.8752 - val_loss: 1.4064 - val_accuracy: 0.6708\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.4833 - accuracy: 0.79 - 0s 3ms/step - loss: 0.6056 - accuracy: 0.8206 - val_loss: 1.2297 - val_accuracy: 0.6522\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.3460 - accuracy: 0.85 - 0s 3ms/step - loss: 0.4436 - accuracy: 0.8019 - val_loss: 1.0712 - val_accuracy: 0.6957\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.3658 - accuracy: 0.84 - 0s 3ms/step - loss: 0.5053 - accuracy: 0.8066 - val_loss: 0.6656 - val_accuracy: 0.6335\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.4511 - accuracy: 0.79 - 0s 3ms/step - loss: 0.4327 - accuracy: 0.8393 - val_loss: 0.9431 - val_accuracy: 0.6894\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN118\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                    | 119/169 [12:31<04:59,  5.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_119\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_476 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_477 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_478 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_479 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.8603 - accuracy: 0.23 - 0s 21ms/step - loss: 0.5754 - accuracy: 0.6981 - val_loss: 0.4986 - val_accuracy: 0.8077\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.3940 - accuracy: 0.85 - 0s 4ms/step - loss: 0.4320 - accuracy: 0.8068 - val_loss: 0.4806 - val_accuracy: 0.8077\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.3870 - accuracy: 0.79 - 0s 4ms/step - loss: 0.3707 - accuracy: 0.8068 - val_loss: 0.4970 - val_accuracy: 0.8077\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.3430 - accuracy: 0.79 - 0s 4ms/step - loss: 0.3354 - accuracy: 0.8068 - val_loss: 0.4829 - val_accuracy: 0.8077\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.3379 - accuracy: 0.76 - 0s 5ms/step - loss: 0.3037 - accuracy: 0.8068 - val_loss: 0.5308 - val_accuracy: 0.8077\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.3074 - accuracy: 0.79 - 0s 4ms/step - loss: 0.2945 - accuracy: 0.8068 - val_loss: 0.5645 - val_accuracy: 0.8077\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2927 - accuracy: 0.73 - 0s 4ms/step - loss: 0.2578 - accuracy: 0.8068 - val_loss: 0.6714 - val_accuracy: 0.7981\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2716 - accuracy: 0.89 - 0s 4ms/step - loss: 0.2442 - accuracy: 0.8913 - val_loss: 0.6983 - val_accuracy: 0.8077\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2449 - accuracy: 0.96 - 0s 4ms/step - loss: 0.2232 - accuracy: 0.9058 - val_loss: 0.8200 - val_accuracy: 0.8077\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2411 - accuracy: 0.84 - 0s 4ms/step - loss: 0.2079 - accuracy: 0.8961 - val_loss: 0.8722 - val_accuracy: 0.7885\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1378 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1898 - accuracy: 0.9179 - val_loss: 0.8989 - val_accuracy: 0.7885\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1030 - accuracy: 0.98 - 0s 5ms/step - loss: 0.1830 - accuracy: 0.9203 - val_loss: 1.0902 - val_accuracy: 0.7692\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1819 - accuracy: 0.92 - 0s 4ms/step - loss: 0.1982 - accuracy: 0.9227 - val_loss: 1.3484 - val_accuracy: 0.7981\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1397 - accuracy: 0.95 - 0s 5ms/step - loss: 0.2148 - accuracy: 0.9106 - val_loss: 1.1092 - val_accuracy: 0.7596\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0952 - accuracy: 0.96 - 0s 4ms/step - loss: 0.2059 - accuracy: 0.8961 - val_loss: 1.0074 - val_accuracy: 0.7596\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1309 - accuracy: 0.93 - 0s 4ms/step - loss: 0.1906 - accuracy: 0.9179 - val_loss: 1.2209 - val_accuracy: 0.7692\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1826 - accuracy: 0.90 - 0s 4ms/step - loss: 0.1814 - accuracy: 0.9082 - val_loss: 0.9387 - val_accuracy: 0.7692\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2433 - accuracy: 0.85 - 0s 4ms/step - loss: 0.1846 - accuracy: 0.9106 - val_loss: 1.1476 - val_accuracy: 0.8173\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1405 - accuracy: 0.93 - 0s 5ms/step - loss: 0.1659 - accuracy: 0.9227 - val_loss: 1.1641 - val_accuracy: 0.7788\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1459 - accuracy: 0.93 - 0s 4ms/step - loss: 0.1561 - accuracy: 0.9348 - val_loss: 1.3666 - val_accuracy: 0.7885\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN119\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                    | 120/169 [12:38<04:57,  6.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_120\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_480 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_481 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_482 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_483 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.6217 - accuracy: 0.79 - 0s 19ms/step - loss: 0.4707 - accuracy: 0.8275 - val_loss: 0.3816 - val_accuracy: 0.8218\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.3939 - accuracy: 0.81 - 0s 4ms/step - loss: 0.3667 - accuracy: 0.8275 - val_loss: 0.3760 - val_accuracy: 0.8218\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.3838 - accuracy: 0.78 - 0s 4ms/step - loss: 0.3239 - accuracy: 0.8300 - val_loss: 0.3648 - val_accuracy: 0.8515\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2618 - accuracy: 0.84 - 0s 4ms/step - loss: 0.2917 - accuracy: 0.8775 - val_loss: 0.3513 - val_accuracy: 0.8317\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2596 - accuracy: 0.90 - 0s 6ms/step - loss: 0.2730 - accuracy: 0.8825 - val_loss: 0.3626 - val_accuracy: 0.8713\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2086 - accuracy: 0.92 - 0s 6ms/step - loss: 0.2345 - accuracy: 0.9100 - val_loss: 0.4569 - val_accuracy: 0.8614\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1644 - accuracy: 0.93 - 0s 4ms/step - loss: 0.2137 - accuracy: 0.9075 - val_loss: 0.4149 - val_accuracy: 0.8614\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1894 - accuracy: 0.93 - 0s 4ms/step - loss: 0.1832 - accuracy: 0.9325 - val_loss: 0.4622 - val_accuracy: 0.8812\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1322 - accuracy: 0.93 - 0s 5ms/step - loss: 0.1453 - accuracy: 0.9550 - val_loss: 0.5273 - val_accuracy: 0.8119\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1894 - accuracy: 0.93 - 0s 4ms/step - loss: 0.1358 - accuracy: 0.9450 - val_loss: 0.6276 - val_accuracy: 0.8614\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1519 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1179 - accuracy: 0.9575 - val_loss: 0.6947 - val_accuracy: 0.8416\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0616 - accuracy: 0.96 - 0s 4ms/step - loss: 0.0888 - accuracy: 0.9700 - val_loss: 0.6945 - val_accuracy: 0.8119\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0748 - accuracy: 0.96 - 0s 4ms/step - loss: 0.0860 - accuracy: 0.9700 - val_loss: 0.7748 - val_accuracy: 0.8317\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0357 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0432 - accuracy: 0.9900 - val_loss: 0.8404 - val_accuracy: 0.8515\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0326 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0753 - accuracy: 0.9725 - val_loss: 1.0425 - val_accuracy: 0.8119\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0350 - accuracy: 1.00 - 0s 4ms/step - loss: 0.1178 - accuracy: 0.9725 - val_loss: 0.9228 - val_accuracy: 0.8812\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2652 - accuracy: 0.90 - 0s 4ms/step - loss: 0.1250 - accuracy: 0.9525 - val_loss: 0.6061 - val_accuracy: 0.8218\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0946 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1357 - accuracy: 0.9475 - val_loss: 0.5560 - val_accuracy: 0.8317\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0470 - accuracy: 0.98 - 0s 4ms/step - loss: 0.1181 - accuracy: 0.9500 - val_loss: 0.5880 - val_accuracy: 0.8317\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1247 - accuracy: 0.95 - 0s 4ms/step - loss: 0.0984 - accuracy: 0.9575 - val_loss: 0.7973 - val_accuracy: 0.8218\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN120\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                   | 121/169 [12:44<04:50,  6.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_121\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_484 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_485 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_486 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_487 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.7312 - accuracy: 0.45 - 0s 17ms/step - loss: 0.5695 - accuracy: 0.7105 - val_loss: 0.5199 - val_accuracy: 0.7459\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.4061 - accuracy: 0.81 - 0s 3ms/step - loss: 0.4260 - accuracy: 0.7474 - val_loss: 0.5659 - val_accuracy: 0.7541\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.4855 - accuracy: 0.64 - 0s 4ms/step - loss: 0.3724 - accuracy: 0.7639 - val_loss: 0.5497 - val_accuracy: 0.7623\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.3343 - accuracy: 0.78 - 0s 4ms/step - loss: 0.3133 - accuracy: 0.8214 - val_loss: 0.6476 - val_accuracy: 0.8033\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.3474 - accuracy: 0.87 - 0s 4ms/step - loss: 0.2823 - accuracy: 0.8665 - val_loss: 0.7199 - val_accuracy: 0.7869\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2686 - accuracy: 0.92 - 0s 4ms/step - loss: 0.2685 - accuracy: 0.8871 - val_loss: 1.0077 - val_accuracy: 0.8279\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1191 - accuracy: 0.95 - 0s 4ms/step - loss: 0.2388 - accuracy: 0.8809 - val_loss: 0.9231 - val_accuracy: 0.7623\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2017 - accuracy: 0.89 - 0s 4ms/step - loss: 0.2228 - accuracy: 0.8912 - val_loss: 1.1482 - val_accuracy: 0.8033\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2211 - accuracy: 0.87 - 0s 3ms/step - loss: 0.1900 - accuracy: 0.9158 - val_loss: 1.1928 - val_accuracy: 0.7623\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1773 - accuracy: 0.92 - 0s 4ms/step - loss: 0.1927 - accuracy: 0.9014 - val_loss: 1.2722 - val_accuracy: 0.7787\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1729 - accuracy: 0.95 - 0s 4ms/step - loss: 0.2007 - accuracy: 0.9097 - val_loss: 1.4377 - val_accuracy: 0.8033\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1587 - accuracy: 0.92 - 0s 4ms/step - loss: 0.2007 - accuracy: 0.9035 - val_loss: 1.6222 - val_accuracy: 0.7951\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1305 - accuracy: 0.95 - 0s 4ms/step - loss: 0.2218 - accuracy: 0.8973 - val_loss: 1.4096 - val_accuracy: 0.7705\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2063 - accuracy: 0.89 - 0s 4ms/step - loss: 0.1956 - accuracy: 0.9035 - val_loss: 1.4956 - val_accuracy: 0.7869\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1223 - accuracy: 0.92 - 0s 4ms/step - loss: 0.1873 - accuracy: 0.9055 - val_loss: 1.5667 - val_accuracy: 0.7623\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1027 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1771 - accuracy: 0.9220 - val_loss: 1.7361 - val_accuracy: 0.8033\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1505 - accuracy: 0.93 - 0s 4ms/step - loss: 0.1551 - accuracy: 0.9405 - val_loss: 1.8664 - val_accuracy: 0.7951\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1618 - accuracy: 0.92 - 0s 4ms/step - loss: 0.1316 - accuracy: 0.9589 - val_loss: 2.0260 - val_accuracy: 0.7869\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1101 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1307 - accuracy: 0.9528 - val_loss: 2.1718 - val_accuracy: 0.7705\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1252 - accuracy: 0.93 - 0s 4ms/step - loss: 0.1522 - accuracy: 0.9261 - val_loss: 1.6401 - val_accuracy: 0.7459\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN121\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                   | 122/169 [12:50<04:43,  6.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_122\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_488 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_489 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_490 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_491 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.4876 - accuracy: 0.82 - 0s 22ms/step - loss: 0.4331 - accuracy: 0.7883 - val_loss: 0.3839 - val_accuracy: 0.7767\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2796 - accuracy: 0.84 - 0s 4ms/step - loss: 0.3009 - accuracy: 0.8467 - val_loss: 0.4280 - val_accuracy: 0.7670\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2461 - accuracy: 0.85 - 0s 5ms/step - loss: 0.2445 - accuracy: 0.8929 - val_loss: 0.5808 - val_accuracy: 0.7670\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1756 - accuracy: 0.89 - 0s 4ms/step - loss: 0.1827 - accuracy: 0.9075 - val_loss: 0.8432 - val_accuracy: 0.7767\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0875 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1517 - accuracy: 0.9319 - val_loss: 1.1052 - val_accuracy: 0.7573\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1461 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1457 - accuracy: 0.9416 - val_loss: 0.8922 - val_accuracy: 0.7961\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1705 - accuracy: 0.93 - 0s 4ms/step - loss: 0.1038 - accuracy: 0.9611 - val_loss: 1.5746 - val_accuracy: 0.7961\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1196 - accuracy: 0.93 - 0s 4ms/step - loss: 0.0851 - accuracy: 0.9659 - val_loss: 2.0124 - val_accuracy: 0.7573\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0554 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0831 - accuracy: 0.9708 - val_loss: 2.3691 - val_accuracy: 0.7961\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0394 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0629 - accuracy: 0.9757 - val_loss: 2.4699 - val_accuracy: 0.7282\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0394 - accuracy: 0.96 - 0s 4ms/step - loss: 0.0711 - accuracy: 0.9708 - val_loss: 2.5695 - val_accuracy: 0.7573\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0289 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0955 - accuracy: 0.9586 - val_loss: 2.4090 - val_accuracy: 0.7864\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0507 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0875 - accuracy: 0.9659 - val_loss: 2.7955 - val_accuracy: 0.7573\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0583 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1040 - accuracy: 0.9635 - val_loss: 1.9153 - val_accuracy: 0.7767\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0336 - accuracy: 1.00 - 0s 4ms/step - loss: 0.1211 - accuracy: 0.9538 - val_loss: 1.5337 - val_accuracy: 0.7864\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0770 - accuracy: 0.96 - 0s 4ms/step - loss: 0.0889 - accuracy: 0.9659 - val_loss: 1.8528 - val_accuracy: 0.7476\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0650 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1293 - accuracy: 0.9611 - val_loss: 1.5869 - val_accuracy: 0.7961\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0228 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0694 - accuracy: 0.9781 - val_loss: 1.5121 - val_accuracy: 0.7767\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0501 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0443 - accuracy: 0.9830 - val_loss: 1.7273 - val_accuracy: 0.7573\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0382 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0252 - accuracy: 0.9927 - val_loss: 2.2258 - val_accuracy: 0.7670\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN122\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 123/169 [12:56<04:36,  6.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_123\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_492 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_493 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_494 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_495 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.6954 - accuracy: 0.42 - 0s 11ms/step - loss: 0.6416 - accuracy: 0.6223 - val_loss: 0.6240 - val_accuracy: 0.6429\n",
      "Epoch 2/20\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.6213 - accuracy: 0.60 - 0s 3ms/step - loss: 0.5671 - accuracy: 0.6402 - val_loss: 0.5830 - val_accuracy: 0.6429\n",
      "Epoch 3/20\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.5569 - accuracy: 0.64 - 0s 3ms/step - loss: 0.5137 - accuracy: 0.7374 - val_loss: 0.5640 - val_accuracy: 0.7277\n",
      "Epoch 4/20\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.4966 - accuracy: 0.78 - 0s 3ms/step - loss: 0.4853 - accuracy: 0.7721 - val_loss: 0.5830 - val_accuracy: 0.6786\n",
      "Epoch 5/20\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.4222 - accuracy: 0.84 - 0s 3ms/step - loss: 0.4685 - accuracy: 0.7821 - val_loss: 0.5594 - val_accuracy: 0.7277\n",
      "Epoch 6/20\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.3090 - accuracy: 0.89 - 0s 3ms/step - loss: 0.4349 - accuracy: 0.8134 - val_loss: 0.5630 - val_accuracy: 0.7143\n",
      "Epoch 7/20\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.3734 - accuracy: 0.82 - 0s 3ms/step - loss: 0.4136 - accuracy: 0.8179 - val_loss: 0.5870 - val_accuracy: 0.7232\n",
      "Epoch 8/20\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.3039 - accuracy: 0.87 - 0s 3ms/step - loss: 0.3766 - accuracy: 0.8391 - val_loss: 0.6036 - val_accuracy: 0.7321\n",
      "Epoch 9/20\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.3249 - accuracy: 0.89 - 0s 3ms/step - loss: 0.3604 - accuracy: 0.8469 - val_loss: 0.6322 - val_accuracy: 0.7277\n",
      "Epoch 10/20\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.4306 - accuracy: 0.81 - 0s 3ms/step - loss: 0.3558 - accuracy: 0.8547 - val_loss: 0.6267 - val_accuracy: 0.6875\n",
      "Epoch 11/20\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.3051 - accuracy: 0.90 - 0s 3ms/step - loss: 0.3602 - accuracy: 0.8425 - val_loss: 0.6795 - val_accuracy: 0.6830\n",
      "Epoch 12/20\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.3526 - accuracy: 0.87 - 0s 3ms/step - loss: 0.3917 - accuracy: 0.8279 - val_loss: 0.6783 - val_accuracy: 0.7455\n",
      "Epoch 13/20\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.3236 - accuracy: 0.85 - 0s 3ms/step - loss: 0.3499 - accuracy: 0.8670 - val_loss: 0.7156 - val_accuracy: 0.7188\n",
      "Epoch 14/20\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.3147 - accuracy: 0.87 - 0s 3ms/step - loss: 0.3217 - accuracy: 0.8603 - val_loss: 0.7202 - val_accuracy: 0.7054\n",
      "Epoch 15/20\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.3749 - accuracy: 0.81 - 0s 4ms/step - loss: 0.2980 - accuracy: 0.8771 - val_loss: 0.7864 - val_accuracy: 0.7188\n",
      "Epoch 16/20\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.3258 - accuracy: 0.87 - 0s 3ms/step - loss: 0.2815 - accuracy: 0.8872 - val_loss: 0.8811 - val_accuracy: 0.7232\n",
      "Epoch 17/20\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.2400 - accuracy: 0.92 - 0s 3ms/step - loss: 0.2822 - accuracy: 0.8860 - val_loss: 0.8990 - val_accuracy: 0.7277\n",
      "Epoch 18/20\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.2392 - accuracy: 0.89 - 0s 3ms/step - loss: 0.2716 - accuracy: 0.8860 - val_loss: 0.8741 - val_accuracy: 0.7321\n",
      "Epoch 19/20\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.2239 - accuracy: 0.95 - 0s 3ms/step - loss: 0.2822 - accuracy: 0.8883 - val_loss: 0.9402 - val_accuracy: 0.6920\n",
      "Epoch 20/20\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.2820 - accuracy: 0.87 - 0s 3ms/step - loss: 0.2650 - accuracy: 0.8927 - val_loss: 1.2590 - val_accuracy: 0.7366\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN123\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                  | 124/169 [13:02<04:32,  6.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_124\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_496 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_497 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_498 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_499 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.5731 - accuracy: 0.68 - 0s 16ms/step - loss: 0.5490 - accuracy: 0.7348 - val_loss: 0.5251 - val_accuracy: 0.7500\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.5174 - accuracy: 0.75 - 0s 3ms/step - loss: 0.3769 - accuracy: 0.8212 - val_loss: 0.4176 - val_accuracy: 0.8281\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2758 - accuracy: 0.89 - 0s 4ms/step - loss: 0.3106 - accuracy: 0.8723 - val_loss: 0.4142 - val_accuracy: 0.8203\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1826 - accuracy: 0.93 - 0s 3ms/step - loss: 0.2398 - accuracy: 0.9136 - val_loss: 0.4588 - val_accuracy: 0.8125\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1935 - accuracy: 0.93 - 0s 3ms/step - loss: 0.1908 - accuracy: 0.9234 - val_loss: 0.5228 - val_accuracy: 0.8359\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1745 - accuracy: 0.93 - 0s 4ms/step - loss: 0.1539 - accuracy: 0.9352 - val_loss: 0.6978 - val_accuracy: 0.8047\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0673 - accuracy: 0.98 - 0s 4ms/step - loss: 0.1223 - accuracy: 0.9528 - val_loss: 0.7528 - val_accuracy: 0.7891\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0702 - accuracy: 0.98 - 0s 3ms/step - loss: 0.0933 - accuracy: 0.9607 - val_loss: 1.1068 - val_accuracy: 0.8125\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1039 - accuracy: 0.95 - 0s 3ms/step - loss: 0.1121 - accuracy: 0.9548 - val_loss: 1.1251 - val_accuracy: 0.7891\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0816 - accuracy: 0.96 - 0s 3ms/step - loss: 0.1606 - accuracy: 0.9568 - val_loss: 1.0952 - val_accuracy: 0.7656\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1647 - accuracy: 0.93 - 0s 3ms/step - loss: 0.0903 - accuracy: 0.9686 - val_loss: 0.8710 - val_accuracy: 0.7891\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0655 - accuracy: 0.96 - 0s 3ms/step - loss: 0.0845 - accuracy: 0.9705 - val_loss: 1.1052 - val_accuracy: 0.7812\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0173 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0613 - accuracy: 0.9804 - val_loss: 1.1501 - val_accuracy: 0.7812\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0426 - accuracy: 0.98 - 0s 3ms/step - loss: 0.0476 - accuracy: 0.9823 - val_loss: 1.3082 - val_accuracy: 0.7891\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0175 - accuracy: 1.00 - 0s 3ms/step - loss: 0.0411 - accuracy: 0.9882 - val_loss: 1.5915 - val_accuracy: 0.8125\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0344 - accuracy: 0.98 - 0s 3ms/step - loss: 0.0351 - accuracy: 0.9902 - val_loss: 1.8395 - val_accuracy: 0.7891\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0364 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0612 - accuracy: 0.9784 - val_loss: 1.7733 - val_accuracy: 0.7812\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1040 - accuracy: 0.95 - 0s 3ms/step - loss: 0.0955 - accuracy: 0.9607 - val_loss: 1.5517 - val_accuracy: 0.7734\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0959 - accuracy: 0.95 - 0s 4ms/step - loss: 0.0833 - accuracy: 0.9745 - val_loss: 1.0273 - val_accuracy: 0.7578\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1234 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1226 - accuracy: 0.9568 - val_loss: 1.0762 - val_accuracy: 0.7812\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN124\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                  | 125/169 [13:08<04:27,  6.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_125\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_500 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_501 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_502 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_503 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.7041 - accuracy: 0.46 - 0s 12ms/step - loss: 0.6270 - accuracy: 0.6170 - val_loss: 0.6175 - val_accuracy: 0.6889\n",
      "Epoch 2/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.6039 - accuracy: 0.64 - 0s 3ms/step - loss: 0.5175 - accuracy: 0.7354 - val_loss: 0.5024 - val_accuracy: 0.7778\n",
      "Epoch 3/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.4596 - accuracy: 0.76 - 0s 3ms/step - loss: 0.4173 - accuracy: 0.8050 - val_loss: 0.5087 - val_accuracy: 0.8000\n",
      "Epoch 4/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.3571 - accuracy: 0.81 - 0s 3ms/step - loss: 0.3842 - accuracy: 0.8384 - val_loss: 0.5252 - val_accuracy: 0.7722\n",
      "Epoch 5/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.4267 - accuracy: 0.73 - 0s 3ms/step - loss: 0.3853 - accuracy: 0.8050 - val_loss: 0.5857 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.3124 - accuracy: 0.87 - 0s 3ms/step - loss: 0.3269 - accuracy: 0.8593 - val_loss: 0.5261 - val_accuracy: 0.8111\n",
      "Epoch 7/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.3558 - accuracy: 0.82 - 0s 3ms/step - loss: 0.3047 - accuracy: 0.8733 - val_loss: 0.6880 - val_accuracy: 0.8056\n",
      "Epoch 8/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2687 - accuracy: 0.84 - 0s 3ms/step - loss: 0.3099 - accuracy: 0.8482 - val_loss: 0.5839 - val_accuracy: 0.7889\n",
      "Epoch 9/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.3486 - accuracy: 0.84 - 0s 3ms/step - loss: 0.3059 - accuracy: 0.8677 - val_loss: 0.8879 - val_accuracy: 0.7833\n",
      "Epoch 10/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.3070 - accuracy: 0.85 - 0s 3ms/step - loss: 0.3903 - accuracy: 0.8175 - val_loss: 0.6715 - val_accuracy: 0.7222\n",
      "Epoch 11/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.3618 - accuracy: 0.82 - 0s 3ms/step - loss: 0.3517 - accuracy: 0.8357 - val_loss: 0.6404 - val_accuracy: 0.7778\n",
      "Epoch 12/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2525 - accuracy: 0.82 - 0s 3ms/step - loss: 0.2884 - accuracy: 0.8565 - val_loss: 0.6559 - val_accuracy: 0.7944\n",
      "Epoch 13/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2605 - accuracy: 0.84 - 0s 3ms/step - loss: 0.2344 - accuracy: 0.8830 - val_loss: 0.6987 - val_accuracy: 0.8111\n",
      "Epoch 14/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2077 - accuracy: 0.87 - 0s 3ms/step - loss: 0.2218 - accuracy: 0.8914 - val_loss: 1.0412 - val_accuracy: 0.8000\n",
      "Epoch 15/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.1734 - accuracy: 0.89 - 0s 3ms/step - loss: 0.2239 - accuracy: 0.8858 - val_loss: 0.7517 - val_accuracy: 0.8111\n",
      "Epoch 16/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2547 - accuracy: 0.93 - 0s 3ms/step - loss: 0.2064 - accuracy: 0.8969 - val_loss: 1.1530 - val_accuracy: 0.8111\n",
      "Epoch 17/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.0833 - accuracy: 0.95 - 0s 3ms/step - loss: 0.2110 - accuracy: 0.9011 - val_loss: 0.9303 - val_accuracy: 0.7944\n",
      "Epoch 18/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.1374 - accuracy: 0.95 - 0s 3ms/step - loss: 0.2126 - accuracy: 0.9011 - val_loss: 1.1968 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2187 - accuracy: 0.87 - 0s 3ms/step - loss: 0.2144 - accuracy: 0.8886 - val_loss: 1.0757 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.1564 - accuracy: 0.90 - 0s 3ms/step - loss: 0.1956 - accuracy: 0.9053 - val_loss: 1.0560 - val_accuracy: 0.7944\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN125\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                 | 126/169 [13:14<04:24,  6.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_126\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_504 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_505 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_506 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_507 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.7059 - accuracy: 0.35 - 0s 15ms/step - loss: 0.6133 - accuracy: 0.5927 - val_loss: 0.4990 - val_accuracy: 0.6159\n",
      "Epoch 2/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.4578 - accuracy: 0.68 - 0s 3ms/step - loss: 0.4810 - accuracy: 0.7182 - val_loss: 0.4559 - val_accuracy: 0.7826\n",
      "Epoch 3/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.5188 - accuracy: 0.76 - 0s 3ms/step - loss: 0.4180 - accuracy: 0.8127 - val_loss: 0.4586 - val_accuracy: 0.7246\n",
      "Epoch 4/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.3802 - accuracy: 0.82 - 0s 3ms/step - loss: 0.3630 - accuracy: 0.8364 - val_loss: 0.4769 - val_accuracy: 0.7899\n",
      "Epoch 5/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2738 - accuracy: 0.90 - 0s 4ms/step - loss: 0.3257 - accuracy: 0.8545 - val_loss: 0.4914 - val_accuracy: 0.7464\n",
      "Epoch 6/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2831 - accuracy: 0.90 - 0s 3ms/step - loss: 0.3344 - accuracy: 0.8545 - val_loss: 0.4829 - val_accuracy: 0.7826\n",
      "Epoch 7/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.3146 - accuracy: 0.89 - 0s 3ms/step - loss: 0.3301 - accuracy: 0.8691 - val_loss: 0.5711 - val_accuracy: 0.7826\n",
      "Epoch 8/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2494 - accuracy: 0.90 - 0s 4ms/step - loss: 0.2969 - accuracy: 0.8909 - val_loss: 0.5030 - val_accuracy: 0.7826\n",
      "Epoch 9/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1964 - accuracy: 0.92 - 0s 3ms/step - loss: 0.2587 - accuracy: 0.9018 - val_loss: 0.5761 - val_accuracy: 0.8188\n",
      "Epoch 10/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1793 - accuracy: 0.95 - 0s 3ms/step - loss: 0.2339 - accuracy: 0.9182 - val_loss: 0.6007 - val_accuracy: 0.8043\n",
      "Epoch 11/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2946 - accuracy: 0.85 - 0s 3ms/step - loss: 0.2326 - accuracy: 0.9127 - val_loss: 0.6279 - val_accuracy: 0.7609\n",
      "Epoch 12/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1646 - accuracy: 0.93 - 0s 3ms/step - loss: 0.2273 - accuracy: 0.9109 - val_loss: 0.7669 - val_accuracy: 0.7899\n",
      "Epoch 13/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2386 - accuracy: 0.89 - 0s 4ms/step - loss: 0.2222 - accuracy: 0.9145 - val_loss: 0.7253 - val_accuracy: 0.7971\n",
      "Epoch 14/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1179 - accuracy: 0.98 - 0s 4ms/step - loss: 0.2112 - accuracy: 0.9291 - val_loss: 0.7084 - val_accuracy: 0.8116\n",
      "Epoch 15/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1556 - accuracy: 0.95 - 0s 4ms/step - loss: 0.2172 - accuracy: 0.9291 - val_loss: 0.7427 - val_accuracy: 0.7899\n",
      "Epoch 16/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2345 - accuracy: 0.90 - 0s 3ms/step - loss: 0.2777 - accuracy: 0.8891 - val_loss: 1.0633 - val_accuracy: 0.7754\n",
      "Epoch 17/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2432 - accuracy: 0.92 - 0s 3ms/step - loss: 0.2773 - accuracy: 0.8891 - val_loss: 0.5420 - val_accuracy: 0.7681\n",
      "Epoch 18/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2171 - accuracy: 0.92 - 0s 3ms/step - loss: 0.2603 - accuracy: 0.8945 - val_loss: 0.7854 - val_accuracy: 0.7899\n",
      "Epoch 19/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2339 - accuracy: 0.92 - 0s 4ms/step - loss: 0.2522 - accuracy: 0.9000 - val_loss: 0.6947 - val_accuracy: 0.7826\n",
      "Epoch 20/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2411 - accuracy: 0.89 - 0s 4ms/step - loss: 0.2422 - accuracy: 0.9073 - val_loss: 0.6559 - val_accuracy: 0.8116\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN126\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                 | 127/169 [13:20<04:15,  6.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_127\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_508 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_509 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_510 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_511 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.6826 - accuracy: 0.56 - 0s 20ms/step - loss: 0.4531 - accuracy: 0.7439 - val_loss: 0.3752 - val_accuracy: 0.7823\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2261 - accuracy: 0.89 - 0s 4ms/step - loss: 0.3074 - accuracy: 0.8455 - val_loss: 0.3625 - val_accuracy: 0.8387\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.3106 - accuracy: 0.82 - 0s 4ms/step - loss: 0.2887 - accuracy: 0.8659 - val_loss: 0.3788 - val_accuracy: 0.7984\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.3113 - accuracy: 0.85 - 0s 4ms/step - loss: 0.2545 - accuracy: 0.8821 - val_loss: 0.3536 - val_accuracy: 0.8226\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1911 - accuracy: 0.93 - 0s 4ms/step - loss: 0.2284 - accuracy: 0.8943 - val_loss: 0.3899 - val_accuracy: 0.8226\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2496 - accuracy: 0.89 - 0s 4ms/step - loss: 0.2096 - accuracy: 0.8963 - val_loss: 0.3958 - val_accuracy: 0.8387\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2124 - accuracy: 0.93 - 0s 4ms/step - loss: 0.1672 - accuracy: 0.9268 - val_loss: 0.4615 - val_accuracy: 0.8306\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1435 - accuracy: 0.90 - 0s 4ms/step - loss: 0.1790 - accuracy: 0.9207 - val_loss: 0.5203 - val_accuracy: 0.8145\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1318 - accuracy: 0.92 - 0s 4ms/step - loss: 0.1747 - accuracy: 0.9065 - val_loss: 0.4507 - val_accuracy: 0.8145\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1529 - accuracy: 0.90 - 0s 4ms/step - loss: 0.1505 - accuracy: 0.9228 - val_loss: 0.5254 - val_accuracy: 0.8226\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0860 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1368 - accuracy: 0.9207 - val_loss: 0.8343 - val_accuracy: 0.8145\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0919 - accuracy: 0.96 - 0s 5ms/step - loss: 0.1298 - accuracy: 0.9207 - val_loss: 1.0561 - val_accuracy: 0.7823\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1764 - accuracy: 0.93 - 0s 5ms/step - loss: 0.1712 - accuracy: 0.9329 - val_loss: 0.5774 - val_accuracy: 0.8306\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1669 - accuracy: 0.93 - 0s 5ms/step - loss: 0.1185 - accuracy: 0.9553 - val_loss: 0.6954 - val_accuracy: 0.8306\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0852 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0853 - accuracy: 0.9695 - val_loss: 0.7709 - val_accuracy: 0.8226\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0916 - accuracy: 0.98 - 0s 5ms/step - loss: 0.0997 - accuracy: 0.9634 - val_loss: 1.1691 - val_accuracy: 0.7984\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0320 - accuracy: 0.98 - 0s 5ms/step - loss: 0.1181 - accuracy: 0.9593 - val_loss: 0.9028 - val_accuracy: 0.8226\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0427 - accuracy: 1.00 - 0s 5ms/step - loss: 0.1222 - accuracy: 0.9533 - val_loss: 0.9154 - val_accuracy: 0.8387\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1114 - accuracy: 0.95 - 0s 6ms/step - loss: 0.1740 - accuracy: 0.9593 - val_loss: 0.6616 - val_accuracy: 0.8387\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0695 - accuracy: 0.95 - 0s 5ms/step - loss: 0.1199 - accuracy: 0.9593 - val_loss: 0.5560 - val_accuracy: 0.8226\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN127\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                | 128/169 [13:27<04:21,  6.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_128\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_512 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_513 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_514 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_515 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.6637 - accuracy: 0.70 - 0s 21ms/step - loss: 0.5578 - accuracy: 0.7309 - val_loss: 0.5644 - val_accuracy: 0.7478\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.4890 - accuracy: 0.76 - 0s 3ms/step - loss: 0.4079 - accuracy: 0.8009 - val_loss: 0.5623 - val_accuracy: 0.7739\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.3224 - accuracy: 0.82 - 0s 4ms/step - loss: 0.3493 - accuracy: 0.8534 - val_loss: 0.4858 - val_accuracy: 0.7913\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2525 - accuracy: 0.90 - 0s 4ms/step - loss: 0.3011 - accuracy: 0.8578 - val_loss: 0.4738 - val_accuracy: 0.8087\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2795 - accuracy: 0.79 - 0s 4ms/step - loss: 0.2839 - accuracy: 0.8578 - val_loss: 0.5708 - val_accuracy: 0.8261\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1881 - accuracy: 0.87 - 0s 4ms/step - loss: 0.2471 - accuracy: 0.8818 - val_loss: 0.6313 - val_accuracy: 0.8261\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.3087 - accuracy: 0.84 - 0s 4ms/step - loss: 0.2343 - accuracy: 0.8884 - val_loss: 0.6833 - val_accuracy: 0.8348\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2847 - accuracy: 0.81 - 0s 4ms/step - loss: 0.2219 - accuracy: 0.8950 - val_loss: 0.7249 - val_accuracy: 0.8348\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2336 - accuracy: 0.85 - 0s 4ms/step - loss: 0.2208 - accuracy: 0.8906 - val_loss: 0.8365 - val_accuracy: 0.7826\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1130 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1876 - accuracy: 0.9081 - val_loss: 1.0540 - val_accuracy: 0.8261\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1366 - accuracy: 0.92 - 0s 4ms/step - loss: 0.1539 - accuracy: 0.9278 - val_loss: 1.2708 - val_accuracy: 0.8087\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1873 - accuracy: 0.90 - 0s 4ms/step - loss: 0.1232 - accuracy: 0.9387 - val_loss: 1.5662 - val_accuracy: 0.7913\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1324 - accuracy: 0.93 - 0s 4ms/step - loss: 0.1135 - accuracy: 0.9584 - val_loss: 1.8860 - val_accuracy: 0.7565\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1107 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1615 - accuracy: 0.9409 - val_loss: 1.5973 - val_accuracy: 0.8261\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0487 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1699 - accuracy: 0.9190 - val_loss: 1.5871 - val_accuracy: 0.7826\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1204 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1543 - accuracy: 0.9409 - val_loss: 1.5640 - val_accuracy: 0.8174\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1974 - accuracy: 0.92 - 0s 4ms/step - loss: 0.1133 - accuracy: 0.9584 - val_loss: 1.8594 - val_accuracy: 0.8087\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0772 - accuracy: 0.98 - 0s 4ms/step - loss: 0.1368 - accuracy: 0.9475 - val_loss: 1.6465 - val_accuracy: 0.8261\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0676 - accuracy: 0.98 - 0s 4ms/step - loss: 0.1255 - accuracy: 0.9519 - val_loss: 1.4648 - val_accuracy: 0.8261\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1005 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1058 - accuracy: 0.9584 - val_loss: 1.3302 - val_accuracy: 0.8348\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN128\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                | 129/169 [13:34<04:26,  6.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_129\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_516 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_517 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_518 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_519 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.8030 - accuracy: 0.37 - 0s 16ms/step - loss: 0.6662 - accuracy: 0.5927 - val_loss: 0.6098 - val_accuracy: 0.6769\n",
      "Epoch 2/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.6206 - accuracy: 0.67 - 0s 3ms/step - loss: 0.4848 - accuracy: 0.7355 - val_loss: 0.4301 - val_accuracy: 0.7923\n",
      "Epoch 3/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2946 - accuracy: 0.89 - 0s 4ms/step - loss: 0.3361 - accuracy: 0.8591 - val_loss: 0.4357 - val_accuracy: 0.8154\n",
      "Epoch 4/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.3428 - accuracy: 0.90 - 0s 3ms/step - loss: 0.2994 - accuracy: 0.8784 - val_loss: 0.4254 - val_accuracy: 0.8000\n",
      "Epoch 5/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.3481 - accuracy: 0.85 - 0s 3ms/step - loss: 0.2794 - accuracy: 0.8784 - val_loss: 0.4562 - val_accuracy: 0.8462\n",
      "Epoch 6/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1365 - accuracy: 0.95 - 0s 4ms/step - loss: 0.2247 - accuracy: 0.9112 - val_loss: 0.4616 - val_accuracy: 0.8385\n",
      "Epoch 7/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2123 - accuracy: 0.92 - 0s 4ms/step - loss: 0.2089 - accuracy: 0.9266 - val_loss: 0.4474 - val_accuracy: 0.8231\n",
      "Epoch 8/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1710 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1766 - accuracy: 0.9421 - val_loss: 0.6270 - val_accuracy: 0.8462\n",
      "Epoch 9/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0729 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1488 - accuracy: 0.9382 - val_loss: 0.7567 - val_accuracy: 0.8308\n",
      "Epoch 10/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1297 - accuracy: 0.96 - 0s 4ms/step - loss: 0.2440 - accuracy: 0.9093 - val_loss: 0.5735 - val_accuracy: 0.8308\n",
      "Epoch 11/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1697 - accuracy: 0.93 - 0s 4ms/step - loss: 0.1659 - accuracy: 0.9363 - val_loss: 0.5344 - val_accuracy: 0.8308\n",
      "Epoch 12/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1310 - accuracy: 0.92 - 0s 4ms/step - loss: 0.1294 - accuracy: 0.9440 - val_loss: 0.7341 - val_accuracy: 0.8308\n",
      "Epoch 13/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0733 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1277 - accuracy: 0.9498 - val_loss: 0.8661 - val_accuracy: 0.8154\n",
      "Epoch 14/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0833 - accuracy: 0.93 - 0s 4ms/step - loss: 0.1057 - accuracy: 0.9537 - val_loss: 0.8487 - val_accuracy: 0.8385\n",
      "Epoch 15/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1075 - accuracy: 0.95 - 0s 4ms/step - loss: 0.0880 - accuracy: 0.9653 - val_loss: 0.8377 - val_accuracy: 0.8462\n",
      "Epoch 16/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0672 - accuracy: 0.95 - 0s 4ms/step - loss: 0.0877 - accuracy: 0.9691 - val_loss: 0.7620 - val_accuracy: 0.8462\n",
      "Epoch 17/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0418 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0718 - accuracy: 0.9710 - val_loss: 0.8619 - val_accuracy: 0.8308\n",
      "Epoch 18/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0150 - accuracy: 1.00 - 0s 5ms/step - loss: 0.0496 - accuracy: 0.9807 - val_loss: 0.9055 - val_accuracy: 0.8077\n",
      "Epoch 19/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0237 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0495 - accuracy: 0.9710 - val_loss: 0.9478 - val_accuracy: 0.8308\n",
      "Epoch 20/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0252 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0703 - accuracy: 0.9653 - val_loss: 0.9358 - val_accuracy: 0.8538\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN129\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                | 130/169 [13:41<04:14,  6.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_130\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_520 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_521 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_522 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_523 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.7805 - accuracy: 0.48 - 0s 18ms/step - loss: 0.6416 - accuracy: 0.6817 - val_loss: 0.5014 - val_accuracy: 0.7265\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.5030 - accuracy: 0.73 - 0s 5ms/step - loss: 0.4889 - accuracy: 0.7398 - val_loss: 0.4577 - val_accuracy: 0.7521\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.3743 - accuracy: 0.82 - 0s 4ms/step - loss: 0.4099 - accuracy: 0.7828 - val_loss: 0.4895 - val_accuracy: 0.7692\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.3531 - accuracy: 0.84 - 0s 4ms/step - loss: 0.3407 - accuracy: 0.8387 - val_loss: 0.4500 - val_accuracy: 0.8120\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.3252 - accuracy: 0.84 - 0s 4ms/step - loss: 0.3068 - accuracy: 0.8581 - val_loss: 0.4165 - val_accuracy: 0.8205\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2877 - accuracy: 0.89 - 0s 3ms/step - loss: 0.2896 - accuracy: 0.8753 - val_loss: 0.4532 - val_accuracy: 0.8205\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2287 - accuracy: 0.93 - 0s 4ms/step - loss: 0.2486 - accuracy: 0.8882 - val_loss: 0.4863 - val_accuracy: 0.8034\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2519 - accuracy: 0.89 - 0s 4ms/step - loss: 0.2313 - accuracy: 0.8882 - val_loss: 0.4990 - val_accuracy: 0.8034\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1802 - accuracy: 0.87 - 0s 4ms/step - loss: 0.2076 - accuracy: 0.8968 - val_loss: 0.5712 - val_accuracy: 0.8034\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1382 - accuracy: 0.90 - 0s 4ms/step - loss: 0.2172 - accuracy: 0.8903 - val_loss: 0.5814 - val_accuracy: 0.8120\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2158 - accuracy: 0.96 - 0s 4ms/step - loss: 0.2007 - accuracy: 0.9075 - val_loss: 0.6841 - val_accuracy: 0.8120\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1498 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1811 - accuracy: 0.9032 - val_loss: 0.7146 - val_accuracy: 0.8205\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1735 - accuracy: 0.90 - 0s 4ms/step - loss: 0.2262 - accuracy: 0.9011 - val_loss: 0.7545 - val_accuracy: 0.8120\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1531 - accuracy: 0.92 - 0s 4ms/step - loss: 0.1670 - accuracy: 0.9204 - val_loss: 0.9410 - val_accuracy: 0.8034\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1274 - accuracy: 0.93 - 0s 4ms/step - loss: 0.1527 - accuracy: 0.9290 - val_loss: 0.9626 - val_accuracy: 0.8205\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0955 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1980 - accuracy: 0.9355 - val_loss: 0.7464 - val_accuracy: 0.7949\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1635 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1718 - accuracy: 0.9398 - val_loss: 0.8654 - val_accuracy: 0.7436\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1289 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1473 - accuracy: 0.9505 - val_loss: 1.2100 - val_accuracy: 0.7521\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0888 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1196 - accuracy: 0.9548 - val_loss: 1.2426 - val_accuracy: 0.7863\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0537 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0880 - accuracy: 0.9699 - val_loss: 1.3864 - val_accuracy: 0.7607\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN130\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–               | 131/169 [13:47<04:06,  6.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_131\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_524 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_525 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_526 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_527 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.7012 - accuracy: 0.57 - 0s 19ms/step - loss: 0.5904 - accuracy: 0.6838 - val_loss: 0.4422 - val_accuracy: 0.8156\n",
      "Epoch 2/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.4903 - accuracy: 0.75 - 0s 4ms/step - loss: 0.3973 - accuracy: 0.8277 - val_loss: 0.4070 - val_accuracy: 0.8298\n",
      "Epoch 3/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2588 - accuracy: 0.87 - 0s 4ms/step - loss: 0.3322 - accuracy: 0.8561 - val_loss: 0.3833 - val_accuracy: 0.8440\n",
      "Epoch 4/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2342 - accuracy: 0.89 - 0s 4ms/step - loss: 0.2659 - accuracy: 0.8792 - val_loss: 0.3770 - val_accuracy: 0.8440\n",
      "Epoch 5/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1769 - accuracy: 0.93 - 0s 4ms/step - loss: 0.2312 - accuracy: 0.9112 - val_loss: 0.4046 - val_accuracy: 0.8511\n",
      "Epoch 6/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1236 - accuracy: 0.95 - 0s 4ms/step - loss: 0.2061 - accuracy: 0.9059 - val_loss: 0.4475 - val_accuracy: 0.8440\n",
      "Epoch 7/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1743 - accuracy: 0.92 - 0s 4ms/step - loss: 0.1670 - accuracy: 0.9290 - val_loss: 0.5398 - val_accuracy: 0.8440\n",
      "Epoch 8/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1773 - accuracy: 0.90 - 0s 4ms/step - loss: 0.1784 - accuracy: 0.9130 - val_loss: 0.5618 - val_accuracy: 0.8227\n",
      "Epoch 9/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2035 - accuracy: 0.89 - 0s 4ms/step - loss: 0.1829 - accuracy: 0.9112 - val_loss: 0.5934 - val_accuracy: 0.8511\n",
      "Epoch 10/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0756 - accuracy: 0.95 - 0s 4ms/step - loss: 0.2024 - accuracy: 0.9005 - val_loss: 0.5876 - val_accuracy: 0.8085\n",
      "Epoch 11/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1571 - accuracy: 0.90 - 0s 4ms/step - loss: 0.2134 - accuracy: 0.8952 - val_loss: 0.4980 - val_accuracy: 0.8298\n",
      "Epoch 12/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2230 - accuracy: 0.89 - 0s 4ms/step - loss: 0.2193 - accuracy: 0.8917 - val_loss: 0.4385 - val_accuracy: 0.8085\n",
      "Epoch 13/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1155 - accuracy: 0.98 - 0s 4ms/step - loss: 0.1809 - accuracy: 0.9147 - val_loss: 0.4551 - val_accuracy: 0.8440\n",
      "Epoch 14/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0767 - accuracy: 0.98 - 0s 4ms/step - loss: 0.1344 - accuracy: 0.9307 - val_loss: 0.4653 - val_accuracy: 0.8298\n",
      "Epoch 15/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1062 - accuracy: 0.93 - 0s 4ms/step - loss: 0.0982 - accuracy: 0.9467 - val_loss: 0.5389 - val_accuracy: 0.8511\n",
      "Epoch 16/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0286 - accuracy: 0.98 - 0s 4ms/step - loss: 0.1007 - accuracy: 0.9467 - val_loss: 0.6528 - val_accuracy: 0.8369\n",
      "Epoch 17/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1001 - accuracy: 0.93 - 0s 4ms/step - loss: 0.0968 - accuracy: 0.9449 - val_loss: 0.6911 - val_accuracy: 0.8440\n",
      "Epoch 18/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0563 - accuracy: 0.96 - 0s 4ms/step - loss: 0.0990 - accuracy: 0.9449 - val_loss: 0.6255 - val_accuracy: 0.8440\n",
      "Epoch 19/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0661 - accuracy: 0.95 - 0s 4ms/step - loss: 0.0771 - accuracy: 0.9520 - val_loss: 0.6163 - val_accuracy: 0.8156\n",
      "Epoch 20/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1126 - accuracy: 0.92 - 0s 4ms/step - loss: 0.0750 - accuracy: 0.9520 - val_loss: 0.7918 - val_accuracy: 0.8369\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN131\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰               | 132/169 [13:53<03:57,  6.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_132\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_528 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_529 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_530 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_531 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.7898 - accuracy: 0.37 - 0s 11ms/step - loss: 0.6469 - accuracy: 0.6617 - val_loss: 0.6190 - val_accuracy: 0.7110\n",
      "Epoch 2/20\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.4680 - accuracy: 0.81 - 0s 3ms/step - loss: 0.5342 - accuracy: 0.7752 - val_loss: 0.5363 - val_accuracy: 0.7202\n",
      "Epoch 3/20\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.4028 - accuracy: 0.85 - 0s 3ms/step - loss: 0.4279 - accuracy: 0.8050 - val_loss: 0.4885 - val_accuracy: 0.7477\n",
      "Epoch 4/20\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.3366 - accuracy: 0.82 - 0s 3ms/step - loss: 0.3758 - accuracy: 0.8417 - val_loss: 0.4828 - val_accuracy: 0.7890\n",
      "Epoch 5/20\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.2832 - accuracy: 0.90 - 0s 3ms/step - loss: 0.3625 - accuracy: 0.8567 - val_loss: 0.5563 - val_accuracy: 0.7706\n",
      "Epoch 6/20\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.4073 - accuracy: 0.82 - 0s 3ms/step - loss: 0.3364 - accuracy: 0.8647 - val_loss: 0.5516 - val_accuracy: 0.7844\n",
      "Epoch 7/20\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.2374 - accuracy: 0.93 - 0s 3ms/step - loss: 0.2956 - accuracy: 0.8819 - val_loss: 0.6170 - val_accuracy: 0.7615\n",
      "Epoch 8/20\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.2424 - accuracy: 0.93 - 0s 3ms/step - loss: 0.2841 - accuracy: 0.8842 - val_loss: 0.5458 - val_accuracy: 0.7752\n",
      "Epoch 9/20\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.1655 - accuracy: 0.93 - 0s 3ms/step - loss: 0.2487 - accuracy: 0.8991 - val_loss: 0.6776 - val_accuracy: 0.7294\n",
      "Epoch 10/20\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.1656 - accuracy: 0.96 - 0s 3ms/step - loss: 0.2299 - accuracy: 0.9174 - val_loss: 0.7216 - val_accuracy: 0.7294\n",
      "Epoch 11/20\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.2020 - accuracy: 0.92 - 0s 3ms/step - loss: 0.2450 - accuracy: 0.9002 - val_loss: 0.6341 - val_accuracy: 0.7385\n",
      "Epoch 12/20\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.1574 - accuracy: 0.96 - 0s 3ms/step - loss: 0.2178 - accuracy: 0.9117 - val_loss: 0.8273 - val_accuracy: 0.7661\n",
      "Epoch 13/20\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.2613 - accuracy: 0.89 - 0s 3ms/step - loss: 0.1956 - accuracy: 0.9312 - val_loss: 0.8394 - val_accuracy: 0.7523\n",
      "Epoch 14/20\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0388 - accuracy: 1.00 - 0s 3ms/step - loss: 0.1654 - accuracy: 0.9415 - val_loss: 1.0470 - val_accuracy: 0.7294\n",
      "Epoch 15/20\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0604 - accuracy: 0.98 - 0s 3ms/step - loss: 0.1618 - accuracy: 0.9427 - val_loss: 1.0437 - val_accuracy: 0.7064\n",
      "Epoch 16/20\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0966 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1474 - accuracy: 0.9461 - val_loss: 1.1252 - val_accuracy: 0.7477\n",
      "Epoch 17/20\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0986 - accuracy: 0.95 - 0s 4ms/step - loss: 0.2018 - accuracy: 0.9323 - val_loss: 0.8583 - val_accuracy: 0.7248\n",
      "Epoch 18/20\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0797 - accuracy: 0.98 - 0s 3ms/step - loss: 0.1420 - accuracy: 0.9553 - val_loss: 1.1603 - val_accuracy: 0.7294\n",
      "Epoch 19/20\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0381 - accuracy: 1.00 - 0s 3ms/step - loss: 0.1158 - accuracy: 0.9622 - val_loss: 1.2421 - val_accuracy: 0.7294\n",
      "Epoch 20/20\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0893 - accuracy: 0.96 - 0s 3ms/step - loss: 0.1012 - accuracy: 0.9667 - val_loss: 1.3075 - val_accuracy: 0.7385\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN132\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž              | 133/169 [14:00<03:56,  6.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_133\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_532 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_533 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_534 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_535 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - ETA: 0s - loss: 1.0375 - accuracy: 0.37 - 0s 14ms/step - loss: 0.6153 - accuracy: 0.6843 - val_loss: 0.5004 - val_accuracy: 0.7950\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.5683 - accuracy: 0.71 - 0s 3ms/step - loss: 0.4074 - accuracy: 0.8243 - val_loss: 0.4862 - val_accuracy: 0.7826\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.2887 - accuracy: 0.87 - 0s 3ms/step - loss: 0.3430 - accuracy: 0.8507 - val_loss: 0.4799 - val_accuracy: 0.7888\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.3167 - accuracy: 0.87 - 0s 3ms/step - loss: 0.3070 - accuracy: 0.8709 - val_loss: 0.5794 - val_accuracy: 0.7888\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.2139 - accuracy: 0.95 - 0s 4ms/step - loss: 0.2728 - accuracy: 0.8849 - val_loss: 0.5772 - val_accuracy: 0.7826\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.1992 - accuracy: 0.93 - 0s 4ms/step - loss: 0.2775 - accuracy: 0.8865 - val_loss: 0.5086 - val_accuracy: 0.7764\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.1455 - accuracy: 0.92 - 0s 4ms/step - loss: 0.2536 - accuracy: 0.8896 - val_loss: 0.5608 - val_accuracy: 0.8012\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.4585 - accuracy: 0.81 - 0s 3ms/step - loss: 0.2873 - accuracy: 0.8709 - val_loss: 0.6447 - val_accuracy: 0.7888\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.2287 - accuracy: 0.90 - 0s 3ms/step - loss: 0.2456 - accuracy: 0.9005 - val_loss: 0.5787 - val_accuracy: 0.8199\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.1959 - accuracy: 0.90 - 0s 3ms/step - loss: 0.3248 - accuracy: 0.8600 - val_loss: 0.5538 - val_accuracy: 0.7950\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.2293 - accuracy: 0.93 - 0s 3ms/step - loss: 0.2634 - accuracy: 0.8989 - val_loss: 0.5520 - val_accuracy: 0.8012\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.2145 - accuracy: 0.89 - 0s 3ms/step - loss: 0.2616 - accuracy: 0.8880 - val_loss: 0.4991 - val_accuracy: 0.8012\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.2018 - accuracy: 0.95 - 0s 3ms/step - loss: 0.2145 - accuracy: 0.9129 - val_loss: 0.6455 - val_accuracy: 0.8012\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.1443 - accuracy: 0.95 - 0s 3ms/step - loss: 0.1910 - accuracy: 0.9114 - val_loss: 0.7684 - val_accuracy: 0.7640\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.1743 - accuracy: 0.93 - 0s 3ms/step - loss: 0.1484 - accuracy: 0.9378 - val_loss: 0.9111 - val_accuracy: 0.7888\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0922 - accuracy: 0.95 - 0s 3ms/step - loss: 0.1267 - accuracy: 0.9425 - val_loss: 1.0752 - val_accuracy: 0.7950\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.1467 - accuracy: 0.95 - 0s 3ms/step - loss: 0.1361 - accuracy: 0.9518 - val_loss: 0.9794 - val_accuracy: 0.7267\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.1452 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1918 - accuracy: 0.8927 - val_loss: 1.1251 - val_accuracy: 0.7702\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.1479 - accuracy: 0.93 - 0s 3ms/step - loss: 0.2971 - accuracy: 0.8974 - val_loss: 0.6651 - val_accuracy: 0.7205\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.2547 - accuracy: 0.87 - 0s 3ms/step - loss: 0.2813 - accuracy: 0.8802 - val_loss: 0.8339 - val_accuracy: 0.7640\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN133\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹              | 134/169 [14:07<03:50,  6.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_134\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_536 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_537 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_538 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_539 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 1.1350 - accuracy: 0.15 - 0s 35ms/step - loss: 0.5518 - accuracy: 0.6836 - val_loss: 0.2804 - val_accuracy: 0.8673\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.3117 - accuracy: 0.82 - 0s 5ms/step - loss: 0.2472 - accuracy: 0.8827 - val_loss: 0.2637 - val_accuracy: 0.8584\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1856 - accuracy: 0.87 - 0s 7ms/step - loss: 0.1773 - accuracy: 0.9049 - val_loss: 0.2803 - val_accuracy: 0.8761\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1365 - accuracy: 0.93 - 0s 5ms/step - loss: 0.1445 - accuracy: 0.9358 - val_loss: 0.3203 - val_accuracy: 0.8761\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0761 - accuracy: 0.98 - 0s 5ms/step - loss: 0.1062 - accuracy: 0.9513 - val_loss: 0.3649 - val_accuracy: 0.8761\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0552 - accuracy: 0.98 - 0s 6ms/step - loss: 0.0836 - accuracy: 0.9646 - val_loss: 0.4143 - val_accuracy: 0.8673\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0982 - accuracy: 0.98 - 0s 6ms/step - loss: 0.0912 - accuracy: 0.9602 - val_loss: 0.6954 - val_accuracy: 0.8496\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2313 - accuracy: 0.92 - 0s 5ms/step - loss: 0.0835 - accuracy: 0.9712 - val_loss: 0.4744 - val_accuracy: 0.8761\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2013 - accuracy: 0.93 - 0s 5ms/step - loss: 0.0857 - accuracy: 0.9646 - val_loss: 0.5532 - val_accuracy: 0.8584\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1268 - accuracy: 0.96 - 0s 6ms/step - loss: 0.0766 - accuracy: 0.9757 - val_loss: 0.4927 - val_accuracy: 0.8673\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0671 - accuracy: 0.96 - 0s 5ms/step - loss: 0.0582 - accuracy: 0.9823 - val_loss: 0.5963 - val_accuracy: 0.8407\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0428 - accuracy: 0.98 - 0s 6ms/step - loss: 0.0430 - accuracy: 0.9801 - val_loss: 0.5796 - val_accuracy: 0.8673\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0235 - accuracy: 1.00 - 0s 5ms/step - loss: 0.0258 - accuracy: 0.9956 - val_loss: 0.6847 - val_accuracy: 0.8584\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0097 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 0.8579 - val_accuracy: 0.8496\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0096 - accuracy: 1.00 - 0s 5ms/step - loss: 0.0109 - accuracy: 0.9956 - val_loss: 0.9320 - val_accuracy: 0.8584\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0062 - accuracy: 1.00 - 0s 5ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.9385 - val_accuracy: 0.8673\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0061 - accuracy: 1.00 - 0s 5ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 1.0105 - val_accuracy: 0.8496\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 8.8626e-04 - accuracy: 1.00 - 0s 5ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.1252 - val_accuracy: 0.8584\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 2.3911e-04 - accuracy: 1.00 - 0s 5ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.1917 - val_accuracy: 0.8584\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 3.6414e-04 - accuracy: 1.00 - 0s 5ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.2158 - val_accuracy: 0.8584\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN134\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ              | 135/169 [14:17<04:24,  7.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_135\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_540 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_541 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_542 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_543 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.9172 - accuracy: 0.34 - 0s 25ms/step - loss: 0.5493 - accuracy: 0.7495 - val_loss: 0.4029 - val_accuracy: 0.8174\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.3614 - accuracy: 0.76 - 0s 5ms/step - loss: 0.3256 - accuracy: 0.8148 - val_loss: 0.4401 - val_accuracy: 0.8174\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.3198 - accuracy: 0.79 - 0s 4ms/step - loss: 0.2903 - accuracy: 0.8170 - val_loss: 0.4163 - val_accuracy: 0.8174\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1739 - accuracy: 0.84 - 0s 4ms/step - loss: 0.2282 - accuracy: 0.8627 - val_loss: 0.4230 - val_accuracy: 0.8696\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1471 - accuracy: 0.90 - 0s 5ms/step - loss: 0.1970 - accuracy: 0.9172 - val_loss: 0.5044 - val_accuracy: 0.8435\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1889 - accuracy: 0.90 - 0s 5ms/step - loss: 0.1654 - accuracy: 0.9325 - val_loss: 0.4864 - val_accuracy: 0.8435\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0906 - accuracy: 0.98 - 0s 4ms/step - loss: 0.1525 - accuracy: 0.9477 - val_loss: 0.6629 - val_accuracy: 0.8000\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1743 - accuracy: 0.92 - 0s 4ms/step - loss: 0.1573 - accuracy: 0.9412 - val_loss: 0.5389 - val_accuracy: 0.8087\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1643 - accuracy: 0.90 - 0s 5ms/step - loss: 0.1361 - accuracy: 0.9499 - val_loss: 0.6732 - val_accuracy: 0.8609\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1657 - accuracy: 0.93 - 0s 4ms/step - loss: 0.1334 - accuracy: 0.9499 - val_loss: 0.6873 - val_accuracy: 0.8261\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0783 - accuracy: 0.98 - 0s 5ms/step - loss: 0.1076 - accuracy: 0.9651 - val_loss: 0.8211 - val_accuracy: 0.8174\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0716 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0960 - accuracy: 0.9651 - val_loss: 0.9485 - val_accuracy: 0.8348\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1113 - accuracy: 0.96 - 0s 4ms/step - loss: 0.0826 - accuracy: 0.9760 - val_loss: 0.9878 - val_accuracy: 0.8261\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0612 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0791 - accuracy: 0.9760 - val_loss: 1.0994 - val_accuracy: 0.8261\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1224 - accuracy: 0.93 - 0s 4ms/step - loss: 0.0821 - accuracy: 0.9717 - val_loss: 1.2007 - val_accuracy: 0.8261\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0242 - accuracy: 1.00 - 0s 5ms/step - loss: 0.0908 - accuracy: 0.9695 - val_loss: 1.0478 - val_accuracy: 0.8000\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0362 - accuracy: 1.00 - 0s 4ms/step - loss: 0.1015 - accuracy: 0.9586 - val_loss: 1.2082 - val_accuracy: 0.8348\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0250 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0832 - accuracy: 0.9739 - val_loss: 1.1346 - val_accuracy: 0.8435\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0910 - accuracy: 0.96 - 0s 4ms/step - loss: 0.0759 - accuracy: 0.9782 - val_loss: 1.4183 - val_accuracy: 0.8435\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0895 - accuracy: 0.96 - 0s 4ms/step - loss: 0.0746 - accuracy: 0.9717 - val_loss: 1.3595 - val_accuracy: 0.8261\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN135\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ             | 136/169 [14:25<04:13,  7.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_136\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_544 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_545 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_546 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_547 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 1.2961 - accuracy: 0.20 - 0s 23ms/step - loss: 0.4943 - accuracy: 0.7512 - val_loss: 0.2839 - val_accuracy: 0.8544\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1778 - accuracy: 0.82 - 0s 5ms/step - loss: 0.1792 - accuracy: 0.8585 - val_loss: 0.3617 - val_accuracy: 0.8544\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1391 - accuracy: 0.90 - 0s 4ms/step - loss: 0.1468 - accuracy: 0.8585 - val_loss: 0.5098 - val_accuracy: 0.8544\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2023 - accuracy: 0.76 - 0s 6ms/step - loss: 0.1349 - accuracy: 0.8585 - val_loss: 0.6855 - val_accuracy: 0.8544\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1584 - accuracy: 0.87 - 0s 5ms/step - loss: 0.1310 - accuracy: 0.9463 - val_loss: 0.6844 - val_accuracy: 0.9126\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0932 - accuracy: 0.96 - 0s 5ms/step - loss: 0.1212 - accuracy: 0.9561 - val_loss: 0.7697 - val_accuracy: 0.9126\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1071 - accuracy: 0.96 - 0s 5ms/step - loss: 0.1172 - accuracy: 0.9537 - val_loss: 0.7594 - val_accuracy: 0.9126\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1358 - accuracy: 0.92 - 0s 5ms/step - loss: 0.1117 - accuracy: 0.9561 - val_loss: 0.7417 - val_accuracy: 0.9029\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1039 - accuracy: 0.96 - 0s 5ms/step - loss: 0.1085 - accuracy: 0.9561 - val_loss: 0.7682 - val_accuracy: 0.9126\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1261 - accuracy: 0.93 - 0s 5ms/step - loss: 0.1060 - accuracy: 0.9561 - val_loss: 0.7905 - val_accuracy: 0.9126\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1194 - accuracy: 0.93 - 0s 5ms/step - loss: 0.1043 - accuracy: 0.9561 - val_loss: 0.8069 - val_accuracy: 0.9126\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1497 - accuracy: 0.92 - 0s 5ms/step - loss: 0.1032 - accuracy: 0.9561 - val_loss: 0.8192 - val_accuracy: 0.9126\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0746 - accuracy: 1.00 - 0s 6ms/step - loss: 0.1028 - accuracy: 0.9561 - val_loss: 0.8272 - val_accuracy: 0.9126\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0606 - accuracy: 0.98 - 0s 6ms/step - loss: 0.1023 - accuracy: 0.9561 - val_loss: 0.8346 - val_accuracy: 0.9126\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0803 - accuracy: 0.96 - 0s 6ms/step - loss: 0.1020 - accuracy: 0.9561 - val_loss: 0.8399 - val_accuracy: 0.9126\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1152 - accuracy: 0.95 - 0s 5ms/step - loss: 0.1019 - accuracy: 0.9561 - val_loss: 0.8444 - val_accuracy: 0.9126\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0726 - accuracy: 0.98 - 0s 5ms/step - loss: 0.1017 - accuracy: 0.9561 - val_loss: 0.8486 - val_accuracy: 0.9126\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1121 - accuracy: 0.96 - 0s 5ms/step - loss: 0.1017 - accuracy: 0.9561 - val_loss: 0.8542 - val_accuracy: 0.9126\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1055 - accuracy: 0.95 - 0s 6ms/step - loss: 0.1017 - accuracy: 0.9561 - val_loss: 0.8590 - val_accuracy: 0.9126\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1196 - accuracy: 0.95 - 0s 5ms/step - loss: 0.1017 - accuracy: 0.9561 - val_loss: 0.8625 - val_accuracy: 0.9126\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN136\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰             | 137/169 [14:32<03:59,  7.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_137\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_548 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_549 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_550 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_551 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.8222 - accuracy: 0.17 - 0s 21ms/step - loss: 0.4429 - accuracy: 0.7206 - val_loss: 0.1955 - val_accuracy: 0.8532\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2582 - accuracy: 0.87 - 0s 4ms/step - loss: 0.1942 - accuracy: 0.9284 - val_loss: 0.0821 - val_accuracy: 0.9725\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0554 - accuracy: 0.98 - 0s 5ms/step - loss: 0.1015 - accuracy: 0.9607 - val_loss: 0.0655 - val_accuracy: 0.9817\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0846 - accuracy: 0.96 - 0s 5ms/step - loss: 0.0851 - accuracy: 0.9700 - val_loss: 0.0698 - val_accuracy: 0.9817\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0420 - accuracy: 1.00 - 0s 5ms/step - loss: 0.0743 - accuracy: 0.9746 - val_loss: 0.0543 - val_accuracy: 0.9817\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0103 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0733 - accuracy: 0.9723 - val_loss: 0.0751 - val_accuracy: 0.9633\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0370 - accuracy: 0.98 - 0s 6ms/step - loss: 0.0592 - accuracy: 0.9769 - val_loss: 0.0550 - val_accuracy: 0.9817\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0370 - accuracy: 0.98 - 0s 5ms/step - loss: 0.0579 - accuracy: 0.9746 - val_loss: 0.0484 - val_accuracy: 0.9817\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0757 - accuracy: 0.96 - 0s 5ms/step - loss: 0.0575 - accuracy: 0.9769 - val_loss: 0.0624 - val_accuracy: 0.9725\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0053 - accuracy: 1.00 - 0s 5ms/step - loss: 0.0495 - accuracy: 0.9815 - val_loss: 0.0972 - val_accuracy: 0.9633\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0400 - accuracy: 0.98 - 0s 5ms/step - loss: 0.0424 - accuracy: 0.9838 - val_loss: 0.0609 - val_accuracy: 0.9725\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0082 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0455 - accuracy: 0.9861 - val_loss: 0.0612 - val_accuracy: 0.9817\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0679 - accuracy: 0.98 - 0s 5ms/step - loss: 0.0421 - accuracy: 0.9861 - val_loss: 0.0779 - val_accuracy: 0.9725\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0454 - accuracy: 0.98 - 0s 5ms/step - loss: 0.0368 - accuracy: 0.9885 - val_loss: 0.1011 - val_accuracy: 0.9633\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0311 - accuracy: 0.98 - 0s 5ms/step - loss: 0.0334 - accuracy: 0.9885 - val_loss: 0.1204 - val_accuracy: 0.9633\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0336 - accuracy: 0.98 - 0s 5ms/step - loss: 0.0318 - accuracy: 0.9885 - val_loss: 0.1537 - val_accuracy: 0.9633\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0317 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0289 - accuracy: 0.9931 - val_loss: 0.1730 - val_accuracy: 0.9725\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0035 - accuracy: 1.00 - 0s 5ms/step - loss: 0.0280 - accuracy: 0.9861 - val_loss: 0.1870 - val_accuracy: 0.9541\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0752 - accuracy: 0.96 - 0s 5ms/step - loss: 0.0475 - accuracy: 0.9861 - val_loss: 0.2575 - val_accuracy: 0.9358\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0116 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0317 - accuracy: 0.9838 - val_loss: 0.2398 - val_accuracy: 0.9633\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN137\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž            | 138/169 [14:38<03:42,  7.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_138\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_552 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_553 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_554 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_555 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.8399 - accuracy: 0.21 - 0s 21ms/step - loss: 0.5491 - accuracy: 0.7462 - val_loss: 0.4727 - val_accuracy: 0.8500\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.3251 - accuracy: 0.87 - 0s 4ms/step - loss: 0.3076 - accuracy: 0.8467 - val_loss: 0.3438 - val_accuracy: 0.8500\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.3012 - accuracy: 0.81 - 0s 4ms/step - loss: 0.2749 - accuracy: 0.8467 - val_loss: 0.3252 - val_accuracy: 0.8500\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2340 - accuracy: 0.81 - 0s 5ms/step - loss: 0.2283 - accuracy: 0.8467 - val_loss: 0.3912 - val_accuracy: 0.8500\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1662 - accuracy: 0.87 - 0s 5ms/step - loss: 0.1932 - accuracy: 0.8467 - val_loss: 0.3287 - val_accuracy: 0.8500\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2361 - accuracy: 0.75 - 0s 5ms/step - loss: 0.1819 - accuracy: 0.8467 - val_loss: 0.3283 - val_accuracy: 0.8500\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1890 - accuracy: 0.84 - 0s 4ms/step - loss: 0.1605 - accuracy: 0.9196 - val_loss: 0.3446 - val_accuracy: 0.8600\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1258 - accuracy: 0.98 - 0s 4ms/step - loss: 0.1467 - accuracy: 0.9497 - val_loss: 0.3942 - val_accuracy: 0.8800\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1536 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1252 - accuracy: 0.9472 - val_loss: 0.5136 - val_accuracy: 0.8800\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1012 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1132 - accuracy: 0.9673 - val_loss: 0.4776 - val_accuracy: 0.8300\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1240 - accuracy: 0.96 - 0s 5ms/step - loss: 0.1231 - accuracy: 0.9598 - val_loss: 0.4119 - val_accuracy: 0.8600\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0953 - accuracy: 0.98 - 0s 4ms/step - loss: 0.1072 - accuracy: 0.9673 - val_loss: 0.4440 - val_accuracy: 0.8300\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1011 - accuracy: 0.96 - 0s 4ms/step - loss: 0.0976 - accuracy: 0.9673 - val_loss: 0.4183 - val_accuracy: 0.8700\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1278 - accuracy: 0.95 - 0s 4ms/step - loss: 0.0908 - accuracy: 0.9724 - val_loss: 0.4081 - val_accuracy: 0.8900\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1162 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1023 - accuracy: 0.9623 - val_loss: 0.4938 - val_accuracy: 0.8700\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0958 - accuracy: 0.96 - 0s 4ms/step - loss: 0.0837 - accuracy: 0.9698 - val_loss: 0.6217 - val_accuracy: 0.8600\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1033 - accuracy: 0.96 - 0s 5ms/step - loss: 0.0895 - accuracy: 0.9698 - val_loss: 0.4383 - val_accuracy: 0.8500\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1027 - accuracy: 0.96 - 0s 5ms/step - loss: 0.0806 - accuracy: 0.9749 - val_loss: 0.4713 - val_accuracy: 0.8500\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1012 - accuracy: 0.96 - 0s 5ms/step - loss: 0.0763 - accuracy: 0.9774 - val_loss: 0.4962 - val_accuracy: 0.8600\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0551 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0610 - accuracy: 0.9799 - val_loss: 0.4923 - val_accuracy: 0.8600\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN138\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š            | 139/169 [14:45<03:29,  6.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_139\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_556 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_557 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_558 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_559 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.7036 - accuracy: 0.56 - 0s 21ms/step - loss: 0.5286 - accuracy: 0.7945 - val_loss: 0.4999 - val_accuracy: 0.8455\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.5664 - accuracy: 0.75 - 0s 4ms/step - loss: 0.3381 - accuracy: 0.8425 - val_loss: 0.3870 - val_accuracy: 0.8455\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2629 - accuracy: 0.85 - 0s 4ms/step - loss: 0.2693 - accuracy: 0.8539 - val_loss: 0.4087 - val_accuracy: 0.8455\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2056 - accuracy: 0.89 - 0s 5ms/step - loss: 0.2174 - accuracy: 0.8995 - val_loss: 0.4255 - val_accuracy: 0.8727\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2044 - accuracy: 0.92 - 0s 4ms/step - loss: 0.1802 - accuracy: 0.9110 - val_loss: 0.4154 - val_accuracy: 0.8545\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1471 - accuracy: 0.93 - 0s 4ms/step - loss: 0.1688 - accuracy: 0.9201 - val_loss: 0.5120 - val_accuracy: 0.8545\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1185 - accuracy: 0.93 - 0s 4ms/step - loss: 0.1449 - accuracy: 0.9178 - val_loss: 0.5808 - val_accuracy: 0.8727\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0994 - accuracy: 0.93 - 0s 4ms/step - loss: 0.1384 - accuracy: 0.9292 - val_loss: 0.7957 - val_accuracy: 0.8364\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1387 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1089 - accuracy: 0.9452 - val_loss: 0.9065 - val_accuracy: 0.8545\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1185 - accuracy: 0.90 - 0s 5ms/step - loss: 0.1064 - accuracy: 0.9452 - val_loss: 1.2085 - val_accuracy: 0.8364\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0738 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1019 - accuracy: 0.9566 - val_loss: 1.5819 - val_accuracy: 0.8091\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0650 - accuracy: 0.96 - 0s 4ms/step - loss: 0.0877 - accuracy: 0.9543 - val_loss: 1.5271 - val_accuracy: 0.8364\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0531 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0736 - accuracy: 0.9635 - val_loss: 1.5004 - val_accuracy: 0.8273\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0955 - accuracy: 0.93 - 0s 4ms/step - loss: 0.0720 - accuracy: 0.9635 - val_loss: 1.3880 - val_accuracy: 0.8455\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0800 - accuracy: 0.93 - 0s 4ms/step - loss: 0.0746 - accuracy: 0.9612 - val_loss: 1.3346 - val_accuracy: 0.8455\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0631 - accuracy: 0.96 - 0s 4ms/step - loss: 0.0724 - accuracy: 0.9658 - val_loss: 1.5101 - val_accuracy: 0.8273\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0811 - accuracy: 0.95 - 0s 4ms/step - loss: 0.0679 - accuracy: 0.9658 - val_loss: 1.9997 - val_accuracy: 0.8636\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0564 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1092 - accuracy: 0.9589 - val_loss: 1.9957 - val_accuracy: 0.8455\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0688 - accuracy: 0.95 - 0s 4ms/step - loss: 0.0961 - accuracy: 0.9566 - val_loss: 1.7373 - val_accuracy: 0.8545\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0326 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0884 - accuracy: 0.9475 - val_loss: 1.5623 - val_accuracy: 0.8636\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN139\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–           | 140/169 [14:51<03:18,  6.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_140\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_560 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_561 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_562 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_563 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.6764 - accuracy: 0.57 - 0s 22ms/step - loss: 0.4681 - accuracy: 0.8101 - val_loss: 0.4226 - val_accuracy: 0.8384\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2858 - accuracy: 0.84 - 0s 4ms/step - loss: 0.2780 - accuracy: 0.8430 - val_loss: 0.3300 - val_accuracy: 0.8384\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2266 - accuracy: 0.81 - 0s 4ms/step - loss: 0.2123 - accuracy: 0.8430 - val_loss: 0.3713 - val_accuracy: 0.8384\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1233 - accuracy: 0.89 - 0s 4ms/step - loss: 0.1681 - accuracy: 0.8684 - val_loss: 0.4456 - val_accuracy: 0.8889\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1663 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1429 - accuracy: 0.9570 - val_loss: 0.5629 - val_accuracy: 0.8788\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1433 - accuracy: 0.98 - 0s 4ms/step - loss: 0.1325 - accuracy: 0.9519 - val_loss: 0.5002 - val_accuracy: 0.8788\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0900 - accuracy: 0.98 - 0s 5ms/step - loss: 0.1332 - accuracy: 0.9443 - val_loss: 0.4834 - val_accuracy: 0.8788\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0886 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0915 - accuracy: 0.9696 - val_loss: 0.5244 - val_accuracy: 0.8586\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0691 - accuracy: 0.98 - 0s 5ms/step - loss: 0.0839 - accuracy: 0.9671 - val_loss: 0.5590 - val_accuracy: 0.8485\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0302 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0659 - accuracy: 0.9797 - val_loss: 0.4680 - val_accuracy: 0.8990\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0075 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0834 - accuracy: 0.9696 - val_loss: 0.4886 - val_accuracy: 0.8990\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0668 - accuracy: 0.96 - 0s 5ms/step - loss: 0.0704 - accuracy: 0.9747 - val_loss: 0.7399 - val_accuracy: 0.8687\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0151 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0642 - accuracy: 0.9772 - val_loss: 0.6818 - val_accuracy: 0.8687\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0102 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0581 - accuracy: 0.9772 - val_loss: 1.1020 - val_accuracy: 0.8788\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0914 - accuracy: 0.96 - 0s 5ms/step - loss: 0.0607 - accuracy: 0.9747 - val_loss: 1.0613 - val_accuracy: 0.8990\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0842 - accuracy: 0.96 - 0s 4ms/step - loss: 0.0675 - accuracy: 0.9747 - val_loss: 1.0833 - val_accuracy: 0.8990\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0456 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0630 - accuracy: 0.9747 - val_loss: 0.9945 - val_accuracy: 0.9091\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0604 - accuracy: 0.96 - 0s 4ms/step - loss: 0.0648 - accuracy: 0.9747 - val_loss: 1.1578 - val_accuracy: 0.8990\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0469 - accuracy: 0.98 - 0s 5ms/step - loss: 0.0760 - accuracy: 0.9646 - val_loss: 1.2719 - val_accuracy: 0.8889\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0892 - accuracy: 0.95 - 0s 4ms/step - loss: 0.0603 - accuracy: 0.9747 - val_loss: 1.1950 - val_accuracy: 0.9091\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN140\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ           | 141/169 [14:58<03:09,  6.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_141\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_564 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_565 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_566 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_567 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.8240 - accuracy: 0.14 - 0s 23ms/step - loss: 0.5367 - accuracy: 0.7083 - val_loss: 0.4222 - val_accuracy: 0.8351\n",
      "Epoch 2/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.2760 - accuracy: 0.87 - 0s 5ms/step - loss: 0.3474 - accuracy: 0.8411 - val_loss: 0.4129 - val_accuracy: 0.8351\n",
      "Epoch 3/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.3066 - accuracy: 0.81 - 0s 5ms/step - loss: 0.2873 - accuracy: 0.8411 - val_loss: 0.4659 - val_accuracy: 0.8351\n",
      "Epoch 4/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.2469 - accuracy: 0.90 - 0s 5ms/step - loss: 0.2714 - accuracy: 0.8411 - val_loss: 0.5893 - val_accuracy: 0.8351\n",
      "Epoch 5/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.2142 - accuracy: 0.85 - 0s 5ms/step - loss: 0.2263 - accuracy: 0.8411 - val_loss: 0.6337 - val_accuracy: 0.8351\n",
      "Epoch 6/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.2054 - accuracy: 0.82 - 0s 5ms/step - loss: 0.1985 - accuracy: 0.8411 - val_loss: 0.9072 - val_accuracy: 0.8351\n",
      "Epoch 7/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1160 - accuracy: 0.90 - 0s 5ms/step - loss: 0.1939 - accuracy: 0.8411 - val_loss: 0.9031 - val_accuracy: 0.8351\n",
      "Epoch 8/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1489 - accuracy: 0.87 - 0s 5ms/step - loss: 0.1761 - accuracy: 0.9115 - val_loss: 1.0042 - val_accuracy: 0.8247\n",
      "Epoch 9/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.2069 - accuracy: 0.92 - 0s 5ms/step - loss: 0.1653 - accuracy: 0.9245 - val_loss: 1.2246 - val_accuracy: 0.7938\n",
      "Epoch 10/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1272 - accuracy: 0.98 - 0s 5ms/step - loss: 0.1547 - accuracy: 0.9297 - val_loss: 1.5666 - val_accuracy: 0.8041\n",
      "Epoch 11/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1775 - accuracy: 0.92 - 0s 5ms/step - loss: 0.1483 - accuracy: 0.9271 - val_loss: 1.8191 - val_accuracy: 0.8041\n",
      "Epoch 12/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1900 - accuracy: 0.89 - 0s 5ms/step - loss: 0.1399 - accuracy: 0.9375 - val_loss: 1.8594 - val_accuracy: 0.8041\n",
      "Epoch 13/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1766 - accuracy: 0.89 - 0s 5ms/step - loss: 0.1396 - accuracy: 0.9349 - val_loss: 1.9844 - val_accuracy: 0.8041\n",
      "Epoch 14/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1418 - accuracy: 0.89 - 0s 5ms/step - loss: 0.1368 - accuracy: 0.9375 - val_loss: 2.1213 - val_accuracy: 0.8041\n",
      "Epoch 15/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1504 - accuracy: 0.92 - 0s 5ms/step - loss: 0.1361 - accuracy: 0.9375 - val_loss: 2.2615 - val_accuracy: 0.8041\n",
      "Epoch 16/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0980 - accuracy: 0.98 - 0s 5ms/step - loss: 0.1289 - accuracy: 0.9427 - val_loss: 2.2943 - val_accuracy: 0.8247\n",
      "Epoch 17/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0807 - accuracy: 0.98 - 0s 5ms/step - loss: 0.1293 - accuracy: 0.9401 - val_loss: 2.4706 - val_accuracy: 0.8144\n",
      "Epoch 18/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1213 - accuracy: 0.93 - 0s 5ms/step - loss: 0.1360 - accuracy: 0.9349 - val_loss: 2.6647 - val_accuracy: 0.7938\n",
      "Epoch 19/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0737 - accuracy: 0.98 - 0s 5ms/step - loss: 0.1357 - accuracy: 0.9349 - val_loss: 2.9613 - val_accuracy: 0.7835\n",
      "Epoch 20/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1537 - accuracy: 0.89 - 0s 5ms/step - loss: 0.1296 - accuracy: 0.9401 - val_loss: 3.1607 - val_accuracy: 0.7835\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN141\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰           | 142/169 [15:05<03:03,  6.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_142\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_568 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_569 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_570 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_571 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.7081 - accuracy: 0.2969WARNING:tensorflow:Callbacks method `on_test_batch_begin` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_begin` time: 0.0010s). Check your callbacks.\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.4813 - accuracy: 0.6870 - val_loss: 0.4831 - val_accuracy: 0.7565\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.3219 - accuracy: 0.75 - 0s 5ms/step - loss: 0.3049 - accuracy: 0.7543 - val_loss: 0.4963 - val_accuracy: 0.7565\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2180 - accuracy: 0.81 - 0s 4ms/step - loss: 0.2537 - accuracy: 0.8043 - val_loss: 0.6063 - val_accuracy: 0.8609\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1750 - accuracy: 0.92 - 0s 4ms/step - loss: 0.2329 - accuracy: 0.9196 - val_loss: 0.7236 - val_accuracy: 0.9043\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1810 - accuracy: 0.98 - 0s 4ms/step - loss: 0.2125 - accuracy: 0.9087 - val_loss: 0.5455 - val_accuracy: 0.8696\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1621 - accuracy: 0.93 - 0s 5ms/step - loss: 0.2085 - accuracy: 0.9109 - val_loss: 0.6371 - val_accuracy: 0.8696\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2067 - accuracy: 0.93 - 0s 5ms/step - loss: 0.2104 - accuracy: 0.9130 - val_loss: 0.5163 - val_accuracy: 0.8783\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1956 - accuracy: 0.90 - 0s 4ms/step - loss: 0.1904 - accuracy: 0.9239 - val_loss: 0.4610 - val_accuracy: 0.8696\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1534 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1665 - accuracy: 0.9304 - val_loss: 0.5168 - val_accuracy: 0.8696\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1725 - accuracy: 0.93 - 0s 4ms/step - loss: 0.1447 - accuracy: 0.9478 - val_loss: 0.5680 - val_accuracy: 0.8870\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1262 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1252 - accuracy: 0.9587 - val_loss: 0.6978 - val_accuracy: 0.9043\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0911 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1178 - accuracy: 0.9587 - val_loss: 0.7591 - val_accuracy: 0.8783\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1265 - accuracy: 0.95 - 0s 5ms/step - loss: 0.1205 - accuracy: 0.9609 - val_loss: 0.7956 - val_accuracy: 0.8957\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1629 - accuracy: 0.93 - 0s 4ms/step - loss: 0.1200 - accuracy: 0.9609 - val_loss: 0.6788 - val_accuracy: 0.8870\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0764 - accuracy: 0.98 - 0s 4ms/step - loss: 0.1155 - accuracy: 0.9609 - val_loss: 0.7349 - val_accuracy: 0.8696\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1148 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1138 - accuracy: 0.9630 - val_loss: 1.0586 - val_accuracy: 0.8435\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1564 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1181 - accuracy: 0.9609 - val_loss: 1.3372 - val_accuracy: 0.8435\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0853 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1220 - accuracy: 0.9522 - val_loss: 1.3070 - val_accuracy: 0.8522\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0418 - accuracy: 1.00 - 0s 4ms/step - loss: 0.1448 - accuracy: 0.9457 - val_loss: 1.0399 - val_accuracy: 0.8609\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1497 - accuracy: 0.93 - 0s 4ms/step - loss: 0.1519 - accuracy: 0.9413 - val_loss: 1.1564 - val_accuracy: 0.8870\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN142\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–          | 143/169 [15:12<02:57,  6.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_143\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_572 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_573 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_574 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_575 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 1.0957 - accuracy: 0.1875WARNING:tensorflow:Callbacks method `on_test_batch_begin` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_begin` time: 0.0010s). Check your callbacks.\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.5672 - accuracy: 0.6610 - val_loss: 0.3905 - val_accuracy: 0.7373\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.3868 - accuracy: 0.67 - 0s 4ms/step - loss: 0.3623 - accuracy: 0.7399 - val_loss: 0.4685 - val_accuracy: 0.7373\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2551 - accuracy: 0.78 - 0s 4ms/step - loss: 0.2839 - accuracy: 0.8678 - val_loss: 0.3387 - val_accuracy: 0.8390\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.3166 - accuracy: 0.85 - 0s 4ms/step - loss: 0.2247 - accuracy: 0.9360 - val_loss: 0.5195 - val_accuracy: 0.8475\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2518 - accuracy: 0.90 - 0s 4ms/step - loss: 0.1777 - accuracy: 0.9446 - val_loss: 0.4272 - val_accuracy: 0.8475\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2051 - accuracy: 0.93 - 0s 4ms/step - loss: 0.1583 - accuracy: 0.9446 - val_loss: 0.6436 - val_accuracy: 0.8475\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1003 - accuracy: 0.96 - 0s 5ms/step - loss: 0.1287 - accuracy: 0.9531 - val_loss: 0.6076 - val_accuracy: 0.8475\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0562 - accuracy: 0.98 - 0s 4ms/step - loss: 0.1157 - accuracy: 0.9595 - val_loss: 0.6477 - val_accuracy: 0.8051\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1113 - accuracy: 0.95 - 0s 5ms/step - loss: 0.1212 - accuracy: 0.9552 - val_loss: 0.8386 - val_accuracy: 0.8390\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0856 - accuracy: 0.98 - 0s 5ms/step - loss: 0.1024 - accuracy: 0.9638 - val_loss: 0.7993 - val_accuracy: 0.8729\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0634 - accuracy: 0.96 - 0s 4ms/step - loss: 0.0890 - accuracy: 0.9723 - val_loss: 0.8325 - val_accuracy: 0.8729\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0889 - accuracy: 0.95 - 0s 4ms/step - loss: 0.0659 - accuracy: 0.9787 - val_loss: 0.8617 - val_accuracy: 0.8729\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0174 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0721 - accuracy: 0.9723 - val_loss: 0.9040 - val_accuracy: 0.8814\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0146 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0676 - accuracy: 0.9680 - val_loss: 1.1236 - val_accuracy: 0.8814\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0043 - accuracy: 1.00 - 0s 5ms/step - loss: 0.0527 - accuracy: 0.9829 - val_loss: 1.0926 - val_accuracy: 0.8559\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0448 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0606 - accuracy: 0.9723 - val_loss: 1.2973 - val_accuracy: 0.8644\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0833 - accuracy: 0.95 - 0s 5ms/step - loss: 0.0550 - accuracy: 0.9787 - val_loss: 1.1554 - val_accuracy: 0.8729\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0394 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0665 - accuracy: 0.9723 - val_loss: 1.2722 - val_accuracy: 0.8729\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1196 - accuracy: 0.93 - 0s 4ms/step - loss: 0.1042 - accuracy: 0.9638 - val_loss: 1.9254 - val_accuracy: 0.8390\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0607 - accuracy: 0.98 - 0s 4ms/step - loss: 0.1200 - accuracy: 0.9616 - val_loss: 0.8482 - val_accuracy: 0.8390\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN143\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š          | 144/169 [15:18<02:47,  6.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_144\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_576 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_577 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_578 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_579 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.5916 - accuracy: 0.82 - 0s 22ms/step - loss: 0.3631 - accuracy: 0.8668 - val_loss: 0.3653 - val_accuracy: 0.8654\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1935 - accuracy: 0.87 - 0s 4ms/step - loss: 0.2714 - accuracy: 0.8668 - val_loss: 0.4909 - val_accuracy: 0.8654\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2493 - accuracy: 0.82 - 0s 5ms/step - loss: 0.2324 - accuracy: 0.8668 - val_loss: 0.6334 - val_accuracy: 0.8654\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2113 - accuracy: 0.87 - 0s 4ms/step - loss: 0.1987 - accuracy: 0.8668 - val_loss: 1.0842 - val_accuracy: 0.8654\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1518 - accuracy: 0.90 - 0s 4ms/step - loss: 0.1681 - accuracy: 0.8741 - val_loss: 1.4410 - val_accuracy: 0.8558\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1294 - accuracy: 0.93 - 0s 4ms/step - loss: 0.1522 - accuracy: 0.9298 - val_loss: 1.7751 - val_accuracy: 0.8462\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1230 - accuracy: 0.93 - 0s 5ms/step - loss: 0.1465 - accuracy: 0.9249 - val_loss: 1.9255 - val_accuracy: 0.8558\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1547 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1342 - accuracy: 0.9395 - val_loss: 2.2961 - val_accuracy: 0.8654\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1124 - accuracy: 0.92 - 0s 5ms/step - loss: 0.1432 - accuracy: 0.9322 - val_loss: 2.0263 - val_accuracy: 0.8269\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1099 - accuracy: 0.95 - 0s 5ms/step - loss: 0.1277 - accuracy: 0.9443 - val_loss: 2.4352 - val_accuracy: 0.8462\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0834 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1149 - accuracy: 0.9467 - val_loss: 2.6704 - val_accuracy: 0.8269\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0728 - accuracy: 0.96 - 0s 4ms/step - loss: 0.0943 - accuracy: 0.9613 - val_loss: 2.8980 - val_accuracy: 0.8462\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0517 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0764 - accuracy: 0.9758 - val_loss: 3.2283 - val_accuracy: 0.8462\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0915 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0775 - accuracy: 0.9734 - val_loss: 3.3167 - val_accuracy: 0.8365\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0759 - accuracy: 0.96 - 0s 5ms/step - loss: 0.0659 - accuracy: 0.9806 - val_loss: 3.5611 - val_accuracy: 0.8269\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0844 - accuracy: 0.96 - 0s 4ms/step - loss: 0.0661 - accuracy: 0.9782 - val_loss: 3.7069 - val_accuracy: 0.8269\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0857 - accuracy: 0.96 - 0s 4ms/step - loss: 0.0665 - accuracy: 0.9782 - val_loss: 4.0539 - val_accuracy: 0.8365\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1091 - accuracy: 0.95 - 0s 5ms/step - loss: 0.0633 - accuracy: 0.9782 - val_loss: 4.2786 - val_accuracy: 0.8558\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0594 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0668 - accuracy: 0.9782 - val_loss: 4.6752 - val_accuracy: 0.8462\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0505 - accuracy: 0.98 - 0s 5ms/step - loss: 0.0634 - accuracy: 0.9782 - val_loss: 5.1988 - val_accuracy: 0.8462\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN144\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–         | 145/169 [15:25<02:43,  6.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_145\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_580 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_581 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_582 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_583 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.8074 - accuracy: 0.40 - 0s 29ms/step - loss: 0.4826 - accuracy: 0.7808 - val_loss: 0.3866 - val_accuracy: 0.8696\n",
      "Epoch 2/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.3043 - accuracy: 0.84 - 0s 5ms/step - loss: 0.2706 - accuracy: 0.8630 - val_loss: 0.3676 - val_accuracy: 0.8696\n",
      "Epoch 3/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.2168 - accuracy: 0.84 - 0s 5ms/step - loss: 0.2104 - accuracy: 0.8630 - val_loss: 0.4156 - val_accuracy: 0.8696\n",
      "Epoch 4/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1532 - accuracy: 0.90 - 0s 5ms/step - loss: 0.1801 - accuracy: 0.8630 - val_loss: 0.4172 - val_accuracy: 0.8696\n",
      "Epoch 5/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1372 - accuracy: 0.84 - 0s 5ms/step - loss: 0.1594 - accuracy: 0.8630 - val_loss: 0.4190 - val_accuracy: 0.8696\n",
      "Epoch 6/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1679 - accuracy: 0.87 - 0s 5ms/step - loss: 0.1382 - accuracy: 0.9178 - val_loss: 0.5295 - val_accuracy: 0.8152\n",
      "Epoch 7/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1283 - accuracy: 0.93 - 0s 5ms/step - loss: 0.1263 - accuracy: 0.9534 - val_loss: 0.5290 - val_accuracy: 0.8043\n",
      "Epoch 8/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0835 - accuracy: 0.98 - 0s 5ms/step - loss: 0.1179 - accuracy: 0.9616 - val_loss: 0.5097 - val_accuracy: 0.8152\n",
      "Epoch 9/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1205 - accuracy: 0.95 - 0s 5ms/step - loss: 0.1092 - accuracy: 0.9589 - val_loss: 0.6068 - val_accuracy: 0.8043\n",
      "Epoch 10/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0830 - accuracy: 0.95 - 0s 5ms/step - loss: 0.1020 - accuracy: 0.9616 - val_loss: 0.5921 - val_accuracy: 0.8043\n",
      "Epoch 11/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0855 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0979 - accuracy: 0.9644 - val_loss: 0.6107 - val_accuracy: 0.7935\n",
      "Epoch 12/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0599 - accuracy: 0.96 - 0s 4ms/step - loss: 0.0980 - accuracy: 0.9616 - val_loss: 0.4977 - val_accuracy: 0.8043\n",
      "Epoch 13/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0849 - accuracy: 0.98 - 0s 5ms/step - loss: 0.0941 - accuracy: 0.9699 - val_loss: 0.5817 - val_accuracy: 0.8261\n",
      "Epoch 14/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1250 - accuracy: 0.93 - 0s 5ms/step - loss: 0.0864 - accuracy: 0.9671 - val_loss: 0.6375 - val_accuracy: 0.8043\n",
      "Epoch 15/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0852 - accuracy: 0.96 - 0s 5ms/step - loss: 0.0868 - accuracy: 0.9671 - val_loss: 0.6568 - val_accuracy: 0.8043\n",
      "Epoch 16/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0456 - accuracy: 0.98 - 0s 5ms/step - loss: 0.0853 - accuracy: 0.9671 - val_loss: 0.6928 - val_accuracy: 0.8043\n",
      "Epoch 17/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0605 - accuracy: 0.98 - 0s 5ms/step - loss: 0.0811 - accuracy: 0.9699 - val_loss: 0.7442 - val_accuracy: 0.8370\n",
      "Epoch 18/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0980 - accuracy: 0.95 - 0s 5ms/step - loss: 0.0770 - accuracy: 0.9726 - val_loss: 0.9278 - val_accuracy: 0.8370\n",
      "Epoch 19/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0684 - accuracy: 0.96 - 0s 5ms/step - loss: 0.0826 - accuracy: 0.9671 - val_loss: 0.6974 - val_accuracy: 0.8152\n",
      "Epoch 20/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0608 - accuracy: 0.98 - 0s 5ms/step - loss: 0.0780 - accuracy: 0.9726 - val_loss: 0.8881 - val_accuracy: 0.8261\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN145\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ         | 146/169 [15:32<02:32,  6.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_146\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_584 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_585 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_586 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_587 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.8012 - accuracy: 0.43 - 0s 42ms/step - loss: 0.6739 - accuracy: 0.7657 - val_loss: 0.5997 - val_accuracy: 0.8587\n",
      "Epoch 2/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.6040 - accuracy: 0.84 - 0s 6ms/step - loss: 0.5701 - accuracy: 0.8556 - val_loss: 0.5286 - val_accuracy: 0.8587\n",
      "Epoch 3/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.4925 - accuracy: 0.92 - 0s 6ms/step - loss: 0.5092 - accuracy: 0.8556 - val_loss: 0.4787 - val_accuracy: 0.8587\n",
      "Epoch 4/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.5172 - accuracy: 0.81 - 0s 6ms/step - loss: 0.4660 - accuracy: 0.8556 - val_loss: 0.4467 - val_accuracy: 0.8587\n",
      "Epoch 5/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.4127 - accuracy: 0.89 - 0s 8ms/step - loss: 0.4412 - accuracy: 0.8556 - val_loss: 0.4272 - val_accuracy: 0.8587\n",
      "Epoch 6/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.4263 - accuracy: 0.85 - 0s 7ms/step - loss: 0.4259 - accuracy: 0.8556 - val_loss: 0.4166 - val_accuracy: 0.8587\n",
      "Epoch 7/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.3485 - accuracy: 0.90 - 0s 5ms/step - loss: 0.4191 - accuracy: 0.8556 - val_loss: 0.4111 - val_accuracy: 0.8587\n",
      "Epoch 8/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.4345 - accuracy: 0.84 - 0s 5ms/step - loss: 0.4148 - accuracy: 0.8556 - val_loss: 0.4087 - val_accuracy: 0.8587\n",
      "Epoch 9/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.3817 - accuracy: 0.87 - 0s 5ms/step - loss: 0.4140 - accuracy: 0.8556 - val_loss: 0.4077 - val_accuracy: 0.8587\n",
      "Epoch 10/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.5415 - accuracy: 0.78 - 0s 5ms/step - loss: 0.4128 - accuracy: 0.8556 - val_loss: 0.4074 - val_accuracy: 0.8587\n",
      "Epoch 11/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.5162 - accuracy: 0.79 - 0s 6ms/step - loss: 0.4128 - accuracy: 0.8556 - val_loss: 0.4074 - val_accuracy: 0.8587\n",
      "Epoch 12/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.4896 - accuracy: 0.81 - 0s 7ms/step - loss: 0.4128 - accuracy: 0.8556 - val_loss: 0.4073 - val_accuracy: 0.8587\n",
      "Epoch 13/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.4061 - accuracy: 0.85 - 0s 6ms/step - loss: 0.4129 - accuracy: 0.8556 - val_loss: 0.4073 - val_accuracy: 0.8587\n",
      "Epoch 14/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.4343 - accuracy: 0.84 - 0s 6ms/step - loss: 0.4129 - accuracy: 0.8556 - val_loss: 0.4073 - val_accuracy: 0.8587\n",
      "Epoch 15/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.5191 - accuracy: 0.79 - 0s 6ms/step - loss: 0.4130 - accuracy: 0.8556 - val_loss: 0.4073 - val_accuracy: 0.8587\n",
      "Epoch 16/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.5193 - accuracy: 0.79 - 0s 7ms/step - loss: 0.4130 - accuracy: 0.8556 - val_loss: 0.4073 - val_accuracy: 0.8587\n",
      "Epoch 17/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.3778 - accuracy: 0.87 - 0s 6ms/step - loss: 0.4131 - accuracy: 0.8556 - val_loss: 0.4073 - val_accuracy: 0.8587\n",
      "Epoch 18/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.4061 - accuracy: 0.85 - 0s 8ms/step - loss: 0.4130 - accuracy: 0.8556 - val_loss: 0.4073 - val_accuracy: 0.8587\n",
      "Epoch 19/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.3778 - accuracy: 0.87 - 0s 7ms/step - loss: 0.4129 - accuracy: 0.8556 - val_loss: 0.4073 - val_accuracy: 0.8587\n",
      "Epoch 20/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.4904 - accuracy: 0.81 - 0s 7ms/step - loss: 0.4130 - accuracy: 0.8556 - val_loss: 0.4073 - val_accuracy: 0.8587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN146\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ         | 147/169 [15:40<02:37,  7.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_147\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_588 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_589 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_590 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_591 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.6741 - accuracy: 0.62 - 0s 25ms/step - loss: 0.4391 - accuracy: 0.8150 - val_loss: 0.3210 - val_accuracy: 0.8617\n",
      "Epoch 2/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.2469 - accuracy: 0.85 - 0s 5ms/step - loss: 0.2467 - accuracy: 0.8579 - val_loss: 0.2915 - val_accuracy: 0.8617\n",
      "Epoch 3/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.2132 - accuracy: 0.89 - 0s 5ms/step - loss: 0.2055 - accuracy: 0.8579 - val_loss: 0.2930 - val_accuracy: 0.8617\n",
      "Epoch 4/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.2224 - accuracy: 0.84 - 0s 6ms/step - loss: 0.1777 - accuracy: 0.8579 - val_loss: 0.2948 - val_accuracy: 0.8617\n",
      "Epoch 5/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1132 - accuracy: 0.89 - 0s 6ms/step - loss: 0.1511 - accuracy: 0.8579 - val_loss: 0.3214 - val_accuracy: 0.8617\n",
      "Epoch 6/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1368 - accuracy: 0.84 - 0s 5ms/step - loss: 0.1432 - accuracy: 0.9303 - val_loss: 0.3546 - val_accuracy: 0.8936\n",
      "Epoch 7/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0923 - accuracy: 0.98 - 0s 6ms/step - loss: 0.1361 - accuracy: 0.9517 - val_loss: 0.3386 - val_accuracy: 0.9043\n",
      "Epoch 8/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1162 - accuracy: 0.96 - 0s 5ms/step - loss: 0.1159 - accuracy: 0.9625 - val_loss: 0.3510 - val_accuracy: 0.9043\n",
      "Epoch 9/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1504 - accuracy: 0.93 - 0s 5ms/step - loss: 0.1112 - accuracy: 0.9571 - val_loss: 0.3982 - val_accuracy: 0.9149\n",
      "Epoch 10/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1295 - accuracy: 0.93 - 0s 5ms/step - loss: 0.1030 - accuracy: 0.9625 - val_loss: 0.4180 - val_accuracy: 0.9149\n",
      "Epoch 11/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1151 - accuracy: 0.93 - 0s 5ms/step - loss: 0.0942 - accuracy: 0.9678 - val_loss: 0.4085 - val_accuracy: 0.9149\n",
      "Epoch 12/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0781 - accuracy: 0.96 - 0s 5ms/step - loss: 0.0908 - accuracy: 0.9678 - val_loss: 0.4480 - val_accuracy: 0.9149\n",
      "Epoch 13/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0772 - accuracy: 0.96 - 0s 5ms/step - loss: 0.0885 - accuracy: 0.9678 - val_loss: 0.4724 - val_accuracy: 0.9255\n",
      "Epoch 14/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0855 - accuracy: 0.96 - 0s 5ms/step - loss: 0.0872 - accuracy: 0.9678 - val_loss: 0.4826 - val_accuracy: 0.9255\n",
      "Epoch 15/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0718 - accuracy: 0.98 - 0s 5ms/step - loss: 0.0855 - accuracy: 0.9678 - val_loss: 0.5087 - val_accuracy: 0.9255\n",
      "Epoch 16/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1408 - accuracy: 0.93 - 0s 5ms/step - loss: 0.0850 - accuracy: 0.9678 - val_loss: 0.5291 - val_accuracy: 0.9255\n",
      "Epoch 17/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1207 - accuracy: 0.93 - 0s 5ms/step - loss: 0.0842 - accuracy: 0.9678 - val_loss: 0.5391 - val_accuracy: 0.8936\n",
      "Epoch 18/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0745 - accuracy: 0.96 - 0s 5ms/step - loss: 0.0841 - accuracy: 0.9678 - val_loss: 0.5654 - val_accuracy: 0.8936\n",
      "Epoch 19/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0795 - accuracy: 0.96 - 0s 6ms/step - loss: 0.0840 - accuracy: 0.9678 - val_loss: 0.6032 - val_accuracy: 0.8936\n",
      "Epoch 20/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0710 - accuracy: 0.96 - 0s 8ms/step - loss: 0.0836 - accuracy: 0.9678 - val_loss: 0.6301 - val_accuracy: 0.8936\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN147\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 148/169 [15:49<02:43,  7.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_148\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_592 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_593 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_594 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_595 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.6771 - accuracy: 0.60 - 0s 21ms/step - loss: 0.3418 - accuracy: 0.8346 - val_loss: 1.7650 - val_accuracy: 0.9485\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1721 - accuracy: 0.93 - 0s 5ms/step - loss: 0.1673 - accuracy: 0.9380 - val_loss: 0.2469 - val_accuracy: 0.9175\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1391 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1237 - accuracy: 0.9483 - val_loss: 0.1728 - val_accuracy: 0.9278\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0985 - accuracy: 0.95 - 0s 5ms/step - loss: 0.1100 - accuracy: 0.9587 - val_loss: 0.1222 - val_accuracy: 0.9278\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0421 - accuracy: 1.00 - 0s 5ms/step - loss: 0.0984 - accuracy: 0.9587 - val_loss: 0.1084 - val_accuracy: 0.9278\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1307 - accuracy: 0.93 - 0s 5ms/step - loss: 0.0932 - accuracy: 0.9612 - val_loss: 0.1456 - val_accuracy: 0.9175\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0955 - accuracy: 0.93 - 0s 5ms/step - loss: 0.0736 - accuracy: 0.9664 - val_loss: 0.2853 - val_accuracy: 0.9278\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0733 - accuracy: 0.96 - 0s 5ms/step - loss: 0.0624 - accuracy: 0.9716 - val_loss: 0.2600 - val_accuracy: 0.9278\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0842 - accuracy: 0.95 - 0s 5ms/step - loss: 0.0636 - accuracy: 0.9716 - val_loss: 0.4331 - val_accuracy: 0.9175\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1272 - accuracy: 0.95 - 0s 6ms/step - loss: 0.0657 - accuracy: 0.9690 - val_loss: 0.4291 - val_accuracy: 0.9175\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0333 - accuracy: 0.98 - 0s 5ms/step - loss: 0.0526 - accuracy: 0.9716 - val_loss: 0.3091 - val_accuracy: 0.9175\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0447 - accuracy: 0.98 - 0s 5ms/step - loss: 0.0824 - accuracy: 0.9587 - val_loss: 0.5383 - val_accuracy: 0.9278\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0597 - accuracy: 0.96 - 0s 5ms/step - loss: 0.0549 - accuracy: 0.9742 - val_loss: 0.3921 - val_accuracy: 0.9381\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0967 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0776 - accuracy: 0.9587 - val_loss: 0.3853 - val_accuracy: 0.9278\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0360 - accuracy: 1.00 - 0s 6ms/step - loss: 0.0573 - accuracy: 0.9664 - val_loss: 0.4050 - val_accuracy: 0.9381\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0245 - accuracy: 1.00 - 0s 5ms/step - loss: 0.0483 - accuracy: 0.9767 - val_loss: 0.5013 - val_accuracy: 0.8969\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1713 - accuracy: 0.90 - 0s 5ms/step - loss: 0.0714 - accuracy: 0.9587 - val_loss: 0.3868 - val_accuracy: 0.9278\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.3168 - accuracy: 0.95 - 0s 6ms/step - loss: 0.0967 - accuracy: 0.9716 - val_loss: 0.6441 - val_accuracy: 0.9278\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0442 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0452 - accuracy: 0.9742 - val_loss: 0.5133 - val_accuracy: 0.9381\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0731 - accuracy: 0.93 - 0s 4ms/step - loss: 0.0307 - accuracy: 0.9845 - val_loss: 0.5126 - val_accuracy: 0.9485\n",
      "WARNING:tensorflow:5 out of the last 14 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001B848B4E798> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN148\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š        | 149/169 [15:56<02:32,  7.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_149\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_596 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_597 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_598 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_599 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.7572 - accuracy: 0.32 - 0s 24ms/step - loss: 0.5089 - accuracy: 0.7458 - val_loss: 0.4035 - val_accuracy: 0.8556\n",
      "Epoch 2/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.3915 - accuracy: 0.85 - 0s 5ms/step - loss: 0.3382 - accuracy: 0.8575 - val_loss: 0.3753 - val_accuracy: 0.8556\n",
      "Epoch 3/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1807 - accuracy: 0.92 - 0s 5ms/step - loss: 0.2786 - accuracy: 0.8575 - val_loss: 0.4229 - val_accuracy: 0.8556\n",
      "Epoch 4/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.2738 - accuracy: 0.81 - 0s 5ms/step - loss: 0.2469 - accuracy: 0.8575 - val_loss: 0.5119 - val_accuracy: 0.8556\n",
      "Epoch 5/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.2720 - accuracy: 0.82 - 0s 5ms/step - loss: 0.2061 - accuracy: 0.8575 - val_loss: 0.5601 - val_accuracy: 0.8556\n",
      "Epoch 6/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1652 - accuracy: 0.89 - 0s 5ms/step - loss: 0.1707 - accuracy: 0.8575 - val_loss: 0.6321 - val_accuracy: 0.8556\n",
      "Epoch 7/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.2166 - accuracy: 0.82 - 0s 5ms/step - loss: 0.1507 - accuracy: 0.8939 - val_loss: 0.8402 - val_accuracy: 0.8444\n",
      "Epoch 8/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1184 - accuracy: 0.93 - 0s 5ms/step - loss: 0.1324 - accuracy: 0.9497 - val_loss: 0.9133 - val_accuracy: 0.8111\n",
      "Epoch 9/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0839 - accuracy: 0.96 - 0s 5ms/step - loss: 0.1122 - accuracy: 0.9609 - val_loss: 1.2262 - val_accuracy: 0.8111\n",
      "Epoch 10/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1370 - accuracy: 0.96 - 0s 5ms/step - loss: 0.1010 - accuracy: 0.9721 - val_loss: 1.4702 - val_accuracy: 0.8111\n",
      "Epoch 11/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0651 - accuracy: 1.00 - 0s 5ms/step - loss: 0.0933 - accuracy: 0.9721 - val_loss: 1.8258 - val_accuracy: 0.8222\n",
      "Epoch 12/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0827 - accuracy: 0.96 - 0s 5ms/step - loss: 0.0894 - accuracy: 0.9693 - val_loss: 1.5270 - val_accuracy: 0.7778\n",
      "Epoch 13/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0430 - accuracy: 0.98 - 0s 5ms/step - loss: 0.1202 - accuracy: 0.9469 - val_loss: 1.4716 - val_accuracy: 0.7333\n",
      "Epoch 14/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0881 - accuracy: 0.96 - 0s 5ms/step - loss: 0.1392 - accuracy: 0.9330 - val_loss: 1.6429 - val_accuracy: 0.7889\n",
      "Epoch 15/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0950 - accuracy: 0.96 - 0s 5ms/step - loss: 0.1684 - accuracy: 0.9413 - val_loss: 2.3223 - val_accuracy: 0.7778\n",
      "Epoch 16/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.2112 - accuracy: 0.90 - 0s 5ms/step - loss: 0.1501 - accuracy: 0.9385 - val_loss: 1.5452 - val_accuracy: 0.7333\n",
      "Epoch 17/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1066 - accuracy: 0.95 - 0s 6ms/step - loss: 0.1175 - accuracy: 0.9497 - val_loss: 1.8197 - val_accuracy: 0.8444\n",
      "Epoch 18/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1107 - accuracy: 0.95 - 0s 6ms/step - loss: 0.1557 - accuracy: 0.9525 - val_loss: 1.2562 - val_accuracy: 0.7778\n",
      "Epoch 19/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0954 - accuracy: 0.95 - 0s 5ms/step - loss: 0.1077 - accuracy: 0.9637 - val_loss: 1.2606 - val_accuracy: 0.7889\n",
      "Epoch 20/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1405 - accuracy: 0.95 - 0s 5ms/step - loss: 0.1018 - accuracy: 0.9609 - val_loss: 1.6782 - val_accuracy: 0.8222\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN149\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–       | 150/169 [16:03<02:18,  7.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_150\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_600 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_601 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_602 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_603 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.6313 - accuracy: 0.68 - 0s 19ms/step - loss: 0.4984 - accuracy: 0.7412 - val_loss: 0.4166 - val_accuracy: 0.7686\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2943 - accuracy: 0.87 - 0s 4ms/step - loss: 0.3715 - accuracy: 0.8157 - val_loss: 0.4242 - val_accuracy: 0.7851\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.3051 - accuracy: 0.85 - 0s 4ms/step - loss: 0.3116 - accuracy: 0.8592 - val_loss: 0.4426 - val_accuracy: 0.7851\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2612 - accuracy: 0.89 - 0s 4ms/step - loss: 0.2743 - accuracy: 0.8861 - val_loss: 0.5072 - val_accuracy: 0.7851\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2309 - accuracy: 0.89 - 0s 4ms/step - loss: 0.2454 - accuracy: 0.8965 - val_loss: 0.4887 - val_accuracy: 0.7934\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1994 - accuracy: 0.89 - 0s 4ms/step - loss: 0.2256 - accuracy: 0.8882 - val_loss: 0.5460 - val_accuracy: 0.8182\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1886 - accuracy: 0.93 - 0s 5ms/step - loss: 0.1758 - accuracy: 0.9255 - val_loss: 0.7296 - val_accuracy: 0.7603\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1411 - accuracy: 0.92 - 0s 5ms/step - loss: 0.1628 - accuracy: 0.9337 - val_loss: 0.8775 - val_accuracy: 0.7934\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0784 - accuracy: 0.96 - 0s 5ms/step - loss: 0.2234 - accuracy: 0.9255 - val_loss: 0.8188 - val_accuracy: 0.7686\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2744 - accuracy: 0.89 - 0s 4ms/step - loss: 0.1928 - accuracy: 0.9275 - val_loss: 1.1384 - val_accuracy: 0.8099\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.3052 - accuracy: 0.93 - 0s 5ms/step - loss: 0.1955 - accuracy: 0.9296 - val_loss: 0.8322 - val_accuracy: 0.7851\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2137 - accuracy: 0.90 - 0s 4ms/step - loss: 0.1394 - accuracy: 0.9482 - val_loss: 1.2707 - val_accuracy: 0.7686\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1127 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1095 - accuracy: 0.9607 - val_loss: 1.0539 - val_accuracy: 0.7851\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0629 - accuracy: 0.98 - 0s 5ms/step - loss: 0.0806 - accuracy: 0.9689 - val_loss: 1.2066 - val_accuracy: 0.7851\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0587 - accuracy: 0.98 - 0s 5ms/step - loss: 0.0700 - accuracy: 0.9731 - val_loss: 1.4101 - val_accuracy: 0.7769\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0603 - accuracy: 0.98 - 0s 5ms/step - loss: 0.0542 - accuracy: 0.9834 - val_loss: 1.5497 - val_accuracy: 0.7686\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1735 - accuracy: 0.92 - 0s 5ms/step - loss: 0.0763 - accuracy: 0.9752 - val_loss: 1.8711 - val_accuracy: 0.7851\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2057 - accuracy: 0.93 - 0s 4ms/step - loss: 0.1044 - accuracy: 0.9565 - val_loss: 1.6337 - val_accuracy: 0.7686\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0093 - accuracy: 1.00 - 0s 4ms/step - loss: 0.1019 - accuracy: 0.9627 - val_loss: 1.5305 - val_accuracy: 0.7934\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0317 - accuracy: 1.00 - 0s 4ms/step - loss: 0.1058 - accuracy: 0.9648 - val_loss: 1.4768 - val_accuracy: 0.7521\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN150\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹       | 151/169 [16:10<02:07,  7.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_151\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_604 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_605 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_606 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_607 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.7409 - accuracy: 0.37 - 0s 23ms/step - loss: 0.4006 - accuracy: 0.7871 - val_loss: 0.2521 - val_accuracy: 0.8667\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2036 - accuracy: 0.84 - 0s 4ms/step - loss: 0.1833 - accuracy: 0.8660 - val_loss: 0.2241 - val_accuracy: 0.8667\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1254 - accuracy: 0.89 - 0s 4ms/step - loss: 0.1371 - accuracy: 0.8660 - val_loss: 0.2356 - val_accuracy: 0.8667\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0856 - accuracy: 0.92 - 0s 4ms/step - loss: 0.1181 - accuracy: 0.8732 - val_loss: 0.2608 - val_accuracy: 0.9143\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0974 - accuracy: 1.00 - 0s 4ms/step - loss: 0.1064 - accuracy: 0.9761 - val_loss: 0.2695 - val_accuracy: 0.9048\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1114 - accuracy: 0.96 - 0s 4ms/step - loss: 0.0955 - accuracy: 0.9809 - val_loss: 0.2613 - val_accuracy: 0.8952\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1193 - accuracy: 0.96 - 0s 4ms/step - loss: 0.0843 - accuracy: 0.9856 - val_loss: 0.4836 - val_accuracy: 0.8762\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0801 - accuracy: 0.95 - 0s 4ms/step - loss: 0.0923 - accuracy: 0.9617 - val_loss: 0.2309 - val_accuracy: 0.9238\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0536 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0838 - accuracy: 0.9761 - val_loss: 0.1539 - val_accuracy: 0.9429\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0548 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0731 - accuracy: 0.9785 - val_loss: 0.1544 - val_accuracy: 0.9333\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0294 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0694 - accuracy: 0.9785 - val_loss: 0.1762 - val_accuracy: 0.9429\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0792 - accuracy: 0.96 - 0s 4ms/step - loss: 0.0685 - accuracy: 0.9785 - val_loss: 0.1558 - val_accuracy: 0.9524\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1120 - accuracy: 0.93 - 0s 4ms/step - loss: 0.0661 - accuracy: 0.9785 - val_loss: 0.1270 - val_accuracy: 0.9619\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0469 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0655 - accuracy: 0.9785 - val_loss: 0.1159 - val_accuracy: 0.9619\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0747 - accuracy: 0.96 - 0s 4ms/step - loss: 0.0646 - accuracy: 0.9785 - val_loss: 0.1143 - val_accuracy: 0.9619\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0426 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0640 - accuracy: 0.9785 - val_loss: 0.1147 - val_accuracy: 0.9524\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1050 - accuracy: 0.95 - 0s 5ms/step - loss: 0.0635 - accuracy: 0.9785 - val_loss: 0.1156 - val_accuracy: 0.9429\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0423 - accuracy: 0.98 - 0s 5ms/step - loss: 0.0633 - accuracy: 0.9785 - val_loss: 0.1122 - val_accuracy: 0.9524\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0728 - accuracy: 0.96 - 0s 4ms/step - loss: 0.0631 - accuracy: 0.9785 - val_loss: 0.1099 - val_accuracy: 0.9524\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0228 - accuracy: 1.00 - 0s 5ms/step - loss: 0.0631 - accuracy: 0.9785 - val_loss: 0.1097 - val_accuracy: 0.9524\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN151\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ       | 152/169 [16:16<01:56,  6.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_152\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_608 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_609 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_610 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_611 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.7303 - accuracy: 0.5000WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.4932 - accuracy: 0.7603 - val_loss: 0.3890 - val_accuracy: 0.8000\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.4117 - accuracy: 0.73 - 0s 4ms/step - loss: 0.3468 - accuracy: 0.7945 - val_loss: 0.3573 - val_accuracy: 0.8000\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2701 - accuracy: 0.82 - 0s 5ms/step - loss: 0.2923 - accuracy: 0.7968 - val_loss: 0.3522 - val_accuracy: 0.8000\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.3175 - accuracy: 0.73 - 0s 5ms/step - loss: 0.2652 - accuracy: 0.7968 - val_loss: 0.3196 - val_accuracy: 0.8455\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2807 - accuracy: 0.82 - 0s 5ms/step - loss: 0.2406 - accuracy: 0.8767 - val_loss: 0.3165 - val_accuracy: 0.8182\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2227 - accuracy: 0.89 - 0s 5ms/step - loss: 0.2164 - accuracy: 0.9018 - val_loss: 0.3977 - val_accuracy: 0.8182\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2926 - accuracy: 0.82 - 0s 5ms/step - loss: 0.2193 - accuracy: 0.8881 - val_loss: 0.4830 - val_accuracy: 0.7545\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2861 - accuracy: 0.84 - 0s 5ms/step - loss: 0.2213 - accuracy: 0.8950 - val_loss: 0.5795 - val_accuracy: 0.7727\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1688 - accuracy: 0.95 - 0s 5ms/step - loss: 0.1902 - accuracy: 0.9041 - val_loss: 0.6299 - val_accuracy: 0.8273\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1056 - accuracy: 0.96 - 0s 5ms/step - loss: 0.1790 - accuracy: 0.9201 - val_loss: 0.6377 - val_accuracy: 0.7636\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1818 - accuracy: 0.92 - 0s 4ms/step - loss: 0.1786 - accuracy: 0.9247 - val_loss: 0.6869 - val_accuracy: 0.7909\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1923 - accuracy: 0.90 - 0s 4ms/step - loss: 0.1459 - accuracy: 0.9475 - val_loss: 0.7625 - val_accuracy: 0.8091\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0994 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1489 - accuracy: 0.9406 - val_loss: 0.9137 - val_accuracy: 0.8455\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0877 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1375 - accuracy: 0.9521 - val_loss: 0.7415 - val_accuracy: 0.7727\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1060 - accuracy: 0.98 - 0s 4ms/step - loss: 0.1358 - accuracy: 0.9475 - val_loss: 1.0572 - val_accuracy: 0.8273\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1053 - accuracy: 0.96 - 0s 5ms/step - loss: 0.1314 - accuracy: 0.9452 - val_loss: 1.1441 - val_accuracy: 0.7545\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1773 - accuracy: 0.92 - 0s 4ms/step - loss: 0.1253 - accuracy: 0.9521 - val_loss: 1.2201 - val_accuracy: 0.8091\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1524 - accuracy: 0.93 - 0s 5ms/step - loss: 0.1274 - accuracy: 0.9521 - val_loss: 1.3219 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1002 - accuracy: 0.96 - 0s 5ms/step - loss: 0.1223 - accuracy: 0.9521 - val_loss: 1.4218 - val_accuracy: 0.7818\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1114 - accuracy: 0.95 - 0s 5ms/step - loss: 0.1182 - accuracy: 0.9566 - val_loss: 1.6253 - val_accuracy: 0.8000\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN152\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–      | 153/169 [16:22<01:48,  6.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_153\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_612 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_613 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_614 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_615 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 1.1749 - accuracy: 0.12 - 0s 22ms/step - loss: 0.6765 - accuracy: 0.7406 - val_loss: 0.3375 - val_accuracy: 0.8700\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2595 - accuracy: 0.92 - 0s 5ms/step - loss: 0.3058 - accuracy: 0.8665 - val_loss: 0.2427 - val_accuracy: 0.8700\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1615 - accuracy: 0.92 - 0s 4ms/step - loss: 0.2190 - accuracy: 0.8665 - val_loss: 0.2463 - val_accuracy: 0.8700\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2718 - accuracy: 0.76 - 0s 5ms/step - loss: 0.2037 - accuracy: 0.8665 - val_loss: 0.2387 - val_accuracy: 0.8700\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1348 - accuracy: 0.89 - 0s 5ms/step - loss: 0.1805 - accuracy: 0.8665 - val_loss: 0.2410 - val_accuracy: 0.8700\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1775 - accuracy: 0.84 - 0s 5ms/step - loss: 0.1646 - accuracy: 0.8665 - val_loss: 0.2384 - val_accuracy: 0.8700\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1280 - accuracy: 0.89 - 0s 6ms/step - loss: 0.1476 - accuracy: 0.8665 - val_loss: 0.2296 - val_accuracy: 0.8700\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1148 - accuracy: 0.90 - 0s 5ms/step - loss: 0.1262 - accuracy: 0.8665 - val_loss: 0.2326 - val_accuracy: 0.8700\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0935 - accuracy: 0.89 - 0s 6ms/step - loss: 0.1112 - accuracy: 0.9270 - val_loss: 0.2676 - val_accuracy: 0.9200\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1256 - accuracy: 0.98 - 0s 7ms/step - loss: 0.1042 - accuracy: 0.9597 - val_loss: 0.3038 - val_accuracy: 0.9200\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0518 - accuracy: 0.98 - 0s 6ms/step - loss: 0.0959 - accuracy: 0.9798 - val_loss: 0.3457 - val_accuracy: 0.8800\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0991 - accuracy: 0.98 - 0s 7ms/step - loss: 0.0888 - accuracy: 0.9798 - val_loss: 0.3990 - val_accuracy: 0.9100\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0795 - accuracy: 1.00 - 0s 7ms/step - loss: 0.0888 - accuracy: 0.9723 - val_loss: 0.4101 - val_accuracy: 0.8900\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0816 - accuracy: 0.98 - 0s 7ms/step - loss: 0.0886 - accuracy: 0.9723 - val_loss: 0.4026 - val_accuracy: 0.8200\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1659 - accuracy: 0.90 - 0s 6ms/step - loss: 0.1085 - accuracy: 0.9521 - val_loss: 0.4239 - val_accuracy: 0.8500\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1378 - accuracy: 0.90 - 0s 7ms/step - loss: 0.0919 - accuracy: 0.9647 - val_loss: 0.3581 - val_accuracy: 0.8600\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1137 - accuracy: 0.95 - 0s 5ms/step - loss: 0.0888 - accuracy: 0.9673 - val_loss: 0.4653 - val_accuracy: 0.8100\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0824 - accuracy: 0.95 - 0s 5ms/step - loss: 0.0810 - accuracy: 0.9698 - val_loss: 0.4628 - val_accuracy: 0.8500\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0761 - accuracy: 0.96 - 0s 5ms/step - loss: 0.0724 - accuracy: 0.9798 - val_loss: 0.4730 - val_accuracy: 0.8900\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0322 - accuracy: 1.00 - 0s 6ms/step - loss: 0.0730 - accuracy: 0.9773 - val_loss: 0.4553 - val_accuracy: 0.8900\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN153\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰      | 154/169 [16:30<01:46,  7.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_154\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_616 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_617 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_618 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_619 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.7836 - accuracy: 0.26 - 0s 45ms/step - loss: 0.5304 - accuracy: 0.6973 - val_loss: 0.4241 - val_accuracy: 0.7679\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.4578 - accuracy: 0.71 - 0s 9ms/step - loss: 0.3762 - accuracy: 0.7646 - val_loss: 0.3793 - val_accuracy: 0.7679\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.3494 - accuracy: 0.65 - 0s 9ms/step - loss: 0.3016 - accuracy: 0.7646 - val_loss: 0.3772 - val_accuracy: 0.7589\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.3045 - accuracy: 0.73 - 0s 6ms/step - loss: 0.2368 - accuracy: 0.8969 - val_loss: 0.3864 - val_accuracy: 0.7679\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2119 - accuracy: 0.90 - 0s 5ms/step - loss: 0.1713 - accuracy: 0.9372 - val_loss: 0.5636 - val_accuracy: 0.7857\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0960 - accuracy: 0.96 - 0s 6ms/step - loss: 0.1255 - accuracy: 0.9529 - val_loss: 0.7428 - val_accuracy: 0.8482\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0192 - accuracy: 1.00 - 0s 5ms/step - loss: 0.1139 - accuracy: 0.9596 - val_loss: 0.7230 - val_accuracy: 0.7768\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0772 - accuracy: 0.95 - 0s 5ms/step - loss: 0.1007 - accuracy: 0.9619 - val_loss: 0.5669 - val_accuracy: 0.8482\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0880 - accuracy: 0.96 - 0s 5ms/step - loss: 0.0919 - accuracy: 0.9641 - val_loss: 0.6337 - val_accuracy: 0.7857\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0683 - accuracy: 0.96 - 0s 6ms/step - loss: 0.0903 - accuracy: 0.9709 - val_loss: 0.7500 - val_accuracy: 0.7857\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0347 - accuracy: 1.00 - 0s 9ms/step - loss: 0.0997 - accuracy: 0.9664 - val_loss: 0.5637 - val_accuracy: 0.8036\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1559 - accuracy: 0.95 - 0s 7ms/step - loss: 0.1002 - accuracy: 0.9664 - val_loss: 0.6163 - val_accuracy: 0.7946\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1371 - accuracy: 0.95 - 0s 6ms/step - loss: 0.0678 - accuracy: 0.9798 - val_loss: 0.5907 - val_accuracy: 0.8036\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0518 - accuracy: 0.98 - 0s 6ms/step - loss: 0.0422 - accuracy: 0.9821 - val_loss: 0.7555 - val_accuracy: 0.7857\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0174 - accuracy: 1.00 - 0s 5ms/step - loss: 0.0306 - accuracy: 0.9821 - val_loss: 0.9045 - val_accuracy: 0.7768\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0221 - accuracy: 0.98 - 0s 6ms/step - loss: 0.0199 - accuracy: 0.9910 - val_loss: 1.0617 - val_accuracy: 0.7857\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0107 - accuracy: 1.00 - 0s 8ms/step - loss: 0.0166 - accuracy: 0.9933 - val_loss: 1.1635 - val_accuracy: 0.7857\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 1.00 - 0s 9ms/step - loss: 0.0123 - accuracy: 0.9933 - val_loss: 1.2873 - val_accuracy: 0.7768\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0073 - accuracy: 1.00 - 0s 7ms/step - loss: 0.0139 - accuracy: 0.9933 - val_loss: 1.4442 - val_accuracy: 0.7768\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0093 - accuracy: 1.00 - 0s 6ms/step - loss: 0.0126 - accuracy: 0.9933 - val_loss: 1.5711 - val_accuracy: 0.7768\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN154\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 155/169 [16:38<01:42,  7.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_155\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_620 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_621 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_622 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_623 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.5709 - accuracy: 0.71 - 1s 66ms/step - loss: 0.5578 - accuracy: 0.7586 - val_loss: 0.4784 - val_accuracy: 0.7440\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.4090 - accuracy: 0.82 - 0s 5ms/step - loss: 0.3347 - accuracy: 0.8531 - val_loss: 0.4542 - val_accuracy: 0.8000\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2398 - accuracy: 0.90 - 0s 5ms/step - loss: 0.2372 - accuracy: 0.9115 - val_loss: 0.4069 - val_accuracy: 0.8080\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1926 - accuracy: 0.92 - 0s 5ms/step - loss: 0.1770 - accuracy: 0.9396 - val_loss: 0.4398 - val_accuracy: 0.8160\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1423 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1226 - accuracy: 0.9416 - val_loss: 0.4897 - val_accuracy: 0.8320\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0863 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1314 - accuracy: 0.9477 - val_loss: 0.6847 - val_accuracy: 0.8320\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0329 - accuracy: 1.00 - 0s 4ms/step - loss: 0.1060 - accuracy: 0.9577 - val_loss: 0.8344 - val_accuracy: 0.8080\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1037 - accuracy: 0.95 - 0s 5ms/step - loss: 0.1190 - accuracy: 0.9537 - val_loss: 0.8564 - val_accuracy: 0.7840\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0701 - accuracy: 0.96 - 0s 5ms/step - loss: 0.1018 - accuracy: 0.9497 - val_loss: 0.8215 - val_accuracy: 0.8320\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0676 - accuracy: 0.96 - 0s 4ms/step - loss: 0.0859 - accuracy: 0.9698 - val_loss: 1.0659 - val_accuracy: 0.8400\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0149 - accuracy: 1.00 - 0s 4ms/step - loss: 0.1007 - accuracy: 0.9557 - val_loss: 0.8949 - val_accuracy: 0.8000\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1562 - accuracy: 0.93 - 0s 6ms/step - loss: 0.1019 - accuracy: 0.9517 - val_loss: 0.8493 - val_accuracy: 0.8000\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0745 - accuracy: 0.96 - 0s 5ms/step - loss: 0.0773 - accuracy: 0.9738 - val_loss: 0.9146 - val_accuracy: 0.7920\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0427 - accuracy: 0.96 - 0s 5ms/step - loss: 0.0454 - accuracy: 0.9779 - val_loss: 1.0369 - val_accuracy: 0.8240\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0138 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0329 - accuracy: 0.9819 - val_loss: 1.1606 - val_accuracy: 0.8160\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0047 - accuracy: 1.00 - 0s 5ms/step - loss: 0.0304 - accuracy: 0.9899 - val_loss: 1.3901 - val_accuracy: 0.8160\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0055 - accuracy: 1.00 - 0s 5ms/step - loss: 0.0589 - accuracy: 0.9819 - val_loss: 1.6158 - val_accuracy: 0.8000\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0581 - accuracy: 0.9879 - val_loss: 1.5255 - val_accuracy: 0.7760\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0324 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0431 - accuracy: 0.9819 - val_loss: 1.2574 - val_accuracy: 0.8080\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0162 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0334 - accuracy: 0.9879 - val_loss: 1.1078 - val_accuracy: 0.8400\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN155\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 156/169 [16:46<01:36,  7.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_156\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_624 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_625 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_626 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_627 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.6546 - accuracy: 0.64 - 0s 25ms/step - loss: 0.4308 - accuracy: 0.8426 - val_loss: 0.2748 - val_accuracy: 0.8750\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1930 - accuracy: 0.92 - 0s 6ms/step - loss: 0.2312 - accuracy: 0.8789 - val_loss: 0.2413 - val_accuracy: 0.8750\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1367 - accuracy: 0.90 - 0s 6ms/step - loss: 0.1831 - accuracy: 0.8789 - val_loss: 0.2709 - val_accuracy: 0.8750\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0795 - accuracy: 0.92 - 0s 7ms/step - loss: 0.1542 - accuracy: 0.8789 - val_loss: 0.2299 - val_accuracy: 0.8750\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1476 - accuracy: 0.87 - 0s 6ms/step - loss: 0.1369 - accuracy: 0.9007 - val_loss: 0.2804 - val_accuracy: 0.8942\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1019 - accuracy: 0.96 - 0s 7ms/step - loss: 0.1236 - accuracy: 0.9467 - val_loss: 0.2650 - val_accuracy: 0.9135\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1219 - accuracy: 0.92 - 0s 6ms/step - loss: 0.1089 - accuracy: 0.9734 - val_loss: 0.2742 - val_accuracy: 0.9135\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0923 - accuracy: 0.96 - 0s 5ms/step - loss: 0.1035 - accuracy: 0.9588 - val_loss: 0.3998 - val_accuracy: 0.9231\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0944 - accuracy: 0.95 - 0s 5ms/step - loss: 0.0874 - accuracy: 0.9758 - val_loss: 0.3502 - val_accuracy: 0.9038\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1357 - accuracy: 0.92 - 0s 5ms/step - loss: 0.0869 - accuracy: 0.9734 - val_loss: 0.4077 - val_accuracy: 0.9038\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0797 - accuracy: 0.96 - 0s 5ms/step - loss: 0.0702 - accuracy: 0.9782 - val_loss: 0.4279 - val_accuracy: 0.9231\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0418 - accuracy: 0.98 - 0s 6ms/step - loss: 0.0595 - accuracy: 0.9831 - val_loss: 0.4478 - val_accuracy: 0.9327\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0944 - accuracy: 0.96 - 0s 5ms/step - loss: 0.0534 - accuracy: 0.9879 - val_loss: 0.5375 - val_accuracy: 0.9231\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1048 - accuracy: 0.95 - 0s 6ms/step - loss: 0.0501 - accuracy: 0.9879 - val_loss: 0.5874 - val_accuracy: 0.9231\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0395 - accuracy: 0.98 - 0s 5ms/step - loss: 0.0472 - accuracy: 0.9879 - val_loss: 0.6424 - val_accuracy: 0.9231\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0528 - accuracy: 0.98 - 0s 6ms/step - loss: 0.0455 - accuracy: 0.9879 - val_loss: 0.6483 - val_accuracy: 0.9135\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0487 - accuracy: 0.98 - 0s 5ms/step - loss: 0.0444 - accuracy: 0.9879 - val_loss: 0.6580 - val_accuracy: 0.9135\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0671 - accuracy: 0.98 - 0s 5ms/step - loss: 0.0434 - accuracy: 0.9879 - val_loss: 0.6764 - val_accuracy: 0.9135\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0103 - accuracy: 1.00 - 0s 5ms/step - loss: 0.0426 - accuracy: 0.9879 - val_loss: 0.6934 - val_accuracy: 0.9231\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0167 - accuracy: 1.00 - 0s 5ms/step - loss: 0.0422 - accuracy: 0.9879 - val_loss: 0.7128 - val_accuracy: 0.9231\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN156\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 157/169 [16:54<01:30,  7.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_157\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_628 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_629 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_630 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_631 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.7234 - accuracy: 0.50 - 0s 23ms/step - loss: 0.5209 - accuracy: 0.7018 - val_loss: 0.3516 - val_accuracy: 0.7455\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.3705 - accuracy: 0.71 - 0s 5ms/step - loss: 0.3393 - accuracy: 0.7408 - val_loss: 0.3336 - val_accuracy: 0.7455\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.3876 - accuracy: 0.65 - 0s 5ms/step - loss: 0.3106 - accuracy: 0.8326 - val_loss: 0.3729 - val_accuracy: 0.8364\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2511 - accuracy: 0.84 - 0s 5ms/step - loss: 0.2613 - accuracy: 0.8853 - val_loss: 0.3614 - val_accuracy: 0.8455\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2472 - accuracy: 0.89 - 0s 4ms/step - loss: 0.2363 - accuracy: 0.9014 - val_loss: 0.4120 - val_accuracy: 0.8545\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1582 - accuracy: 0.96 - 0s 5ms/step - loss: 0.2124 - accuracy: 0.9128 - val_loss: 0.4148 - val_accuracy: 0.8545\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1512 - accuracy: 0.93 - 0s 5ms/step - loss: 0.1906 - accuracy: 0.9220 - val_loss: 0.4463 - val_accuracy: 0.8455\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2386 - accuracy: 0.92 - 0s 5ms/step - loss: 0.1747 - accuracy: 0.9312 - val_loss: 0.4874 - val_accuracy: 0.8545\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1614 - accuracy: 0.93 - 0s 6ms/step - loss: 0.1745 - accuracy: 0.9266 - val_loss: 0.4279 - val_accuracy: 0.8727\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1496 - accuracy: 0.95 - 0s 5ms/step - loss: 0.1636 - accuracy: 0.9404 - val_loss: 0.4358 - val_accuracy: 0.8727\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1860 - accuracy: 0.92 - 0s 5ms/step - loss: 0.1559 - accuracy: 0.9358 - val_loss: 0.4861 - val_accuracy: 0.8727\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1832 - accuracy: 0.92 - 0s 5ms/step - loss: 0.1689 - accuracy: 0.9312 - val_loss: 0.4798 - val_accuracy: 0.8636\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1462 - accuracy: 0.95 - 0s 5ms/step - loss: 0.1656 - accuracy: 0.9381 - val_loss: 0.7215 - val_accuracy: 0.8909\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2147 - accuracy: 0.92 - 0s 4ms/step - loss: 0.1736 - accuracy: 0.9358 - val_loss: 0.6591 - val_accuracy: 0.8636\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1798 - accuracy: 0.92 - 0s 4ms/step - loss: 0.1791 - accuracy: 0.9358 - val_loss: 0.5791 - val_accuracy: 0.8727\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0993 - accuracy: 0.98 - 0s 6ms/step - loss: 0.1512 - accuracy: 0.9472 - val_loss: 0.4975 - val_accuracy: 0.8818\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1918 - accuracy: 0.93 - 0s 5ms/step - loss: 0.1536 - accuracy: 0.9472 - val_loss: 0.4657 - val_accuracy: 0.8818\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1564 - accuracy: 0.93 - 0s 5ms/step - loss: 0.1342 - accuracy: 0.9518 - val_loss: 0.5164 - val_accuracy: 0.8727\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1358 - accuracy: 0.95 - 0s 5ms/step - loss: 0.1307 - accuracy: 0.9541 - val_loss: 0.5908 - val_accuracy: 0.8636\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0924 - accuracy: 0.96 - 0s 5ms/step - loss: 0.1200 - accuracy: 0.9587 - val_loss: 0.5944 - val_accuracy: 0.8636\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN157\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 158/169 [17:00<01:20,  7.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_158\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_632 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_633 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_634 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_635 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.6742 - accuracy: 0.73 - 0s 20ms/step - loss: 0.5482 - accuracy: 0.7349 - val_loss: 0.4985 - val_accuracy: 0.7778\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.4455 - accuracy: 0.76 - 0s 4ms/step - loss: 0.3759 - accuracy: 0.8168 - val_loss: 0.7495 - val_accuracy: 0.7949\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2625 - accuracy: 0.85 - 0s 4ms/step - loss: 0.2555 - accuracy: 0.8815 - val_loss: 0.6746 - val_accuracy: 0.8034\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2259 - accuracy: 0.93 - 0s 4ms/step - loss: 0.2161 - accuracy: 0.9138 - val_loss: 0.6652 - val_accuracy: 0.7863\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1272 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1491 - accuracy: 0.9483 - val_loss: 0.7251 - val_accuracy: 0.7949\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1256 - accuracy: 0.93 - 0s 4ms/step - loss: 0.1342 - accuracy: 0.9461 - val_loss: 0.7654 - val_accuracy: 0.8205\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0734 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1229 - accuracy: 0.9504 - val_loss: 0.7646 - val_accuracy: 0.7949\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0678 - accuracy: 0.98 - 0s 4ms/step - loss: 0.1177 - accuracy: 0.9461 - val_loss: 0.9842 - val_accuracy: 0.8120\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0850 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1102 - accuracy: 0.9504 - val_loss: 1.0176 - val_accuracy: 0.8120\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1055 - accuracy: 0.95 - 0s 4ms/step - loss: 0.0860 - accuracy: 0.9591 - val_loss: 1.1350 - val_accuracy: 0.7949\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0624 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0608 - accuracy: 0.9784 - val_loss: 1.2541 - val_accuracy: 0.8120\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0866 - accuracy: 0.95 - 0s 5ms/step - loss: 0.0524 - accuracy: 0.9741 - val_loss: 1.2461 - val_accuracy: 0.8291\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0569 - accuracy: 0.95 - 0s 4ms/step - loss: 0.0392 - accuracy: 0.9806 - val_loss: 1.4279 - val_accuracy: 0.8120\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0353 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0560 - accuracy: 0.9849 - val_loss: 1.7264 - val_accuracy: 0.8034\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0245 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0558 - accuracy: 0.9828 - val_loss: 1.8599 - val_accuracy: 0.8205\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0384 - accuracy: 0.96 - 0s 4ms/step - loss: 0.0715 - accuracy: 0.9698 - val_loss: 1.5317 - val_accuracy: 0.7949\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0636 - accuracy: 0.96 - 0s 4ms/step - loss: 0.0711 - accuracy: 0.9698 - val_loss: 1.6111 - val_accuracy: 0.8205\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0600 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0829 - accuracy: 0.9784 - val_loss: 1.5489 - val_accuracy: 0.8205\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0288 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0548 - accuracy: 0.9784 - val_loss: 1.5778 - val_accuracy: 0.8034\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0319 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0455 - accuracy: 0.9871 - val_loss: 1.6415 - val_accuracy: 0.8205\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN158\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 159/169 [17:07<01:11,  7.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_159\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_636 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_637 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_638 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_639 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.7098 - accuracy: 0.43 - 0s 22ms/step - loss: 0.6142 - accuracy: 0.6338 - val_loss: 0.5108 - val_accuracy: 0.7278\n",
      "Epoch 2/20\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3643 - accuracy: 0.79 - 0s 5ms/step - loss: 0.4778 - accuracy: 0.7420 - val_loss: 0.5153 - val_accuracy: 0.7911\n",
      "Epoch 3/20\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.4860 - accuracy: 0.73 - 0s 4ms/step - loss: 0.4434 - accuracy: 0.7787 - val_loss: 0.4676 - val_accuracy: 0.7785\n",
      "Epoch 4/20\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3624 - accuracy: 0.85 - 0s 4ms/step - loss: 0.3907 - accuracy: 0.8121 - val_loss: 0.5167 - val_accuracy: 0.7848\n",
      "Epoch 5/20\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.4074 - accuracy: 0.78 - 0s 4ms/step - loss: 0.3372 - accuracy: 0.8424 - val_loss: 0.5277 - val_accuracy: 0.7595\n",
      "Epoch 6/20\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3241 - accuracy: 0.78 - 0s 4ms/step - loss: 0.3093 - accuracy: 0.8503 - val_loss: 0.5511 - val_accuracy: 0.7975\n",
      "Epoch 7/20\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2928 - accuracy: 0.82 - 0s 3ms/step - loss: 0.2746 - accuracy: 0.8599 - val_loss: 0.7091 - val_accuracy: 0.7405\n",
      "Epoch 8/20\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2439 - accuracy: 0.87 - 0s 4ms/step - loss: 0.2666 - accuracy: 0.8710 - val_loss: 0.8224 - val_accuracy: 0.7658\n",
      "Epoch 9/20\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1834 - accuracy: 0.92 - 0s 4ms/step - loss: 0.2419 - accuracy: 0.8806 - val_loss: 0.6872 - val_accuracy: 0.7722\n",
      "Epoch 10/20\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2690 - accuracy: 0.87 - 0s 3ms/step - loss: 0.2305 - accuracy: 0.8774 - val_loss: 0.7571 - val_accuracy: 0.7595\n",
      "Epoch 11/20\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2269 - accuracy: 0.90 - 0s 4ms/step - loss: 0.2144 - accuracy: 0.8933 - val_loss: 0.7583 - val_accuracy: 0.7089\n",
      "Epoch 12/20\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2657 - accuracy: 0.85 - 0s 3ms/step - loss: 0.2364 - accuracy: 0.8838 - val_loss: 0.8877 - val_accuracy: 0.7152\n",
      "Epoch 13/20\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2280 - accuracy: 0.89 - 0s 4ms/step - loss: 0.2381 - accuracy: 0.8901 - val_loss: 1.0742 - val_accuracy: 0.7658\n",
      "Epoch 14/20\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1940 - accuracy: 0.90 - 0s 3ms/step - loss: 0.2432 - accuracy: 0.8981 - val_loss: 0.8968 - val_accuracy: 0.7595\n",
      "Epoch 15/20\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2032 - accuracy: 0.92 - 0s 4ms/step - loss: 0.2252 - accuracy: 0.8917 - val_loss: 1.3155 - val_accuracy: 0.7405\n",
      "Epoch 16/20\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1342 - accuracy: 0.95 - 0s 3ms/step - loss: 0.1817 - accuracy: 0.9124 - val_loss: 1.4759 - val_accuracy: 0.7089\n",
      "Epoch 17/20\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1318 - accuracy: 0.93 - 0s 3ms/step - loss: 0.2175 - accuracy: 0.9172 - val_loss: 0.8921 - val_accuracy: 0.7595\n",
      "Epoch 18/20\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1430 - accuracy: 0.95 - 0s 3ms/step - loss: 0.1821 - accuracy: 0.9252 - val_loss: 0.8053 - val_accuracy: 0.7722\n",
      "Epoch 19/20\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1331 - accuracy: 0.92 - 0s 4ms/step - loss: 0.1541 - accuracy: 0.9331 - val_loss: 0.9448 - val_accuracy: 0.7658\n",
      "Epoch 20/20\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0822 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1506 - accuracy: 0.9363 - val_loss: 0.8858 - val_accuracy: 0.7785\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN159\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 160/169 [17:14<01:03,  7.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_160\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_640 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_641 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_642 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_643 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.6017 - accuracy: 0.71 - 0s 19ms/step - loss: 0.5693 - accuracy: 0.7056 - val_loss: 0.4467 - val_accuracy: 0.7759\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.3077 - accuracy: 0.85 - 0s 4ms/step - loss: 0.3503 - accuracy: 0.8333 - val_loss: 0.5218 - val_accuracy: 0.7845\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.3519 - accuracy: 0.79 - 0s 4ms/step - loss: 0.3648 - accuracy: 0.8268 - val_loss: 0.5184 - val_accuracy: 0.7586\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2898 - accuracy: 0.85 - 0s 4ms/step - loss: 0.3223 - accuracy: 0.8139 - val_loss: 0.5126 - val_accuracy: 0.7586\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2007 - accuracy: 0.89 - 0s 4ms/step - loss: 0.2794 - accuracy: 0.8398 - val_loss: 0.4910 - val_accuracy: 0.7672\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2713 - accuracy: 0.85 - 0s 4ms/step - loss: 0.2552 - accuracy: 0.8636 - val_loss: 0.5369 - val_accuracy: 0.8017\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2722 - accuracy: 0.85 - 0s 4ms/step - loss: 0.2348 - accuracy: 0.8831 - val_loss: 0.5398 - val_accuracy: 0.7931\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2283 - accuracy: 0.85 - 0s 4ms/step - loss: 0.1928 - accuracy: 0.9026 - val_loss: 0.6231 - val_accuracy: 0.8103\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1351 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1897 - accuracy: 0.9156 - val_loss: 0.5598 - val_accuracy: 0.7931\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2463 - accuracy: 0.85 - 0s 4ms/step - loss: 0.1862 - accuracy: 0.9199 - val_loss: 0.6606 - val_accuracy: 0.7931\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1418 - accuracy: 0.93 - 0s 4ms/step - loss: 0.1609 - accuracy: 0.9329 - val_loss: 0.8872 - val_accuracy: 0.8103\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0898 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1535 - accuracy: 0.9177 - val_loss: 0.8917 - val_accuracy: 0.8017\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0624 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1331 - accuracy: 0.9394 - val_loss: 1.0363 - val_accuracy: 0.8103\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0615 - accuracy: 0.98 - 0s 4ms/step - loss: 0.1342 - accuracy: 0.9351 - val_loss: 0.8312 - val_accuracy: 0.7759\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1885 - accuracy: 0.87 - 0s 5ms/step - loss: 0.1297 - accuracy: 0.9351 - val_loss: 0.9981 - val_accuracy: 0.7672\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0835 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1368 - accuracy: 0.9481 - val_loss: 1.0981 - val_accuracy: 0.8103\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1056 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1478 - accuracy: 0.9264 - val_loss: 0.9043 - val_accuracy: 0.8017\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1014 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1350 - accuracy: 0.9329 - val_loss: 0.9158 - val_accuracy: 0.7586\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1233 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1566 - accuracy: 0.9329 - val_loss: 0.7390 - val_accuracy: 0.8276\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1813 - accuracy: 0.90 - 0s 4ms/step - loss: 0.1563 - accuracy: 0.9329 - val_loss: 0.7908 - val_accuracy: 0.8276\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN160\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 161/169 [17:20<00:55,  6.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_161\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_644 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_645 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_646 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_647 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.7403 - accuracy: 0.37 - 0s 26ms/step - loss: 0.4497 - accuracy: 0.7080 - val_loss: 0.3207 - val_accuracy: 0.7706\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1910 - accuracy: 0.82 - 0s 4ms/step - loss: 0.2897 - accuracy: 0.7678 - val_loss: 0.2428 - val_accuracy: 0.7706\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1898 - accuracy: 0.79 - 0s 4ms/step - loss: 0.2355 - accuracy: 0.8621 - val_loss: 0.2441 - val_accuracy: 0.9174\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2381 - accuracy: 0.92 - 0s 5ms/step - loss: 0.1962 - accuracy: 0.9379 - val_loss: 0.2521 - val_accuracy: 0.9174\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2013 - accuracy: 0.93 - 0s 5ms/step - loss: 0.1707 - accuracy: 0.9517 - val_loss: 0.2258 - val_accuracy: 0.9266\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2132 - accuracy: 0.93 - 0s 5ms/step - loss: 0.1406 - accuracy: 0.9632 - val_loss: 0.2000 - val_accuracy: 0.9450\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1574 - accuracy: 0.92 - 0s 5ms/step - loss: 0.1273 - accuracy: 0.9609 - val_loss: 0.2512 - val_accuracy: 0.9358\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1399 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1176 - accuracy: 0.9655 - val_loss: 0.3488 - val_accuracy: 0.9174\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1075 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1039 - accuracy: 0.9724 - val_loss: 0.3745 - val_accuracy: 0.9083\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1200 - accuracy: 0.95 - 0s 5ms/step - loss: 0.0942 - accuracy: 0.9747 - val_loss: 0.4139 - val_accuracy: 0.9083\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0280 - accuracy: 1.00 - 0s 5ms/step - loss: 0.1000 - accuracy: 0.9701 - val_loss: 0.3950 - val_accuracy: 0.9174\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0942 - accuracy: 0.96 - 0s 5ms/step - loss: 0.1138 - accuracy: 0.9609 - val_loss: 0.3763 - val_accuracy: 0.9266\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0628 - accuracy: 0.98 - 0s 5ms/step - loss: 0.1008 - accuracy: 0.9655 - val_loss: 0.3866 - val_accuracy: 0.9266\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0983 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1101 - accuracy: 0.9655 - val_loss: 0.3248 - val_accuracy: 0.9266\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1396 - accuracy: 0.95 - 0s 6ms/step - loss: 0.1030 - accuracy: 0.9655 - val_loss: 0.3420 - val_accuracy: 0.9174\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1642 - accuracy: 0.93 - 0s 5ms/step - loss: 0.0948 - accuracy: 0.9701 - val_loss: 0.4343 - val_accuracy: 0.9174\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1024 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1018 - accuracy: 0.9678 - val_loss: 0.3976 - val_accuracy: 0.9174\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0409 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0928 - accuracy: 0.9701 - val_loss: 0.3447 - val_accuracy: 0.9174\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0815 - accuracy: 0.98 - 0s 5ms/step - loss: 0.0869 - accuracy: 0.9747 - val_loss: 0.3809 - val_accuracy: 0.9174\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0381 - accuracy: 1.00 - 0s 5ms/step - loss: 0.0860 - accuracy: 0.9724 - val_loss: 0.4079 - val_accuracy: 0.9083\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN161\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 162/169 [17:28<00:49,  7.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_162\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_648 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_649 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_650 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_651 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.8247 - accuracy: 0.40 - 0s 24ms/step - loss: 0.5188 - accuracy: 0.6983 - val_loss: 0.3943 - val_accuracy: 0.7736\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.3106 - accuracy: 0.85 - 0s 5ms/step - loss: 0.3354 - accuracy: 0.8314 - val_loss: 0.3600 - val_accuracy: 0.8585\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2343 - accuracy: 0.89 - 0s 6ms/step - loss: 0.2687 - accuracy: 0.8765 - val_loss: 0.5463 - val_accuracy: 0.8585\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2066 - accuracy: 0.89 - 0s 5ms/step - loss: 0.2269 - accuracy: 0.9026 - val_loss: 0.4707 - val_accuracy: 0.8585\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2086 - accuracy: 0.89 - 0s 5ms/step - loss: 0.1959 - accuracy: 0.9145 - val_loss: 0.5157 - val_accuracy: 0.8491\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1450 - accuracy: 0.96 - 0s 6ms/step - loss: 0.1620 - accuracy: 0.9287 - val_loss: 0.5862 - val_accuracy: 0.8679\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0994 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1428 - accuracy: 0.9430 - val_loss: 0.7503 - val_accuracy: 0.8491\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0977 - accuracy: 0.95 - 0s 5ms/step - loss: 0.1179 - accuracy: 0.9572 - val_loss: 0.8113 - val_accuracy: 0.8679\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1759 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1021 - accuracy: 0.9644 - val_loss: 0.9727 - val_accuracy: 0.8491\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0494 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0829 - accuracy: 0.9644 - val_loss: 1.2240 - val_accuracy: 0.8302\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0615 - accuracy: 0.98 - 0s 6ms/step - loss: 0.0816 - accuracy: 0.9667 - val_loss: 1.1944 - val_accuracy: 0.8302\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1152 - accuracy: 0.93 - 0s 5ms/step - loss: 0.0507 - accuracy: 0.9810 - val_loss: 1.6605 - val_accuracy: 0.8396\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0356 - accuracy: 0.98 - 0s 5ms/step - loss: 0.0524 - accuracy: 0.9786 - val_loss: 1.9617 - val_accuracy: 0.8019\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1647 - accuracy: 0.98 - 0s 5ms/step - loss: 0.1176 - accuracy: 0.9620 - val_loss: 1.8266 - val_accuracy: 0.8491\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1245 - accuracy: 0.95 - 0s 5ms/step - loss: 0.1386 - accuracy: 0.9406 - val_loss: 1.0523 - val_accuracy: 0.8774\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1710 - accuracy: 0.89 - 0s 5ms/step - loss: 0.1150 - accuracy: 0.9406 - val_loss: 1.0704 - val_accuracy: 0.9057\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0870 - accuracy: 0.95 - 0s 5ms/step - loss: 0.1190 - accuracy: 0.9430 - val_loss: 0.9324 - val_accuracy: 0.9057\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1607 - accuracy: 0.90 - 0s 5ms/step - loss: 0.1006 - accuracy: 0.9477 - val_loss: 0.9848 - val_accuracy: 0.9151\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0722 - accuracy: 0.95 - 0s 4ms/step - loss: 0.0733 - accuracy: 0.9691 - val_loss: 1.2457 - val_accuracy: 0.8774\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0690 - accuracy: 0.95 - 0s 4ms/step - loss: 0.0457 - accuracy: 0.9810 - val_loss: 1.5014 - val_accuracy: 0.8774\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN162\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 163/169 [17:35<00:42,  7.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_163\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_652 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_653 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_654 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_655 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.7941 - accuracy: 0.37 - 0s 21ms/step - loss: 0.5318 - accuracy: 0.6897 - val_loss: 0.3602 - val_accuracy: 0.7434\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.3072 - accuracy: 0.76 - 0s 4ms/step - loss: 0.3262 - accuracy: 0.7902 - val_loss: 0.3254 - val_accuracy: 0.8761\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2422 - accuracy: 0.87 - 0s 5ms/step - loss: 0.2508 - accuracy: 0.8638 - val_loss: 0.3647 - val_accuracy: 0.8761\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1701 - accuracy: 0.89 - 0s 5ms/step - loss: 0.1915 - accuracy: 0.9062 - val_loss: 0.3880 - val_accuracy: 0.8673\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1206 - accuracy: 0.92 - 0s 5ms/step - loss: 0.1520 - accuracy: 0.9308 - val_loss: 0.4653 - val_accuracy: 0.8761\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0856 - accuracy: 0.93 - 0s 5ms/step - loss: 0.1316 - accuracy: 0.9464 - val_loss: 0.5003 - val_accuracy: 0.8938\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1454 - accuracy: 0.95 - 0s 5ms/step - loss: 0.1152 - accuracy: 0.9531 - val_loss: 0.5262 - val_accuracy: 0.8850\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0517 - accuracy: 0.98 - 0s 5ms/step - loss: 0.1065 - accuracy: 0.9509 - val_loss: 0.5453 - val_accuracy: 0.8938\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0722 - accuracy: 0.93 - 0s 6ms/step - loss: 0.1077 - accuracy: 0.9487 - val_loss: 0.6843 - val_accuracy: 0.9027\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1439 - accuracy: 0.93 - 0s 5ms/step - loss: 0.0929 - accuracy: 0.9531 - val_loss: 0.7253 - val_accuracy: 0.9027\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2077 - accuracy: 0.87 - 0s 5ms/step - loss: 0.1195 - accuracy: 0.9420 - val_loss: 0.6703 - val_accuracy: 0.8850\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1270 - accuracy: 0.93 - 0s 5ms/step - loss: 0.1319 - accuracy: 0.9308 - val_loss: 0.7015 - val_accuracy: 0.9027\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1192 - accuracy: 0.95 - 0s 5ms/step - loss: 0.1148 - accuracy: 0.9330 - val_loss: 0.8329 - val_accuracy: 0.8761\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0776 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1006 - accuracy: 0.9397 - val_loss: 0.7960 - val_accuracy: 0.8761\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0882 - accuracy: 0.95 - 0s 5ms/step - loss: 0.0989 - accuracy: 0.9308 - val_loss: 0.7837 - val_accuracy: 0.8584\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0676 - accuracy: 0.96 - 0s 5ms/step - loss: 0.0962 - accuracy: 0.9353 - val_loss: 1.1069 - val_accuracy: 0.8850\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0831 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1170 - accuracy: 0.9531 - val_loss: 0.8729 - val_accuracy: 0.8938\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0841 - accuracy: 0.96 - 0s 4ms/step - loss: 0.0814 - accuracy: 0.9665 - val_loss: 0.6401 - val_accuracy: 0.8761\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0819 - accuracy: 0.96 - 0s 4ms/step - loss: 0.0667 - accuracy: 0.9621 - val_loss: 0.6831 - val_accuracy: 0.8761\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0354 - accuracy: 0.98 - 0s 5ms/step - loss: 0.0690 - accuracy: 0.9643 - val_loss: 0.6191 - val_accuracy: 0.8673\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN163\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 164/169 [17:42<00:35,  7.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_164\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_656 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_657 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_658 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_659 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 0.6972 - accuracy: 0.5625WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.5236 - accuracy: 0.7714 - val_loss: 0.3056 - val_accuracy: 0.8714\n",
      "Epoch 2/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.3792 - accuracy: 0.82 - 0s 4ms/step - loss: 0.3573 - accuracy: 0.8446 - val_loss: 0.3052 - val_accuracy: 0.8786\n",
      "Epoch 3/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2083 - accuracy: 0.95 - 0s 5ms/step - loss: 0.2773 - accuracy: 0.8857 - val_loss: 0.3122 - val_accuracy: 0.8786\n",
      "Epoch 4/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2056 - accuracy: 0.92 - 0s 5ms/step - loss: 0.2274 - accuracy: 0.9089 - val_loss: 0.3264 - val_accuracy: 0.8571\n",
      "Epoch 5/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2139 - accuracy: 0.90 - 0s 5ms/step - loss: 0.1803 - accuracy: 0.9214 - val_loss: 0.3804 - val_accuracy: 0.8714\n",
      "Epoch 6/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1337 - accuracy: 0.96 - 0s 5ms/step - loss: 0.1625 - accuracy: 0.9375 - val_loss: 0.3836 - val_accuracy: 0.9000\n",
      "Epoch 7/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1599 - accuracy: 0.92 - 0s 5ms/step - loss: 0.1657 - accuracy: 0.9339 - val_loss: 0.4229 - val_accuracy: 0.8714\n",
      "Epoch 8/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1519 - accuracy: 0.95 - 0s 5ms/step - loss: 0.1225 - accuracy: 0.9536 - val_loss: 0.5362 - val_accuracy: 0.8714\n",
      "Epoch 9/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1381 - accuracy: 0.92 - 0s 6ms/step - loss: 0.1128 - accuracy: 0.9411 - val_loss: 0.5893 - val_accuracy: 0.8429\n",
      "Epoch 10/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1037 - accuracy: 0.93 - 0s 6ms/step - loss: 0.1301 - accuracy: 0.9482 - val_loss: 0.6961 - val_accuracy: 0.8714\n",
      "Epoch 11/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1188 - accuracy: 0.93 - 0s 6ms/step - loss: 0.1349 - accuracy: 0.9375 - val_loss: 0.5413 - val_accuracy: 0.8286\n",
      "Epoch 12/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1397 - accuracy: 0.95 - 0s 5ms/step - loss: 0.1008 - accuracy: 0.9643 - val_loss: 0.5362 - val_accuracy: 0.8857\n",
      "Epoch 13/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0692 - accuracy: 0.98 - 0s 5ms/step - loss: 0.0703 - accuracy: 0.9679 - val_loss: 0.6006 - val_accuracy: 0.8786\n",
      "Epoch 14/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0724 - accuracy: 0.98 - 0s 5ms/step - loss: 0.0803 - accuracy: 0.9714 - val_loss: 0.6513 - val_accuracy: 0.8643\n",
      "Epoch 15/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0764 - accuracy: 0.95 - 0s 5ms/step - loss: 0.1506 - accuracy: 0.9643 - val_loss: 0.7495 - val_accuracy: 0.8714\n",
      "Epoch 16/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0349 - accuracy: 1.00 - 0s 5ms/step - loss: 0.1062 - accuracy: 0.9643 - val_loss: 0.6374 - val_accuracy: 0.8857\n",
      "Epoch 17/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1519 - accuracy: 0.95 - 0s 5ms/step - loss: 0.1032 - accuracy: 0.9661 - val_loss: 0.5776 - val_accuracy: 0.8786\n",
      "Epoch 18/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0453 - accuracy: 0.96 - 0s 5ms/step - loss: 0.0591 - accuracy: 0.9768 - val_loss: 0.7286 - val_accuracy: 0.8857\n",
      "Epoch 19/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0140 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0377 - accuracy: 0.9893 - val_loss: 0.8815 - val_accuracy: 0.8857\n",
      "Epoch 20/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0985 - accuracy: 0.98 - 0s 5ms/step - loss: 0.0252 - accuracy: 0.9929 - val_loss: 1.1400 - val_accuracy: 0.8786\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN164\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 165/169 [17:49<00:28,  7.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_165\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_660 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_661 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_662 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_663 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.7194 - accuracy: 0.59 - 0s 29ms/step - loss: 0.5592 - accuracy: 0.7000 - val_loss: 0.4568 - val_accuracy: 0.7297\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.3980 - accuracy: 0.73 - 0s 4ms/step - loss: 0.4002 - accuracy: 0.7295 - val_loss: 0.4612 - val_accuracy: 0.7297\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.3406 - accuracy: 0.75 - 0s 4ms/step - loss: 0.3357 - accuracy: 0.7295 - val_loss: 0.4456 - val_accuracy: 0.7297\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2682 - accuracy: 0.75 - 0s 4ms/step - loss: 0.2892 - accuracy: 0.8273 - val_loss: 0.6349 - val_accuracy: 0.7297\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2866 - accuracy: 0.87 - 0s 4ms/step - loss: 0.2702 - accuracy: 0.8864 - val_loss: 0.7047 - val_accuracy: 0.7658\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2926 - accuracy: 0.84 - 0s 5ms/step - loss: 0.2298 - accuracy: 0.9068 - val_loss: 0.8795 - val_accuracy: 0.7658\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1876 - accuracy: 0.90 - 0s 5ms/step - loss: 0.2218 - accuracy: 0.9068 - val_loss: 0.7225 - val_accuracy: 0.7658\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1628 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1938 - accuracy: 0.9273 - val_loss: 0.9201 - val_accuracy: 0.7568\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1361 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1844 - accuracy: 0.9364 - val_loss: 0.7023 - val_accuracy: 0.7838\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2184 - accuracy: 0.89 - 0s 5ms/step - loss: 0.1575 - accuracy: 0.9477 - val_loss: 0.9602 - val_accuracy: 0.8198\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1576 - accuracy: 0.92 - 0s 4ms/step - loss: 0.1610 - accuracy: 0.9409 - val_loss: 0.8723 - val_accuracy: 0.7928\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1596 - accuracy: 0.93 - 0s 5ms/step - loss: 0.1472 - accuracy: 0.9500 - val_loss: 1.0418 - val_accuracy: 0.7838\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1900 - accuracy: 0.92 - 0s 5ms/step - loss: 0.1630 - accuracy: 0.9477 - val_loss: 1.2626 - val_accuracy: 0.7838\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0892 - accuracy: 0.96 - 0s 5ms/step - loss: 0.1485 - accuracy: 0.9455 - val_loss: 1.0934 - val_accuracy: 0.7748\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1087 - accuracy: 0.96 - 0s 5ms/step - loss: 0.1545 - accuracy: 0.9386 - val_loss: 1.0637 - val_accuracy: 0.8288\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1485 - accuracy: 0.93 - 0s 5ms/step - loss: 0.1370 - accuracy: 0.9545 - val_loss: 1.3544 - val_accuracy: 0.8468\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1436 - accuracy: 0.93 - 0s 5ms/step - loss: 0.1405 - accuracy: 0.9500 - val_loss: 1.2170 - val_accuracy: 0.8288\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1771 - accuracy: 0.92 - 0s 6ms/step - loss: 0.1416 - accuracy: 0.9477 - val_loss: 1.0826 - val_accuracy: 0.7928\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0750 - accuracy: 0.98 - 0s 5ms/step - loss: 0.1197 - accuracy: 0.9636 - val_loss: 0.9956 - val_accuracy: 0.8018\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1081 - accuracy: 0.96 - 0s 5ms/step - loss: 0.1309 - accuracy: 0.9568 - val_loss: 0.9466 - val_accuracy: 0.7748\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN165\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 166/169 [17:57<00:21,  7.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_166\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_664 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_665 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_666 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_667 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.5748 - accuracy: 0.67 - 0s 32ms/step - loss: 0.4051 - accuracy: 0.7537 - val_loss: 0.3587 - val_accuracy: 0.8119\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2361 - accuracy: 0.93 - 0s 6ms/step - loss: 0.2400 - accuracy: 0.9179 - val_loss: 0.4548 - val_accuracy: 0.8317\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1884 - accuracy: 0.93 - 0s 6ms/step - loss: 0.2064 - accuracy: 0.9303 - val_loss: 0.4821 - val_accuracy: 0.8317\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1765 - accuracy: 0.92 - 0s 6ms/step - loss: 0.1847 - accuracy: 0.9378 - val_loss: 0.5850 - val_accuracy: 0.8119\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1841 - accuracy: 0.89 - 0s 6ms/step - loss: 0.1673 - accuracy: 0.9453 - val_loss: 0.8023 - val_accuracy: 0.8317\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1893 - accuracy: 0.92 - 0s 6ms/step - loss: 0.1536 - accuracy: 0.9453 - val_loss: 0.9399 - val_accuracy: 0.8317\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1268 - accuracy: 0.96 - 0s 6ms/step - loss: 0.1448 - accuracy: 0.9453 - val_loss: 0.9874 - val_accuracy: 0.8317\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0802 - accuracy: 0.98 - 0s 5ms/step - loss: 0.1575 - accuracy: 0.9453 - val_loss: 0.9472 - val_accuracy: 0.8416\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0812 - accuracy: 0.98 - 0s 5ms/step - loss: 0.1345 - accuracy: 0.9552 - val_loss: 0.6883 - val_accuracy: 0.8119\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1608 - accuracy: 0.93 - 0s 5ms/step - loss: 0.1324 - accuracy: 0.9552 - val_loss: 0.8256 - val_accuracy: 0.8416\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2451 - accuracy: 0.89 - 0s 4ms/step - loss: 0.1297 - accuracy: 0.9478 - val_loss: 0.8557 - val_accuracy: 0.8515\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1852 - accuracy: 0.92 - 0s 5ms/step - loss: 0.1288 - accuracy: 0.9527 - val_loss: 0.6781 - val_accuracy: 0.8317\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1192 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1421 - accuracy: 0.9453 - val_loss: 0.9781 - val_accuracy: 0.8614\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2441 - accuracy: 0.89 - 0s 5ms/step - loss: 0.1339 - accuracy: 0.9478 - val_loss: 1.1763 - val_accuracy: 0.8515\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1558 - accuracy: 0.93 - 0s 5ms/step - loss: 0.1327 - accuracy: 0.9552 - val_loss: 0.6780 - val_accuracy: 0.8317\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0756 - accuracy: 0.98 - 0s 5ms/step - loss: 0.1365 - accuracy: 0.9502 - val_loss: 0.8340 - val_accuracy: 0.8218\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0928 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1412 - accuracy: 0.9453 - val_loss: 0.7380 - val_accuracy: 0.8416\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2413 - accuracy: 0.89 - 0s 4ms/step - loss: 0.1261 - accuracy: 0.9552 - val_loss: 0.6939 - val_accuracy: 0.8317\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1375 - accuracy: 0.95 - 0s 4ms/step - loss: 0.1166 - accuracy: 0.9602 - val_loss: 0.7807 - val_accuracy: 0.8218\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2214 - accuracy: 0.90 - 0s 5ms/step - loss: 0.1156 - accuracy: 0.9602 - val_loss: 0.8595 - val_accuracy: 0.8317\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN166\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 167/169 [18:04<00:14,  7.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_167\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_668 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_669 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_670 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_671 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.6882 - accuracy: 0.46 - 0s 19ms/step - loss: 0.5449 - accuracy: 0.6694 - val_loss: 0.4774 - val_accuracy: 0.7049\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.3644 - accuracy: 0.78 - 0s 4ms/step - loss: 0.3873 - accuracy: 0.7066 - val_loss: 0.4510 - val_accuracy: 0.7049\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.3504 - accuracy: 0.68 - 0s 4ms/step - loss: 0.3263 - accuracy: 0.8430 - val_loss: 0.5933 - val_accuracy: 0.8361\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.4479 - accuracy: 0.82 - 0s 4ms/step - loss: 0.3068 - accuracy: 0.8802 - val_loss: 0.5240 - val_accuracy: 0.8361\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2493 - accuracy: 0.93 - 0s 5ms/step - loss: 0.2624 - accuracy: 0.8988 - val_loss: 0.5193 - val_accuracy: 0.8443\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2384 - accuracy: 0.93 - 0s 5ms/step - loss: 0.2309 - accuracy: 0.9174 - val_loss: 0.5858 - val_accuracy: 0.8361\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2068 - accuracy: 0.90 - 0s 4ms/step - loss: 0.2075 - accuracy: 0.9070 - val_loss: 0.5829 - val_accuracy: 0.8525\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1327 - accuracy: 0.96 - 0s 5ms/step - loss: 0.1781 - accuracy: 0.9298 - val_loss: 0.7379 - val_accuracy: 0.8197\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1693 - accuracy: 0.93 - 0s 4ms/step - loss: 0.1714 - accuracy: 0.9483 - val_loss: 0.7197 - val_accuracy: 0.8361\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1344 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1524 - accuracy: 0.9463 - val_loss: 0.6656 - val_accuracy: 0.8197\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1248 - accuracy: 0.96 - 0s 5ms/step - loss: 0.1445 - accuracy: 0.9545 - val_loss: 0.6825 - val_accuracy: 0.8033\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0884 - accuracy: 0.98 - 0s 4ms/step - loss: 0.1566 - accuracy: 0.9380 - val_loss: 1.0078 - val_accuracy: 0.8197\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2103 - accuracy: 0.93 - 0s 5ms/step - loss: 0.1869 - accuracy: 0.9421 - val_loss: 0.6671 - val_accuracy: 0.8033\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2155 - accuracy: 0.92 - 0s 4ms/step - loss: 0.1834 - accuracy: 0.9277 - val_loss: 0.6973 - val_accuracy: 0.8525\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0805 - accuracy: 0.98 - 0s 5ms/step - loss: 0.1161 - accuracy: 0.9587 - val_loss: 0.7912 - val_accuracy: 0.8443\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0626 - accuracy: 0.98 - 0s 5ms/step - loss: 0.1057 - accuracy: 0.9690 - val_loss: 0.7447 - val_accuracy: 0.8443\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1541 - accuracy: 0.93 - 0s 6ms/step - loss: 0.0938 - accuracy: 0.9731 - val_loss: 1.0498 - val_accuracy: 0.8197\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0503 - accuracy: 1.00 - 0s 6ms/step - loss: 0.0793 - accuracy: 0.9752 - val_loss: 0.9792 - val_accuracy: 0.8279\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0694 - accuracy: 0.98 - 0s 5ms/step - loss: 0.0704 - accuracy: 0.9835 - val_loss: 1.1404 - val_accuracy: 0.8197\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0630 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0635 - accuracy: 0.9855 - val_loss: 1.2281 - val_accuracy: 0.8279\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN167\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress :  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 168/169 [18:12<00:07,  7.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_168\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_672 (Dense)            (None, 24)                840       \n",
      "_________________________________________________________________\n",
      "dense_673 (Dense)            (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_674 (Dense)            (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_675 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.6858 - accuracy: 0.62 - 0s 63ms/step - loss: 0.4941 - accuracy: 0.7578 - val_loss: 0.3647 - val_accuracy: 0.8393\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2268 - accuracy: 0.85 - 0s 4ms/step - loss: 0.2950 - accuracy: 0.8520 - val_loss: 0.4299 - val_accuracy: 0.8125\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1543 - accuracy: 0.92 - 0s 5ms/step - loss: 0.2078 - accuracy: 0.8991 - val_loss: 0.4623 - val_accuracy: 0.8125\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2148 - accuracy: 0.90 - 0s 5ms/step - loss: 0.1618 - accuracy: 0.9260 - val_loss: 0.5932 - val_accuracy: 0.8125\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0427 - accuracy: 1.00 - 0s 5ms/step - loss: 0.1206 - accuracy: 0.9507 - val_loss: 0.7676 - val_accuracy: 0.8214\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1220 - accuracy: 0.93 - 0s 5ms/step - loss: 0.0844 - accuracy: 0.9641 - val_loss: 0.9010 - val_accuracy: 0.8214\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0847 - accuracy: 0.93 - 0s 5ms/step - loss: 0.0650 - accuracy: 0.9686 - val_loss: 1.1894 - val_accuracy: 0.8304\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0355 - accuracy: 0.98 - 0s 5ms/step - loss: 0.0546 - accuracy: 0.9843 - val_loss: 1.3524 - val_accuracy: 0.8036\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0137 - accuracy: 1.00 - 0s 5ms/step - loss: 0.0404 - accuracy: 0.9776 - val_loss: 1.3698 - val_accuracy: 0.8214\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0319 - accuracy: 0.96 - 0s 5ms/step - loss: 0.0393 - accuracy: 0.9753 - val_loss: 1.5552 - val_accuracy: 0.7857\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0269 - accuracy: 1.00 - 0s 5ms/step - loss: 0.1097 - accuracy: 0.9731 - val_loss: 1.4616 - val_accuracy: 0.8125\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0238 - accuracy: 1.00 - 0s 5ms/step - loss: 0.1145 - accuracy: 0.9664 - val_loss: 1.4177 - val_accuracy: 0.8036\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1465 - accuracy: 0.93 - 0s 4ms/step - loss: 0.0916 - accuracy: 0.9574 - val_loss: 1.0226 - val_accuracy: 0.8125\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0566 - accuracy: 0.95 - 0s 4ms/step - loss: 0.0708 - accuracy: 0.9686 - val_loss: 1.0730 - val_accuracy: 0.8214\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0568 - accuracy: 0.96 - 0s 4ms/step - loss: 0.0420 - accuracy: 0.9821 - val_loss: 1.2598 - val_accuracy: 0.8393\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0101 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0185 - accuracy: 0.9933 - val_loss: 1.5664 - val_accuracy: 0.8482\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0074 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0098 - accuracy: 0.9955 - val_loss: 1.8918 - val_accuracy: 0.8482\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 3.0830e-04 - accuracy: 1.00 - 0s 5ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 2.1603 - val_accuracy: 0.8393\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 6.2056e-04 - accuracy: 1.00 - 0s 5ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.3411 - val_accuracy: 0.8304\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 8.1043e-04 - accuracy: 1.00 - 0s 5ms/step - loss: 7.8723e-04 - accuracy: 1.0000 - val_loss: 2.4691 - val_accuracy: 0.8304\n",
      "INFO:tensorflow:Assets written to: saved_models_binary/ANN/ANN168\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 169/169 [18:20<00:00,  6.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {'Precision Score ': 0.7836990595611285, 'Recall Score ': 0.7457013574660634, 'F1 Score ': 0.7625968992248062}, 1: {'Precision Score ': 0.6908496732026144, 'Recall Score ': 0.7005494505494505, 'F1 Score ': 0.6954629164573916}, 2: {'Precision Score ': 0.7159090909090908, 'Recall Score ': 0.7505494505494505, 'F1 Score ': 0.7308278313864905}, 3: {'Precision Score ': 0.844017094017094, 'Recall Score ': 0.836038961038961, 'F1 Score ': 0.839882697947214}, 4: {'Precision Score ': 0.7495697074010327, 'Recall Score ': 0.7810077519379846, 'F1 Score ': 0.7633136094674555}, 5: {'Precision Score ': 0.8527443105756358, 'Recall Score ': 0.7565725413826679, 'F1 Score ': 0.7934904601571269}, 6: {'Precision Score ': 0.7684108527131783, 'Recall Score ': 0.78944618599791, 'F1 Score ': 0.778336265393315}, 7: {'Precision Score ': 0.7857142857142857, 'Recall Score ': 0.9488636363636364, 'F1 Score ': 0.8366902558519325}, 8: {'Precision Score ': 0.7436090225563909, 'Recall Score ': 0.65, 'F1 Score ': 0.680796586059744}, 9: {'Precision Score ': 0.6869701026327533, 'Recall Score ': 0.6918498168498168, 'F1 Score ': 0.6893006439950288}, 10: {'Precision Score ': 0.8477124183006536, 'Recall Score ': 0.7375, 'F1 Score ': 0.7770750988142292}, 11: {'Precision Score ': 0.8540391676866586, 'Recall Score ': 0.8168127053669222, 'F1 Score ': 0.8333092798383605}, 12: {'Precision Score ': 0.8487394957983193, 'Recall Score ': 0.759375, 'F1 Score ': 0.7932263814616756}, 13: {'Precision Score ': 0.7767045454545455, 'Recall Score ': 0.8539244186046512, 'F1 Score ': 0.8059606848446418}, 14: {'Precision Score ': 0.7940259740259741, 'Recall Score ': 0.8451219512195123, 'F1 Score ': 0.8146750524109014}, 15: {'Precision Score ': 0.8998899889988998, 'Recall Score ': 0.7299177735610374, 'F1 Score ': 0.781919111816019}, 16: {'Precision Score ': 0.7964352720450281, 'Recall Score ': 0.8340380549682875, 'F1 Score ': 0.8125}, 17: {'Precision Score ': 0.7666666666666666, 'Recall Score ': 0.7936329588014981, 'F1 Score ': 0.7777678968430413}, 18: {'Precision Score ': 0.8298245614035087, 'Recall Score ': 0.783816425120773, 'F1 Score ': 0.803921568627451}, 19: {'Precision Score ': 0.7353731343283583, 'Recall Score ': 0.7530487804878049, 'F1 Score ': 0.7392607392607393}, 20: {'Precision Score ': 0.763157894736842, 'Recall Score ': 0.8166666666666667, 'F1 Score ': 0.7850678733031674}, 21: {'Precision Score ': 0.4292929292929293, 'Recall Score ': 0.5, 'F1 Score ': 0.46195652173913043}, 22: {'Precision Score ': 0.8047619047619048, 'Recall Score ': 0.8508771929824561, 'F1 Score ': 0.8224251648909184}, 23: {'Precision Score ': 0.6802884615384616, 'Recall Score ': 0.7136752136752136, 'F1 Score ': 0.6942094990240729}, 24: {'Precision Score ': 0.7349624060150376, 'Recall Score ': 0.7976190476190477, 'F1 Score ': 0.7562500000000001}, 25: {'Precision Score ': 0.8286660644384222, 'Recall Score ': 0.8371949335804757, 'F1 Score ': 0.8326219512195121}, 26: {'Precision Score ': 0.7071251035625518, 'Recall Score ': 0.7741228070175439, 'F1 Score ': 0.7316443818906873}, 27: {'Precision Score ': 0.5959224598930482, 'Recall Score ': 0.6126373626373627, 'F1 Score ': 0.6026311047035502}, 28: {'Precision Score ': 0.8310917721518987, 'Recall Score ': 0.8925891181988743, 'F1 Score ': 0.8575712143928036}, 29: {'Precision Score ': 0.6808510638297872, 'Recall Score ': 0.6234119782214156, 'F1 Score ': 0.6410621992514702}, 30: {'Precision Score ': 0.7400438072481084, 'Recall Score ': 0.7517752715121135, 'F1 Score ': 0.7447447447447446}, 31: {'Precision Score ': 0.69375, 'Recall Score ': 0.69375, 'F1 Score ': 0.69375}, 32: {'Precision Score ': 0.7884615384615384, 'Recall Score ': 0.7884615384615384, 'F1 Score ': 0.7884615384615384}, 33: {'Precision Score ': 0.8158914728682171, 'Recall Score ': 0.8158914728682171, 'F1 Score ': 0.8158914728682171}, 34: {'Precision Score ': 0.8295121951219512, 'Recall Score ': 0.8496376811594203, 'F1 Score ': 0.838855421686747}, 35: {'Precision Score ': 0.7232142857142857, 'Recall Score ': 0.6743817374762207, 'F1 Score ': 0.6927166400850611}, 36: {'Precision Score ': 0.8626543209876543, 'Recall Score ': 0.9114145658263305, 'F1 Score ': 0.884193284193284}, 37: {'Precision Score ': 0.7464131994261118, 'Recall Score ': 0.8290229885057472, 'F1 Score ': 0.7778004488879822}, 38: {'Precision Score ': 0.8619103773584906, 'Recall Score ': 0.8697590361445783, 'F1 Score ': 0.8653284888915361}, 39: {'Precision Score ': 0.7175368139223561, 'Recall Score ': 0.6406926406926406, 'F1 Score ': 0.6645833333333333}, 40: {'Precision Score ': 0.8521594684385382, 'Recall Score ': 0.8440162271805274, 'F1 Score ': 0.8479532163742689}, 41: {'Precision Score ': 0.7697470933716888, 'Recall Score ': 0.7684599785279733, 'F1 Score ': 0.7690100430416069}, 42: {'Precision Score ': 0.6681004213483146, 'Recall Score ': 0.680967680967681, 'F1 Score ': 0.6708622914450004}, 43: {'Precision Score ': 0.8014950166112957, 'Recall Score ': 0.8378629932985853, 'F1 Score ': 0.8128649873616316}, 44: {'Precision Score ': 0.7761071623838163, 'Recall Score ': 0.771505376344086, 'F1 Score ': 0.7734724292101341}, 45: {'Precision Score ': 0.9001623376623377, 'Recall Score ': 0.8908045977011494, 'F1 Score ': 0.8953383458646617}, 46: {'Precision Score ': 0.7951345235101835, 'Recall Score ': 0.7930711610486891, 'F1 Score ': 0.7928823842136535}, 47: {'Precision Score ': 0.7613636363636364, 'Recall Score ': 0.7154108131119625, 'F1 Score ': 0.7319874695440307}, 48: {'Precision Score ': 0.7536273115220484, 'Recall Score ': 0.7389439828464219, 'F1 Score ': 0.7452440033085195}, 49: {'Precision Score ': 0.8204588014981273, 'Recall Score ': 0.8306763285024155, 'F1 Score ': 0.8253892784975634}, 50: {'Precision Score ': 0.7452873563218391, 'Recall Score ': 0.7216452014956377, 'F1 Score ': 0.7315904139433551}, 51: {'Precision Score ': 0.7502083333333334, 'Recall Score ': 0.7851377018043684, 'F1 Score ': 0.7634836427939875}, 52: {'Precision Score ': 0.816557734204793, 'Recall Score ': 0.8340229885057471, 'F1 Score ': 0.8246869409660108}, 53: {'Precision Score ': 0.7853535353535352, 'Recall Score ': 0.8009988901220866, 'F1 Score ': 0.7857945726061124}, 54: {'Precision Score ': 0.7257142857142858, 'Recall Score ': 0.7564935064935066, 'F1 Score ': 0.7350943396226415}, 55: {'Precision Score ': 0.7927002126151665, 'Recall Score ': 0.7927002126151665, 'F1 Score ': 0.7927002126151665}, 56: {'Precision Score ': 0.8138888888888889, 'Recall Score ': 0.7586996336996337, 'F1 Score ': 0.7801099450274862}, 57: {'Precision Score ': 0.7324561403508771, 'Recall Score ': 0.7634358496427462, 'F1 Score ': 0.7404547094911584}, 58: {'Precision Score ': 0.780570142535634, 'Recall Score ': 0.780570142535634, 'F1 Score ': 0.780570142535634}, 59: {'Precision Score ': 0.8227513227513228, 'Recall Score ': 0.814974182444062, 'F1 Score ': 0.818726183995645}, 60: {'Precision Score ': 0.7400408580183861, 'Recall Score ': 0.731117230527144, 'F1 Score ': 0.7336932073774178}, 61: {'Precision Score ': 0.7168284789644013, 'Recall Score ': 0.6840659340659341, 'F1 Score ': 0.6929307805596465}, 62: {'Precision Score ': 0.8191516064257028, 'Recall Score ': 0.8191516064257028, 'F1 Score ': 0.8191516064257027}, 63: {'Precision Score ': 0.7841215388385199, 'Recall Score ': 0.7972314791079211, 'F1 Score ': 0.7887500000000001}, 64: {'Precision Score ': 0.3739130434782609, 'Recall Score ': 0.5, 'F1 Score ': 0.42786069651741293}, 65: {'Precision Score ': 0.7941520467836257, 'Recall Score ': 0.7941520467836257, 'F1 Score ': 0.7941520467836258}, 66: {'Precision Score ': 0.8701298701298701, 'Recall Score ': 0.8701298701298701, 'F1 Score ': 0.8701298701298701}, 67: {'Precision Score ': 0.78159757330637, 'Recall Score ': 0.7677884615384616, 'F1 Score ': 0.7728055077452668}, 68: {'Precision Score ': 0.7355769230769231, 'Recall Score ': 0.7321428571428572, 'F1 Score ': 0.72497582205029}, 69: {'Precision Score ': 0.7365015618027666, 'Recall Score ': 0.7208333333333333, 'F1 Score ': 0.7276934667958239}, 70: {'Precision Score ': 0.781012658227848, 'Recall Score ': 0.8384146341463414, 'F1 Score ': 0.805383022774327}, 71: {'Precision Score ': 0.9057971014492754, 'Recall Score ': 0.9057971014492754, 'F1 Score ': 0.9057971014492754}, 72: {'Precision Score ': 0.9409883720930232, 'Recall Score ': 0.9512195121951219, 'F1 Score ': 0.9457671957671958}, 73: {'Precision Score ': 0.8665430954587581, 'Recall Score ': 0.8665430954587581, 'F1 Score ': 0.8665430954587581}, 74: {'Precision Score ': 0.8299689440993789, 'Recall Score ': 0.88127990430622, 'F1 Score ': 0.8518826135105204}, 75: {'Precision Score ': 0.7887640449438202, 'Recall Score ': 0.8768328445747801, 'F1 Score ': 0.8241758241758241}, 76: {'Precision Score ': 0.7267706302794021, 'Recall Score ': 0.742361111111111, 'F1 Score ': 0.7309941520467836}, 77: {'Precision Score ': 0.7837789661319073, 'Recall Score ': 0.7787114845938375, 'F1 Score ': 0.7811534045747595}, 78: {'Precision Score ': 0.773051948051948, 'Recall Score ': 0.7980155917788803, 'F1 Score ': 0.7826013513513513}, 79: {'Precision Score ': 0.9162222222222223, 'Recall Score ': 0.8972428419936374, 'F1 Score ': 0.9040584415584414}, 80: {'Precision Score ': 0.8023041474654378, 'Recall Score ': 0.8023041474654378, 'F1 Score ': 0.8023041474654378}, 81: {'Precision Score ': 0.782051282051282, 'Recall Score ': 0.8040396881644224, 'F1 Score ': 0.790946992257296}, 82: {'Precision Score ': 0.9034996534996536, 'Recall Score ': 0.9410984848484849, 'F1 Score ': 0.9184704184704184}, 83: {'Precision Score ': 0.834013605442177, 'Recall Score ': 0.8607111372318543, 'F1 Score ': 0.8430379746835444}, 84: {'Precision Score ': 0.8190070921985815, 'Recall Score ': 0.8310273770974389, 'F1 Score ': 0.823953823953824}, 85: {'Precision Score ': 0.9060497308382467, 'Recall Score ': 0.9099378881987578, 'F1 Score ': 0.9079260833172365}, 86: {'Precision Score ': 0.8576615831517792, 'Recall Score ': 0.8576615831517792, 'F1 Score ': 0.8576615831517793}, 87: {'Precision Score ': 0.8061336254107339, 'Recall Score ': 0.8925561797752809, 'F1 Score ': 0.8393512851897185}, 88: {'Precision Score ': 0.8011363636363636, 'Recall Score ': 0.8687539531941808, 'F1 Score ': 0.8285876186428673}, 89: {'Precision Score ': 0.8902777777777777, 'Recall Score ': 0.9265654648956356, 'F1 Score ': 0.9055630936227952}, 90: {'Precision Score ': 0.8378048780487805, 'Recall Score ': 0.9026162790697674, 'F1 Score ': 0.8650793650793651}, 91: {'Precision Score ': 0.8073417721518987, 'Recall Score ': 0.8921188630490956, 'F1 Score ': 0.8387596899224805}, 92: {'Precision Score ': 0.8620689655172413, 'Recall Score ': 0.956043956043956, 'F1 Score ': 0.8970114942528736}, 93: {'Precision Score ': 0.8929564411492122, 'Recall Score ': 0.83125, 'F1 Score ': 0.8578379521895494}, 94: {'Precision Score ': 0.7967479674796748, 'Recall Score ': 0.8160173160173161, 'F1 Score ': 0.8056574122577265}, 95: {'Precision Score ': 0.8134146341463415, 'Recall Score ': 0.8134146341463415, 'F1 Score ': 0.8134146341463415}, 96: {'Precision Score ': 0.7987711213517665, 'Recall Score ': 0.8929292929292929, 'F1 Score ': 0.8350694444444444}, 97: {'Precision Score ': 0.9054355919583024, 'Recall Score ': 0.9481481481481482, 'F1 Score ': 0.9249999999999999}, 98: {'Precision Score ': 0.7715909090909091, 'Recall Score ': 0.7497387669801463, 'F1 Score ': 0.76}, 99: {'Precision Score ': 0.8936708860759495, 'Recall Score ': 0.9461979913916786, 'F1 Score ': 0.9169044821218735}, 100: {'Precision Score ': 0.42201834862385323, 'Recall Score ': 0.5, 'F1 Score ': 0.4577114427860697}, 101: {'Precision Score ': 0.9583333333333333, 'Recall Score ': 0.9945054945054945, 'F1 Score ': 0.9754984386259908}, 102: {'Precision Score ': 0.9004010695187166, 'Recall Score ': 0.9206460674157304, 'F1 Score ': 0.9101181304571135}, 103: {'Precision Score ': 0.8152896486229819, 'Recall Score ': 0.7964285714285715, 'F1 Score ': 0.805383022774327}, 104: {'Precision Score ': 0.7818220519369945, 'Recall Score ': 0.7865800865800866, 'F1 Score ': 0.7838026280504158}, 105: {'Precision Score ': 0.8182989690721649, 'Recall Score ': 0.760989010989011, 'F1 Score ': 0.7835337650323775}, 106: {'Precision Score ': 0.8093434343434344, 'Recall Score ': 0.7177777777777778, 'F1 Score ': 0.7477093818557233}, 107: {'Precision Score ': 0.775994575045208, 'Recall Score ': 0.769893899204244, 'F1 Score ': 0.772823779193206}, 108: {'Precision Score ': 0.6993670886075949, 'Recall Score ': 0.7358288770053476, 'F1 Score ': 0.7129268292682926}, 109: {'Precision Score ': 0.7282489989078995, 'Recall Score ': 0.767948717948718, 'F1 Score ': 0.7377367654201069}, 110: {'Precision Score ': 0.7288961038961039, 'Recall Score ': 0.7210031347962382, 'F1 Score ': 0.7247840531561461}, 111: {'Precision Score ': 0.8142307692307692, 'Recall Score ': 0.7209302325581395, 'F1 Score ': 0.7404024767801858}, 112: {'Precision Score ': 0.704139137193937, 'Recall Score ': 0.704139137193937, 'F1 Score ': 0.704139137193937}, 113: {'Precision Score ': 0.6841467635860159, 'Recall Score ': 0.6414893617021277, 'F1 Score ': 0.6517412935323383}, 114: {'Precision Score ': 0.8000693000693001, 'Recall Score ': 0.8144517066085692, 'F1 Score ': 0.8064487554256357}, 115: {'Precision Score ': 0.7241497767090348, 'Recall Score ': 0.7598566308243728, 'F1 Score ': 0.7339181286549707}, 116: {'Precision Score ': 0.7522347454333462, 'Recall Score ': 0.7695182724252492, 'F1 Score ': 0.7599037207902918}, 117: {'Precision Score ': 0.5976851851851852, 'Recall Score ': 0.6059236947791165, 'F1 Score ': 0.6009864068326718}, 118: {'Precision Score ': 0.692902711323764, 'Recall Score ': 0.68682421995675, 'F1 Score ': 0.6859394506866416}, 119: {'Precision Score ': 0.6729166666666666, 'Recall Score ': 0.6976190476190476, 'F1 Score ': 0.6829268292682926}, 120: {'Precision Score ': 0.7006172839506173, 'Recall Score ': 0.7175368139223561, 'F1 Score ': 0.7082798459563543}, 121: {'Precision Score ': 0.6553578049684835, 'Recall Score ': 0.6518115942028986, 'F1 Score ': 0.6535043518094366}, 122: {'Precision Score ': 0.6466867469879518, 'Recall Score ': 0.6366442199775533, 'F1 Score ': 0.6411149825783972}, 123: {'Precision Score ': 0.7126174496644295, 'Recall Score ': 0.70625, 'F1 Score ': 0.7089948254981835}, 124: {'Precision Score ': 0.7490636704119851, 'Recall Score ': 0.7423605270535464, 'F1 Score ': 0.7454545454545454}, 125: {'Precision Score ': 0.7914781297134239, 'Recall Score ': 0.7906379245519488, 'F1 Score ': 0.7910326001694331}, 126: {'Precision Score ': 0.8038095238095238, 'Recall Score ': 0.8186459489456159, 'F1 Score ': 0.8066810344827586}, 127: {'Precision Score ': 0.7773809523809524, 'Recall Score ': 0.8045751633986928, 'F1 Score ': 0.7881329605467537}, 128: {'Precision Score ': 0.7979688850475367, 'Recall Score ': 0.7647849462365591, 'F1 Score ': 0.7784200385356455}, 129: {'Precision Score ': 0.8484848484848485, 'Recall Score ': 0.8301717508331197, 'F1 Score ': 0.8377028714107365}, 130: {'Precision Score ': 0.6988970588235295, 'Recall Score ': 0.6988970588235295, 'F1 Score ': 0.6988970588235295}, 131: {'Precision Score ': 0.8301347488770927, 'Recall Score ': 0.8377192982456141, 'F1 Score ': 0.8328091972985512}, 132: {'Precision Score ': 0.7182923459519204, 'Recall Score ': 0.7146739130434783, 'F1 Score ': 0.7163207999452093}, 133: {'Precision Score ': 0.7618421052631579, 'Recall Score ': 0.7639669163545568, 'F1 Score ': 0.762426219322771}, 134: {'Precision Score ': 0.7659090909090909, 'Recall Score ': 0.8027950310559007, 'F1 Score ': 0.7816425120772947}, 135: {'Precision Score ': 0.7058662280701754, 'Recall Score ': 0.6902228976697062, 'F1 Score ': 0.6973684210526316}, 136: {'Precision Score ': 0.8290529695024077, 'Recall Score ': 0.8106060606060606, 'F1 Score ': 0.8194038573933372}, 137: {'Precision Score ': 0.9260710553814002, 'Recall Score ': 0.9581460674157303, 'F1 Score ': 0.9410173160173161}, 138: {'Precision Score ': 0.7232537577365163, 'Recall Score ': 0.6980392156862745, 'F1 Score ': 0.7093023255813954}, 139: {'Precision Score ': 0.7386968085106382, 'Recall Score ': 0.7270714737507906, 'F1 Score ': 0.732620320855615}, 140: {'Precision Score ': 0.8497316636851521, 'Recall Score ': 0.7944277108433735, 'F1 Score ': 0.8182003672719853}, 141: {'Precision Score ': 0.6583333333333333, 'Recall Score ': 0.7199074074074074, 'F1 Score ': 0.6752749880439981}, 142: {'Precision Score ': 0.8392461197339246, 'Recall Score ': 0.8768472906403941, 'F1 Score ': 0.8549810844892813}, 143: {'Precision Score ': 0.7906162464985995, 'Recall Score ': 0.8077493511308862, 'F1 Score ': 0.7982905982905983}, 144: {'Precision Score ': 0.6698412698412698, 'Recall Score ': 0.6698412698412698, 'F1 Score ': 0.6698412698412698}, 145: {'Precision Score ': 0.6480263157894737, 'Recall Score ': 0.6875, 'F1 Score ': 0.663003663003663}, 146: {'Precision Score ': 0.42934782608695654, 'Recall Score ': 0.5, 'F1 Score ': 0.4619883040935673}, 147: {'Precision Score ': 0.7746835443037974, 'Recall Score ': 0.809116809116809, 'F1 Score ': 0.7901785714285715}, 148: {'Precision Score ': 0.8992647058823529, 'Recall Score ': 0.9189814814814814, 'F1 Score ': 0.9087144739318652}, 149: {'Precision Score ': 0.6533333333333333, 'Recall Score ': 0.6723276723276723, 'F1 Score ': 0.6616541353383458}, 150: {'Precision Score ': 0.7122701331642358, 'Recall Score ': 0.7122701331642358, 'F1 Score ': 0.7122701331642359}, 151: {'Precision Score ': 0.9067725752508361, 'Recall Score ': 0.8818681318681318, 'F1 Score ': 0.893746205221615}, 152: {'Precision Score ': 0.6918604651162791, 'Recall Score ': 0.7045454545454546, 'F1 Score ': 0.6976511744127936}, 153: {'Precision Score ': 0.7625, 'Recall Score ': 0.8713527851458887, 'F1 Score ': 0.8003992015968064}, 154: {'Precision Score ': 0.7051948051948052, 'Recall Score ': 0.7473166368515205, 'F1 Score ': 0.7183948506486975}, 155: {'Precision Score ': 0.7966604244694132, 'Recall Score ': 0.807207498383969, 'F1 Score ': 0.8015873015873016}, 156: {'Precision Score ': 0.8573099415204679, 'Recall Score ': 0.7582417582417582, 'F1 Score ': 0.7966764418377321}, 157: {'Precision Score ': 0.8188590889740315, 'Recall Score ': 0.8262195121951219, 'F1 Score ': 0.8224087826929287}, 158: {'Precision Score ': 0.7818815331010454, 'Recall Score ': 0.7866761162296244, 'F1 Score ': 0.7841897233201582}, 159: {'Precision Score ': 0.7783625730994153, 'Recall Score ': 0.7704545454545455, 'F1 Score ': 0.7727926373310323}, 160: {'Precision Score ': 0.7919655667144907, 'Recall Score ': 0.7919655667144907, 'F1 Score ': 0.7919655667144907}, 161: {'Precision Score ': 0.8702380952380953, 'Recall Score ': 0.8702380952380953, 'F1 Score ': 0.8702380952380953}, 162: {'Precision Score ': 0.83679012345679, 'Recall Score ': 0.8278846153846153, 'F1 Score ': 0.8321763488003897}, 163: {'Precision Score ': 0.8357487922705313, 'Recall Score ': 0.7920168067226891, 'F1 Score ': 0.8100840336134454}, 164: {'Precision Score ': 0.8788888888888888, 'Recall Score ': 0.8647058823529412, 'F1 Score ': 0.8704761904761905}, 165: {'Precision Score ': 0.722972972972973, 'Recall Score ': 0.7512345679012346, 'F1 Score ': 0.7327876745305729}, 166: {'Precision Score ': 0.7686781609195402, 'Recall Score ': 0.8035714285714286, 'F1 Score ': 0.7825756616436621}, 167: {'Precision Score ': 0.7939244663382594, 'Recall Score ': 0.7890826873385013, 'F1 Score ': 0.791419034437841}, 168: {'Precision Score ': 0.7831541218637992, 'Recall Score ': 0.7890243902439025, 'F1 Score ': 0.7859800864930101}}\n"
     ]
    }
   ],
   "source": [
    "result_history = run_model(model_type = \"ANN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = open(\"binary_ANN_result\", \"wb\")\n",
    "# pickle.dump(result_history, f)\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"binary_ANN_result\", \"rb\")\n",
    "l = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = {k: v for k, v in sorted(l.items(), key=lambda item: item[1][\"F1 Score \"], reverse = True)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97  =  {'Precision Score ': 0.96875, 'Recall Score ': 0.9938271604938271, 'F1 Score ': 0.9807653776798237}\n",
      "101  =  {'Precision Score ': 0.9583333333333333, 'Recall Score ': 0.9945054945054945, 'F1 Score ': 0.9754984386259908}\n",
      "72  =  {'Precision Score ': 0.9633126934984519, 'Recall Score ': 0.9451219512195121, 'F1 Score ': 0.9533843704995073}\n",
      "7  =  {'Precision Score ': 0.9, 'Recall Score ': 0.9829545454545454, 'F1 Score ': 0.9357739242132306}\n",
      "89  =  {'Precision Score ': 0.9273457466228551, 'Recall Score ': 0.944212523719165, 'F1 Score ': 0.9352678571428572}\n",
      "137  =  {'Precision Score ': 0.9072295247724975, 'Recall Score ': 0.9525280898876405, 'F1 Score ': 0.9275747508305648}\n",
      "103  =  {'Precision Score ': 0.8998397435897436, 'Recall Score ': 0.9455357142857144, 'F1 Score ': 0.920675105485232}\n",
      "45  =  {'Precision Score ': 0.8938271604938272, 'Recall Score ': 0.9425287356321839, 'F1 Score ': 0.9136904761904763}\n",
      "161  =  {'Precision Score ': 0.9050046339202966, 'Recall Score ': 0.9161904761904762, 'F1 Score ': 0.9104144651872724}\n",
      "102  =  {'Precision Score ': 0.9004010695187166, 'Recall Score ': 0.9206460674157304, 'F1 Score ': 0.9101181304571135}\n",
      "100  =  {'Precision Score ': 0.943233082706767, 'Recall Score ': 0.8769181585677749, 'F1 Score ': 0.9059858547524582}\n",
      "85  =  {'Precision Score ': 0.8942495126705653, 'Recall Score ': 0.9187370600414079, 'F1 Score ': 0.9025000000000001}\n",
      "79  =  {'Precision Score ': 0.9027569191160696, 'Recall Score ': 0.8981442205726404, 'F1 Score ': 0.9002212566310346}\n",
      "99  =  {'Precision Score ': 0.8822368421052631, 'Recall Score ': 0.9167862266857962, 'F1 Score ': 0.8981481481481481}\n",
      "37  =  {'Precision Score ': 0.9331460674157304, 'Recall Score ': 0.8692528735632183, 'F1 Score ': 0.8977272727272727}\n",
      "71  =  {'Precision Score ': 0.8610486891385767, 'Recall Score ': 0.9365942028985508, 'F1 Score ': 0.8935952527112747}\n",
      "93  =  {'Precision Score ': 0.9705882352941176, 'Recall Score ': 0.84375, 'F1 Score ': 0.8922558922558923}\n",
      "88  =  {'Precision Score ': 0.8638888888888889, 'Recall Score ': 0.9142947501581278, 'F1 Score ': 0.8862797223452961}\n",
      "34  =  {'Precision Score ': 0.8995016611295681, 'Recall Score ': 0.8734472049689441, 'F1 Score ': 0.8855614973262032}\n",
      "66  =  {'Precision Score ': 0.8788699690402477, 'Recall Score ': 0.8852813852813852, 'F1 Score ': 0.8819627353428934}\n"
     ]
    }
   ],
   "source": [
    "# Top 20 playlists \n",
    "for key in list(l.keys())[:20]:\n",
    "    print(key,\" = \",  l[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_list = []\n",
    "for key in list(l.keys()):\n",
    "    f1_list.append(l[key]['F1 Score '])\n",
    "print(f1_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum(f1_list)/len(f1_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"binary_svc_linear_result\", \"rb\")\n",
    "l1 = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"binary_linear_regression_result\", \"rb\")\n",
    "l2 = pickle.load(f)\n",
    "f.close()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"binary_decision_tree_result\", \"rb\")\n",
    "l3 = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"binary_random_forest_result\", \"rb\")\n",
    "l4 = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"binary_xgb_result\", \"rb\")\n",
    "l5 = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"binary_KNN_13_result\", \"rb\")\n",
    "l6 = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"binary_ANN_result\", \"rb\")\n",
    "l7 = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = 0\n",
    "s2 = 0\n",
    "s3 = 0\n",
    "for i in range(169):\n",
    "    s1 += l1[i]['F1 Score ']\n",
    "    s2 += l1[i]['Precision Score ']\n",
    "    s3 += l1[i]['Recall Score ']\n",
    "s1 = s1/169\n",
    "s2 = s2/169\n",
    "s3 = s3/169\n",
    "print(\"SVC:\", s1, s2, s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = 0\n",
    "s2 = 0\n",
    "s3 = 0\n",
    "for i in range(169):\n",
    "    s1 += l2[i]['F1 Score ']\n",
    "    s2 += l2[i]['Precision Score ']\n",
    "    s3 += l2[i]['Recall Score ']\n",
    "s1 = s1/169\n",
    "s2 = s2/169\n",
    "s3 = s3/169\n",
    "print(\"LR:\", s1, s2, s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = 0\n",
    "s2 = 0\n",
    "s3 = 0\n",
    "for i in range(169):\n",
    "    s1 += l3[i]['F1 Score ']\n",
    "    s2 += l3[i]['Precision Score ']\n",
    "    s3 += l3[i]['Recall Score ']\n",
    "s1 = s1/169\n",
    "s2 = s2/169\n",
    "s3 = s3/169\n",
    "print(\"DT:\", s1, s2, s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = 0\n",
    "s2 = 0\n",
    "s3 = 0\n",
    "for i in range(169):\n",
    "    s1 += l4[i]['F1 Score ']\n",
    "    s2 += l4[i]['Precision Score ']\n",
    "    s3 += l4[i]['Recall Score ']\n",
    "s1 = s1/169\n",
    "s2 = s2/169\n",
    "s3 = s3/169\n",
    "print(\"RF:\", s1, s2, s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = 0\n",
    "s2 = 0\n",
    "s3 = 0\n",
    "for i in range(169):\n",
    "    s1 += l5[i]['F1 Score ']\n",
    "    s2 += l5[i]['Precision Score ']\n",
    "    s3 += l5[i]['Recall Score ']\n",
    "s1 = s1/169\n",
    "s2 = s2/169\n",
    "s3 = s3/169\n",
    "print(\"XGB:\", s1, s2, s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = 0\n",
    "s2 = 0\n",
    "s3 = 0\n",
    "for i in range(169):\n",
    "    s1 += l6[i]['F1 Score ']\n",
    "    s2 += l6[i]['Precision Score ']\n",
    "    s3 += l6[i]['Recall Score ']\n",
    "s1 = s1/169\n",
    "s2 = s2/169\n",
    "s3 = s3/169\n",
    "print(\"KNN_13:\", s1, s2, s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = 0\n",
    "s2 = 0\n",
    "s3 = 0\n",
    "for i in range(169):\n",
    "    s1 += l7[i]['F1 Score ']\n",
    "    s2 += l7[i]['Precision Score ']\n",
    "    s3 += l7[i]['Recall Score ']\n",
    "s1 = s1/169\n",
    "s2 = s2/169\n",
    "s3 = s3/169\n",
    "print(\"ANN:\", s1, s2, s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
