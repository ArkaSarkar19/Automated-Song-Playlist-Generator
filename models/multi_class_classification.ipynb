{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import recall_score\n",
    "from tqdm import tqdm\n",
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn import preprocessing\n",
    "from xgboost import plot_importance\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../Data_Scrape/Dataset/updated_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sp_song_id</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>...</th>\n",
       "      <th>lda_topic_11</th>\n",
       "      <th>lda_topic_12</th>\n",
       "      <th>lda_topic_13</th>\n",
       "      <th>lda_topic_14</th>\n",
       "      <th>lda_topic_15</th>\n",
       "      <th>lda_topic_16</th>\n",
       "      <th>lda_topic_17</th>\n",
       "      <th>lda_topic_18</th>\n",
       "      <th>lda_topic_19</th>\n",
       "      <th>Playlists</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6edQfeOlqbGteYixpJl3Sm</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.602</td>\n",
       "      <td>10</td>\n",
       "      <td>-8.311</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0290</td>\n",
       "      <td>0.489000</td>\n",
       "      <td>0.02440</td>\n",
       "      <td>0.3170</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.022993</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.122078</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.081108</td>\n",
       "      <td>0.386042</td>\n",
       "      <td>[165]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5Oe7wHPL4hdEXeF4AOayCi</td>\n",
       "      <td>0.322</td>\n",
       "      <td>0.990</td>\n",
       "      <td>8</td>\n",
       "      <td>-1.785</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1710</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.41700</td>\n",
       "      <td>0.0366</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.163142</td>\n",
       "      <td>0.022999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.144614</td>\n",
       "      <td>0.187207</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[79]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6i1uWZYWabNHq2wQnoca58</td>\n",
       "      <td>0.666</td>\n",
       "      <td>0.884</td>\n",
       "      <td>9</td>\n",
       "      <td>-5.243</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0429</td>\n",
       "      <td>0.506000</td>\n",
       "      <td>0.00612</td>\n",
       "      <td>0.0408</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.582131</td>\n",
       "      <td>[15]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4BzBtS6PBreni5hNPo2hos</td>\n",
       "      <td>0.609</td>\n",
       "      <td>0.578</td>\n",
       "      <td>9</td>\n",
       "      <td>-7.081</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0414</td>\n",
       "      <td>0.296000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.511716</td>\n",
       "      <td>0.084905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.115004</td>\n",
       "      <td>0.108140</td>\n",
       "      <td>[168]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0GvhHQbWSnGltjl0je61dI</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.514</td>\n",
       "      <td>4</td>\n",
       "      <td>-12.610</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0315</td>\n",
       "      <td>0.587000</td>\n",
       "      <td>0.02900</td>\n",
       "      <td>0.2200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.401954</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[30, 133]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               sp_song_id  danceability  energy  key  loudness  mode  \\\n",
       "0  6edQfeOlqbGteYixpJl3Sm         0.857   0.602   10    -8.311     1   \n",
       "1  5Oe7wHPL4hdEXeF4AOayCi         0.322   0.990    8    -1.785     1   \n",
       "2  6i1uWZYWabNHq2wQnoca58         0.666   0.884    9    -5.243     0   \n",
       "3  4BzBtS6PBreni5hNPo2hos         0.609   0.578    9    -7.081     1   \n",
       "4  0GvhHQbWSnGltjl0je61dI         0.699   0.514    4   -12.610     1   \n",
       "\n",
       "   speechiness  acousticness  instrumentalness  liveness  ...  lda_topic_11  \\\n",
       "0       0.0290      0.489000           0.02440    0.3170  ...           0.0   \n",
       "1       0.1710      0.000044           0.41700    0.0366  ...           0.0   \n",
       "2       0.0429      0.506000           0.00612    0.0408  ...           0.0   \n",
       "3       0.0414      0.296000           0.00000    0.1500  ...           0.0   \n",
       "4       0.0315      0.587000           0.02900    0.2200  ...           0.0   \n",
       "\n",
       "   lda_topic_12  lda_topic_13  lda_topic_14  lda_topic_15  lda_topic_16  \\\n",
       "0      0.022993      0.000000      0.122078           0.0      0.000000   \n",
       "1      0.000000      0.163142      0.022999           0.0      0.144614   \n",
       "2      0.000000      0.000000      0.000000           0.0      0.000000   \n",
       "3      0.000000      0.511716      0.084905           0.0      0.000000   \n",
       "4      0.000000      0.000000      0.401954           0.0      0.000000   \n",
       "\n",
       "   lda_topic_17  lda_topic_18  lda_topic_19  Playlists  \n",
       "0      0.000000      0.081108      0.386042      [165]  \n",
       "1      0.187207      0.000000      0.000000       [79]  \n",
       "2      0.000000      0.000000      0.582131       [15]  \n",
       "3      0.000000      0.115004      0.108140      [168]  \n",
       "4      0.000000      0.000000      0.000000  [30, 133]  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove songs which are in more than one playlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "data = np.array(df)\n",
    "for i in df.index:\n",
    "    l = eval(df[\"Playlists\"][i])\n",
    "    if len(l) > 1:\n",
    "        continue\n",
    "    data[i][-1] = str(l[0])\n",
    "    dataset.append(data[i])\n",
    "dataset = np.array(dataset)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11159\n",
      "6120\n"
     ]
    }
   ],
   "source": [
    "print(len(df))\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    }
   ],
   "source": [
    "counts = []\n",
    "for i in range(169):\n",
    "    counts.append(0)\n",
    "for i in range(len(dataset)):\n",
    "    counts[int(dataset[i][-1])] += 1\n",
    "c = 0\n",
    "playlists_to_keep = set()\n",
    "for i in range(len(counts)):\n",
    "    if counts[i] >= 100:\n",
    "        c += 1\n",
    "        playlists_to_keep.add(str(i))        \n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_dataset = []\n",
    "for c in dataset:\n",
    "    if str(c[-1]) in playlists_to_keep:\n",
    "        temp_dataset.append(c)\n",
    "dataset = temp_dataset\n",
    "dataset = np.array(dataset)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2249"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset[:, 1:-1]\n",
    "y = dataset[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(model_type = \"LR\", neighbours = 5):\n",
    "    playlists = []\n",
    "\n",
    "    np.random.seed(123)\n",
    "\n",
    "    X = dataset[:, 1:-1]\n",
    "    y = dataset[:, -1]\n",
    "    \n",
    "    s = set()\n",
    "    for c in y:\n",
    "        s.add(c)\n",
    "    \n",
    "    if model_type == 'ANN':\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        le.fit(y)\n",
    "        y = le.transform(y)\n",
    "        \n",
    "        enc = OneHotEncoder()\n",
    "        y = y.reshape(-1, 1)\n",
    "        enc.fit(y)\n",
    "        y = enc.transform(y).toarray()\n",
    "        \n",
    "    \n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10, stratify = y)\n",
    "\n",
    "    standardScalar = StandardScaler()\n",
    "    X_train = standardScalar.fit_transform(X_train)\n",
    "    X_test = standardScalar.transform(X_test)\n",
    "     \n",
    "    \n",
    "    if(model_type == \"LR\" ):\n",
    "        model = LogisticRegression()\n",
    "\n",
    "    elif(model_type == \"SVM\"):\n",
    "        model = SVC(kernel = 'linear')\n",
    "\n",
    "    elif (model_type == \"DT\"):\n",
    "        model = DecisionTreeClassifier(criterion = 'entropy', max_depth =  20)\n",
    "\n",
    "    elif (model_type == \"RF\"):\n",
    "        model = RandomForestClassifier(criterion = 'entropy')\n",
    "\n",
    "    elif(model_type == \"XGB\"):\n",
    "\n",
    "        param = {\n",
    "            \"learning_rate\" : 0.1,\n",
    "            \"n_estimators\" : 500,\n",
    "            \"max_depth\" : 20,\n",
    "            \"min_child_weight\" : 1,\n",
    "            \"gamma\" : 0.1,\n",
    "            \"subsample\": 0.9,\n",
    "            \"colsample_bytree\" : 0.9,\n",
    "            \"objective\" : 'binary:logistic',\n",
    "            \"nthread\" : 4,\n",
    "            \"scale_pos_weight\" :  1,\n",
    "            \"seed\" : 27\n",
    "        }\n",
    "\n",
    "        model = XGBClassifier(**param)\n",
    "\n",
    "    elif(model_type == \"KNN\"):\n",
    "        model = KNeighborsClassifier(n_neighbors=neighbours)\n",
    "\n",
    "    elif(model_type == \"ANN\"):\n",
    "        model = Sequential([Dense(units = 64, input_shape = (34, ), activation = 'relu'),\n",
    "        Dense(units = 32, activation = 'relu'),\n",
    "        Dense(units = 16, activation = 'relu'),       \n",
    "        Dense(units = len(s), activation = 'softmax')\n",
    "        ])\n",
    "        model.compile(optimizer = tf.keras.optimizers.Adam(lr = 0.05), loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "        model.summary()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#         xgb = XGBClassifier(**param)    \n",
    "\n",
    "    if model_type != 'ANN':\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "#         if model_type == 'XGB':\n",
    "#             plot_importance(model)\n",
    "#             plt.show()\n",
    "#         if model_type == 'SVM':\n",
    "#             f_importances(model.coef_, df.columns[1:-1])\n",
    "        if model_type == 'RF':\n",
    "            importances = model.feature_importances_\n",
    "            combined_list = []\n",
    "            features = list(df.columns[1:-1])\n",
    "            \n",
    "            s = 0\n",
    "            for i in range(len(importances)):\n",
    "                if \"lda\" in features[i]:\n",
    "                    s += importances[i]\n",
    "                    continue\n",
    "                combined_list.append((importances[i], features[i]))\n",
    "            combined_list.append((s, \"all topics combined\"))\n",
    "            combined_list.sort()\n",
    "            print(combined_list)\n",
    "            features = []\n",
    "            importances = []\n",
    "            for c in combined_list:\n",
    "                features.append(c[1])\n",
    "                importances.append(c[0])\n",
    "                \n",
    "            indices = np.argsort(importances)\n",
    "\n",
    "            plt.title('Feature Importances')\n",
    "            plt.barh(range(len(features)), importances, color='b', align='center')\n",
    "            plt.yticks(range(len(features)), features)\n",
    "            plt.xlabel('Relative Importance')\n",
    "            plt.show()\n",
    "\n",
    "    else:\n",
    "        model.fit(X_train, y_train, validation_data = (X_test, y_test), batch_size = 64, epochs = 100)\n",
    "        \n",
    "\n",
    "        y_pred = model.predict_classes(X_test)\n",
    "#         print(y_test)\n",
    "        temp = []\n",
    "        for c in y_test:\n",
    "            for i in range(len(c)):\n",
    "                if c[i] == 1:\n",
    "                    temp.append(i+1)\n",
    "        y_test = temp\n",
    "        y_test = np.array(y_test)\n",
    "    \n",
    "#     print(y_pred)\n",
    "#     print(y_test)\n",
    "\n",
    "    pres_score = precision_score(y_test, y_pred, average = \"macro\")\n",
    "    acc_score = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    \n",
    "    f1= f1_score(y_test, y_pred, average = \"macro\")\n",
    "    recall_Score = recall_score(y_test, y_pred, average = \"macro\")\n",
    "\n",
    "    result_history = {\"Precision Score \" : pres_score, \"Recall Score \" : recall_Score, \"F1 Score \" : f1, \"Accuracy Score \": acc_score}\n",
    "\n",
    "\n",
    "    print(result_history)\n",
    "    return result_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:23:03] WARNING: ../src/learner.cc:516: \n",
      "Parameters: { scale_pos_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "{'Precision Score ': 0.5926373839465681, 'Recall Score ': 0.5819345582431832, 'F1 Score ': 0.585059532938555, 'Accuracy Score ': 0.6022222222222222}\n"
     ]
    }
   ],
   "source": [
    "result_history = run_model(model_type = \"XGB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.007014089902247543, 'mode'), (0.01855788829851921, 'key'), (0.025308209412053605, 'liveness'), (0.028068341672251612, 'tempo'), (0.035752862209776304, 'duration_ms'), (0.04654799667442491, 'instrumentalness'), (0.05726222912868504, 'valence'), (0.0609829472084903, 'speechiness'), (0.06279872763674345, 'loudness'), (0.06668418186019734, 'popularity'), (0.0671916854341815, 'danceability'), (0.07268189011878806, 'energy'), (0.08980457367525346, 'acousticness'), (0.09871041883165428, 'release_date'), (0.2626339579367333, 'all topics combined')]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "RandomForestClassifier should be a binary classifier",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-8440d5ca3a8c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresult_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"RF\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-58-68a52b6392a9>\u001b[0m in \u001b[0;36mrun_model\u001b[0;34m(model_type, neighbours)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;31m#             plt.xlabel('Relative Importance')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;31m#             plt.show()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             \u001b[0mplot_roc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m             \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/metrics/_plot/roc_curve.py\u001b[0m in \u001b[0;36mplot_roc_curve\u001b[0;34m(estimator, X, y, sample_weight, drop_intermediate, response_method, name, ax, **kwargs)\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_error\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: RandomForestClassifier should be a binary classifier"
     ]
    }
   ],
   "source": [
    "result_history = run_model(model_type = \"RF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_history = run_model(model_type = \"KNN\", neighbours = 23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_history = run_model(model_type = \"LR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', 'duration_ms', 'release_date', 'popularity', 'lda_topic_0', 'lda_topic_1', 'lda_topic_2', 'lda_topic_3', 'lda_topic_4', 'lda_topic_5', 'lda_topic_6', 'lda_topic_7', 'lda_topic_8', 'lda_topic_9', 'lda_topic_10', 'lda_topic_11', 'lda_topic_12', 'lda_topic_13', 'lda_topic_14', 'lda_topic_15', 'lda_topic_16', 'lda_topic_17', 'lda_topic_18', 'lda_topic_19']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-efa5224026f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresult_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"SVM\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-21-6bd80298c0ec>\u001b[0m in \u001b[0;36mrun_model\u001b[0;34m(model_type, neighbours)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;31m#             plt.show()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmodel_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'SVM'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0mf_importances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-7b7d1b0b14bd>\u001b[0m in \u001b[0;36mf_importances\u001b[0;34m(coef, names)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mimp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoef\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mimp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbarh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malign\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'center'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "result_history = run_model(model_type = \"SVM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_history = run_model(model_type = \"DT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_history = run_model(model_type = \"ANN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = open(\"binary_svc_linear_result\", \"wb\")\n",
    "# pickle.dump(result_history, f)\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = open(\"binary_svc_linear_result\", \"rb\")\n",
    "# l = pickle.load(f)\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = {k: v for k, v in sorted(l.items(), key=lambda item: item[1][\"F1 Score \"], reverse = True)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 20 playlists \n",
    "for key in list(l.keys())[:20]:\n",
    "    print(key,\" = \",  l[key])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
