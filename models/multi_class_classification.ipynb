{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import recall_score\n",
    "from tqdm import tqdm\n",
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../Data_Scrape/Dataset/updated_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sp_song_id</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>...</th>\n",
       "      <th>lda_topic_11</th>\n",
       "      <th>lda_topic_12</th>\n",
       "      <th>lda_topic_13</th>\n",
       "      <th>lda_topic_14</th>\n",
       "      <th>lda_topic_15</th>\n",
       "      <th>lda_topic_16</th>\n",
       "      <th>lda_topic_17</th>\n",
       "      <th>lda_topic_18</th>\n",
       "      <th>lda_topic_19</th>\n",
       "      <th>Playlists</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6edQfeOlqbGteYixpJl3Sm</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.602</td>\n",
       "      <td>10</td>\n",
       "      <td>-8.311</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0290</td>\n",
       "      <td>0.489000</td>\n",
       "      <td>0.02440</td>\n",
       "      <td>0.3170</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.022993</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.122078</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.081108</td>\n",
       "      <td>0.386042</td>\n",
       "      <td>[165]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5Oe7wHPL4hdEXeF4AOayCi</td>\n",
       "      <td>0.322</td>\n",
       "      <td>0.990</td>\n",
       "      <td>8</td>\n",
       "      <td>-1.785</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1710</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.41700</td>\n",
       "      <td>0.0366</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.163142</td>\n",
       "      <td>0.022999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.144614</td>\n",
       "      <td>0.187207</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[79]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6i1uWZYWabNHq2wQnoca58</td>\n",
       "      <td>0.666</td>\n",
       "      <td>0.884</td>\n",
       "      <td>9</td>\n",
       "      <td>-5.243</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0429</td>\n",
       "      <td>0.506000</td>\n",
       "      <td>0.00612</td>\n",
       "      <td>0.0408</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.582131</td>\n",
       "      <td>[15]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4BzBtS6PBreni5hNPo2hos</td>\n",
       "      <td>0.609</td>\n",
       "      <td>0.578</td>\n",
       "      <td>9</td>\n",
       "      <td>-7.081</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0414</td>\n",
       "      <td>0.296000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.511716</td>\n",
       "      <td>0.084905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.115004</td>\n",
       "      <td>0.108140</td>\n",
       "      <td>[168]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0GvhHQbWSnGltjl0je61dI</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.514</td>\n",
       "      <td>4</td>\n",
       "      <td>-12.610</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0315</td>\n",
       "      <td>0.587000</td>\n",
       "      <td>0.02900</td>\n",
       "      <td>0.2200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.401954</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[30, 133]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               sp_song_id  danceability  energy  key  loudness  mode  \\\n",
       "0  6edQfeOlqbGteYixpJl3Sm         0.857   0.602   10    -8.311     1   \n",
       "1  5Oe7wHPL4hdEXeF4AOayCi         0.322   0.990    8    -1.785     1   \n",
       "2  6i1uWZYWabNHq2wQnoca58         0.666   0.884    9    -5.243     0   \n",
       "3  4BzBtS6PBreni5hNPo2hos         0.609   0.578    9    -7.081     1   \n",
       "4  0GvhHQbWSnGltjl0je61dI         0.699   0.514    4   -12.610     1   \n",
       "\n",
       "   speechiness  acousticness  instrumentalness  liveness  ...  lda_topic_11  \\\n",
       "0       0.0290      0.489000           0.02440    0.3170  ...           0.0   \n",
       "1       0.1710      0.000044           0.41700    0.0366  ...           0.0   \n",
       "2       0.0429      0.506000           0.00612    0.0408  ...           0.0   \n",
       "3       0.0414      0.296000           0.00000    0.1500  ...           0.0   \n",
       "4       0.0315      0.587000           0.02900    0.2200  ...           0.0   \n",
       "\n",
       "   lda_topic_12  lda_topic_13  lda_topic_14  lda_topic_15  lda_topic_16  \\\n",
       "0      0.022993      0.000000      0.122078           0.0      0.000000   \n",
       "1      0.000000      0.163142      0.022999           0.0      0.144614   \n",
       "2      0.000000      0.000000      0.000000           0.0      0.000000   \n",
       "3      0.000000      0.511716      0.084905           0.0      0.000000   \n",
       "4      0.000000      0.000000      0.401954           0.0      0.000000   \n",
       "\n",
       "   lda_topic_17  lda_topic_18  lda_topic_19  Playlists  \n",
       "0      0.000000      0.081108      0.386042      [165]  \n",
       "1      0.187207      0.000000      0.000000       [79]  \n",
       "2      0.000000      0.000000      0.582131       [15]  \n",
       "3      0.000000      0.115004      0.108140      [168]  \n",
       "4      0.000000      0.000000      0.000000  [30, 133]  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove songs which are in more than one playlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "data = np.array(df)\n",
    "for i in df.index:\n",
    "    l = eval(df[\"Playlists\"][i])\n",
    "    if len(l) > 1:\n",
    "        continue\n",
    "    data[i][-1] = str(l[0])\n",
    "    dataset.append(data[i])\n",
    "dataset = np.array(dataset)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11159\n",
      "6120\n"
     ]
    }
   ],
   "source": [
    "print(len(df))\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "counts = []\n",
    "for i in range(169):\n",
    "    counts.append(0)\n",
    "for i in range(len(dataset)):\n",
    "    counts[int(dataset[i][-1])] += 1\n",
    "c = 0\n",
    "playlists_to_keep = set()\n",
    "for i in range(len(counts)):\n",
    "    if counts[i] >= 100:\n",
    "        c += 1\n",
    "        playlists_to_keep.add(str(i))        \n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_dataset = []\n",
    "for c in dataset:\n",
    "    if str(c[-1]) in playlists_to_keep:\n",
    "        temp_dataset.append(c)\n",
    "dataset = temp_dataset\n",
    "dataset = np.array(dataset)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1912"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset[:, 1:-1]\n",
    "y = dataset[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(model_type = \"LR\", neighbours = 5):\n",
    "    playlists = []\n",
    "\n",
    "    np.random.seed(123)\n",
    "\n",
    "    X = dataset[:, 1:-1]\n",
    "    y = dataset[:, -1]\n",
    "    \n",
    "    s = set()\n",
    "    for c in y:\n",
    "        s.add(c)\n",
    "    \n",
    "    if model_type == 'ANN':\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        le.fit(y)\n",
    "        y = le.transform(y)\n",
    "        \n",
    "        enc = OneHotEncoder()\n",
    "        y = y.reshape(-1, 1)\n",
    "        enc.fit(y)\n",
    "        y = enc.transform(y).toarray()\n",
    "        \n",
    "    \n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10, stratify = y)\n",
    "\n",
    "    standardScalar = StandardScaler()\n",
    "    X_train = standardScalar.fit_transform(X_train)\n",
    "    X_test = standardScalar.transform(X_test)\n",
    "     \n",
    "    \n",
    "    if(model_type == \"LR\" ):\n",
    "        model = LogisticRegression()\n",
    "\n",
    "    elif(model_type == \"SVM\"):\n",
    "        model = SVC(kernel = 'linear')\n",
    "\n",
    "    elif (model_type == \"DT\"):\n",
    "        model = DecisionTreeClassifier(criterion = 'entropy', max_depth =  20)\n",
    "\n",
    "    elif (model_type == \"RF\"):\n",
    "        model = RandomForestClassifier(criterion = 'entropy')\n",
    "\n",
    "\n",
    "    elif(model_type == \"XGB\"):\n",
    "\n",
    "        param = {\n",
    "            \"learning_rate\" : 0.1,\n",
    "            \"n_estimators\" : 500,\n",
    "            \"max_depth\" : 20,\n",
    "            \"min_child_weight\" : 1,\n",
    "            \"gamma\" : 0.1,\n",
    "            \"subsample\": 0.9,\n",
    "            \"colsample_bytree\" : 0.9,\n",
    "            \"objective\" : 'binary:logistic',\n",
    "            \"nthread\" : 4,\n",
    "            \"scale_pos_weight\" :  1,\n",
    "            \"seed\" : 27\n",
    "        }\n",
    "\n",
    "        model = XGBClassifier(**param)\n",
    "\n",
    "    elif(model_type == \"KNN\"):\n",
    "        model = KNeighborsClassifier(n_neighbors=neighbours)\n",
    "\n",
    "    elif(model_type == \"ANN\"):\n",
    "        model = Sequential([Dense(units = 64, input_shape = (34, ), activation = 'relu'),\n",
    "        Dense(units = 32, activation = 'relu'),\n",
    "        Dense(units = 16, activation = 'relu'),       \n",
    "        Dense(units = len(s), activation = 'softmax')\n",
    "        ])\n",
    "        model.compile(optimizer = tf.keras.optimizers.Adam(lr = 0.05), loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "        model.summary()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#         xgb = XGBClassifier(**param)    \n",
    "\n",
    "    if model_type != 'ANN':\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "    else:\n",
    "        model.fit(X_train, y_train, validation_data = (X_test, y_test), batch_size = 64, epochs = 100)\n",
    "        y_pred = model.predict_classes(X_test)\n",
    "#         print(y_test)\n",
    "        temp = []\n",
    "        for c in y_test:\n",
    "            for i in range(len(c)):\n",
    "                if c[i] == 1:\n",
    "                    temp.append(i+1)\n",
    "        y_test = temp\n",
    "        y_test = np.array(y_test)\n",
    "    \n",
    "#     print(y_pred)\n",
    "#     print(y_test)\n",
    "\n",
    "    pres_score = precision_score(y_test, y_pred, average = \"macro\")\n",
    "    acc_score = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    \n",
    "    f1= f1_score(y_test, y_pred, average = \"macro\")\n",
    "    recall_Score = recall_score(y_test, y_pred, average = \"macro\")\n",
    "\n",
    "    result_history = {\"Precision Score \" : pres_score, \"Recall Score \" : recall_Score, \"F1 Score \" : f1, \"Accuracy Score \": acc_score}\n",
    "\n",
    "\n",
    "    print(result_history)\n",
    "    return result_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:22:46] WARNING: ../src/learner.cc:516: \n",
      "Parameters: { scale_pos_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Accuracy Score: 0.6109660574412533\n",
      "{'Precision Score ': 0.5883792495791792, 'Recall Score ': 0.5706449722541873, 'F1 Score ': 0.5776523654139553}\n"
     ]
    }
   ],
   "source": [
    "result_history = run_model(model_type = \"XGB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_history = run_model(model_type = \"RF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_history = run_model(model_type = \"KNN\", neighbours = 23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_history = run_model(model_type = \"LR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_history = run_model(model_type = \"SVM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_history = run_model(model_type = \"DT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_history = run_model(model_type = \"ANN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = open(\"binary_svc_linear_result\", \"wb\")\n",
    "# pickle.dump(result_history, f)\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = open(\"binary_svc_linear_result\", \"rb\")\n",
    "# l = pickle.load(f)\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = {k: v for k, v in sorted(l.items(), key=lambda item: item[1][\"F1 Score \"], reverse = True)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 20 playlists \n",
    "for key in list(l.keys())[:20]:\n",
    "    print(key,\" = \",  l[key])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
